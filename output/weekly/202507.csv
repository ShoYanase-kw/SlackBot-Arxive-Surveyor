id,guidislink,updated,updated_parsed,published,published_parsed,title,title_detail,summary,summary_detail,authors,author_detail,author,arxiv_comment,links,arxiv_primary_category,tags,pdf_url,affiliation,arxiv_url,journal_reference,doi,citation_author,citation_paper
http://arxiv.org/abs/2502.10620v1,True,2025-02-15T01:14:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=1, tm_min=14, tm_sec=23, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T01:14:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=1, tm_min=14, tm_sec=23, tm_wday=5, tm_yday=46, tm_isdst=0)","ProMRVL-CAD: Proactive Dialogue System with Multi-Round Vision-Language
  Interactions for Computer-Aided Diagnosis","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'ProMRVL-CAD: Proactive Dialogue System with Multi-Round Vision-Language\n  Interactions for Computer-Aided Diagnosis'}","Recent advancements in large language models (LLMs) have demonstrated
extraordinary comprehension capabilities with remarkable breakthroughs on
various vision-language tasks. However, the application of LLMs in generating
reliable medical diagnostic reports remains in the early stages. Currently,
medical LLMs typically feature a passive interaction model where doctors
respond to patient queries with little or no involvement in analyzing medical
images. In contrast, some ChatBots simply respond to predefined queries based
on visual inputs, lacking interactive dialogue or consideration of medical
history. As such, there is a gap between LLM-generated patient-ChatBot
interactions and those occurring in actual patient-doctor consultations. To
bridge this gap, we develop an LLM-based dialogue system, namely proactive
multi-round vision-language interactions for computer-aided diagnosis
(ProMRVL-CAD), to generate patient-friendly disease diagnostic reports. The
proposed ProMRVL-CAD system allows proactive dialogue to provide patients with
constant and reliable medical access via an integration of knowledge graph into
a recommendation system. Specifically, we devise two generators: a Proactive
Question Generator (Pro-Q Gen) to generate proactive questions that guide the
diagnostic procedure and a Multi-Vision Patient-Text Diagnostic Report
Generator (MVP-DR Gen) to produce high-quality diagnostic reports. Evaluating
two real-world publicly available datasets, MIMIC-CXR and IU-Xray, our model
has better quality in generating medical reports. We further demonstrate the
performance of ProMRVL achieves robust under the scenarios with low image
quality. Moreover, we have created a synthetic medical dialogue dataset that
simulates proactive diagnostic interactions between patients and doctors,
serving as a valuable resource for training LLM.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Recent advancements in large language models (LLMs) have demonstrated\nextraordinary comprehension capabilities with remarkable breakthroughs on\nvarious vision-language tasks. However, the application of LLMs in generating\nreliable medical diagnostic reports remains in the early stages. Currently,\nmedical LLMs typically feature a passive interaction model where doctors\nrespond to patient queries with little or no involvement in analyzing medical\nimages. In contrast, some ChatBots simply respond to predefined queries based\non visual inputs, lacking interactive dialogue or consideration of medical\nhistory. As such, there is a gap between LLM-generated patient-ChatBot\ninteractions and those occurring in actual patient-doctor consultations. To\nbridge this gap, we develop an LLM-based dialogue system, namely proactive\nmulti-round vision-language interactions for computer-aided diagnosis\n(ProMRVL-CAD), to generate patient-friendly disease diagnostic reports. The\nproposed ProMRVL-CAD system allows proactive dialogue to provide patients with\nconstant and reliable medical access via an integration of knowledge graph into\na recommendation system. Specifically, we devise two generators: a Proactive\nQuestion Generator (Pro-Q Gen) to generate proactive questions that guide the\ndiagnostic procedure and a Multi-Vision Patient-Text Diagnostic Report\nGenerator (MVP-DR Gen) to produce high-quality diagnostic reports. Evaluating\ntwo real-world publicly available datasets, MIMIC-CXR and IU-Xray, our model\nhas better quality in generating medical reports. We further demonstrate the\nperformance of ProMRVL achieves robust under the scenarios with low image\nquality. Moreover, we have created a synthetic medical dialogue dataset that\nsimulates proactive diagnostic interactions between patients and doctors,\nserving as a valuable resource for training LLM.'}","['Xueshen Li', 'Xinlong Hou', 'Ziyi Huang', 'Yu Gan']",{'name': 'Yu Gan'},Yu Gan,"17 pages, 6 figures","[{'href': 'http://arxiv.org/abs/2502.10620v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10620v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10620v1,None,http://arxiv.org/abs/2502.10620v1,,,30,0
http://arxiv.org/abs/2502.10705v1,True,2025-02-15T07:33:33Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=7, tm_min=33, tm_sec=33, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T07:33:33Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=7, tm_min=33, tm_sec=33, tm_wday=5, tm_yday=46, tm_isdst=0)","CoPEFT: Fast Adaptation Framework for Multi-Agent Collaborative
  Perception with Parameter-Efficient Fine-Tuning","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'CoPEFT: Fast Adaptation Framework for Multi-Agent Collaborative\n  Perception with Parameter-Efficient Fine-Tuning'}","Multi-agent collaborative perception is expected to significantly improve
perception performance by overcoming the limitations of single-agent perception
through exchanging complementary information. However, training a robust
collaborative perception model requires collecting sufficient training data
that covers all possible collaboration scenarios, which is impractical due to
intolerable deployment costs. Hence, the trained model is not robust against
new traffic scenarios with inconsistent data distribution and fundamentally
restricts its real-world applicability. Further, existing methods, such as
domain adaptation, have mitigated this issue by exposing the deployment data
during the training stage but incur a high training cost, which is infeasible
for resource-constrained agents. In this paper, we propose a
Parameter-Efficient Fine-Tuning-based lightweight framework, CoPEFT, for fast
adapting a trained collaborative perception model to new deployment
environments under low-cost conditions. CoPEFT develops a Collaboration Adapter
and Agent Prompt to perform macro-level and micro-level adaptations separately.
Specifically, the Collaboration Adapter utilizes the inherent knowledge from
training data and limited deployment data to adapt the feature map to new data
distribution. The Agent Prompt further enhances the Collaboration Adapter by
inserting fine-grained contextual information about the environment. Extensive
experiments demonstrate that our CoPEFT surpasses existing methods with less
than 1\% trainable parameters, proving the effectiveness and efficiency of our
proposed method.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Multi-agent collaborative perception is expected to significantly improve\nperception performance by overcoming the limitations of single-agent perception\nthrough exchanging complementary information. However, training a robust\ncollaborative perception model requires collecting sufficient training data\nthat covers all possible collaboration scenarios, which is impractical due to\nintolerable deployment costs. Hence, the trained model is not robust against\nnew traffic scenarios with inconsistent data distribution and fundamentally\nrestricts its real-world applicability. Further, existing methods, such as\ndomain adaptation, have mitigated this issue by exposing the deployment data\nduring the training stage but incur a high training cost, which is infeasible\nfor resource-constrained agents. In this paper, we propose a\nParameter-Efficient Fine-Tuning-based lightweight framework, CoPEFT, for fast\nadapting a trained collaborative perception model to new deployment\nenvironments under low-cost conditions. CoPEFT develops a Collaboration Adapter\nand Agent Prompt to perform macro-level and micro-level adaptations separately.\nSpecifically, the Collaboration Adapter utilizes the inherent knowledge from\ntraining data and limited deployment data to adapt the feature map to new data\ndistribution. The Agent Prompt further enhances the Collaboration Adapter by\ninserting fine-grained contextual information about the environment. Extensive\nexperiments demonstrate that our CoPEFT surpasses existing methods with less\nthan 1\\% trainable parameters, proving the effectiveness and efficiency of our\nproposed method.'}","['Quanmin Wei', 'Penglin Dai', 'Wei Li', 'Bingyi Liu', 'Xiao Wu']",{'name': 'Xiao Wu'},Xiao Wu,"Accepted by the 39th AAAI Conference on Artificial Intelligence
  (AAAI-25)","[{'href': 'http://arxiv.org/abs/2502.10705v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10705v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10705v1,None,http://arxiv.org/abs/2502.10705v1,,,11,0
http://arxiv.org/abs/2502.10742v1,True,2025-02-15T09:47:20Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=9, tm_min=47, tm_sec=20, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T09:47:20Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=9, tm_min=47, tm_sec=20, tm_wday=5, tm_yday=46, tm_isdst=0)",The Philosophical Foundations of Growing AI Like A Child,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The Philosophical Foundations of Growing AI Like A Child'}","Despite excelling in high-level reasoning, current language models lack
robustness in real-world scenarios and perform poorly on fundamental
problem-solving tasks that are intuitive to humans. This paper argues that both
challenges stem from a core discrepancy between human and machine cognitive
development. While both systems rely on increasing representational power, the
absence of core knowledge-foundational cognitive structures in humans-prevents
language models from developing robust, generalizable abilities, where complex
skills are grounded in simpler ones within their respective domains. It
explores empirical evidence of core knowledge in humans, analyzes why language
models fail to acquire it, and argues that this limitation is not an inherent
architectural constraint. Finally, it outlines a workable proposal for
systematically integrating core knowledge into future multi-modal language
models through the large-scale generation of synthetic training data using a
cognitive prototyping strategy.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Despite excelling in high-level reasoning, current language models lack\nrobustness in real-world scenarios and perform poorly on fundamental\nproblem-solving tasks that are intuitive to humans. This paper argues that both\nchallenges stem from a core discrepancy between human and machine cognitive\ndevelopment. While both systems rely on increasing representational power, the\nabsence of core knowledge-foundational cognitive structures in humans-prevents\nlanguage models from developing robust, generalizable abilities, where complex\nskills are grounded in simpler ones within their respective domains. It\nexplores empirical evidence of core knowledge in humans, analyzes why language\nmodels fail to acquire it, and argues that this limitation is not an inherent\narchitectural constraint. Finally, it outlines a workable proposal for\nsystematically integrating core knowledge into future multi-modal language\nmodels through the large-scale generation of synthetic training data using a\ncognitive prototyping strategy.'}","['Dezhi Luo', 'Yijiang Li', 'Hokin Deng']",{'name': 'Hokin Deng'},Hokin Deng,,"[{'href': 'http://arxiv.org/abs/2502.10742v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10742v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10742v1,None,http://arxiv.org/abs/2502.10742v1,,,1,0
http://arxiv.org/abs/2502.10906v1,True,2025-02-15T21:00:40Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=21, tm_min=0, tm_sec=40, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T21:00:40Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=21, tm_min=0, tm_sec=40, tm_wday=5, tm_yday=46, tm_isdst=0)","PCGRLLM: Large Language Model-Driven Reward Design for Procedural
  Content Generation Reinforcement Learning","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'PCGRLLM: Large Language Model-Driven Reward Design for Procedural\n  Content Generation Reinforcement Learning'}","Reward design plays a pivotal role in the training of game AIs, requiring
substantial domain-specific knowledge and human effort. In recent years,
several studies have explored reward generation for training game agents and
controlling robots using large language models (LLMs). In the content
generation literature, there has been early work on generating reward functions
for reinforcement learning agent generators. This work introduces PCGRLLM, an
extended architecture based on earlier work, which employs a feedback mechanism
and several reasoning-based prompt engineering techniques. We evaluate the
proposed method on a story-to-reward generation task in a two-dimensional
environment using two state-of-the-art LLMs, demonstrating the generalizability
of our approach. Our experiments provide insightful evaluations that
demonstrate the capabilities of LLMs essential for content generation tasks.
The results highlight significant performance improvements of 415% and 40%
respectively, depending on the zero-shot capabilities of the language model.
Our work demonstrates the potential to reduce human dependency in game AI
development, while supporting and enhancing creative processes.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Reward design plays a pivotal role in the training of game AIs, requiring\nsubstantial domain-specific knowledge and human effort. In recent years,\nseveral studies have explored reward generation for training game agents and\ncontrolling robots using large language models (LLMs). In the content\ngeneration literature, there has been early work on generating reward functions\nfor reinforcement learning agent generators. This work introduces PCGRLLM, an\nextended architecture based on earlier work, which employs a feedback mechanism\nand several reasoning-based prompt engineering techniques. We evaluate the\nproposed method on a story-to-reward generation task in a two-dimensional\nenvironment using two state-of-the-art LLMs, demonstrating the generalizability\nof our approach. Our experiments provide insightful evaluations that\ndemonstrate the capabilities of LLMs essential for content generation tasks.\nThe results highlight significant performance improvements of 415% and 40%\nrespectively, depending on the zero-shot capabilities of the language model.\nOur work demonstrates the potential to reduce human dependency in game AI\ndevelopment, while supporting and enhancing creative processes.'}","['In-Chang Baek', 'Sung-Hyun Kim', 'Sam Earle', 'Zehua Jiang', 'Noh Jin-Ha', 'Julian Togelius', 'Kyung-Joong Kim']",{'name': 'Kyung-Joong Kim'},Kyung-Joong Kim,"14 pages, 9 figures","[{'href': 'http://arxiv.org/abs/2502.10906v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10906v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10906v1,None,http://arxiv.org/abs/2502.10906v1,,,700,0
http://arxiv.org/abs/2502.10938v1,True,2025-02-16T00:27:05Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=0, tm_min=27, tm_sec=5, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T00:27:05Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=0, tm_min=27, tm_sec=5, tm_wday=6, tm_yday=47, tm_isdst=0)",PEA: Enhancing LLM Performance on Computational-Reasoning Tasks,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'PEA: Enhancing LLM Performance on Computational-Reasoning Tasks'}","Large Language Models (LLMs) have exhibited remarkable capabilities across
diverse domains, prompting investigations into their potential as generic
reasoning engines. While recent studies have explored inference-time
computation to enhance model performance on complex problems, current research
lacks a formal framework to characterize the complexity of reasoning tasks.
This study introduces the Predicate-Enumeration-Aggregation (PEA) framework, a
formal approach to describe and solve a class of important reasoning tasks
termed computational reasoning problems. The PEA framework decomposes these
problems into predicate and enumeration components, using LLMs to synthesize
programs based on specified predicates, enumeration, and aggregation rules.
These synthesized programs are then executed to obtain solutions to the
computational tasks. We demonstrate the framework's efficacy on benchmark tasks
including Boolean satisfiability problems, game of $24$, and planning problems.
Empirical evaluation reveals that PEA substantially enhances the performance of
underlying models on benchmark computational problems, yielding an average
accuracy improvement of approximately $50\%$, coupled with increased
efficiency.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Large Language Models (LLMs) have exhibited remarkable capabilities across\ndiverse domains, prompting investigations into their potential as generic\nreasoning engines. While recent studies have explored inference-time\ncomputation to enhance model performance on complex problems, current research\nlacks a formal framework to characterize the complexity of reasoning tasks.\nThis study introduces the Predicate-Enumeration-Aggregation (PEA) framework, a\nformal approach to describe and solve a class of important reasoning tasks\ntermed computational reasoning problems. The PEA framework decomposes these\nproblems into predicate and enumeration components, using LLMs to synthesize\nprograms based on specified predicates, enumeration, and aggregation rules.\nThese synthesized programs are then executed to obtain solutions to the\ncomputational tasks. We demonstrate the framework's efficacy on benchmark tasks\nincluding Boolean satisfiability problems, game of $24$, and planning problems.\nEmpirical evaluation reveals that PEA substantially enhances the performance of\nunderlying models on benchmark computational problems, yielding an average\naccuracy improvement of approximately $50\\%$, coupled with increased\nefficiency.""}","['Zi Wang', 'Shiwei Weng', 'Mohannad Alhanahnah', 'Somesh Jha', 'Tom Reps']",{'name': 'Tom Reps'},Tom Reps,,"[{'href': 'http://arxiv.org/abs/2502.10938v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10938v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10938v1,None,http://arxiv.org/abs/2502.10938v1,,,402,0
http://arxiv.org/abs/2502.11122v1,True,2025-02-16T13:36:31Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=13, tm_min=36, tm_sec=31, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T13:36:31Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=13, tm_min=36, tm_sec=31, tm_wday=6, tm_yday=47, tm_isdst=0)","Hierarchical Expert Prompt for Large-Language-Model: An Approach Defeat
  Elite AI in TextStarCraft II for the First Time","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Hierarchical Expert Prompt for Large-Language-Model: An Approach Defeat\n  Elite AI in TextStarCraft II for the First Time'}","Since the emergence of the Large Language Model (LLM), LLM has been widely
used in fields such as writing, translating, and searching. However, there is
still great potential for LLM-based methods in handling complex tasks such as
decision-making in the StarCraft II environment. To address problems such as
lack of relevant knowledge and poor control over subtasks of varying
importance, we propose a Hierarchical Expert Prompt (HEP) for LLM. Our method
improves the understanding of game situations through expert-level tactical
knowledge, improving the processing quality of tasks of varying importance
through a hierarchical framework. Our approach defeated the highest level
(Elite) standard built-in agent in TextStarCraft II for the first time and
consistently outperformed the baseline method in other difficulties. Our
experiments suggest that the proposed method is a practical solution for
tackling complex decision-making challenges. The replay video can be viewed on
https://www.bilibili.com/video/BV1uz42187EF and https://youtu.be/dO3PshWLV5M,
and our codes have been open-sourced on
https://github.com/luchang1113/HEP-LLM-play-StarCraftII.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Since the emergence of the Large Language Model (LLM), LLM has been widely\nused in fields such as writing, translating, and searching. However, there is\nstill great potential for LLM-based methods in handling complex tasks such as\ndecision-making in the StarCraft II environment. To address problems such as\nlack of relevant knowledge and poor control over subtasks of varying\nimportance, we propose a Hierarchical Expert Prompt (HEP) for LLM. Our method\nimproves the understanding of game situations through expert-level tactical\nknowledge, improving the processing quality of tasks of varying importance\nthrough a hierarchical framework. Our approach defeated the highest level\n(Elite) standard built-in agent in TextStarCraft II for the first time and\nconsistently outperformed the baseline method in other difficulties. Our\nexperiments suggest that the proposed method is a practical solution for\ntackling complex decision-making challenges. The replay video can be viewed on\nhttps://www.bilibili.com/video/BV1uz42187EF and https://youtu.be/dO3PshWLV5M,\nand our codes have been open-sourced on\nhttps://github.com/luchang1113/HEP-LLM-play-StarCraftII.'}","['Zongyuan Li', 'Chang Lu', 'Xiaojie Xu', 'Runnan Qi', 'Yanan Ni', 'Lumin Jiang', 'Xiangbei Liu', 'Xuebo Zhang', 'Yongchun Fang', 'Kuihua Huang', 'Xian Guo']",{'name': 'Xian Guo'},Xian Guo,,"[{'href': 'http://arxiv.org/abs/2502.11122v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11122v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11122v1,None,http://arxiv.org/abs/2502.11122v1,,,6,0
http://arxiv.org/abs/2502.11157v1,True,2025-02-16T15:11:19Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=15, tm_min=11, tm_sec=19, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T15:11:19Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=15, tm_min=11, tm_sec=19, tm_wday=6, tm_yday=47, tm_isdst=0)",Dyve: Thinking Fast and Slow for Dynamic Process Verification,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Dyve: Thinking Fast and Slow for Dynamic Process Verification'}","We present Dyve, a dynamic process verifier that enhances reasoning error
detection in large language models by integrating fast and slow thinking,
inspired by Kahneman's Systems Theory. Dyve adaptively applies immediate
token-level confirmation System 1 for straightforward steps and comprehensive
analysis System 2 for complex ones. Leveraging a novel step-wise
consensus-filtered process supervision technique, combining Monte Carlo
estimation with LLM based evaluation, Dyve curates high-quality supervision
signals from noisy data. Experimental results on ProcessBench and the MATH
dataset confirm that Dyve significantly outperforms existing process-based
verifiers and boosts performance in Best-of-N settings.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""We present Dyve, a dynamic process verifier that enhances reasoning error\ndetection in large language models by integrating fast and slow thinking,\ninspired by Kahneman's Systems Theory. Dyve adaptively applies immediate\ntoken-level confirmation System 1 for straightforward steps and comprehensive\nanalysis System 2 for complex ones. Leveraging a novel step-wise\nconsensus-filtered process supervision technique, combining Monte Carlo\nestimation with LLM based evaluation, Dyve curates high-quality supervision\nsignals from noisy data. Experimental results on ProcessBench and the MATH\ndataset confirm that Dyve significantly outperforms existing process-based\nverifiers and boosts performance in Best-of-N settings.""}","['Jianyuan Zhong', 'Zeju Li', 'Zhijian Xu', 'Xiangyu Wen', 'Qiang Xu']",{'name': 'Qiang Xu'},Qiang Xu,"8 pages, 4 figures","[{'href': 'http://arxiv.org/abs/2502.11157v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11157v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11157v1,None,http://arxiv.org/abs/2502.11157v1,,,390,0
http://arxiv.org/abs/2502.11312v1,True,2025-02-16T23:19:44Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=23, tm_min=19, tm_sec=44, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T23:19:44Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=23, tm_min=19, tm_sec=44, tm_wday=6, tm_yday=47, tm_isdst=0)",AI Generations: From AI 1.0 to AI 4.0,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'AI Generations: From AI 1.0 to AI 4.0'}","This paper proposes that Artificial Intelligence (AI) progresses through
several overlapping generations: AI 1.0 (Information AI), AI 2.0 (Agentic AI),
AI 3.0 (Physical AI), and now a speculative AI 4.0 (Conscious AI). Each of
these AI generations is driven by shifting priorities among algorithms,
computing power, and data. AI 1.0 ushered in breakthroughs in pattern
recognition and information processing, fueling advances in computer vision,
natural language processing, and recommendation systems. AI 2.0 built on these
foundations through real-time decision-making in digital environments,
leveraging reinforcement learning and adaptive planning for agentic AI
applications. AI 3.0 extended intelligence into physical contexts, integrating
robotics, autonomous vehicles, and sensor-fused control systems to act in
uncertain real-world settings. Building on these developments, AI 4.0 puts
forward the bold vision of self-directed AI capable of setting its own goals,
orchestrating complex training regimens, and possibly exhibiting elements of
machine consciousness. This paper traces the historical foundations of AI
across roughly seventy years, mapping how changes in technological bottlenecks
from algorithmic innovation to high-performance computing to specialized data,
have spurred each generational leap. It further highlights the ongoing
synergies among AI 1.0, 2.0, 3.0, and 4.0, and explores the profound ethical,
regulatory, and philosophical challenges that arise when artificial systems
approach (or aspire to) human-like autonomy. Ultimately, understanding these
evolutions and their interdependencies is pivotal for guiding future research,
crafting responsible governance, and ensuring that AI transformative potential
benefits society as a whole.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'This paper proposes that Artificial Intelligence (AI) progresses through\nseveral overlapping generations: AI 1.0 (Information AI), AI 2.0 (Agentic AI),\nAI 3.0 (Physical AI), and now a speculative AI 4.0 (Conscious AI). Each of\nthese AI generations is driven by shifting priorities among algorithms,\ncomputing power, and data. AI 1.0 ushered in breakthroughs in pattern\nrecognition and information processing, fueling advances in computer vision,\nnatural language processing, and recommendation systems. AI 2.0 built on these\nfoundations through real-time decision-making in digital environments,\nleveraging reinforcement learning and adaptive planning for agentic AI\napplications. AI 3.0 extended intelligence into physical contexts, integrating\nrobotics, autonomous vehicles, and sensor-fused control systems to act in\nuncertain real-world settings. Building on these developments, AI 4.0 puts\nforward the bold vision of self-directed AI capable of setting its own goals,\norchestrating complex training regimens, and possibly exhibiting elements of\nmachine consciousness. This paper traces the historical foundations of AI\nacross roughly seventy years, mapping how changes in technological bottlenecks\nfrom algorithmic innovation to high-performance computing to specialized data,\nhave spurred each generational leap. It further highlights the ongoing\nsynergies among AI 1.0, 2.0, 3.0, and 4.0, and explores the profound ethical,\nregulatory, and philosophical challenges that arise when artificial systems\napproach (or aspire to) human-like autonomy. Ultimately, understanding these\nevolutions and their interdependencies is pivotal for guiding future research,\ncrafting responsible governance, and ensuring that AI transformative potential\nbenefits society as a whole.'}","['Jiahao Wu', 'Hengxu You', 'Jing Du']",{'name': 'Jing Du'},Jing Du,17 pages,"[{'href': 'http://arxiv.org/abs/2502.11312v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11312v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11312v1,None,http://arxiv.org/abs/2502.11312v1,,,149,0
http://arxiv.org/abs/2502.11422v1,True,2025-02-17T04:35:01Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=4, tm_min=35, tm_sec=1, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T04:35:01Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=4, tm_min=35, tm_sec=1, tm_wday=0, tm_yday=48, tm_isdst=0)","Planning of Heuristics: Strategic Planning on Large Language Models with
  Monte Carlo Tree Search for Automating Heuristic Optimization","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Planning of Heuristics: Strategic Planning on Large Language Models with\n  Monte Carlo Tree Search for Automating Heuristic Optimization'}","Heuristics have achieved great success in solving combinatorial optimization
problems (COPs). However, heuristics designed by humans require too much domain
knowledge and testing time. Given the fact that Large Language Models (LLMs)
possess strong capabilities to understand and generate content, and a knowledge
base that covers various domains, which offer a novel way to automatically
optimize heuristics. Therefore, we propose Planning of Heuristics (PoH), an
optimization method that integrates the self-reflection of LLMs with the Monte
Carlo Tree Search (MCTS), a well-known planning algorithm. PoH iteratively
refines generated heuristics by evaluating their performance and providing
improvement suggestions. Our method enables to iteratively evaluate the
generated heuristics (states) and improve them based on the improvement
suggestions (actions) and evaluation results (rewards), by effectively
simulating future states to search for paths with higher rewards. In this
paper, we apply PoH to solve the Traveling Salesman Problem (TSP) and the Flow
Shop Scheduling Problem (FSSP). The experimental results show that PoH
outperforms other hand-crafted heuristics and Automatic Heuristic Design (AHD)
by other LLMs-based methods, and achieves the significant improvements and the
state-of-the-art performance of our proposed method in automating heuristic
optimization with LLMs to solve COPs.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Heuristics have achieved great success in solving combinatorial optimization\nproblems (COPs). However, heuristics designed by humans require too much domain\nknowledge and testing time. Given the fact that Large Language Models (LLMs)\npossess strong capabilities to understand and generate content, and a knowledge\nbase that covers various domains, which offer a novel way to automatically\noptimize heuristics. Therefore, we propose Planning of Heuristics (PoH), an\noptimization method that integrates the self-reflection of LLMs with the Monte\nCarlo Tree Search (MCTS), a well-known planning algorithm. PoH iteratively\nrefines generated heuristics by evaluating their performance and providing\nimprovement suggestions. Our method enables to iteratively evaluate the\ngenerated heuristics (states) and improve them based on the improvement\nsuggestions (actions) and evaluation results (rewards), by effectively\nsimulating future states to search for paths with higher rewards. In this\npaper, we apply PoH to solve the Traveling Salesman Problem (TSP) and the Flow\nShop Scheduling Problem (FSSP). The experimental results show that PoH\noutperforms other hand-crafted heuristics and Automatic Heuristic Design (AHD)\nby other LLMs-based methods, and achieves the significant improvements and the\nstate-of-the-art performance of our proposed method in automating heuristic\noptimization with LLMs to solve COPs.'}","['Chaoxu Mu', 'Xufeng Zhang', 'Hui Wang']",{'name': 'Hui Wang'},Hui Wang,"17 pages, 8 figures","[{'href': 'http://arxiv.org/abs/2502.11422v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11422v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11422v1,None,http://arxiv.org/abs/2502.11422v1,,,0,0
http://arxiv.org/abs/2502.11448v2,True,2025-02-18T05:37:44Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=5, tm_min=37, tm_sec=44, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-17T05:12:33Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=5, tm_min=12, tm_sec=33, tm_wday=0, tm_yday=48, tm_isdst=0)","AGrail: A Lifelong Agent Guardrail with Effective and Adaptive Safety
  Detection","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'AGrail: A Lifelong Agent Guardrail with Effective and Adaptive Safety\n  Detection'}","The rapid advancements in Large Language Models (LLMs) have enabled their
deployment as autonomous agents for handling complex tasks in dynamic
environments. These LLMs demonstrate strong problem-solving capabilities and
adaptability to multifaceted scenarios. However, their use as agents also
introduces significant risks, including task-specific risks, which are
identified by the agent administrator based on the specific task requirements
and constraints, and systemic risks, which stem from vulnerabilities in their
design or interactions, potentially compromising confidentiality, integrity, or
availability (CIA) of information and triggering security risks. Existing
defense agencies fail to adaptively and effectively mitigate these risks. In
this paper, we propose AGrail, a lifelong agent guardrail to enhance LLM agent
safety, which features adaptive safety check generation, effective safety check
optimization, and tool compatibility and flexibility. Extensive experiments
demonstrate that AGrail not only achieves strong performance against
task-specific and system risks but also exhibits transferability across
different LLM agents' tasks.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""The rapid advancements in Large Language Models (LLMs) have enabled their\ndeployment as autonomous agents for handling complex tasks in dynamic\nenvironments. These LLMs demonstrate strong problem-solving capabilities and\nadaptability to multifaceted scenarios. However, their use as agents also\nintroduces significant risks, including task-specific risks, which are\nidentified by the agent administrator based on the specific task requirements\nand constraints, and systemic risks, which stem from vulnerabilities in their\ndesign or interactions, potentially compromising confidentiality, integrity, or\navailability (CIA) of information and triggering security risks. Existing\ndefense agencies fail to adaptively and effectively mitigate these risks. In\nthis paper, we propose AGrail, a lifelong agent guardrail to enhance LLM agent\nsafety, which features adaptive safety check generation, effective safety check\noptimization, and tool compatibility and flexibility. Extensive experiments\ndemonstrate that AGrail not only achieves strong performance against\ntask-specific and system risks but also exhibits transferability across\ndifferent LLM agents' tasks.""}","['Weidi Luo', 'Shenghong Dai', 'Xiaogeng Liu', 'Suman Banerjee', 'Huan Sun', 'Muhao Chen', 'Chaowei Xiao']",{'name': 'Chaowei Xiao'},Chaowei Xiao,,"[{'href': 'http://arxiv.org/abs/2502.11448v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11448v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11448v2,None,http://arxiv.org/abs/2502.11448v2,,,535,0
http://arxiv.org/abs/2502.11528v1,True,2025-02-17T07:58:31Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=7, tm_min=58, tm_sec=31, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T07:58:31Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=7, tm_min=58, tm_sec=31, tm_wday=0, tm_yday=48, tm_isdst=0)","A Survey of Personalized Large Language Models: Progress and Future
  Directions","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A Survey of Personalized Large Language Models: Progress and Future\n  Directions'}","Large Language Models (LLMs) excel in handling general knowledge tasks, yet
they struggle with user-specific personalization, such as understanding
individual emotions, writing styles, and preferences. Personalized Large
Language Models (PLLMs) tackle these challenges by leveraging individual user
data, such as user profiles, historical dialogues, content, and interactions,
to deliver responses that are contextually relevant and tailored to each user's
specific needs. This is a highly valuable research topic, as PLLMs can
significantly enhance user satisfaction and have broad applications in
conversational agents, recommendation systems, emotion recognition, medical
assistants, and more. This survey reviews recent advancements in PLLMs from
three technical perspectives: prompting for personalized context (input level),
finetuning for personalized adapters (model level), and alignment for
personalized preferences (objective level). To provide deeper insights, we also
discuss current limitations and outline several promising directions for future
research. Updated information about this survey can be found at the
https://github.com/JiahongLiu21/Awesome-Personalized-Large-Language-Models.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Large Language Models (LLMs) excel in handling general knowledge tasks, yet\nthey struggle with user-specific personalization, such as understanding\nindividual emotions, writing styles, and preferences. Personalized Large\nLanguage Models (PLLMs) tackle these challenges by leveraging individual user\ndata, such as user profiles, historical dialogues, content, and interactions,\nto deliver responses that are contextually relevant and tailored to each user's\nspecific needs. This is a highly valuable research topic, as PLLMs can\nsignificantly enhance user satisfaction and have broad applications in\nconversational agents, recommendation systems, emotion recognition, medical\nassistants, and more. This survey reviews recent advancements in PLLMs from\nthree technical perspectives: prompting for personalized context (input level),\nfinetuning for personalized adapters (model level), and alignment for\npersonalized preferences (objective level). To provide deeper insights, we also\ndiscuss current limitations and outline several promising directions for future\nresearch. Updated information about this survey can be found at the\nhttps://github.com/JiahongLiu21/Awesome-Personalized-Large-Language-Models.""}","['Jiahong Liu', 'Zexuan Qiu', 'Zhongyang Li', 'Quanyu Dai', 'Jieming Zhu', 'Minda Hu', 'Menglin Yang', 'Irwin King']",{'name': 'Irwin King'},Irwin King,"7pages, 5 figures, Under Review","[{'href': 'http://arxiv.org/abs/2502.11528v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11528v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11528v1,None,http://arxiv.org/abs/2502.11528v1,,,240,0
http://arxiv.org/abs/2502.11555v1,True,2025-02-17T08:40:30Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=8, tm_min=40, tm_sec=30, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T08:40:30Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=8, tm_min=40, tm_sec=30, tm_wday=0, tm_yday=48, tm_isdst=0)","Equilibrate RLHF: Towards Balancing Helpfulness-Safety Trade-off in
  Large Language Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Equilibrate RLHF: Towards Balancing Helpfulness-Safety Trade-off in\n  Large Language Models'}","Fine-tuning large language models (LLMs) based on human preferences, commonly
achieved through reinforcement learning from human feedback (RLHF), has been
effective in improving their performance. However, maintaining LLM safety
throughout the fine-tuning process remains a significant challenge, as
resolving conflicts between safety and helpfulness can be non-trivial.
Typically, the safety alignment of LLM is trained on data with safety-related
categories. However, our experiments find that naively increasing the scale of
safety training data usually leads the LLMs to an ``overly safe'' state rather
than a ``truly safe'' state, boosting the refusal rate through extensive
safety-aligned data without genuinely understanding the requirements for safe
responses. Such an approach can inadvertently diminish the models' helpfulness.
To understand the phenomenon, we first investigate the role of safety data by
categorizing them into three different groups, and observe that each group
behaves differently as training data scales up. To boost the balance between
safety and helpfulness, we propose an Equilibrate RLHF framework including a
Fine-grained Data-centric (FDC) approach that achieves better safety alignment
even with fewer training data, and an Adaptive Message-wise Alignment (AMA)
approach, which selectively highlight the key segments through a gradient
masking strategy. Extensive experimental results demonstrate that our approach
significantly enhances the safety alignment of LLMs while balancing safety and
helpfulness.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Fine-tuning large language models (LLMs) based on human preferences, commonly\nachieved through reinforcement learning from human feedback (RLHF), has been\neffective in improving their performance. However, maintaining LLM safety\nthroughout the fine-tuning process remains a significant challenge, as\nresolving conflicts between safety and helpfulness can be non-trivial.\nTypically, the safety alignment of LLM is trained on data with safety-related\ncategories. However, our experiments find that naively increasing the scale of\nsafety training data usually leads the LLMs to an ``overly safe'' state rather\nthan a ``truly safe'' state, boosting the refusal rate through extensive\nsafety-aligned data without genuinely understanding the requirements for safe\nresponses. Such an approach can inadvertently diminish the models' helpfulness.\nTo understand the phenomenon, we first investigate the role of safety data by\ncategorizing them into three different groups, and observe that each group\nbehaves differently as training data scales up. To boost the balance between\nsafety and helpfulness, we propose an Equilibrate RLHF framework including a\nFine-grained Data-centric (FDC) approach that achieves better safety alignment\neven with fewer training data, and an Adaptive Message-wise Alignment (AMA)\napproach, which selectively highlight the key segments through a gradient\nmasking strategy. Extensive experimental results demonstrate that our approach\nsignificantly enhances the safety alignment of LLMs while balancing safety and\nhelpfulness.""}","['Yingshui Tan', 'Yilei Jiang', 'Yanshi Li', 'Jiaheng Liu', 'Xingyuan Bu', 'Wenbo Su', 'Xiangyu Yue', 'Xiaoyong Zhu', 'Bo Zheng']",{'name': 'Bo Zheng'},Bo Zheng,,"[{'href': 'http://arxiv.org/abs/2502.11555v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11555v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11555v1,None,http://arxiv.org/abs/2502.11555v1,,,163,0
http://arxiv.org/abs/2502.11574v1,True,2025-02-17T09:07:32Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=9, tm_min=7, tm_sec=32, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T09:07:32Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=9, tm_min=7, tm_sec=32, tm_wday=0, tm_yday=48, tm_isdst=0)",Large Language Models and Mathematical Reasoning Failures,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Language Models and Mathematical Reasoning Failures'}","This paper investigates the mathematical reasoning capabilities of large
language models (LLMs) using 50 newly constructed high-school-level word
problems. Unlike prior studies that focus solely on answer correctness, we
rigorously analyze both final answers and solution steps to identify reasoning
failures. Evaluating eight state-of-the-art models - including Mixtral, Llama,
Gemini, GPT-4o, and OpenAI's o1 variants - we find that while newer models
(e.g., o3-mini, deepseek-r1) achieve higher accuracy, all models exhibit errors
in spatial reasoning, strategic planning, and arithmetic, sometimes producing
correct answers through flawed logic. Common failure modes include unwarranted
assumptions, over-reliance on numerical patterns, and difficulty translating
physical intuition into mathematical steps. Manual analysis reveals that models
struggle with problems requiring multi-step deduction or real-world knowledge,
despite possessing broad mathematical knowledge. Our results underscore the
importance of evaluating reasoning processes, not just answers, and caution
against overestimating LLMs' problem-solving proficiency. The study highlights
persistent gaps in LLMs' generalization abilities, emphasizing the need for
targeted improvements in structured reasoning and constraint handling.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""This paper investigates the mathematical reasoning capabilities of large\nlanguage models (LLMs) using 50 newly constructed high-school-level word\nproblems. Unlike prior studies that focus solely on answer correctness, we\nrigorously analyze both final answers and solution steps to identify reasoning\nfailures. Evaluating eight state-of-the-art models - including Mixtral, Llama,\nGemini, GPT-4o, and OpenAI's o1 variants - we find that while newer models\n(e.g., o3-mini, deepseek-r1) achieve higher accuracy, all models exhibit errors\nin spatial reasoning, strategic planning, and arithmetic, sometimes producing\ncorrect answers through flawed logic. Common failure modes include unwarranted\nassumptions, over-reliance on numerical patterns, and difficulty translating\nphysical intuition into mathematical steps. Manual analysis reveals that models\nstruggle with problems requiring multi-step deduction or real-world knowledge,\ndespite possessing broad mathematical knowledge. Our results underscore the\nimportance of evaluating reasoning processes, not just answers, and caution\nagainst overestimating LLMs' problem-solving proficiency. The study highlights\npersistent gaps in LLMs' generalization abilities, emphasizing the need for\ntargeted improvements in structured reasoning and constraint handling.""}","['Johan Boye', 'Birger Moell']",{'name': 'Birger Moell'},Birger Moell,,"[{'href': 'http://arxiv.org/abs/2502.11574v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11574v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11574v1,None,http://arxiv.org/abs/2502.11574v1,,,33,0
http://arxiv.org/abs/2502.11585v1,True,2025-02-17T09:17:01Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=9, tm_min=17, tm_sec=1, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T09:17:01Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=9, tm_min=17, tm_sec=1, tm_wday=0, tm_yday=48, tm_isdst=0)",Calibration of Vehicular Traffic Simulation Models by Local Optimization,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Calibration of Vehicular Traffic Simulation Models by Local Optimization'}","Simulation is a valuable tool for traffic management experts to assist them
in refining and improving transportation systems and anticipating the impact of
possible changes in the infrastructure network before their actual
implementation. Calibrating simulation models using traffic count data is
challenging because of the complexity of the environment, the lack of data, and
the uncertainties in traffic dynamics. This paper introduces a novel stochastic
simulation-based traffic calibration technique. The novelty of the proposed
method is: (i) it performs local traffic calibration, (ii) it allows
calibrating simulated traffic in large-scale environments, (iii) it requires
only the traffic count data. The local approach enables decentralizing the
calibration task to reach near real-time performance, enabling the fostering of
digital twins. Using only traffic count data makes the proposed method generic
so that it can be applied in different traffic scenarios at various scales
(from neighborhood to region). We assess the proposed technique on a model of
Brussels, Belgium, using data from real traffic monitoring devices. The
proposed method has been implemented using the open-source traffic simulator
SUMO. Experimental results show that the traffic model calibrated using the
proposed method is on average 16% more accurate than those obtained by the
state-of-the-art methods, using the same dataset. We also make available the
output traffic model obtained from real data.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Simulation is a valuable tool for traffic management experts to assist them\nin refining and improving transportation systems and anticipating the impact of\npossible changes in the infrastructure network before their actual\nimplementation. Calibrating simulation models using traffic count data is\nchallenging because of the complexity of the environment, the lack of data, and\nthe uncertainties in traffic dynamics. This paper introduces a novel stochastic\nsimulation-based traffic calibration technique. The novelty of the proposed\nmethod is: (i) it performs local traffic calibration, (ii) it allows\ncalibrating simulated traffic in large-scale environments, (iii) it requires\nonly the traffic count data. The local approach enables decentralizing the\ncalibration task to reach near real-time performance, enabling the fostering of\ndigital twins. Using only traffic count data makes the proposed method generic\nso that it can be applied in different traffic scenarios at various scales\n(from neighborhood to region). We assess the proposed technique on a model of\nBrussels, Belgium, using data from real traffic monitoring devices. The\nproposed method has been implemented using the open-source traffic simulator\nSUMO. Experimental results show that the traffic model calibrated using the\nproposed method is on average 16% more accurate than those obtained by the\nstate-of-the-art methods, using the same dataset. We also make available the\noutput traffic model obtained from real data.'}","['Davide Andrea Guastella', 'Alejandro Morales-Hernndez', 'Bruno Cornelis', 'Gianluca Bontempi']",{'name': 'Gianluca Bontempi'},Gianluca Bontempi,Published on Springer Transportation,"[{'title': 'doi', 'href': 'http://dx.doi.org/10.1007/s11116-025-10593-x', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2502.11585v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11585v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11585v1,None,http://arxiv.org/abs/2502.11585v1,,10.1007/s11116-025-10593-x,69,0
http://arxiv.org/abs/2502.11664v1,True,2025-02-17T10:53:57Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=10, tm_min=53, tm_sec=57, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T10:53:57Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=10, tm_min=53, tm_sec=57, tm_wday=0, tm_yday=48, tm_isdst=0)",VRoPE: Rotary Position Embedding for Video Large Language Models,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'VRoPE: Rotary Position Embedding for Video Large Language Models'}","Rotary Position Embedding (RoPE) has shown strong performance in text-based
Large Language Models (LLMs), but extending it to video remains a challenge due
to the intricate spatiotemporal structure of video frames. Existing
adaptations, such as RoPE-3D, attempt to encode spatial and temporal dimensions
separately but suffer from two major limitations: positional bias in attention
distribution and disruptions in video-text transitions. To overcome these
issues, we propose Video Rotary Position Embedding (VRoPE), a novel positional
encoding method tailored for Video-LLMs. Our approach restructures positional
indices to preserve spatial coherence and ensure a smooth transition between
video and text tokens. Additionally, we introduce a more balanced encoding
strategy that mitigates attention biases, ensuring a more uniform distribution
of spatial focus. Extensive experiments on Vicuna and Qwen2 across different
model scales demonstrate that VRoPE consistently outperforms previous RoPE
variants, achieving significant improvements in video understanding, temporal
reasoning, and retrieval tasks. Code will be available at
https://github.com/johncaged/VRoPE","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Rotary Position Embedding (RoPE) has shown strong performance in text-based\nLarge Language Models (LLMs), but extending it to video remains a challenge due\nto the intricate spatiotemporal structure of video frames. Existing\nadaptations, such as RoPE-3D, attempt to encode spatial and temporal dimensions\nseparately but suffer from two major limitations: positional bias in attention\ndistribution and disruptions in video-text transitions. To overcome these\nissues, we propose Video Rotary Position Embedding (VRoPE), a novel positional\nencoding method tailored for Video-LLMs. Our approach restructures positional\nindices to preserve spatial coherence and ensure a smooth transition between\nvideo and text tokens. Additionally, we introduce a more balanced encoding\nstrategy that mitigates attention biases, ensuring a more uniform distribution\nof spatial focus. Extensive experiments on Vicuna and Qwen2 across different\nmodel scales demonstrate that VRoPE consistently outperforms previous RoPE\nvariants, achieving significant improvements in video understanding, temporal\nreasoning, and retrieval tasks. Code will be available at\nhttps://github.com/johncaged/VRoPE'}","['Zikang Liu', 'Longteng Guo', 'Yepeng Tang', 'Junxian Cai', 'Kai Ma', 'Xi Chen', 'Jing Liu']",{'name': 'Jing Liu'},Jing Liu,10 pages,"[{'href': 'http://arxiv.org/abs/2502.11664v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11664v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11664v1,None,http://arxiv.org/abs/2502.11664v1,,,956,0
http://arxiv.org/abs/2502.11723v1,True,2025-02-17T12:10:25Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=12, tm_min=10, tm_sec=25, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T12:10:25Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=12, tm_min=10, tm_sec=25, tm_wday=0, tm_yday=48, tm_isdst=0)","Energy-Conscious LLM Decoding: Impact of Text Generation Strategies on
  GPU Energy Consumption","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Energy-Conscious LLM Decoding: Impact of Text Generation Strategies on\n  GPU Energy Consumption'}","Decoding strategies significantly influence the quality and diversity of the
generated texts in large language models (LLMs), yet their impact on
computational resource consumption, particularly GPU energy usage, is
insufficiently studied. This paper investigates the relationship between text
generation decoding methods and energy efficiency, focusing on the trade-off
between generation quality and GPU energy consumption across diverse tasks and
decoding configurations. By benchmarking multiple strategies across different
text generation tasks, such as Translation, Code Summarization, and Math
Problem Solving, we reveal how selecting appropriate decoding techniques with
their tuned hyperparameters affects text quality and has measurable
implications for resource utilization, emphasizing the need for balanced
optimization. To the best of our knowledge, this study is among the first to
explore decoding strategies in LLMs through the lens of energy consumption,
offering actionable insights for designing resource-aware applications that
maintain high-quality text generation.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Decoding strategies significantly influence the quality and diversity of the\ngenerated texts in large language models (LLMs), yet their impact on\ncomputational resource consumption, particularly GPU energy usage, is\ninsufficiently studied. This paper investigates the relationship between text\ngeneration decoding methods and energy efficiency, focusing on the trade-off\nbetween generation quality and GPU energy consumption across diverse tasks and\ndecoding configurations. By benchmarking multiple strategies across different\ntext generation tasks, such as Translation, Code Summarization, and Math\nProblem Solving, we reveal how selecting appropriate decoding techniques with\ntheir tuned hyperparameters affects text quality and has measurable\nimplications for resource utilization, emphasizing the need for balanced\noptimization. To the best of our knowledge, this study is among the first to\nexplore decoding strategies in LLMs through the lens of energy consumption,\noffering actionable insights for designing resource-aware applications that\nmaintain high-quality text generation.'}","['Alireza Nik', 'Michael A. Riegler', 'Pl Halvorsen']",{'name': 'Pl Halvorsen'},Pl Halvorsen,,"[{'href': 'http://arxiv.org/abs/2502.11723v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11723v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11723v1,None,http://arxiv.org/abs/2502.11723v1,,,566,0
http://arxiv.org/abs/2502.11753v1,True,2025-02-17T12:49:55Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=12, tm_min=49, tm_sec=55, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T12:49:55Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=12, tm_min=49, tm_sec=55, tm_wday=0, tm_yday=48, tm_isdst=0)","HintsOfTruth: A Multimodal Checkworthiness Detection Dataset with Real
  and Synthetic Claims","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'HintsOfTruth: A Multimodal Checkworthiness Detection Dataset with Real\n  and Synthetic Claims'}","Misinformation can be countered with fact-checking, but the process is costly
and slow. Identifying checkworthy claims is the first step, where automation
can help scale fact-checkers' efforts. However, detection methods struggle with
content that is 1) multimodal, 2) from diverse domains, and 3) synthetic. We
introduce HintsOfTruth, a public dataset for multimodal checkworthiness
detection with $27$K real-world and synthetic image/claim pairs. The mix of
real and synthetic data makes this dataset unique and ideal for benchmarking
detection methods. We compare fine-tuned and prompted Large Language Models
(LLMs). We find that well-configured lightweight text-based encoders perform
comparably to multimodal models but the first only focus on identifying
non-claim-like content. Multimodal LLMs can be more accurate but come at a
significant computational cost, making them impractical for large-scale
applications. When faced with synthetic data, multimodal models perform more
robustly","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Misinformation can be countered with fact-checking, but the process is costly\nand slow. Identifying checkworthy claims is the first step, where automation\ncan help scale fact-checkers' efforts. However, detection methods struggle with\ncontent that is 1) multimodal, 2) from diverse domains, and 3) synthetic. We\nintroduce HintsOfTruth, a public dataset for multimodal checkworthiness\ndetection with $27$K real-world and synthetic image/claim pairs. The mix of\nreal and synthetic data makes this dataset unique and ideal for benchmarking\ndetection methods. We compare fine-tuned and prompted Large Language Models\n(LLMs). We find that well-configured lightweight text-based encoders perform\ncomparably to multimodal models but the first only focus on identifying\nnon-claim-like content. Multimodal LLMs can be more accurate but come at a\nsignificant computational cost, making them impractical for large-scale\napplications. When faced with synthetic data, multimodal models perform more\nrobustly""}","['Michiel van der Meer', 'Pavel Korshunov', 'Sbastien Marcel', 'Lonneke van der Plas']",{'name': 'Lonneke van der Plas'},Lonneke van der Plas,,"[{'href': 'http://arxiv.org/abs/2502.11753v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11753v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11753v1,None,http://arxiv.org/abs/2502.11753v1,,,324,0
http://arxiv.org/abs/2502.11770v1,True,2025-02-17T13:00:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=13, tm_min=0, tm_sec=15, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T13:00:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=13, tm_min=0, tm_sec=15, tm_wday=0, tm_yday=48, tm_isdst=0)",Cognitive-Aligned Document Selection for Retrieval-augmented Generation,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Cognitive-Aligned Document Selection for Retrieval-augmented Generation'}","Large language models (LLMs) inherently display hallucinations since the
precision of generated texts cannot be guaranteed purely by the parametric
knowledge they include. Although retrieval-augmented generation (RAG) systems
enhance the accuracy and reliability of generative models by incorporating
external documents, these retrieved documents often fail to adequately support
the model's responses in practical applications. To address this issue, we
propose GGatrieval (Fine-\textbf{G}rained \textbf{G}rounded \textbf{A}lignment
Re\textbf{trieval} for verifiable generation), which leverages an LLM to
dynamically update queries and filter high-quality, reliable retrieval
documents. Specifically, we parse the user query into its syntactic components
and perform fine-grained grounded alignment with the retrieved documents. For
query components that cannot be individually aligned, we propose a dynamic
semantic compensation mechanism that iteratively refines and rewrites the query
while continuously updating the retrieval results. This iterative process
continues until the retrieved documents sufficiently support the query's
response. Our approach introduces a novel criterion for filtering retrieved
documents, closely emulating human strategies for acquiring targeted
information. This ensures that the retrieved content effectively supports and
verifies the generated outputs. On the ALCE benchmark, our method significantly
surpasses a wide range of baselines, achieving state-of-the-art performance.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Large language models (LLMs) inherently display hallucinations since the\nprecision of generated texts cannot be guaranteed purely by the parametric\nknowledge they include. Although retrieval-augmented generation (RAG) systems\nenhance the accuracy and reliability of generative models by incorporating\nexternal documents, these retrieved documents often fail to adequately support\nthe model's responses in practical applications. To address this issue, we\npropose GGatrieval (Fine-\\textbf{G}rained \\textbf{G}rounded \\textbf{A}lignment\nRe\\textbf{trieval} for verifiable generation), which leverages an LLM to\ndynamically update queries and filter high-quality, reliable retrieval\ndocuments. Specifically, we parse the user query into its syntactic components\nand perform fine-grained grounded alignment with the retrieved documents. For\nquery components that cannot be individually aligned, we propose a dynamic\nsemantic compensation mechanism that iteratively refines and rewrites the query\nwhile continuously updating the retrieval results. This iterative process\ncontinues until the retrieved documents sufficiently support the query's\nresponse. Our approach introduces a novel criterion for filtering retrieved\ndocuments, closely emulating human strategies for acquiring targeted\ninformation. This ensures that the retrieved content effectively supports and\nverifies the generated outputs. On the ALCE benchmark, our method significantly\nsurpasses a wide range of baselines, achieving state-of-the-art performance.""}","['Bingyu Wan', 'Fuxi Zhang', 'Zhongpeng Qi', 'Jiayi Ding', 'Jijun Li', 'Baoshi Fan', 'Yijia Zhang', 'Jun Zhang']",{'name': 'Jun Zhang'},Jun Zhang,,"[{'href': 'http://arxiv.org/abs/2502.11770v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11770v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11770v1,None,http://arxiv.org/abs/2502.11770v1,,,1,0
http://arxiv.org/abs/2502.11959v1,True,2025-02-17T16:07:07Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=16, tm_min=7, tm_sec=7, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T16:07:07Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=16, tm_min=7, tm_sec=7, tm_wday=0, tm_yday=48, tm_isdst=0)",STRIVE: Structured Reasoning for Self-Improvement in Claim Verification,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'STRIVE: Structured Reasoning for Self-Improvement in Claim Verification'}","Claim verification is the task of determining whether a claim is supported or
refuted by evidence. Self-improvement methods, where reasoning chains are
generated and those leading to correct results are selected for training, have
succeeded in tasks like mathematical problem solving. However, in claim
verification, this approach struggles. Low-quality reasoning chains may falsely
match binary truth labels, introducing faulty reasoning into the
self-improvement process and ultimately degrading performance. To address this,
we propose STRIVE: Structured Reasoning for Self-Improved Verification. Our
method introduces a structured reasoning design with Claim Decomposition,
Entity Analysis, and Evidence Grounding Verification. These components improve
reasoning quality, reduce errors, and provide additional supervision signals
for self-improvement. STRIVE begins with a warm-up phase, where the base model
is fine-tuned on a small number of annotated examples to learn the structured
reasoning design. It is then applied to generate reasoning chains for all
training examples, selecting only those that are correct and structurally sound
for subsequent self-improvement training. We demonstrate that STRIVE achieves
significant improvements over baseline models, with a 31.4% performance gain
over the base model and 20.7% over Chain of Thought on the HOVER datasets,
highlighting its effectiveness.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Claim verification is the task of determining whether a claim is supported or\nrefuted by evidence. Self-improvement methods, where reasoning chains are\ngenerated and those leading to correct results are selected for training, have\nsucceeded in tasks like mathematical problem solving. However, in claim\nverification, this approach struggles. Low-quality reasoning chains may falsely\nmatch binary truth labels, introducing faulty reasoning into the\nself-improvement process and ultimately degrading performance. To address this,\nwe propose STRIVE: Structured Reasoning for Self-Improved Verification. Our\nmethod introduces a structured reasoning design with Claim Decomposition,\nEntity Analysis, and Evidence Grounding Verification. These components improve\nreasoning quality, reduce errors, and provide additional supervision signals\nfor self-improvement. STRIVE begins with a warm-up phase, where the base model\nis fine-tuned on a small number of annotated examples to learn the structured\nreasoning design. It is then applied to generate reasoning chains for all\ntraining examples, selecting only those that are correct and structurally sound\nfor subsequent self-improvement training. We demonstrate that STRIVE achieves\nsignificant improvements over baseline models, with a 31.4% performance gain\nover the base model and 20.7% over Chain of Thought on the HOVER datasets,\nhighlighting its effectiveness.'}","['Haisong Gong', 'Jing Li', 'Junfei Wu', 'Qiang Liu', 'Shu Wu', 'Liang Wang']",{'name': 'Liang Wang'},Liang Wang,,"[{'href': 'http://arxiv.org/abs/2502.11959v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11959v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11959v1,None,http://arxiv.org/abs/2502.11959v1,,,0,0
http://arxiv.org/abs/2502.12029v1,True,2025-02-17T17:02:01Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=17, tm_min=2, tm_sec=1, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T17:02:01Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=17, tm_min=2, tm_sec=1, tm_wday=0, tm_yday=48, tm_isdst=0)","KnowPath: Knowledge-enhanced Reasoning via LLM-generated Inference Paths
  over Knowledge Graphs","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'KnowPath: Knowledge-enhanced Reasoning via LLM-generated Inference Paths\n  over Knowledge Graphs'}","Large language models (LLMs) have demonstrated remarkable capabilities in
various complex tasks, yet they still suffer from hallucinations. Introducing
external knowledge, such as knowledge graph, can enhance the LLMs' ability to
provide factual answers. LLMs have the ability to interactively explore
knowledge graphs. However, most approaches have been affected by insufficient
internal knowledge excavation in LLMs, limited generation of trustworthy
knowledge reasoning paths, and a vague integration between internal and
external knowledge. Therefore, we propose KnowPath, a knowledge-enhanced large
model framework driven by the collaboration of internal and external knowledge.
It relies on the internal knowledge of the LLM to guide the exploration of
interpretable directed subgraphs in external knowledge graphs, better
integrating the two knowledge sources for more accurate reasoning. Extensive
experiments on multiple real-world datasets confirm the superiority of
KnowPath.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Large language models (LLMs) have demonstrated remarkable capabilities in\nvarious complex tasks, yet they still suffer from hallucinations. Introducing\nexternal knowledge, such as knowledge graph, can enhance the LLMs' ability to\nprovide factual answers. LLMs have the ability to interactively explore\nknowledge graphs. However, most approaches have been affected by insufficient\ninternal knowledge excavation in LLMs, limited generation of trustworthy\nknowledge reasoning paths, and a vague integration between internal and\nexternal knowledge. Therefore, we propose KnowPath, a knowledge-enhanced large\nmodel framework driven by the collaboration of internal and external knowledge.\nIt relies on the internal knowledge of the LLM to guide the exploration of\ninterpretable directed subgraphs in external knowledge graphs, better\nintegrating the two knowledge sources for more accurate reasoning. Extensive\nexperiments on multiple real-world datasets confirm the superiority of\nKnowPath.""}","['Qi Zhao', 'Hongyu Yang', 'Qi Song', 'Xinwei Yao', 'Xiangyang Li']",{'name': 'Xiangyang Li'},Xiangyang Li,,"[{'href': 'http://arxiv.org/abs/2502.12029v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12029v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12029v1,None,http://arxiv.org/abs/2502.12029v1,,,0,0
http://arxiv.org/abs/2502.12054v1,True,2025-02-17T17:24:14Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=17, tm_min=24, tm_sec=14, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T17:24:14Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=17, tm_min=24, tm_sec=14, tm_wday=0, tm_yday=48, tm_isdst=0)",PhysReason: A Comprehensive Benchmark towards Physics-Based Reasoning,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'PhysReason: A Comprehensive Benchmark towards Physics-Based Reasoning'}","Large language models demonstrate remarkable capabilities across various
domains, especially mathematics and logic reasoning. However, current
evaluations overlook physics-based reasoning - a complex task requiring physics
theorems and constraints. We present PhysReason, a 1,200-problem benchmark
comprising knowledge-based (25%) and reasoning-based (75%) problems, where the
latter are divided into three difficulty levels (easy, medium, hard). Notably,
problems require an average of 8.1 solution steps, with hard requiring 15.6,
reflecting the complexity of physics-based reasoning. We propose the Physics
Solution Auto Scoring Framework, incorporating efficient answer-level and
comprehensive step-level evaluations. Top-performing models like Deepseek-R1,
Gemini-2.0-Flash-Thinking, and o3-mini-high achieve less than 60% on
answer-level evaluation, with performance dropping from knowledge questions
(75.11%) to hard problems (31.95%). Through step-level evaluation, we
identified four key bottlenecks: Physics Theorem Application, Physics Process
Understanding, Calculation, and Physics Condition Analysis. These findings
position PhysReason as a novel and comprehensive benchmark for evaluating
physics-based reasoning capabilities in large language models. Our code and
data will be published at https:/dxzxy12138.github.io/PhysReason.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large language models demonstrate remarkable capabilities across various\ndomains, especially mathematics and logic reasoning. However, current\nevaluations overlook physics-based reasoning - a complex task requiring physics\ntheorems and constraints. We present PhysReason, a 1,200-problem benchmark\ncomprising knowledge-based (25%) and reasoning-based (75%) problems, where the\nlatter are divided into three difficulty levels (easy, medium, hard). Notably,\nproblems require an average of 8.1 solution steps, with hard requiring 15.6,\nreflecting the complexity of physics-based reasoning. We propose the Physics\nSolution Auto Scoring Framework, incorporating efficient answer-level and\ncomprehensive step-level evaluations. Top-performing models like Deepseek-R1,\nGemini-2.0-Flash-Thinking, and o3-mini-high achieve less than 60% on\nanswer-level evaluation, with performance dropping from knowledge questions\n(75.11%) to hard problems (31.95%). Through step-level evaluation, we\nidentified four key bottlenecks: Physics Theorem Application, Physics Process\nUnderstanding, Calculation, and Physics Condition Analysis. These findings\nposition PhysReason as a novel and comprehensive benchmark for evaluating\nphysics-based reasoning capabilities in large language models. Our code and\ndata will be published at https:/dxzxy12138.github.io/PhysReason.'}","['Xinyu Zhang', 'Yuxuan Dong', 'Yanrui Wu', 'Jiaxing Huang', 'Chengyou Jia', 'Basura Fernando', 'Mike Zheng Shou', 'Lingling Zhang', 'Jun Liu']",{'name': 'Jun Liu'},Jun Liu,,"[{'href': 'http://arxiv.org/abs/2502.12054v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12054v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12054v1,None,http://arxiv.org/abs/2502.12054v1,,,699,0
http://arxiv.org/abs/2502.12130v1,True,2025-02-17T18:49:25Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=49, tm_sec=25, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T18:49:25Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=49, tm_sec=25, tm_wday=0, tm_yday=48, tm_isdst=0)",Scaling Autonomous Agents via Automatic Reward Modeling And Planning,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Scaling Autonomous Agents via Automatic Reward Modeling And Planning'}","Large language models (LLMs) have demonstrated remarkable capabilities across
a range of text-generation tasks. However, LLMs still struggle with problems
requiring multi-step decision-making and environmental feedback, such as online
shopping, scientific reasoning, and mathematical problem-solving. Unlike pure
text data, collecting large-scale decision-making data is challenging.
Moreover, many powerful LLMs are only accessible through APIs, which hinders
their fine-tuning for agent tasks due to cost and complexity. To address LLM
agents' limitations, we propose a framework that can automatically learn a
reward model from the environment without human annotations. This model can be
used to evaluate the action trajectories of LLM agents and provide heuristics
for task planning. Specifically, our approach involves employing one LLM-based
agent to navigate an environment randomly, generating diverse action
trajectories. Subsequently, a separate LLM is leveraged to assign a task intent
and synthesize a negative response alongside the correct response for each
trajectory. These triplets (task intent, positive response, and negative
response) are then utilized as training data to optimize a reward model capable
of scoring action trajectories. The effectiveness and generalizability of our
framework are demonstrated through evaluations conducted on different agent
benchmarks. In conclusion, our proposed framework represents a significant
advancement in enhancing LLM agents' decision-making capabilities. By
automating the learning of reward models, we overcome the challenges of data
scarcity and API limitations, potentially revolutionizing the application of
LLMs in complex and interactive environments. This research paves the way for
more sophisticated AI agents capable of tackling a wide range of real-world
problems requiring multi-step decision-making.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Large language models (LLMs) have demonstrated remarkable capabilities across\na range of text-generation tasks. However, LLMs still struggle with problems\nrequiring multi-step decision-making and environmental feedback, such as online\nshopping, scientific reasoning, and mathematical problem-solving. Unlike pure\ntext data, collecting large-scale decision-making data is challenging.\nMoreover, many powerful LLMs are only accessible through APIs, which hinders\ntheir fine-tuning for agent tasks due to cost and complexity. To address LLM\nagents' limitations, we propose a framework that can automatically learn a\nreward model from the environment without human annotations. This model can be\nused to evaluate the action trajectories of LLM agents and provide heuristics\nfor task planning. Specifically, our approach involves employing one LLM-based\nagent to navigate an environment randomly, generating diverse action\ntrajectories. Subsequently, a separate LLM is leveraged to assign a task intent\nand synthesize a negative response alongside the correct response for each\ntrajectory. These triplets (task intent, positive response, and negative\nresponse) are then utilized as training data to optimize a reward model capable\nof scoring action trajectories. The effectiveness and generalizability of our\nframework are demonstrated through evaluations conducted on different agent\nbenchmarks. In conclusion, our proposed framework represents a significant\nadvancement in enhancing LLM agents' decision-making capabilities. By\nautomating the learning of reward models, we overcome the challenges of data\nscarcity and API limitations, potentially revolutionizing the application of\nLLMs in complex and interactive environments. This research paves the way for\nmore sophisticated AI agents capable of tackling a wide range of real-world\nproblems requiring multi-step decision-making.""}","['Zhenfang Chen', 'Delin Chen', 'Rui Sun', 'Wenjun Liu', 'Chuang Gan']",{'name': 'Chuang Gan'},Chuang Gan,"ICLR2025, Project page: https://armap-agent.github.io","[{'href': 'http://arxiv.org/abs/2502.12130v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12130v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12130v1,None,http://arxiv.org/abs/2502.12130v1,,,10,0
http://arxiv.org/abs/2502.12131v1,True,2025-02-17T18:49:40Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=49, tm_sec=40, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T18:49:40Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=49, tm_sec=40, tm_wday=0, tm_yday=48, tm_isdst=0)","Transformer Dynamics: A neuroscientific approach to interpretability of
  large language models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Transformer Dynamics: A neuroscientific approach to interpretability of\n  large language models'}","As artificial intelligence models have exploded in scale and capability,
understanding of their internal mechanisms remains a critical challenge.
Inspired by the success of dynamical systems approaches in neuroscience, here
we propose a novel framework for studying computations in deep learning
systems. We focus on the residual stream (RS) in transformer models,
conceptualizing it as a dynamical system evolving across layers. We find that
activations of individual RS units exhibit strong continuity across layers,
despite the RS being a non-privileged basis. Activations in the RS accelerate
and grow denser over layers, while individual units trace unstable periodic
orbits. In reduced-dimensional spaces, the RS follows a curved trajectory with
attractor-like dynamics in the lower layers. These insights bridge dynamical
systems theory and mechanistic interpretability, establishing a foundation for
a ""neuroscience of AI"" that combines theoretical rigor with large-scale data
analysis to advance our understanding of modern neural networks.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'As artificial intelligence models have exploded in scale and capability,\nunderstanding of their internal mechanisms remains a critical challenge.\nInspired by the success of dynamical systems approaches in neuroscience, here\nwe propose a novel framework for studying computations in deep learning\nsystems. We focus on the residual stream (RS) in transformer models,\nconceptualizing it as a dynamical system evolving across layers. We find that\nactivations of individual RS units exhibit strong continuity across layers,\ndespite the RS being a non-privileged basis. Activations in the RS accelerate\nand grow denser over layers, while individual units trace unstable periodic\norbits. In reduced-dimensional spaces, the RS follows a curved trajectory with\nattractor-like dynamics in the lower layers. These insights bridge dynamical\nsystems theory and mechanistic interpretability, establishing a foundation for\na ""neuroscience of AI"" that combines theoretical rigor with large-scale data\nanalysis to advance our understanding of modern neural networks.'}","['Jesseba Fernando', 'Grigori Guitchounts']",{'name': 'Grigori Guitchounts'},Grigori Guitchounts,,"[{'href': 'http://arxiv.org/abs/2502.12131v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12131v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12131v1,None,http://arxiv.org/abs/2502.12131v1,,,488,0
http://arxiv.org/abs/2502.12143v1,True,2025-02-17T18:56:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=56, tm_sec=15, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T18:56:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=56, tm_sec=15, tm_wday=0, tm_yday=48, tm_isdst=0)",Small Models Struggle to Learn from Strong Reasoners,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Small Models Struggle to Learn from Strong Reasoners'}","Large language models (LLMs) excel in complex reasoning tasks, and distilling
their reasoning capabilities into smaller models has shown promise. However, we
uncover an interesting phenomenon, which we term the Small Model Learnability
Gap: small models ($\leq$3B parameters) do not consistently benefit from long
chain-of-thought (CoT) reasoning or distillation from larger models. Instead,
they perform better when fine-tuned on shorter, simpler reasoning chains that
better align with their intrinsic learning capacity. To address this, we
propose Mix Distillation, a simple yet effective strategy that balances
reasoning complexity by combining long and short CoT examples or reasoning from
both larger and smaller models. Our experiments demonstrate that Mix
Distillation significantly improves small model reasoning performance compared
to training on either data alone. These findings highlight the limitations of
direct strong model distillation and underscore the importance of adapting
reasoning complexity for effective reasoning capability transfer.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large language models (LLMs) excel in complex reasoning tasks, and distilling\ntheir reasoning capabilities into smaller models has shown promise. However, we\nuncover an interesting phenomenon, which we term the Small Model Learnability\nGap: small models ($\\leq$3B parameters) do not consistently benefit from long\nchain-of-thought (CoT) reasoning or distillation from larger models. Instead,\nthey perform better when fine-tuned on shorter, simpler reasoning chains that\nbetter align with their intrinsic learning capacity. To address this, we\npropose Mix Distillation, a simple yet effective strategy that balances\nreasoning complexity by combining long and short CoT examples or reasoning from\nboth larger and smaller models. Our experiments demonstrate that Mix\nDistillation significantly improves small model reasoning performance compared\nto training on either data alone. These findings highlight the limitations of\ndirect strong model distillation and underscore the importance of adapting\nreasoning complexity for effective reasoning capability transfer.'}","['Yuetai Li', 'Xiang Yue', 'Zhangchen Xu', 'Fengqing Jiang', 'Luyao Niu', 'Bill Yuchen Lin', 'Bhaskar Ramasubramanian', 'Radha Poovendran']",{'name': 'Radha Poovendran'},Radha Poovendran,,"[{'href': 'http://arxiv.org/abs/2502.12143v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12143v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12143v1,None,http://arxiv.org/abs/2502.12143v1,,,1055,0
http://arxiv.org/abs/2502.12450v1,True,2025-02-18T02:30:46Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=2, tm_min=30, tm_sec=46, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T02:30:46Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=2, tm_min=30, tm_sec=46, tm_wday=1, tm_yday=49, tm_isdst=0)","Investigating and Extending Homans' Social Exchange Theory with Large
  Language Model based Agents","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Investigating and Extending Homans' Social Exchange Theory with Large\n  Language Model based Agents""}","Homans' Social Exchange Theory (SET) is widely recognized as a basic
framework for understanding the formation and emergence of human civilizations
and social structures. In social science, this theory is typically studied
based on simple simulation experiments or real-world human studies, both of
which either lack realism or are too expensive to control. In artificial
intelligence, recent advances in large language models (LLMs) have shown
promising capabilities in simulating human behaviors. Inspired by these
insights, we adopt an interdisciplinary research perspective and propose using
LLM-based agents to study Homans' SET. Specifically, we construct a virtual
society composed of three LLM agents and have them engage in a social exchange
game to observe their behaviors. Through extensive experiments, we found that
Homans' SET is well validated in our agent society, demonstrating the
consistency between the agent and human behaviors. Building on this foundation,
we intentionally alter the settings of the agent society to extend the
traditional Homans' SET, making it more comprehensive and detailed. To the best
of our knowledge, this paper marks the first step in studying Homans' SET with
LLM-based agents. More importantly, it introduces a novel and feasible research
paradigm that bridges the fields of social science and computer science through
LLM-based agents. Code is available at https://github.com/Paitesanshi/SET.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Homans' Social Exchange Theory (SET) is widely recognized as a basic\nframework for understanding the formation and emergence of human civilizations\nand social structures. In social science, this theory is typically studied\nbased on simple simulation experiments or real-world human studies, both of\nwhich either lack realism or are too expensive to control. In artificial\nintelligence, recent advances in large language models (LLMs) have shown\npromising capabilities in simulating human behaviors. Inspired by these\ninsights, we adopt an interdisciplinary research perspective and propose using\nLLM-based agents to study Homans' SET. Specifically, we construct a virtual\nsociety composed of three LLM agents and have them engage in a social exchange\ngame to observe their behaviors. Through extensive experiments, we found that\nHomans' SET is well validated in our agent society, demonstrating the\nconsistency between the agent and human behaviors. Building on this foundation,\nwe intentionally alter the settings of the agent society to extend the\ntraditional Homans' SET, making it more comprehensive and detailed. To the best\nof our knowledge, this paper marks the first step in studying Homans' SET with\nLLM-based agents. More importantly, it introduces a novel and feasible research\nparadigm that bridges the fields of social science and computer science through\nLLM-based agents. Code is available at https://github.com/Paitesanshi/SET.""}","['Lei Wang', 'Zheqing Zhang', 'Xu Chen']",{'name': 'Xu Chen'},Xu Chen,,"[{'href': 'http://arxiv.org/abs/2502.12450v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12450v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12450v1,None,http://arxiv.org/abs/2502.12450v1,,,893,0
http://arxiv.org/abs/2502.12492v1,True,2025-02-18T03:20:50Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=3, tm_min=20, tm_sec=50, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T03:20:50Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=3, tm_min=20, tm_sec=50, tm_wday=1, tm_yday=49, tm_isdst=0)","Boost, Disentangle, and Customize: A Robust System2-to-System1 Pipeline
  for Code Generation","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Boost, Disentangle, and Customize: A Robust System2-to-System1 Pipeline\n  for Code Generation'}","Large language models (LLMs) have demonstrated remarkable capabilities in
various domains, particularly in system 1 tasks, yet the intricacies of their
problem-solving mechanisms in system 2 tasks are not sufficiently explored.
Recent research on System2-to-System1 methods surge, exploring the System 2
reasoning knowledge via inference-time computation and compressing the explored
knowledge into System 1 process. In this paper, we focus on code generation,
which is a representative System 2 task, and identify two primary challenges:
(1) the complex hidden reasoning processes and (2) the heterogeneous data
distributions that complicate the exploration and training of robust LLM
solvers. To tackle these issues, we propose a novel BDC framework that explores
insightful System 2 knowledge of LLMs using a MC-Tree-Of-Agents algorithm with
mutual \textbf{B}oosting, \textbf{D}isentangles the heterogeneous training data
for composable LoRA-experts, and obtain \textbf{C}ustomized problem solver for
each data instance with an input-aware hypernetwork to weight over the
LoRA-experts, offering effectiveness, flexibility, and robustness. This
framework leverages multiple LLMs through mutual verification and boosting,
integrated into a Monte-Carlo Tree Search process enhanced by reflection-based
pruning and refinement. Additionally, we introduce the DisenLora algorithm,
which clusters heterogeneous data to fine-tune LLMs into composable Lora
experts, enabling the adaptive generation of customized problem solvers through
an input-aware hypernetwork. This work lays the groundwork for advancing LLM
capabilities in complex reasoning tasks, offering a novel System2-to-System1
solution.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large language models (LLMs) have demonstrated remarkable capabilities in\nvarious domains, particularly in system 1 tasks, yet the intricacies of their\nproblem-solving mechanisms in system 2 tasks are not sufficiently explored.\nRecent research on System2-to-System1 methods surge, exploring the System 2\nreasoning knowledge via inference-time computation and compressing the explored\nknowledge into System 1 process. In this paper, we focus on code generation,\nwhich is a representative System 2 task, and identify two primary challenges:\n(1) the complex hidden reasoning processes and (2) the heterogeneous data\ndistributions that complicate the exploration and training of robust LLM\nsolvers. To tackle these issues, we propose a novel BDC framework that explores\ninsightful System 2 knowledge of LLMs using a MC-Tree-Of-Agents algorithm with\nmutual \\textbf{B}oosting, \\textbf{D}isentangles the heterogeneous training data\nfor composable LoRA-experts, and obtain \\textbf{C}ustomized problem solver for\neach data instance with an input-aware hypernetwork to weight over the\nLoRA-experts, offering effectiveness, flexibility, and robustness. This\nframework leverages multiple LLMs through mutual verification and boosting,\nintegrated into a Monte-Carlo Tree Search process enhanced by reflection-based\npruning and refinement. Additionally, we introduce the DisenLora algorithm,\nwhich clusters heterogeneous data to fine-tune LLMs into composable Lora\nexperts, enabling the adaptive generation of customized problem solvers through\nan input-aware hypernetwork. This work lays the groundwork for advancing LLM\ncapabilities in complex reasoning tasks, offering a novel System2-to-System1\nsolution.'}","['Kounianhua Du', 'Hanjing Wang', 'Jianxing Liu', 'Jizheng Chen', 'Xinyi Dai', 'Yasheng Wang', 'Ruiming Tang', 'Yong Yu', 'Jun Wang', 'Weinan Zhang']",{'name': 'Weinan Zhang'},Weinan Zhang,,"[{'href': 'http://arxiv.org/abs/2502.12492v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12492v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12492v1,None,http://arxiv.org/abs/2502.12492v1,,,1303,0
http://arxiv.org/abs/2502.12532v2,True,2025-02-20T06:56:20Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=6, tm_min=56, tm_sec=20, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-18T04:36:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=4, tm_min=36, tm_sec=15, tm_wday=1, tm_yday=49, tm_isdst=0)","CityEQA: A Hierarchical LLM Agent on Embodied Question Answering
  Benchmark in City Space","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'CityEQA: A Hierarchical LLM Agent on Embodied Question Answering\n  Benchmark in City Space'}","Embodied Question Answering (EQA) has primarily focused on indoor
environments, leaving the complexities of urban settings - spanning
environment, action, and perception - largely unexplored. To bridge this gap,
we introduce CityEQA, a new task where an embodied agent answers
open-vocabulary questions through active exploration in dynamic city spaces. To
support this task, we present CityEQA-EC, the first benchmark dataset featuring
1,412 human-annotated tasks across six categories, grounded in a realistic 3D
urban simulator. Moreover, we propose Planner-Manager-Actor (PMA), a novel
agent tailored for CityEQA. PMA enables long-horizon planning and hierarchical
task execution: the Planner breaks down the question answering into sub-tasks,
the Manager maintains an object-centric cognitive map for spatial reasoning
during the process control, and the specialized Actors handle navigation,
exploration, and collection sub-tasks. Experiments demonstrate that PMA
achieves 60.7% of human-level answering accuracy, significantly outperforming
frontier-based baselines. While promising, the performance gap compared to
humans highlights the need for enhanced visual reasoning in CityEQA. This work
paves the way for future advancements in urban spatial intelligence. Dataset
and code are available at https://github.com/BiluYong/CityEQA.git.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Embodied Question Answering (EQA) has primarily focused on indoor\nenvironments, leaving the complexities of urban settings - spanning\nenvironment, action, and perception - largely unexplored. To bridge this gap,\nwe introduce CityEQA, a new task where an embodied agent answers\nopen-vocabulary questions through active exploration in dynamic city spaces. To\nsupport this task, we present CityEQA-EC, the first benchmark dataset featuring\n1,412 human-annotated tasks across six categories, grounded in a realistic 3D\nurban simulator. Moreover, we propose Planner-Manager-Actor (PMA), a novel\nagent tailored for CityEQA. PMA enables long-horizon planning and hierarchical\ntask execution: the Planner breaks down the question answering into sub-tasks,\nthe Manager maintains an object-centric cognitive map for spatial reasoning\nduring the process control, and the specialized Actors handle navigation,\nexploration, and collection sub-tasks. Experiments demonstrate that PMA\nachieves 60.7% of human-level answering accuracy, significantly outperforming\nfrontier-based baselines. While promising, the performance gap compared to\nhumans highlights the need for enhanced visual reasoning in CityEQA. This work\npaves the way for future advancements in urban spatial intelligence. Dataset\nand code are available at https://github.com/BiluYong/CityEQA.git.'}","['Yong Zhao', 'Kai Xu', 'Zhengqiu Zhu', 'Yue Hu', 'Zhiheng Zheng', 'Yingfeng Chen', 'Yatai Ji', 'Chen Gao', 'Yong Li', 'Jincai Huang']",{'name': 'Jincai Huang'},Jincai Huang,,"[{'href': 'http://arxiv.org/abs/2502.12532v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12532v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12532v2,None,http://arxiv.org/abs/2502.12532v2,,,547,0
http://arxiv.org/abs/2502.12566v1,True,2025-02-18T06:07:09Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=6, tm_min=7, tm_sec=9, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T06:07:09Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=6, tm_min=7, tm_sec=9, tm_wday=1, tm_yday=49, tm_isdst=0)",Exploring the Impact of Personality Traits on LLM Bias and Toxicity,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Exploring the Impact of Personality Traits on LLM Bias and Toxicity'}","With the different roles that AI is expected to play in human life, imbuing
large language models (LLMs) with different personalities has attracted
increasing research interests. While the ""personification"" enhances human
experiences of interactivity and adaptability of LLMs, it gives rise to
critical concerns about content safety, particularly regarding bias, sentiment
and toxicity of LLM generation. This study explores how assigning different
personality traits to LLMs affects the toxicity and biases of their outputs.
Leveraging the widely accepted HEXACO personality framework developed in social
psychology, we design experimentally sound prompts to test three LLMs'
performance on three toxic and bias benchmarks. The findings demonstrate the
sensitivity of all three models to HEXACO personality traits and, more
importantly, a consistent variation in the biases, negative sentiment and
toxicity of their output. In particular, adjusting the levels of several
personality traits can effectively reduce bias and toxicity in model
performance, similar to humans' correlations between personality traits and
toxic behaviors. The findings highlight the additional need to examine content
safety besides the efficiency of training or fine-tuning methods for LLM
personification. They also suggest a potential for the adjustment of
personalities to be a simple and low-cost method to conduct controlled text
generation.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'With the different roles that AI is expected to play in human life, imbuing\nlarge language models (LLMs) with different personalities has attracted\nincreasing research interests. While the ""personification"" enhances human\nexperiences of interactivity and adaptability of LLMs, it gives rise to\ncritical concerns about content safety, particularly regarding bias, sentiment\nand toxicity of LLM generation. This study explores how assigning different\npersonality traits to LLMs affects the toxicity and biases of their outputs.\nLeveraging the widely accepted HEXACO personality framework developed in social\npsychology, we design experimentally sound prompts to test three LLMs\'\nperformance on three toxic and bias benchmarks. The findings demonstrate the\nsensitivity of all three models to HEXACO personality traits and, more\nimportantly, a consistent variation in the biases, negative sentiment and\ntoxicity of their output. In particular, adjusting the levels of several\npersonality traits can effectively reduce bias and toxicity in model\nperformance, similar to humans\' correlations between personality traits and\ntoxic behaviors. The findings highlight the additional need to examine content\nsafety besides the efficiency of training or fine-tuning methods for LLM\npersonification. They also suggest a potential for the adjustment of\npersonalities to be a simple and low-cost method to conduct controlled text\ngeneration.'}","['Shuo Wang', 'Renhao Li', 'Xi Chen', 'Yulin Yuan', 'Derek F. Wong', 'Min Yang']",{'name': 'Min Yang'},Min Yang,,"[{'href': 'http://arxiv.org/abs/2502.12566v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12566v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12566v1,None,http://arxiv.org/abs/2502.12566v1,,,37,0
http://arxiv.org/abs/2502.12589v1,True,2025-02-18T06:54:32Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=6, tm_min=54, tm_sec=32, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T06:54:32Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=6, tm_min=54, tm_sec=32, tm_wday=1, tm_yday=49, tm_isdst=0)","RM-PoT: Reformulating Mathematical Problems and Solving via Program of
  Thoughts","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'RM-PoT: Reformulating Mathematical Problems and Solving via Program of\n  Thoughts'}","Recently, substantial advancements have been made in training language models
to carry out step-by-step reasoning for solving intricate numerical reasoning
tasks. Beyond the methods used to solve these problems, the structure and
formulation of the problems themselves also play a crucial role in determining
the performance of large language models. We observe that even small changes in
the surface form of mathematical problems can have a profound impact on both
the answer distribution and solve rate. This highlights the vulnerability of
LLMs to surface-level variations, revealing its limited robustness when
reasoning through complex problems. In this paper, we propose RM-PoT, a
three-stage framework that integrates problem reformulation (RM), code-aided
reasoning (PoT), and domain-aware few-shot learning to address these
limitations. Our approach first reformulates the input problem into diverse
surface forms to reduce structural bias, then retrieves five semantically
aligned examples from a pre-constructed domain-specific question bank to
provide contextual guidance, and finally generates executable Python code for
precise computation.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Recently, substantial advancements have been made in training language models\nto carry out step-by-step reasoning for solving intricate numerical reasoning\ntasks. Beyond the methods used to solve these problems, the structure and\nformulation of the problems themselves also play a crucial role in determining\nthe performance of large language models. We observe that even small changes in\nthe surface form of mathematical problems can have a profound impact on both\nthe answer distribution and solve rate. This highlights the vulnerability of\nLLMs to surface-level variations, revealing its limited robustness when\nreasoning through complex problems. In this paper, we propose RM-PoT, a\nthree-stage framework that integrates problem reformulation (RM), code-aided\nreasoning (PoT), and domain-aware few-shot learning to address these\nlimitations. Our approach first reformulates the input problem into diverse\nsurface forms to reduce structural bias, then retrieves five semantically\naligned examples from a pre-constructed domain-specific question bank to\nprovide contextual guidance, and finally generates executable Python code for\nprecise computation.'}","['Yu Zhang', 'Shujun Peng', 'Nengwu Wu', 'Xinhan Lin', 'Yang Hu', 'Jie Tang']",{'name': 'Jie Tang'},Jie Tang,,"[{'href': 'http://arxiv.org/abs/2502.12589v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12589v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12589v1,None,http://arxiv.org/abs/2502.12589v1,,,0,0
http://arxiv.org/abs/2502.12669v1,True,2025-02-18T09:19:24Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=9, tm_min=19, tm_sec=24, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T09:19:24Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=9, tm_min=19, tm_sec=24, tm_wday=1, tm_yday=49, tm_isdst=0)","Perovskite-LLM: Knowledge-Enhanced Large Language Models for Perovskite
  Solar Cell Research","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Perovskite-LLM: Knowledge-Enhanced Large Language Models for Perovskite\n  Solar Cell Research'}","The rapid advancement of perovskite solar cells (PSCs) has led to an
exponential growth in research publications, creating an urgent need for
efficient knowledge management and reasoning systems in this domain. We present
a comprehensive knowledge-enhanced system for PSCs that integrates three key
components. First, we develop Perovskite-KG, a domain-specific knowledge graph
constructed from 1,517 research papers, containing 23,789 entities and 22,272
relationships. Second, we create two complementary datasets: Perovskite-Chat,
comprising 55,101 high-quality question-answer pairs generated through a novel
multi-agent framework, and Perovskite-Reasoning, containing 2,217 carefully
curated materials science problems. Third, we introduce two specialized large
language models: Perovskite-Chat-LLM for domain-specific knowledge assistance
and Perovskite-Reasoning-LLM for scientific reasoning tasks. Experimental
results demonstrate that our system significantly outperforms existing models
in both domain-specific knowledge retrieval and scientific reasoning tasks,
providing researchers with effective tools for literature review, experimental
design, and complex problem-solving in PSC research.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The rapid advancement of perovskite solar cells (PSCs) has led to an\nexponential growth in research publications, creating an urgent need for\nefficient knowledge management and reasoning systems in this domain. We present\na comprehensive knowledge-enhanced system for PSCs that integrates three key\ncomponents. First, we develop Perovskite-KG, a domain-specific knowledge graph\nconstructed from 1,517 research papers, containing 23,789 entities and 22,272\nrelationships. Second, we create two complementary datasets: Perovskite-Chat,\ncomprising 55,101 high-quality question-answer pairs generated through a novel\nmulti-agent framework, and Perovskite-Reasoning, containing 2,217 carefully\ncurated materials science problems. Third, we introduce two specialized large\nlanguage models: Perovskite-Chat-LLM for domain-specific knowledge assistance\nand Perovskite-Reasoning-LLM for scientific reasoning tasks. Experimental\nresults demonstrate that our system significantly outperforms existing models\nin both domain-specific knowledge retrieval and scientific reasoning tasks,\nproviding researchers with effective tools for literature review, experimental\ndesign, and complex problem-solving in PSC research.'}","['Xiang Liu', 'Penglei Sun', 'Shuyan Chen', 'Longhan Zhang', 'Peijie Dong', 'Huajie You', 'Yongqi Zhang', 'Chang Yan', 'Xiaowen Chu', 'Tong-yi Zhang']",{'name': 'Tong-yi Zhang'},Tong-yi Zhang,23pages,"[{'href': 'http://arxiv.org/abs/2502.12669v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12669v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12669v1,None,http://arxiv.org/abs/2502.12669v1,,,262,0
http://arxiv.org/abs/2502.12782v1,True,2025-02-18T11:42:17Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=11, tm_min=42, tm_sec=17, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T11:42:17Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=11, tm_min=42, tm_sec=17, tm_wday=1, tm_yday=49, tm_isdst=0)","VidCapBench: A Comprehensive Benchmark of Video Captioning for
  Controllable Text-to-Video Generation","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'VidCapBench: A Comprehensive Benchmark of Video Captioning for\n  Controllable Text-to-Video Generation'}","The training of controllable text-to-video (T2V) models relies heavily on the
alignment between videos and captions, yet little existing research connects
video caption evaluation with T2V generation assessment. This paper introduces
VidCapBench, a video caption evaluation scheme specifically designed for T2V
generation, agnostic to any particular caption format. VidCapBench employs a
data annotation pipeline, combining expert model labeling and human refinement,
to associate each collected video with key information spanning video
aesthetics, content, motion, and physical laws. VidCapBench then partitions
these key information attributes into automatically assessable and manually
assessable subsets, catering to both the rapid evaluation needs of agile
development and the accuracy requirements of thorough validation. By evaluating
numerous state-of-the-art captioning models, we demonstrate the superior
stability and comprehensiveness of VidCapBench compared to existing video
captioning evaluation approaches. Verification with off-the-shelf T2V models
reveals a significant positive correlation between scores on VidCapBench and
the T2V quality evaluation metrics, indicating that VidCapBench can provide
valuable guidance for training T2V models. The project is available at
https://github.com/VidCapBench/VidCapBench.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The training of controllable text-to-video (T2V) models relies heavily on the\nalignment between videos and captions, yet little existing research connects\nvideo caption evaluation with T2V generation assessment. This paper introduces\nVidCapBench, a video caption evaluation scheme specifically designed for T2V\ngeneration, agnostic to any particular caption format. VidCapBench employs a\ndata annotation pipeline, combining expert model labeling and human refinement,\nto associate each collected video with key information spanning video\naesthetics, content, motion, and physical laws. VidCapBench then partitions\nthese key information attributes into automatically assessable and manually\nassessable subsets, catering to both the rapid evaluation needs of agile\ndevelopment and the accuracy requirements of thorough validation. By evaluating\nnumerous state-of-the-art captioning models, we demonstrate the superior\nstability and comprehensiveness of VidCapBench compared to existing video\ncaptioning evaluation approaches. Verification with off-the-shelf T2V models\nreveals a significant positive correlation between scores on VidCapBench and\nthe T2V quality evaluation metrics, indicating that VidCapBench can provide\nvaluable guidance for training T2V models. The project is available at\nhttps://github.com/VidCapBench/VidCapBench.'}","['Xinlong Chen', 'Yuanxing Zhang', 'Chongling Rao', 'Yushuo Guan', 'Jiaheng Liu', 'Fuzheng Zhang', 'Chengru Song', 'Qiang Liu', 'Di Zhang', 'Tieniu Tan']",{'name': 'Tieniu Tan'},Tieniu Tan,,"[{'href': 'http://arxiv.org/abs/2502.12782v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12782v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12782v1,None,http://arxiv.org/abs/2502.12782v1,,,55,0
http://arxiv.org/abs/2502.12876v1,True,2025-02-18T14:05:59Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=14, tm_min=5, tm_sec=59, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T14:05:59Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=14, tm_min=5, tm_sec=59, tm_wday=1, tm_yday=49, tm_isdst=0)","Continuous Learning Conversational AI: A Personalized Agent Framework
  via A2C Reinforcement Learning","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Continuous Learning Conversational AI: A Personalized Agent Framework\n  via A2C Reinforcement Learning'}","Creating personalized and adaptable conversational AI remains a key
challenge. This paper introduces a Continuous Learning Conversational AI (CLCA)
approach, implemented using A2C reinforcement learning, to move beyond static
Large Language Models (LLMs). We use simulated sales dialogues, generated by
LLMs, to train an A2C agent. This agent learns to optimize conversation
strategies for personalization, focusing on engagement and delivering value.
Our system architecture integrates reinforcement learning with LLMs for both
data creation and response selection. This method offers a practical way to
build personalized AI companions that evolve through continuous learning,
advancing beyond traditional static LLM techniques.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Creating personalized and adaptable conversational AI remains a key\nchallenge. This paper introduces a Continuous Learning Conversational AI (CLCA)\napproach, implemented using A2C reinforcement learning, to move beyond static\nLarge Language Models (LLMs). We use simulated sales dialogues, generated by\nLLMs, to train an A2C agent. This agent learns to optimize conversation\nstrategies for personalization, focusing on engagement and delivering value.\nOur system architecture integrates reinforcement learning with LLMs for both\ndata creation and response selection. This method offers a practical way to\nbuild personalized AI companions that evolve through continuous learning,\nadvancing beyond traditional static LLM techniques.'}","['Nandakishor M', 'Anjali M']",{'name': 'Anjali M'},Anjali M,,"[{'href': 'http://arxiv.org/abs/2502.12876v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12876v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12876v1,None,http://arxiv.org/abs/2502.12876v1,,,0,0
http://arxiv.org/abs/2502.12926v1,True,2025-02-18T15:07:06Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=15, tm_min=7, tm_sec=6, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T15:07:06Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=15, tm_min=7, tm_sec=6, tm_wday=1, tm_yday=49, tm_isdst=0)","Towards more Contextual Agents: An extractor-Generator Optimization
  Framework","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Towards more Contextual Agents: An extractor-Generator Optimization\n  Framework'}","Large Language Model (LLM)-based agents have demonstrated remarkable success
in solving complex tasks across a wide range of general-purpose applications.
However, their performance often degrades in context-specific scenarios, such
as specialized industries or research domains, where the absence of
domain-relevant knowledge leads to imprecise or suboptimal outcomes. To address
this challenge, our work introduces a systematic approach to enhance the
contextual adaptability of LLM-based agents by optimizing their underlying
prompts-critical components that govern agent behavior, roles, and
interactions. Manually crafting optimized prompts for context-specific tasks is
labor-intensive, error-prone, and lacks scalability. In this work, we introduce
an Extractor-Generator framework designed to automate the optimization of
contextual LLM-based agents. Our method operates through two key stages: (i)
feature extraction from a dataset of gold-standard input-output examples, and
(ii) prompt generation via a high-level optimization strategy that iteratively
identifies underperforming cases and applies self-improvement techniques. This
framework substantially improves prompt adaptability by enabling more precise
generalization across diverse inputs, particularly in context-specific tasks
where maintaining semantic consistency and minimizing error propagation are
critical for reliable performance. Although developed with single-stage
workflows in mind, the approach naturally extends to multi-stage workflows,
offering broad applicability across various agent-based systems. Empirical
evaluations demonstrate that our framework significantly enhances the
performance of prompt-optimized agents, providing a structured and efficient
approach to contextual LLM-based agents.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Language Model (LLM)-based agents have demonstrated remarkable success\nin solving complex tasks across a wide range of general-purpose applications.\nHowever, their performance often degrades in context-specific scenarios, such\nas specialized industries or research domains, where the absence of\ndomain-relevant knowledge leads to imprecise or suboptimal outcomes. To address\nthis challenge, our work introduces a systematic approach to enhance the\ncontextual adaptability of LLM-based agents by optimizing their underlying\nprompts-critical components that govern agent behavior, roles, and\ninteractions. Manually crafting optimized prompts for context-specific tasks is\nlabor-intensive, error-prone, and lacks scalability. In this work, we introduce\nan Extractor-Generator framework designed to automate the optimization of\ncontextual LLM-based agents. Our method operates through two key stages: (i)\nfeature extraction from a dataset of gold-standard input-output examples, and\n(ii) prompt generation via a high-level optimization strategy that iteratively\nidentifies underperforming cases and applies self-improvement techniques. This\nframework substantially improves prompt adaptability by enabling more precise\ngeneralization across diverse inputs, particularly in context-specific tasks\nwhere maintaining semantic consistency and minimizing error propagation are\ncritical for reliable performance. Although developed with single-stage\nworkflows in mind, the approach naturally extends to multi-stage workflows,\noffering broad applicability across various agent-based systems. Empirical\nevaluations demonstrate that our framework significantly enhances the\nperformance of prompt-optimized agents, providing a structured and efficient\napproach to contextual LLM-based agents.'}","['Mourad Aouini', 'Jinan Loubani']",{'name': 'Jinan Loubani'},Jinan Loubani,,"[{'href': 'http://arxiv.org/abs/2502.12926v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12926v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12926v1,None,http://arxiv.org/abs/2502.12926v1,,,3,0
http://arxiv.org/abs/2502.12995v1,True,2025-02-18T16:15:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=16, tm_min=15, tm_sec=36, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T16:15:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=16, tm_min=15, tm_sec=36, tm_wday=1, tm_yday=49, tm_isdst=0)",Free Argumentative Exchanges for Explaining Image Classifiers,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Free Argumentative Exchanges for Explaining Image Classifiers'}","Deep learning models are powerful image classifiers but their opacity hinders
their trustworthiness. Explanation methods for capturing the reasoning process
within these classifiers faithfully and in a clear manner are scarce, due to
their sheer complexity and size. We provide a solution for this problem by
defining a novel method for explaining the outputs of image classifiers with
debates between two agents, each arguing for a particular class. We obtain
these debates as concrete instances of Free Argumentative eXchanges (FAXs), a
novel argumentation-based multi-agent framework allowing agents to internalise
opinions by other agents differently than originally stated. We define two
metrics (consensus and persuasion rate) to assess the usefulness of FAXs as
argumentative explanations for image classifiers. We then conduct a number of
empirical experiments showing that FAXs perform well along these metrics as
well as being more faithful to the image classifiers than conventional,
non-argumentative explanation methods. All our implementations can be found at
https://github.com/koriavinash1/FAX.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Deep learning models are powerful image classifiers but their opacity hinders\ntheir trustworthiness. Explanation methods for capturing the reasoning process\nwithin these classifiers faithfully and in a clear manner are scarce, due to\ntheir sheer complexity and size. We provide a solution for this problem by\ndefining a novel method for explaining the outputs of image classifiers with\ndebates between two agents, each arguing for a particular class. We obtain\nthese debates as concrete instances of Free Argumentative eXchanges (FAXs), a\nnovel argumentation-based multi-agent framework allowing agents to internalise\nopinions by other agents differently than originally stated. We define two\nmetrics (consensus and persuasion rate) to assess the usefulness of FAXs as\nargumentative explanations for image classifiers. We then conduct a number of\nempirical experiments showing that FAXs perform well along these metrics as\nwell as being more faithful to the image classifiers than conventional,\nnon-argumentative explanation methods. All our implementations can be found at\nhttps://github.com/koriavinash1/FAX.'}","['Avinash Kori', 'Antonio Rago', 'Francesca Toni']",{'name': 'Francesca Toni'},Francesca Toni,"10 pages, 3 figures. To be published at AAMAS 2025","[{'href': 'http://arxiv.org/abs/2502.12995v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12995v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12995v1,None,http://arxiv.org/abs/2502.12995v1,,,1894,0
http://arxiv.org/abs/2502.13006v1,True,2025-02-18T16:26:21Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=16, tm_min=26, tm_sec=21, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T16:26:21Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=16, tm_min=26, tm_sec=21, tm_wday=1, tm_yday=49, tm_isdst=0)","Integrating Reinforcement Learning, Action Model Learning, and Numeric
  Planning for Tackling Complex Tasks","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Integrating Reinforcement Learning, Action Model Learning, and Numeric\n  Planning for Tackling Complex Tasks'}","Automated Planning algorithms require a model of the domain that specifies
the preconditions and effects of each action. Obtaining such a domain model is
notoriously hard. Algorithms for learning domain models exist, yet it remains
unclear whether learning a domain model and planning is an effective approach
for numeric planning environments, i.e., where states include discrete and
numeric state variables. In this work, we explore the benefits of learning a
numeric domain model and compare it with alternative model-free solutions. As a
case study, we use two tasks in Minecraft, a popular sandbox game that has been
used as an AI challenge. First, we consider an offline learning setting, where
a set of expert trajectories are available to learn from. This is the standard
setting for learning domain models. We used the Numeric Safe Action Model
Learning (NSAM) algorithm to learn a numeric domain model and solve new
problems with the learned domain model and a numeric planner. We call this
model-based solution NSAM_(+p), and compare it to several model-free Imitation
Learning (IL) and Offline Reinforcement Learning (RL) algorithms. Empirical
results show that some IL algorithms can learn faster to solve simple tasks,
while NSAM_(+p) allows solving tasks that require long-term planning and
enables generalizing to solve problems in larger environments. Then, we
consider an online learning setting, where learning is done by moving an agent
in the environment. For this setting, we introduce RAMP. In RAMP, observations
collected during the agent's execution are used to simultaneously train an RL
policy and learn a planning domain action model. This forms a positive feedback
loop between the RL policy and the learned domain model. We demonstrate
experimentally the benefits of using RAMP, showing that it finds more efficient
plans and solves more problems than several RL baselines.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Automated Planning algorithms require a model of the domain that specifies\nthe preconditions and effects of each action. Obtaining such a domain model is\nnotoriously hard. Algorithms for learning domain models exist, yet it remains\nunclear whether learning a domain model and planning is an effective approach\nfor numeric planning environments, i.e., where states include discrete and\nnumeric state variables. In this work, we explore the benefits of learning a\nnumeric domain model and compare it with alternative model-free solutions. As a\ncase study, we use two tasks in Minecraft, a popular sandbox game that has been\nused as an AI challenge. First, we consider an offline learning setting, where\na set of expert trajectories are available to learn from. This is the standard\nsetting for learning domain models. We used the Numeric Safe Action Model\nLearning (NSAM) algorithm to learn a numeric domain model and solve new\nproblems with the learned domain model and a numeric planner. We call this\nmodel-based solution NSAM_(+p), and compare it to several model-free Imitation\nLearning (IL) and Offline Reinforcement Learning (RL) algorithms. Empirical\nresults show that some IL algorithms can learn faster to solve simple tasks,\nwhile NSAM_(+p) allows solving tasks that require long-term planning and\nenables generalizing to solve problems in larger environments. Then, we\nconsider an online learning setting, where learning is done by moving an agent\nin the environment. For this setting, we introduce RAMP. In RAMP, observations\ncollected during the agent's execution are used to simultaneously train an RL\npolicy and learn a planning domain action model. This forms a positive feedback\nloop between the RL policy and the learned domain model. We demonstrate\nexperimentally the benefits of using RAMP, showing that it finds more efficient\nplans and solves more problems than several RL baselines.""}","['Yarin Benyamin', 'Argaman Mordoch', 'Shahaf S. Shperberg', 'Roni Stern']",{'name': 'Roni Stern'},Roni Stern,,"[{'href': 'http://arxiv.org/abs/2502.13006v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13006v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13006v1,None,http://arxiv.org/abs/2502.13006v1,,,5362,0
http://arxiv.org/abs/2502.13069v1,True,2025-02-18T17:12:26Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=17, tm_min=12, tm_sec=26, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T17:12:26Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=17, tm_min=12, tm_sec=26, tm_wday=1, tm_yday=49, tm_isdst=0)",Interactive Agents to Overcome Ambiguity in Software Engineering,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Interactive Agents to Overcome Ambiguity in Software Engineering'}","AI agents are increasingly being deployed to automate tasks, often based on
ambiguous and underspecified user instructions. Making unwarranted assumptions
and failing to ask clarifying questions can lead to suboptimal outcomes, safety
risks due to tool misuse, and wasted computational resources. In this work, we
study the ability of LLM agents to handle ambiguous instructions in interactive
code generation settings by evaluating proprietary and open-weight models on
their performance across three key steps: (a) leveraging interactivity to
improve performance in ambiguous scenarios, (b) detecting ambiguity, and (c)
asking targeted questions. Our findings reveal that models struggle to
distinguish between well-specified and underspecified instructions. However,
when models interact for underspecified inputs, they effectively obtain vital
information from the user, leading to significant improvements in performance
and underscoring the value of effective interaction. Our study highlights
critical gaps in how current state-of-the-art models handle ambiguity in
complex software engineering tasks and structures the evaluation into distinct
steps to enable targeted improvements.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'AI agents are increasingly being deployed to automate tasks, often based on\nambiguous and underspecified user instructions. Making unwarranted assumptions\nand failing to ask clarifying questions can lead to suboptimal outcomes, safety\nrisks due to tool misuse, and wasted computational resources. In this work, we\nstudy the ability of LLM agents to handle ambiguous instructions in interactive\ncode generation settings by evaluating proprietary and open-weight models on\ntheir performance across three key steps: (a) leveraging interactivity to\nimprove performance in ambiguous scenarios, (b) detecting ambiguity, and (c)\nasking targeted questions. Our findings reveal that models struggle to\ndistinguish between well-specified and underspecified instructions. However,\nwhen models interact for underspecified inputs, they effectively obtain vital\ninformation from the user, leading to significant improvements in performance\nand underscoring the value of effective interaction. Our study highlights\ncritical gaps in how current state-of-the-art models handle ambiguity in\ncomplex software engineering tasks and structures the evaluation into distinct\nsteps to enable targeted improvements.'}","['Sanidhya Vijayvargiya', 'Xuhui Zhou', 'Akhila Yerukola', 'Maarten Sap', 'Graham Neubig']",{'name': 'Graham Neubig'},Graham Neubig,"15 pages, 5 figures","[{'href': 'http://arxiv.org/abs/2502.13069v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13069v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13069v1,None,http://arxiv.org/abs/2502.13069v1,,,10121,0
http://arxiv.org/abs/2502.13137v1,True,2025-02-18T18:57:09Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=57, tm_sec=9, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T18:57:09Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=57, tm_sec=9, tm_wday=1, tm_yday=49, tm_isdst=0)",Theorem Prover as a Judge for Synthetic Data Generation,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Theorem Prover as a Judge for Synthetic Data Generation'}","The demand for synthetic data in mathematical reasoning has increased due to
its potential to enhance the mathematical capabilities of large language models
(LLMs). However, ensuring the validity of intermediate reasoning steps remains
a significant challenge, affecting data quality. While formal verification via
theorem provers effectively validates LLM reasoning, the autoformalisation of
mathematical proofs remains error-prone. In response, we introduce iterative
autoformalisation, an approach that iteratively refines theorem prover
formalisation to mitigate errors, thereby increasing the execution rate on the
Lean prover from 60% to 87%. Building upon that, we introduce Theorem Prover as
a Judge (TP-as-a-Judge), a method that employs theorem prover formalisation to
rigorously assess LLM intermediate reasoning, effectively integrating
autoformalisation with synthetic data generation. Finally, we present
Reinforcement Learning from Theorem Prover Feedback (RLTPF), a framework that
replaces human annotation with theorem prover feedback in Reinforcement
Learning from Human Feedback (RLHF). Across multiple LLMs, applying
TP-as-a-Judge and RLTPF improves benchmarks with only 3,508 samples, achieving
5.56% accuracy gain on Mistral-7B for MultiArith, 6.00% on Llama-2-7B for
SVAMP, and 3.55% on Llama-3.1-8B for AQUA.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The demand for synthetic data in mathematical reasoning has increased due to\nits potential to enhance the mathematical capabilities of large language models\n(LLMs). However, ensuring the validity of intermediate reasoning steps remains\na significant challenge, affecting data quality. While formal verification via\ntheorem provers effectively validates LLM reasoning, the autoformalisation of\nmathematical proofs remains error-prone. In response, we introduce iterative\nautoformalisation, an approach that iteratively refines theorem prover\nformalisation to mitigate errors, thereby increasing the execution rate on the\nLean prover from 60% to 87%. Building upon that, we introduce Theorem Prover as\na Judge (TP-as-a-Judge), a method that employs theorem prover formalisation to\nrigorously assess LLM intermediate reasoning, effectively integrating\nautoformalisation with synthetic data generation. Finally, we present\nReinforcement Learning from Theorem Prover Feedback (RLTPF), a framework that\nreplaces human annotation with theorem prover feedback in Reinforcement\nLearning from Human Feedback (RLHF). Across multiple LLMs, applying\nTP-as-a-Judge and RLTPF improves benchmarks with only 3,508 samples, achieving\n5.56% accuracy gain on Mistral-7B for MultiArith, 6.00% on Llama-2-7B for\nSVAMP, and 3.55% on Llama-3.1-8B for AQUA.'}","['Joshua Ong Jun Leang', 'Giwon Hong', 'Wenda Li', 'Shay B. Cohen']",{'name': 'Shay B. Cohen'},Shay B. Cohen,,"[{'href': 'http://arxiv.org/abs/2502.13137v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13137v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13137v1,None,http://arxiv.org/abs/2502.13137v1,,,15,0
http://arxiv.org/abs/2502.13295v1,True,2025-02-18T21:32:24Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=21, tm_min=32, tm_sec=24, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T21:32:24Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=21, tm_min=32, tm_sec=24, tm_wday=1, tm_yday=49, tm_isdst=0)",Demonstrating specification gaming in reasoning models,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Demonstrating specification gaming in reasoning models'}","We demonstrate LLM agent specification gaming by instructing models to win
against a chess engine. We find reasoning models like o1 preview and
DeepSeek-R1 will often hack the benchmark by default, while language models
like GPT-4o and Claude 3.5 Sonnet need to be told that normal play won't work
to hack.
  We improve upon prior work like (Hubinger et al., 2024; Meinke et al., 2024;
Weij et al., 2024) by using realistic task prompts and avoiding excess nudging.
Our results suggest reasoning models may resort to hacking to solve difficult
problems, as observed in OpenAI (2024)'s o1 Docker escape during cyber
capabilities testing.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""We demonstrate LLM agent specification gaming by instructing models to win\nagainst a chess engine. We find reasoning models like o1 preview and\nDeepSeek-R1 will often hack the benchmark by default, while language models\nlike GPT-4o and Claude 3.5 Sonnet need to be told that normal play won't work\nto hack.\n  We improve upon prior work like (Hubinger et al., 2024; Meinke et al., 2024;\nWeij et al., 2024) by using realistic task prompts and avoiding excess nudging.\nOur results suggest reasoning models may resort to hacking to solve difficult\nproblems, as observed in OpenAI (2024)'s o1 Docker escape during cyber\ncapabilities testing.""}","['Alexander Bondarenko', 'Denis Volk', 'Dmitrii Volkov', 'Jeffrey Ladish']",{'name': 'Jeffrey Ladish'},Jeffrey Ladish,,"[{'href': 'http://arxiv.org/abs/2502.13295v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13295v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13295v1,None,http://arxiv.org/abs/2502.13295v1,,,1312,0
http://arxiv.org/abs/2502.13373v1,True,2025-02-19T02:14:27Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=2, tm_min=14, tm_sec=27, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T02:14:27Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=2, tm_min=14, tm_sec=27, tm_wday=2, tm_yday=50, tm_isdst=0)","Fighter Jet Navigation and Combat using Deep Reinforcement Learning with
  Explainable AI","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Fighter Jet Navigation and Combat using Deep Reinforcement Learning with\n  Explainable AI'}","This paper presents the development of an Artificial Intelligence (AI) based
fighter jet agent within a customized Pygame simulation environment, designed
to solve multi-objective tasks via deep reinforcement learning (DRL). The jet's
primary objectives include efficiently navigating the environment, reaching a
target, and selectively engaging or evading an enemy. A reward function
balances these goals while optimized hyperparameters enhance learning
efficiency. Results show more than 80\% task completion rate, demonstrating
effective decision-making. To enhance transparency, the jet's action choices
are analyzed by comparing the rewards of the actual chosen action (factual
action) with those of alternate actions (counterfactual actions), providing
insights into the decision-making rationale. This study illustrates DRL's
potential for multi-objective problem-solving with explainable AI. Project page
is available at:
\href{https://github.com/swatikar95/Autonomous-Fighter-Jet-Navigation-and-Combat}{Project
GitHub Link}.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""This paper presents the development of an Artificial Intelligence (AI) based\nfighter jet agent within a customized Pygame simulation environment, designed\nto solve multi-objective tasks via deep reinforcement learning (DRL). The jet's\nprimary objectives include efficiently navigating the environment, reaching a\ntarget, and selectively engaging or evading an enemy. A reward function\nbalances these goals while optimized hyperparameters enhance learning\nefficiency. Results show more than 80\\% task completion rate, demonstrating\neffective decision-making. To enhance transparency, the jet's action choices\nare analyzed by comparing the rewards of the actual chosen action (factual\naction) with those of alternate actions (counterfactual actions), providing\ninsights into the decision-making rationale. This study illustrates DRL's\npotential for multi-objective problem-solving with explainable AI. Project page\nis available at:\n\\href{https://github.com/swatikar95/Autonomous-Fighter-Jet-Navigation-and-Combat}{Project\nGitHub Link}.""}","['Swati Kar', 'Soumyabrata Dey', 'Mahesh K Banavar', 'Shahnewaz Karim Sakib']",{'name': 'Shahnewaz Karim Sakib'},Shahnewaz Karim Sakib,,"[{'href': 'http://arxiv.org/abs/2502.13373v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13373v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13373v1,None,http://arxiv.org/abs/2502.13373v1,,,1379,0
http://arxiv.org/abs/2502.13388v1,True,2025-02-19T02:53:43Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=2, tm_min=53, tm_sec=43, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T02:53:43Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=2, tm_min=53, tm_sec=43, tm_wday=2, tm_yday=50, tm_isdst=0)","Reflection of Episodes: Learning to Play Game from Expert and Self
  Experiences","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Reflection of Episodes: Learning to Play Game from Expert and Self\n  Experiences'}","StarCraft II is a complex and dynamic real-time strategy (RTS) game
environment, which is very suitable for artificial intelligence and
reinforcement learning research. To address the problem of Large Language
Model(LLM) learning in complex environments through self-reflection, we propose
a Reflection of Episodes(ROE) framework based on expert experience and
self-experience. This framework first obtains key information in the game
through a keyframe selection method, then makes decisions based on expert
experience and self-experience. After a game is completed, it reflects on the
previous experience to obtain new self-experience. Finally, in the experiment,
our method beat the robot under the Very Hard difficulty in TextStarCraft II.
We analyze the data of the LLM in the process of the game in detail, verified
its effectiveness.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'StarCraft II is a complex and dynamic real-time strategy (RTS) game\nenvironment, which is very suitable for artificial intelligence and\nreinforcement learning research. To address the problem of Large Language\nModel(LLM) learning in complex environments through self-reflection, we propose\na Reflection of Episodes(ROE) framework based on expert experience and\nself-experience. This framework first obtains key information in the game\nthrough a keyframe selection method, then makes decisions based on expert\nexperience and self-experience. After a game is completed, it reflects on the\nprevious experience to obtain new self-experience. Finally, in the experiment,\nour method beat the robot under the Very Hard difficulty in TextStarCraft II.\nWe analyze the data of the LLM in the process of the game in detail, verified\nits effectiveness.'}","['Xiaojie Xu', 'Zongyuan Li', 'Chang Lu', 'Runnan Qi', 'Yanan Ni', 'Lumin Jiang', 'Xiangbei Liu', 'Xuebo Zhang', 'Yongchun Fang', 'Kuihua Huang', 'Xian Guo', 'Zhanghua Wu', 'Zhenya Li']",{'name': 'Zhenya Li'},Zhenya Li,,"[{'href': 'http://arxiv.org/abs/2502.13388v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13388v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13388v1,None,http://arxiv.org/abs/2502.13388v1,,,6,0
http://arxiv.org/abs/2502.13389v1,True,2025-02-19T02:59:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=2, tm_min=59, tm_sec=42, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T02:59:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=2, tm_min=59, tm_sec=42, tm_wday=2, tm_yday=50, tm_isdst=0)",Reasoning with Reinforced Functional Token Tuning,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Reasoning with Reinforced Functional Token Tuning'}","In this work, we propose Reinforced Functional Token Tuning (RFTT), a novel
reinforced fine-tuning framework that empowers Large Language Models (LLMs)
with self-play learn-to-reason capabilities. Unlike prior prompt-driven
reasoning efforts, RFTT embeds a rich set of learnable functional tokens (e.g.,
<analyze>, <verify>, <refine>) directly into the model vocabulary, enabling
chain-of-thought construction with diverse human-like reasoning behaviors.
Specifically, RFTT comprises two phases: (1) supervised fine-tuning performs
prompt-driven tree search to obtain self-generated training data annotated with
functional tokens, which warms up the model to learn these tokens for
reasoning; and (2) online reinforcement learning further allows the model to
explore different reasoning pathways through functional token sampling without
relying on prompts, thereby facilitating effective self-improvement for
functional reasoning. Extensive experiments demonstrate the superiority of the
proposed RFTT on mathematical benchmarks, significantly boosting
Qwen-2.5-7B-Instruct (70.6% to 79.8%) and LLaMA-3.1-8B-Instruct (32.2% to
60.2%) on the MATH dataset. Moreover, the performance of RFTT consistently
improves with more search rollouts at inference time. Our code is available at
https://github.com/sastpg/RFTT.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'In this work, we propose Reinforced Functional Token Tuning (RFTT), a novel\nreinforced fine-tuning framework that empowers Large Language Models (LLMs)\nwith self-play learn-to-reason capabilities. Unlike prior prompt-driven\nreasoning efforts, RFTT embeds a rich set of learnable functional tokens (e.g.,\n<analyze>, <verify>, <refine>) directly into the model vocabulary, enabling\nchain-of-thought construction with diverse human-like reasoning behaviors.\nSpecifically, RFTT comprises two phases: (1) supervised fine-tuning performs\nprompt-driven tree search to obtain self-generated training data annotated with\nfunctional tokens, which warms up the model to learn these tokens for\nreasoning; and (2) online reinforcement learning further allows the model to\nexplore different reasoning pathways through functional token sampling without\nrelying on prompts, thereby facilitating effective self-improvement for\nfunctional reasoning. Extensive experiments demonstrate the superiority of the\nproposed RFTT on mathematical benchmarks, significantly boosting\nQwen-2.5-7B-Instruct (70.6% to 79.8%) and LLaMA-3.1-8B-Instruct (32.2% to\n60.2%) on the MATH dataset. Moreover, the performance of RFTT consistently\nimproves with more search rollouts at inference time. Our code is available at\nhttps://github.com/sastpg/RFTT.'}","['Kongcheng Zhang', 'Qi Yao', 'Baisheng Lai', 'Jiaxing Huang', 'Wenkai Fang', 'Dacheng Tao', 'Mingli Song', 'Shunyu Liu']",{'name': 'Shunyu Liu'},Shunyu Liu,,"[{'href': 'http://arxiv.org/abs/2502.13389v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13389v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13389v1,None,http://arxiv.org/abs/2502.13389v1,,,6,0
http://arxiv.org/abs/2502.13392v1,True,2025-02-19T03:05:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=3, tm_min=5, tm_sec=23, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T03:05:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=3, tm_min=5, tm_sec=23, tm_wday=2, tm_yday=50, tm_isdst=0)","Atomic Proximal Policy Optimization for Electric Robo-Taxi Dispatch and
  Charger Allocation","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Atomic Proximal Policy Optimization for Electric Robo-Taxi Dispatch and\n  Charger Allocation'}","Pioneering companies such as Waymo have deployed robo-taxi services in
several U.S. cities. These robo-taxis are electric vehicles, and their
operations require the joint optimization of ride matching, vehicle
repositioning, and charging scheduling in a stochastic environment. We model
the operations of the ride-hailing system with robo-taxis as a discrete-time,
average reward Markov Decision Process with infinite horizon. As the fleet size
grows, the dispatching is challenging as the set of system state and the fleet
dispatching action set grow exponentially with the number of vehicles. To
address this, we introduce a scalable deep reinforcement learning algorithm,
called Atomic Proximal Policy Optimization (Atomic-PPO), that reduces the
action space using atomic action decomposition. We evaluate our algorithm using
real-world NYC for-hire vehicle data and we measure the performance using the
long-run average reward achieved by the dispatching policy relative to a
fluid-based reward upper bound. Our experiments demonstrate the superior
performance of our Atomic-PPO compared to benchmarks. Furthermore, we conduct
extensive numerical experiments to analyze the efficient allocation of charging
facilities and assess the impact of vehicle range and charger speed on fleet
performance.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Pioneering companies such as Waymo have deployed robo-taxi services in\nseveral U.S. cities. These robo-taxis are electric vehicles, and their\noperations require the joint optimization of ride matching, vehicle\nrepositioning, and charging scheduling in a stochastic environment. We model\nthe operations of the ride-hailing system with robo-taxis as a discrete-time,\naverage reward Markov Decision Process with infinite horizon. As the fleet size\ngrows, the dispatching is challenging as the set of system state and the fleet\ndispatching action set grow exponentially with the number of vehicles. To\naddress this, we introduce a scalable deep reinforcement learning algorithm,\ncalled Atomic Proximal Policy Optimization (Atomic-PPO), that reduces the\naction space using atomic action decomposition. We evaluate our algorithm using\nreal-world NYC for-hire vehicle data and we measure the performance using the\nlong-run average reward achieved by the dispatching policy relative to a\nfluid-based reward upper bound. Our experiments demonstrate the superior\nperformance of our Atomic-PPO compared to benchmarks. Furthermore, we conduct\nextensive numerical experiments to analyze the efficient allocation of charging\nfacilities and assess the impact of vehicle range and charger speed on fleet\nperformance.'}","['Jim Dai', 'Manxi Wu', 'Zhanhao Zhang']",{'name': 'Zhanhao Zhang'},Zhanhao Zhang,,"[{'href': 'http://arxiv.org/abs/2502.13392v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13392v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13392v1,None,http://arxiv.org/abs/2502.13392v1,,,0,0
http://arxiv.org/abs/2502.13516v1,True,2025-02-19T08:11:26Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=8, tm_min=11, tm_sec=26, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T08:11:26Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=8, tm_min=11, tm_sec=26, tm_wday=2, tm_yday=50, tm_isdst=0)","SPPD: Self-training with Process Preference Learning Using Dynamic Value
  Margin","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'SPPD: Self-training with Process Preference Learning Using Dynamic Value\n  Margin'}","Recently, enhancing the numerical and logical reasoning capability of Large
Language Models (LLMs) has emerged as a research hotspot. Existing methods face
several limitations: inference-phase techniques (e.g., Chain of Thoughts) rely
on prompt selection and the pretrained knowledge; sentence-level Supervised
Fine-Tuning (SFT) and Direct Preference Optimization (DPO) struggle with
step-wise mathematical correctness and depend on stronger models distillation
or human annotations; while Reinforcement Learning (RL) approaches incur high
GPU memory costs and unstable training. To address these, we propose
\textbf{S}elf-training framework integrating \textbf{P}rocess
\textbf{P}reference learning using \textbf{D}ynamic value margin (SPPD). SPPD
leverages a process-based Markov Decision Process (MDP) and Bellman optimality
equation to derive \textbf{dynamic value margin} on step-level preference
optimization, which employs tree-based self-sampling on model responses
\textbf{without any distillation} from other models. Furthermore, we
theoretically prove that SPPD is \textbf{equivalent to on-policy policy
gradient methods} under reward constraints. Experiments on 7B-scale models
demonstrate superior performance across in-domain and out-domain mathematical
benchmarks. We open-source our code at
\href{https://anonymous.4open.science/r/SSDPO-D-DCDD}{https://anonymous.4open.science/r/SPPD-DCDD}.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Recently, enhancing the numerical and logical reasoning capability of Large\nLanguage Models (LLMs) has emerged as a research hotspot. Existing methods face\nseveral limitations: inference-phase techniques (e.g., Chain of Thoughts) rely\non prompt selection and the pretrained knowledge; sentence-level Supervised\nFine-Tuning (SFT) and Direct Preference Optimization (DPO) struggle with\nstep-wise mathematical correctness and depend on stronger models distillation\nor human annotations; while Reinforcement Learning (RL) approaches incur high\nGPU memory costs and unstable training. To address these, we propose\n\\textbf{S}elf-training framework integrating \\textbf{P}rocess\n\\textbf{P}reference learning using \\textbf{D}ynamic value margin (SPPD). SPPD\nleverages a process-based Markov Decision Process (MDP) and Bellman optimality\nequation to derive \\textbf{dynamic value margin} on step-level preference\noptimization, which employs tree-based self-sampling on model responses\n\\textbf{without any distillation} from other models. Furthermore, we\ntheoretically prove that SPPD is \\textbf{equivalent to on-policy policy\ngradient methods} under reward constraints. Experiments on 7B-scale models\ndemonstrate superior performance across in-domain and out-domain mathematical\nbenchmarks. We open-source our code at\n\\href{https://anonymous.4open.science/r/SSDPO-D-DCDD}{https://anonymous.4open.science/r/SPPD-DCDD}.'}","['Hao Yi', 'Qingyang Li', 'Yulan Hu', 'Fuzheng Zhang', 'Di Zhang', 'Yong Liu']",{'name': 'Yong Liu'},Yong Liu,,"[{'href': 'http://arxiv.org/abs/2502.13516v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13516v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13516v1,None,http://arxiv.org/abs/2502.13516v1,,,69,0
http://arxiv.org/abs/2502.13569v1,True,2025-02-19T09:22:34Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=9, tm_min=22, tm_sec=34, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T09:22:34Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=9, tm_min=22, tm_sec=34, tm_wday=2, tm_yday=50, tm_isdst=0)","Model Evolution Framework with Genetic Algorithm for Multi-Task
  Reinforcement Learning","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Model Evolution Framework with Genetic Algorithm for Multi-Task\n  Reinforcement Learning'}","Multi-task reinforcement learning employs a single policy to complete various
tasks, aiming to develop an agent with generalizability across different
scenarios. Given the shared characteristics of tasks, the agent's learning
efficiency can be enhanced through parameter sharing. Existing approaches
typically use a routing network to generate specific routes for each task and
reconstruct a set of modules into diverse models to complete multiple tasks
simultaneously. However, due to the inherent difference between tasks, it is
crucial to allocate resources based on task difficulty, which is constrained by
the model's structure. To this end, we propose a Model Evolution framework with
Genetic Algorithm (MEGA), which enables the model to evolve during training
according to the difficulty of the tasks. When the current model is
insufficient for certain tasks, the framework will automatically incorporate
additional modules, enhancing the model's capabilities. Moreover, to adapt to
our model evolution framework, we introduce a genotype module-level model,
using binary sequences as genotype policies for model reconstruction, while
leveraging a non-gradient genetic algorithm to optimize these genotype
policies. Unlike routing networks with fixed output dimensions, our approach
allows for the dynamic adjustment of the genotype policy length, enabling it to
accommodate models with a varying number of modules. We conducted experiments
on various robotics manipulation tasks in the Meta-World benchmark. Our
state-of-the-art performance demonstrated the effectiveness of the MEGA
framework. We will release our source code to the public.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Multi-task reinforcement learning employs a single policy to complete various\ntasks, aiming to develop an agent with generalizability across different\nscenarios. Given the shared characteristics of tasks, the agent's learning\nefficiency can be enhanced through parameter sharing. Existing approaches\ntypically use a routing network to generate specific routes for each task and\nreconstruct a set of modules into diverse models to complete multiple tasks\nsimultaneously. However, due to the inherent difference between tasks, it is\ncrucial to allocate resources based on task difficulty, which is constrained by\nthe model's structure. To this end, we propose a Model Evolution framework with\nGenetic Algorithm (MEGA), which enables the model to evolve during training\naccording to the difficulty of the tasks. When the current model is\ninsufficient for certain tasks, the framework will automatically incorporate\nadditional modules, enhancing the model's capabilities. Moreover, to adapt to\nour model evolution framework, we introduce a genotype module-level model,\nusing binary sequences as genotype policies for model reconstruction, while\nleveraging a non-gradient genetic algorithm to optimize these genotype\npolicies. Unlike routing networks with fixed output dimensions, our approach\nallows for the dynamic adjustment of the genotype policy length, enabling it to\naccommodate models with a varying number of modules. We conducted experiments\non various robotics manipulation tasks in the Meta-World benchmark. Our\nstate-of-the-art performance demonstrated the effectiveness of the MEGA\nframework. We will release our source code to the public.""}","['Yan Yu', 'Wengang Zhou', 'Yaodong Yang', 'Wanxuan Lu', 'Yingyan Hou', 'Houqiang Li']",{'name': 'Houqiang Li'},Houqiang Li,,"[{'href': 'http://arxiv.org/abs/2502.13569v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13569v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13569v1,None,http://arxiv.org/abs/2502.13569v1,,,14957,0
http://arxiv.org/abs/2502.13731v1,True,2025-02-19T13:56:20Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=13, tm_min=56, tm_sec=20, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T13:56:20Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=13, tm_min=56, tm_sec=20, tm_wday=2, tm_yday=50, tm_isdst=0)",Robust Counterfactual Inference in Markov Decision Processes,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Robust Counterfactual Inference in Markov Decision Processes'}","This paper addresses a key limitation in existing counterfactual inference
methods for Markov Decision Processes (MDPs). Current approaches assume a
specific causal model to make counterfactuals identifiable. However, there are
usually many causal models that align with the observational and interventional
distributions of an MDP, each yielding different counterfactual distributions,
so fixing a particular causal model limits the validity (and usefulness) of
counterfactual inference. We propose a novel non-parametric approach that
computes tight bounds on counterfactual transition probabilities across all
compatible causal models. Unlike previous methods that require solving
prohibitively large optimisation problems (with variables that grow
exponentially in the size of the MDP), our approach provides closed-form
expressions for these bounds, making computation highly efficient and scalable
for non-trivial MDPs. Once such an interval counterfactual MDP is constructed,
our method identifies robust counterfactual policies that optimise the
worst-case reward w.r.t. the uncertain interval MDP probabilities. We evaluate
our method on various case studies, demonstrating improved robustness over
existing methods.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'This paper addresses a key limitation in existing counterfactual inference\nmethods for Markov Decision Processes (MDPs). Current approaches assume a\nspecific causal model to make counterfactuals identifiable. However, there are\nusually many causal models that align with the observational and interventional\ndistributions of an MDP, each yielding different counterfactual distributions,\nso fixing a particular causal model limits the validity (and usefulness) of\ncounterfactual inference. We propose a novel non-parametric approach that\ncomputes tight bounds on counterfactual transition probabilities across all\ncompatible causal models. Unlike previous methods that require solving\nprohibitively large optimisation problems (with variables that grow\nexponentially in the size of the MDP), our approach provides closed-form\nexpressions for these bounds, making computation highly efficient and scalable\nfor non-trivial MDPs. Once such an interval counterfactual MDP is constructed,\nour method identifies robust counterfactual policies that optimise the\nworst-case reward w.r.t. the uncertain interval MDP probabilities. We evaluate\nour method on various case studies, demonstrating improved robustness over\nexisting methods.'}","['Jessica Lally', 'Milad Kazemi', 'Nicola Paoletti']",{'name': 'Nicola Paoletti'},Nicola Paoletti,,"[{'href': 'http://arxiv.org/abs/2502.13731v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13731v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13731v1,None,http://arxiv.org/abs/2502.13731v1,,,204,0
http://arxiv.org/abs/2502.13743v1,True,2025-02-19T14:07:34Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=14, tm_min=7, tm_sec=34, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T14:07:34Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=14, tm_min=7, tm_sec=34, tm_wday=2, tm_yday=50, tm_isdst=0)",Inference of Abstraction for Grounded Predicate Logic,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Inference of Abstraction for Grounded Predicate Logic'}","An important open question in AI is what simple and natural principle enables
a machine to reason logically for meaningful abstraction with grounded symbols.
This paper explores a conceptually new approach to combining probabilistic
reasoning and predicative symbolic reasoning over data. We return to the era of
reasoning with a full joint distribution before the advent of Bayesian
networks. We then discuss that a full joint distribution over models of
exponential size in propositional logic and of infinite size in predicate logic
should be simply derived from a full joint distribution over data of linear
size. We show that the same process is not only enough to generalise the
logical consequence relation of predicate logic but also to provide a new
perspective to rethink well-known limitations such as the undecidability of
predicate logic, the symbol grounding problem and the principle of explosion.
The reproducibility of this theoretical work is fully demonstrated by the
included proofs.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'An important open question in AI is what simple and natural principle enables\na machine to reason logically for meaningful abstraction with grounded symbols.\nThis paper explores a conceptually new approach to combining probabilistic\nreasoning and predicative symbolic reasoning over data. We return to the era of\nreasoning with a full joint distribution before the advent of Bayesian\nnetworks. We then discuss that a full joint distribution over models of\nexponential size in propositional logic and of infinite size in predicate logic\nshould be simply derived from a full joint distribution over data of linear\nsize. We show that the same process is not only enough to generalise the\nlogical consequence relation of predicate logic but also to provide a new\nperspective to rethink well-known limitations such as the undecidability of\npredicate logic, the symbol grounding problem and the principle of explosion.\nThe reproducibility of this theoretical work is fully demonstrated by the\nincluded proofs.'}",['Hiroyuki Kido'],{'name': 'Hiroyuki Kido'},Hiroyuki Kido,,"[{'href': 'http://arxiv.org/abs/2502.13743v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13743v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13743v1,None,http://arxiv.org/abs/2502.13743v1,,,0,0
http://arxiv.org/abs/2502.13769v1,True,2025-02-19T14:32:16Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=14, tm_min=32, tm_sec=16, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T14:32:16Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=14, tm_min=32, tm_sec=16, tm_wday=2, tm_yday=50, tm_isdst=0)","A consensus set for the aggregation of partial rankings: the case of the
  Optimal Set of Bucket Orders Problem","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A consensus set for the aggregation of partial rankings: the case of the\n  Optimal Set of Bucket Orders Problem'}","In rank aggregation problems (RAP), the solution is usually a consensus
ranking that generalizes a set of input orderings. There are different variants
that differ not only in terms of the type of rankings that are used as input
and output, but also in terms of the objective function employed to evaluate
the quality of the desired output ranking. In contrast, in some machine
learning tasks (e.g. subgroup discovery) or multimodal optimization tasks,
attention is devoted to obtaining several models/results to account for the
diversity in the input data or across the search landscape. Thus, in this paper
we propose to provide, as the solution to an RAP, a set of rankings to better
explain the preferences expressed in the input orderings. We exemplify our
proposal through the Optimal Bucket Order Problem (OBOP), an RAP which consists
in finding a single consensus ranking (with ties) that generalizes a set of
input rankings codified as a precedence matrix. To address this, we introduce
the Optimal Set of Bucket Orders Problem (OSBOP), a generalization of the OBOP
that aims to produce not a single ranking as output but a set of consensus
rankings. Experimental results are presented to illustrate this proposal,
showing how, by providing a set of consensus rankings, the fitness of the
solution significantly improves with respect to the one of the original OBOP,
without losing comprehensibility.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'In rank aggregation problems (RAP), the solution is usually a consensus\nranking that generalizes a set of input orderings. There are different variants\nthat differ not only in terms of the type of rankings that are used as input\nand output, but also in terms of the objective function employed to evaluate\nthe quality of the desired output ranking. In contrast, in some machine\nlearning tasks (e.g. subgroup discovery) or multimodal optimization tasks,\nattention is devoted to obtaining several models/results to account for the\ndiversity in the input data or across the search landscape. Thus, in this paper\nwe propose to provide, as the solution to an RAP, a set of rankings to better\nexplain the preferences expressed in the input orderings. We exemplify our\nproposal through the Optimal Bucket Order Problem (OBOP), an RAP which consists\nin finding a single consensus ranking (with ties) that generalizes a set of\ninput rankings codified as a precedence matrix. To address this, we introduce\nthe Optimal Set of Bucket Orders Problem (OSBOP), a generalization of the OBOP\nthat aims to produce not a single ranking as output but a set of consensus\nrankings. Experimental results are presented to illustrate this proposal,\nshowing how, by providing a set of consensus rankings, the fitness of the\nsolution significantly improves with respect to the one of the original OBOP,\nwithout losing comprehensibility.'}","['Juan A. Aledo', 'Jos A. Gmez', 'Alejandro Rosete']",{'name': 'Alejandro Rosete'},Alejandro Rosete,"26 pages, 2 figures","[{'href': 'http://arxiv.org/abs/2502.13769v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13769v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13769v1,None,http://arxiv.org/abs/2502.13769v1,,,1888,0
http://arxiv.org/abs/2502.13834v1,True,2025-02-19T15:54:21Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=15, tm_min=54, tm_sec=21, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T15:54:21Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=15, tm_min=54, tm_sec=21, tm_wday=2, tm_yday=50, tm_isdst=0)",Proving Olympiad Inequalities by Synergizing LLMs and Symbolic Reasoning,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Proving Olympiad Inequalities by Synergizing LLMs and Symbolic Reasoning'}","Large language models (LLMs) can prove mathematical theorems formally by
generating proof steps (\textit{a.k.a.} tactics) within a proof system.
However, the space of possible tactics is vast and complex, while the available
training data for formal proofs is limited, posing a significant challenge to
LLM-based tactic generation. To address this, we introduce a neuro-symbolic
tactic generator that synergizes the mathematical intuition learned by LLMs
with domain-specific insights encoded by symbolic methods. The key aspect of
this integration is identifying which parts of mathematical reasoning are best
suited to LLMs and which to symbolic methods. While the high-level idea of
neuro-symbolic integration is broadly applicable to various mathematical
problems, in this paper, we focus specifically on Olympiad inequalities
(Figure~1). We analyze how humans solve these problems and distill the
techniques into two types of tactics: (1) scaling, handled by symbolic methods,
and (2) rewriting, handled by LLMs. In addition, we combine symbolic tools with
LLMs to prune and rank the proof goals for efficient proof search. We evaluate
our framework on 161 challenging inequalities from multiple mathematics
competitions, achieving state-of-the-art performance and significantly
outperforming existing LLM and symbolic approaches without requiring additional
training data.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large language models (LLMs) can prove mathematical theorems formally by\ngenerating proof steps (\\textit{a.k.a.} tactics) within a proof system.\nHowever, the space of possible tactics is vast and complex, while the available\ntraining data for formal proofs is limited, posing a significant challenge to\nLLM-based tactic generation. To address this, we introduce a neuro-symbolic\ntactic generator that synergizes the mathematical intuition learned by LLMs\nwith domain-specific insights encoded by symbolic methods. The key aspect of\nthis integration is identifying which parts of mathematical reasoning are best\nsuited to LLMs and which to symbolic methods. While the high-level idea of\nneuro-symbolic integration is broadly applicable to various mathematical\nproblems, in this paper, we focus specifically on Olympiad inequalities\n(Figure~1). We analyze how humans solve these problems and distill the\ntechniques into two types of tactics: (1) scaling, handled by symbolic methods,\nand (2) rewriting, handled by LLMs. In addition, we combine symbolic tools with\nLLMs to prune and rank the proof goals for efficient proof search. We evaluate\nour framework on 161 challenging inequalities from multiple mathematics\ncompetitions, achieving state-of-the-art performance and significantly\noutperforming existing LLM and symbolic approaches without requiring additional\ntraining data.'}","['Zenan Li', 'Zhaoyu Li', 'Wen Tang', 'Xian Zhang', 'Yuan Yao', 'Xujie Si', 'Fan Yang', 'Kaiyu Yang', 'Xiaoxing Ma']",{'name': 'Xiaoxing Ma'},Xiaoxing Ma,"Published as a conference paper at ICLR 2025. Code is available at
  https://github.com/Lizn-zn/NeqLIPS/","[{'href': 'http://arxiv.org/abs/2502.13834v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13834v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13834v1,None,http://arxiv.org/abs/2502.13834v1,,,98,0
http://arxiv.org/abs/2502.13953v1,True,2025-02-19T18:53:16Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=18, tm_min=53, tm_sec=16, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T18:53:16Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=18, tm_min=53, tm_sec=16, tm_wday=2, tm_yday=50, tm_isdst=0)","Neurosymbolic artificial intelligence via large language models and
  coherence-driven inference","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Neurosymbolic artificial intelligence via large language models and\n  coherence-driven inference'}","We devise an algorithm to generate sets of propositions that objectively
instantiate graphs that support coherence-driven inference. We then benchmark
the ability of large language models (LLMs) to reconstruct coherence graphs
from (a straightforward transformation of) propositions expressed in natural
language, with promising results from a single prompt to models optimized for
reasoning. Combining coherence-driven inference with consistency evaluations by
neural models may advance the state of the art in machine cognition.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'We devise an algorithm to generate sets of propositions that objectively\ninstantiate graphs that support coherence-driven inference. We then benchmark\nthe ability of large language models (LLMs) to reconstruct coherence graphs\nfrom (a straightforward transformation of) propositions expressed in natural\nlanguage, with promising results from a single prompt to models optimized for\nreasoning. Combining coherence-driven inference with consistency evaluations by\nneural models may advance the state of the art in machine cognition.'}","['Steve Huntsman', 'Jewell Thomas']",{'name': 'Jewell Thomas'},Jewell Thomas,,"[{'href': 'http://arxiv.org/abs/2502.13953v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13953v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13953v1,None,http://arxiv.org/abs/2502.13953v1,,,0,0
http://arxiv.org/abs/2502.14102v1,True,2025-02-19T21:06:30Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=21, tm_min=6, tm_sec=30, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T21:06:30Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=21, tm_min=6, tm_sec=30, tm_wday=2, tm_yday=50, tm_isdst=0)",Explainable Distributed Constraint Optimization Problems,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Explainable Distributed Constraint Optimization Problems'}","The Distributed Constraint Optimization Problem (DCOP) formulation is a
powerful tool to model cooperative multi-agent problems that need to be solved
distributively. A core assumption of existing approaches is that DCOP solutions
can be easily understood, accepted, and adopted, which may not hold, as
evidenced by the large body of literature on Explainable AI. In this paper, we
propose the Explainable DCOP (X-DCOP) model, which extends a DCOP to include
its solution and a contrastive query for that solution. We formally define some
key properties that contrastive explanations must satisfy for them to be
considered as valid solutions to X-DCOPs as well as theoretical results on the
existence of such valid explanations. To solve X-DCOPs, we propose a
distributed framework as well as several optimizations and suboptimal variants
to find valid explanations. We also include a human user study that showed that
users, not surprisingly, prefer shorter explanations over longer ones. Our
empirical evaluations showed that our approach can scale to large problems, and
the different variants provide different options for trading off explanation
lengths for smaller runtimes. Thus, our model and algorithmic contributions
extend the state of the art by reducing the barrier for users to understand
DCOP solutions, facilitating their adoption in more real-world applications.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The Distributed Constraint Optimization Problem (DCOP) formulation is a\npowerful tool to model cooperative multi-agent problems that need to be solved\ndistributively. A core assumption of existing approaches is that DCOP solutions\ncan be easily understood, accepted, and adopted, which may not hold, as\nevidenced by the large body of literature on Explainable AI. In this paper, we\npropose the Explainable DCOP (X-DCOP) model, which extends a DCOP to include\nits solution and a contrastive query for that solution. We formally define some\nkey properties that contrastive explanations must satisfy for them to be\nconsidered as valid solutions to X-DCOPs as well as theoretical results on the\nexistence of such valid explanations. To solve X-DCOPs, we propose a\ndistributed framework as well as several optimizations and suboptimal variants\nto find valid explanations. We also include a human user study that showed that\nusers, not surprisingly, prefer shorter explanations over longer ones. Our\nempirical evaluations showed that our approach can scale to large problems, and\nthe different variants provide different options for trading off explanation\nlengths for smaller runtimes. Thus, our model and algorithmic contributions\nextend the state of the art by reducing the barrier for users to understand\nDCOP solutions, facilitating their adoption in more real-world applications.'}","['Ben Rachmut', 'Stylianos Loukas Vasileiou', 'Nimrod Meir Weinstein', 'Roie Zivan', 'William Yeoh']",{'name': 'William Yeoh'},William Yeoh,,"[{'href': 'http://arxiv.org/abs/2502.14102v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14102v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14102v1,None,http://arxiv.org/abs/2502.14102v1,,,1913,0
http://arxiv.org/abs/2502.14219v1,True,2025-02-20T03:15:54Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=3, tm_min=15, tm_sec=54, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T03:15:54Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=3, tm_min=15, tm_sec=54, tm_wday=3, tm_yday=51, tm_isdst=0)","Investigating the Impact of LLM Personality on Cognitive Bias
  Manifestation in Automated Decision-Making Tasks","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Investigating the Impact of LLM Personality on Cognitive Bias\n  Manifestation in Automated Decision-Making Tasks'}","Large Language Models (LLMs) are increasingly used in decision-making, yet
their susceptibility to cognitive biases remains a pressing challenge. This
study explores how personality traits influence these biases and evaluates the
effectiveness of mitigation strategies across various model architectures. Our
findings identify six prevalent cognitive biases, while the sunk cost and group
attribution biases exhibit minimal impact. Personality traits play a crucial
role in either amplifying or reducing biases, significantly affecting how LLMs
respond to debiasing techniques. Notably, Conscientiousness and Agreeableness
may generally enhance the efficacy of bias mitigation strategies, suggesting
that LLMs exhibiting these traits are more receptive to corrective measures.
These findings address the importance of personality-driven bias dynamics and
highlight the need for targeted mitigation approaches to improve fairness and
reliability in AI-assisted decision-making.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Language Models (LLMs) are increasingly used in decision-making, yet\ntheir susceptibility to cognitive biases remains a pressing challenge. This\nstudy explores how personality traits influence these biases and evaluates the\neffectiveness of mitigation strategies across various model architectures. Our\nfindings identify six prevalent cognitive biases, while the sunk cost and group\nattribution biases exhibit minimal impact. Personality traits play a crucial\nrole in either amplifying or reducing biases, significantly affecting how LLMs\nrespond to debiasing techniques. Notably, Conscientiousness and Agreeableness\nmay generally enhance the efficacy of bias mitigation strategies, suggesting\nthat LLMs exhibiting these traits are more receptive to corrective measures.\nThese findings address the importance of personality-driven bias dynamics and\nhighlight the need for targeted mitigation approaches to improve fairness and\nreliability in AI-assisted decision-making.'}","['Jiangen He', 'Jiqun Liu']",{'name': 'Jiqun Liu'},Jiqun Liu,,"[{'href': 'http://arxiv.org/abs/2502.14219v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14219v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14219v1,None,http://arxiv.org/abs/2502.14219v1,,,0,0
http://arxiv.org/abs/2502.14264v1,True,2025-02-20T05:02:29Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=5, tm_min=2, tm_sec=29, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T05:02:29Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=5, tm_min=2, tm_sec=29, tm_wday=3, tm_yday=51, tm_isdst=0)","SPRIG: Stackelberg Perception-Reinforcement Learning with Internal Game
  Dynamics","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'SPRIG: Stackelberg Perception-Reinforcement Learning with Internal Game\n  Dynamics'}","Deep reinforcement learning agents often face challenges to effectively
coordinate perception and decision-making components, particularly in
environments with high-dimensional sensory inputs where feature relevance
varies. This work introduces SPRIG (Stackelberg Perception-Reinforcement
learning with Internal Game dynamics), a framework that models the internal
perception-policy interaction within a single agent as a cooperative
Stackelberg game. In SPRIG, the perception module acts as a leader,
strategically processing raw sensory states, while the policy module follows,
making decisions based on extracted features. SPRIG provides theoretical
guarantees through a modified Bellman operator while preserving the benefits of
modern policy optimization. Experimental results on the Atari BeamRider
environment demonstrate SPRIG's effectiveness, achieving around 30% higher
returns than standard PPO through its game-theoretical balance of feature
extraction and decision-making.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Deep reinforcement learning agents often face challenges to effectively\ncoordinate perception and decision-making components, particularly in\nenvironments with high-dimensional sensory inputs where feature relevance\nvaries. This work introduces SPRIG (Stackelberg Perception-Reinforcement\nlearning with Internal Game dynamics), a framework that models the internal\nperception-policy interaction within a single agent as a cooperative\nStackelberg game. In SPRIG, the perception module acts as a leader,\nstrategically processing raw sensory states, while the policy module follows,\nmaking decisions based on extracted features. SPRIG provides theoretical\nguarantees through a modified Bellman operator while preserving the benefits of\nmodern policy optimization. Experimental results on the Atari BeamRider\nenvironment demonstrate SPRIG's effectiveness, achieving around 30% higher\nreturns than standard PPO through its game-theoretical balance of feature\nextraction and decision-making.""}","['Fernando Martinez-Lopez', 'Juntao Chen', 'Yingdong Lu']",{'name': 'Yingdong Lu'},Yingdong Lu,"To appear in: AAAI 2025 Workshop on Planning and Reinforcement
  Learning (PRL) - Bridging the Gap Between AI Planning and Reinforcement
  Learning","[{'href': 'http://arxiv.org/abs/2502.14264v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14264v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14264v1,None,http://arxiv.org/abs/2502.14264v1,,,4,0
http://arxiv.org/abs/2502.14345v1,True,2025-02-20T07:59:31Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=7, tm_min=59, tm_sec=31, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T07:59:31Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=7, tm_min=59, tm_sec=31, tm_wday=3, tm_yday=51, tm_isdst=0)",FlowAgent: Achieving Compliance and Flexibility for Workflow Agents,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'FlowAgent: Achieving Compliance and Flexibility for Workflow Agents'}","The integration of workflows with large language models (LLMs) enables
LLM-based agents to execute predefined procedures, enhancing automation in
real-world applications. Traditional rule-based methods tend to limit the
inherent flexibility of LLMs, as their predefined execution paths restrict the
models' action space, particularly when the unexpected, out-of-workflow (OOW)
queries are encountered. Conversely, prompt-based methods allow LLMs to fully
control the flow, which can lead to diminished enforcement of procedural
compliance. To address these challenges, we introduce FlowAgent, a novel agent
framework designed to maintain both compliance and flexibility. We propose the
Procedure Description Language (PDL), which combines the adaptability of
natural language with the precision of code to formulate workflows. Building on
PDL, we develop a comprehensive framework that empowers LLMs to manage OOW
queries effectively, while keeping the execution path under the supervision of
a set of controllers. Additionally, we present a new evaluation methodology to
rigorously assess an LLM agent's ability to handle OOW scenarios, going beyond
routine flow compliance tested in existing benchmarks. Experiments on three
datasets demonstrate that FlowAgent not only adheres to workflows but also
effectively manages OOW queries, highlighting its dual strengths in compliance
and flexibility. The code is available at
https://github.com/Lightblues/FlowAgent.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""The integration of workflows with large language models (LLMs) enables\nLLM-based agents to execute predefined procedures, enhancing automation in\nreal-world applications. Traditional rule-based methods tend to limit the\ninherent flexibility of LLMs, as their predefined execution paths restrict the\nmodels' action space, particularly when the unexpected, out-of-workflow (OOW)\nqueries are encountered. Conversely, prompt-based methods allow LLMs to fully\ncontrol the flow, which can lead to diminished enforcement of procedural\ncompliance. To address these challenges, we introduce FlowAgent, a novel agent\nframework designed to maintain both compliance and flexibility. We propose the\nProcedure Description Language (PDL), which combines the adaptability of\nnatural language with the precision of code to formulate workflows. Building on\nPDL, we develop a comprehensive framework that empowers LLMs to manage OOW\nqueries effectively, while keeping the execution path under the supervision of\na set of controllers. Additionally, we present a new evaluation methodology to\nrigorously assess an LLM agent's ability to handle OOW scenarios, going beyond\nroutine flow compliance tested in existing benchmarks. Experiments on three\ndatasets demonstrate that FlowAgent not only adheres to workflows but also\neffectively manages OOW queries, highlighting its dual strengths in compliance\nand flexibility. The code is available at\nhttps://github.com/Lightblues/FlowAgent.""}","['Yuchen Shi', 'Siqi Cai', 'Zihan Xu', 'Yuei Qin', 'Gang Li', 'Hang Shao', 'Jiawei Chen', 'Deqing Yang', 'Ke Li', 'Xing Sun']",{'name': 'Xing Sun'},Xing Sun,8 pages,"[{'href': 'http://arxiv.org/abs/2502.14345v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14345v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14345v1,None,http://arxiv.org/abs/2502.14345v1,,,16,0
http://arxiv.org/abs/2502.14400v1,True,2025-02-20T09:37:41Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=9, tm_min=37, tm_sec=41, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T09:37:41Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=9, tm_min=37, tm_sec=41, tm_wday=3, tm_yday=51, tm_isdst=0)",HPS: Hard Preference Sampling for Human Preference Alignment,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'HPS: Hard Preference Sampling for Human Preference Alignment'}","Aligning Large Language Model (LLM) responses with human preferences is vital
for building safe and controllable AI systems. While preference optimization
methods based on Plackett-Luce (PL) and Bradley-Terry (BT) models have shown
promise, they face challenges such as poor handling of harmful content,
inefficient use of dispreferred responses, and, specifically for PL, high
computational costs. To address these issues, we propose Hard Preference
Sampling (HPS), a novel framework for robust and efficient human preference
alignment. HPS introduces a training loss that prioritizes the most preferred
response while rejecting all dispreferred and harmful ones. It emphasizes
""hard"" dispreferred responses--those closely resembling preferred ones--to
enhance the model's rejection capabilities. By leveraging a single-sample Monte
Carlo sampling strategy, HPS reduces computational overhead while maintaining
alignment quality. Theoretically, HPS improves sample efficiency over existing
PL methods and maximizes the reward margin between preferred and dispreferred
responses, ensuring clearer distinctions. Experiments on HH-RLHF and PKU-Safety
datasets validate HPS's effectiveness, achieving comparable BLEU and reward
scores while greatly improving reward margins and thus reducing harmful content
generation.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Aligning Large Language Model (LLM) responses with human preferences is vital\nfor building safe and controllable AI systems. While preference optimization\nmethods based on Plackett-Luce (PL) and Bradley-Terry (BT) models have shown\npromise, they face challenges such as poor handling of harmful content,\ninefficient use of dispreferred responses, and, specifically for PL, high\ncomputational costs. To address these issues, we propose Hard Preference\nSampling (HPS), a novel framework for robust and efficient human preference\nalignment. HPS introduces a training loss that prioritizes the most preferred\nresponse while rejecting all dispreferred and harmful ones. It emphasizes\n""hard"" dispreferred responses--those closely resembling preferred ones--to\nenhance the model\'s rejection capabilities. By leveraging a single-sample Monte\nCarlo sampling strategy, HPS reduces computational overhead while maintaining\nalignment quality. Theoretically, HPS improves sample efficiency over existing\nPL methods and maximizes the reward margin between preferred and dispreferred\nresponses, ensuring clearer distinctions. Experiments on HH-RLHF and PKU-Safety\ndatasets validate HPS\'s effectiveness, achieving comparable BLEU and reward\nscores while greatly improving reward margins and thus reducing harmful content\ngeneration.'}","['Xiandong Zou', 'Wanyu Lin', 'Yuchen Li', 'Pan Zhou']",{'name': 'Pan Zhou'},Pan Zhou,,"[{'href': 'http://arxiv.org/abs/2502.14400v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14400v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14400v1,None,http://arxiv.org/abs/2502.14400v1,,,0,0
http://arxiv.org/abs/2502.14456v1,True,2025-02-20T11:15:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=11, tm_min=15, tm_sec=23, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T11:15:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=11, tm_min=15, tm_sec=23, tm_wday=3, tm_yday=51, tm_isdst=0)","Narrative-Driven Travel Planning: Geoculturally-Grounded Script
  Generation with Evolutionary Itinerary Optimization","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Narrative-Driven Travel Planning: Geoculturally-Grounded Script\n  Generation with Evolutionary Itinerary Optimization'}","To enhance tourists' experiences and immersion, this paper proposes a
narrative-driven travel planning framework called NarrativeGuide, which
generates a geoculturally-grounded narrative script for travelers, offering a
novel, role-playing experience for their journey. In the initial stage,
NarrativeGuide constructs a knowledge graph for attractions within a city, then
configures the worldview, character setting, and exposition based on the
knowledge graph. Using this foundation, the knowledge graph is combined to
generate an independent scene unit for each attraction. During the itinerary
planning stage, NarrativeGuide models narrative-driven travel planning as an
optimization problem, utilizing a genetic algorithm (GA) to refine the
itinerary. Before evaluating the candidate itinerary, transition scripts are
generated for each pair of adjacent attractions, which, along with the scene
units, form a complete script. The weighted sum of script coherence, travel
time, and attraction scores is then used as the fitness value to update the
candidate solution set. Experimental results across four cities, i.e., Nanjing
and Yangzhou in China, Paris in France, and Berlin in Germany, demonstrate
significant improvements in narrative coherence and cultural fit, alongside a
notable reduction in travel time and an increase in the quality of visited
attractions. Our study highlights that incorporating external evolutionary
optimization effectively addresses the limitations of large language models in
travel planning.Our codes are available at
https://github.com/Evan01225/Narrative-Driven-Travel-Planning.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""To enhance tourists' experiences and immersion, this paper proposes a\nnarrative-driven travel planning framework called NarrativeGuide, which\ngenerates a geoculturally-grounded narrative script for travelers, offering a\nnovel, role-playing experience for their journey. In the initial stage,\nNarrativeGuide constructs a knowledge graph for attractions within a city, then\nconfigures the worldview, character setting, and exposition based on the\nknowledge graph. Using this foundation, the knowledge graph is combined to\ngenerate an independent scene unit for each attraction. During the itinerary\nplanning stage, NarrativeGuide models narrative-driven travel planning as an\noptimization problem, utilizing a genetic algorithm (GA) to refine the\nitinerary. Before evaluating the candidate itinerary, transition scripts are\ngenerated for each pair of adjacent attractions, which, along with the scene\nunits, form a complete script. The weighted sum of script coherence, travel\ntime, and attraction scores is then used as the fitness value to update the\ncandidate solution set. Experimental results across four cities, i.e., Nanjing\nand Yangzhou in China, Paris in France, and Berlin in Germany, demonstrate\nsignificant improvements in narrative coherence and cultural fit, alongside a\nnotable reduction in travel time and an increase in the quality of visited\nattractions. Our study highlights that incorporating external evolutionary\noptimization effectively addresses the limitations of large language models in\ntravel planning.Our codes are available at\nhttps://github.com/Evan01225/Narrative-Driven-Travel-Planning.""}","['Ran Ding', 'Ziyu Zhang', 'Ying Zhu', 'Ziqian Kong', 'Peilan Xu']",{'name': 'Peilan Xu'},Peilan Xu,,"[{'href': 'http://arxiv.org/abs/2502.14456v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14456v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14456v1,None,http://arxiv.org/abs/2502.14456v1,,,0,0
http://arxiv.org/abs/2502.14491v1,True,2025-02-20T12:14:54Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=12, tm_min=14, tm_sec=54, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T12:14:54Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=12, tm_min=14, tm_sec=54, tm_wday=3, tm_yday=51, tm_isdst=0)","Statistical Scenario Modelling and Lookalike Distributions for
  Multi-Variate AI Risk","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Statistical Scenario Modelling and Lookalike Distributions for\n  Multi-Variate AI Risk'}","Evaluating AI safety requires statistically rigorous methods and risk metrics
for understanding how the use of AI affects aggregated risk. However, much AI
safety literature focuses upon risks arising from AI models in isolation,
lacking consideration of how modular use of AI affects risk distribution of
workflow components or overall risk metrics. There is also a lack of
statistical grounding enabling sensitisation of risk models in the presence of
absence of AI to estimate causal contributions of AI. This is in part due to
the dearth of AI impact data upon which to fit distributions. In this work, we
address these gaps in two ways. First, we demonstrate how scenario modelling
(grounded in established statistical techniques such as Markov chains, copulas
and Monte Carlo simulation) can be used to model AI risk holistically. Second,
we show how lookalike distributions from phenomena analogous to AI can be used
to estimate AI impacts in the absence of directly observable data. We
demonstrate the utility of our methods for benchmarking cumulative AI risk via
risk analysis of a logistic scenario simulations.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Evaluating AI safety requires statistically rigorous methods and risk metrics\nfor understanding how the use of AI affects aggregated risk. However, much AI\nsafety literature focuses upon risks arising from AI models in isolation,\nlacking consideration of how modular use of AI affects risk distribution of\nworkflow components or overall risk metrics. There is also a lack of\nstatistical grounding enabling sensitisation of risk models in the presence of\nabsence of AI to estimate causal contributions of AI. This is in part due to\nthe dearth of AI impact data upon which to fit distributions. In this work, we\naddress these gaps in two ways. First, we demonstrate how scenario modelling\n(grounded in established statistical techniques such as Markov chains, copulas\nand Monte Carlo simulation) can be used to model AI risk holistically. Second,\nwe show how lookalike distributions from phenomena analogous to AI can be used\nto estimate AI impacts in the absence of directly observable data. We\ndemonstrate the utility of our methods for benchmarking cumulative AI risk via\nrisk analysis of a logistic scenario simulations.'}",['Elija Perrier'],{'name': 'Elija Perrier'},Elija Perrier,Under review,"[{'href': 'http://arxiv.org/abs/2502.14491v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14491v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14491v1,None,http://arxiv.org/abs/2502.14491v1,,,0,0
http://arxiv.org/abs/2502.14563v1,True,2025-02-20T13:47:51Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=13, tm_min=47, tm_sec=51, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T13:47:51Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=13, tm_min=47, tm_sec=51, tm_wday=3, tm_yday=51, tm_isdst=0)",Plan-over-Graph: Towards Parallelable LLM Agent Schedule,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Plan-over-Graph: Towards Parallelable LLM Agent Schedule'}","Large Language Models (LLMs) have demonstrated exceptional abilities in
reasoning for task planning. However, challenges remain under-explored for
parallel schedules. This paper introduces a novel paradigm, plan-over-graph, in
which the model first decomposes a real-life textual task into executable
subtasks and constructs an abstract task graph. The model then understands this
task graph as input and generates a plan for parallel execution. To enhance the
planning capability of complex, scalable graphs, we design an automated and
controllable pipeline to generate synthetic graphs and propose a two-stage
training scheme. Experimental results show that our plan-over-graph method
significantly improves task performance on both API-based LLMs and trainable
open-sourced LLMs. By normalizing complex tasks as graphs, our method naturally
supports parallel execution, demonstrating global efficiency. The code and data
are available at https://github.com/zsq259/Plan-over-Graph.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Language Models (LLMs) have demonstrated exceptional abilities in\nreasoning for task planning. However, challenges remain under-explored for\nparallel schedules. This paper introduces a novel paradigm, plan-over-graph, in\nwhich the model first decomposes a real-life textual task into executable\nsubtasks and constructs an abstract task graph. The model then understands this\ntask graph as input and generates a plan for parallel execution. To enhance the\nplanning capability of complex, scalable graphs, we design an automated and\ncontrollable pipeline to generate synthetic graphs and propose a two-stage\ntraining scheme. Experimental results show that our plan-over-graph method\nsignificantly improves task performance on both API-based LLMs and trainable\nopen-sourced LLMs. By normalizing complex tasks as graphs, our method naturally\nsupports parallel execution, demonstrating global efficiency. The code and data\nare available at https://github.com/zsq259/Plan-over-Graph.'}","['Shiqi Zhang', 'Xinbei Ma', 'Zouying Cao', 'Zhuosheng Zhang', 'Hai Zhao']",{'name': 'Hai Zhao'},Hai Zhao,,"[{'href': 'http://arxiv.org/abs/2502.14563v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14563v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14563v1,None,http://arxiv.org/abs/2502.14563v1,,,202,0
http://arxiv.org/abs/2502.14777v1,True,2025-02-20T17:59:55Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=17, tm_min=59, tm_sec=55, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T17:59:55Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=17, tm_min=59, tm_sec=55, tm_wday=3, tm_yday=51, tm_isdst=0)",Making Universal Policies Universal,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Making Universal Policies Universal'}","The development of a generalist agent capable of solving a wide range of
sequential decision-making tasks remains a significant challenge. We address
this problem in a cross-agent setup where agents share the same observation
space but differ in their action spaces. Our approach builds on the universal
policy framework, which decouples policy learning into two stages: a
diffusion-based planner that generates observation sequences and an inverse
dynamics model that assigns actions to these plans. We propose a method for
training the planner on a joint dataset composed of trajectories from all
agents. This method offers the benefit of positive transfer by pooling data
from different agents, while the primary challenge lies in adapting shared
plans to each agent's unique constraints. We evaluate our approach on the
BabyAI environment, covering tasks of varying complexity, and demonstrate
positive transfer across agents. Additionally, we examine the planner's
generalisation ability to unseen agents and compare our method to traditional
imitation learning approaches. By training on a pooled dataset from multiple
agents, our universal policy achieves an improvement of up to $42.20\%$ in task
completion accuracy compared to a policy trained on a dataset from a single
agent.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""The development of a generalist agent capable of solving a wide range of\nsequential decision-making tasks remains a significant challenge. We address\nthis problem in a cross-agent setup where agents share the same observation\nspace but differ in their action spaces. Our approach builds on the universal\npolicy framework, which decouples policy learning into two stages: a\ndiffusion-based planner that generates observation sequences and an inverse\ndynamics model that assigns actions to these plans. We propose a method for\ntraining the planner on a joint dataset composed of trajectories from all\nagents. This method offers the benefit of positive transfer by pooling data\nfrom different agents, while the primary challenge lies in adapting shared\nplans to each agent's unique constraints. We evaluate our approach on the\nBabyAI environment, covering tasks of varying complexity, and demonstrate\npositive transfer across agents. Additionally, we examine the planner's\ngeneralisation ability to unseen agents and compare our method to traditional\nimitation learning approaches. By training on a pooled dataset from multiple\nagents, our universal policy achieves an improvement of up to $42.20\\%$ in task\ncompletion accuracy compared to a policy trained on a dataset from a single\nagent.""}","['Niklas Hpner', 'David Kuric', 'Herke van Hoof']",{'name': 'Herke van Hoof'},Herke van Hoof,,"[{'href': 'http://arxiv.org/abs/2502.14777v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14777v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14777v1,None,http://arxiv.org/abs/2502.14777v1,,,0,0
http://arxiv.org/abs/2502.10624v1,True,2025-02-15T01:25:13Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=1, tm_min=25, tm_sec=13, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T01:25:13Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=1, tm_min=25, tm_sec=13, tm_wday=5, tm_yday=46, tm_isdst=0)",Network evasion detection with Bi-LSTM model,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Network evasion detection with Bi-LSTM model'}","Network evasion detection aims to distinguish whether the network flow comes
from link layer exists network evasion threat, which is a means to disguise the
data traffic on detection system by confusing the signature. Since the previous
research works has all sorts of frauds, we propose a architecture with deep
learning network to handle this problem. In this paper, we extract the critical
information as key features from data frame and also specifically propose to
use bidirectional long short-term memory (Bi-LSTM) neural network which shows
an outstanding performance to trace the serial information, to encode both the
past and future trait on the network flows. Furthermore we introduce a
classifier named Softmax at the bottom of Bi-LSTM, holding a character to
select the correct class. All experiments results shows that we can achieve a
significant performance with a deep Bi-LSTM in network evasion detection and
it's average accuracy reaches 96.1%.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Network evasion detection aims to distinguish whether the network flow comes\nfrom link layer exists network evasion threat, which is a means to disguise the\ndata traffic on detection system by confusing the signature. Since the previous\nresearch works has all sorts of frauds, we propose a architecture with deep\nlearning network to handle this problem. In this paper, we extract the critical\ninformation as key features from data frame and also specifically propose to\nuse bidirectional long short-term memory (Bi-LSTM) neural network which shows\nan outstanding performance to trace the serial information, to encode both the\npast and future trait on the network flows. Furthermore we introduce a\nclassifier named Softmax at the bottom of Bi-LSTM, holding a character to\nselect the correct class. All experiments results shows that we can achieve a\nsignificant performance with a deep Bi-LSTM in network evasion detection and\nit's average accuracy reaches 96.1%.""}","['Kehua Chen', 'Jingping Jia']",{'name': 'Jingping Jia'},Jingping Jia,"4 pages,5 figures","[{'href': 'http://arxiv.org/abs/2502.10624v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10624v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10624v1,None,http://arxiv.org/abs/2502.10624v1,CSAI 2018,,134,0
http://arxiv.org/abs/2502.10626v1,True,2025-02-15T01:35:13Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=1, tm_min=35, tm_sec=13, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T01:35:13Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=1, tm_min=35, tm_sec=13, tm_wday=5, tm_yday=46, tm_isdst=0)",K-Edit: Language Model Editing with Contextual Knowledge Awareness,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'K-Edit: Language Model Editing with Contextual Knowledge Awareness'}","As the world changes, we need to be able to update our models and correct
false information without costly retraining. Knowledge-based model editing
enables precise modifications to the weights of large language models in order
to modify the information encoded within. Recent approaches have seen success
in enabling recall of edited information for thousands of edits at once.
However, these approaches fail to produce edits that account for associated
contextual information. We present K-Edit, an effective approach to generating
contextually consistent knowledge edits. By using knowledge graphs, which
maintain contextual consistency when an edge is edited, we are able to generate
additional \textit{contextual edits} that ensure consistency of related
information in the language model. Our experiments demonstrate significant
improvements in multi-hop question answering while maintaining the general
effectiveness and scalability of model edits.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'As the world changes, we need to be able to update our models and correct\nfalse information without costly retraining. Knowledge-based model editing\nenables precise modifications to the weights of large language models in order\nto modify the information encoded within. Recent approaches have seen success\nin enabling recall of edited information for thousands of edits at once.\nHowever, these approaches fail to produce edits that account for associated\ncontextual information. We present K-Edit, an effective approach to generating\ncontextually consistent knowledge edits. By using knowledge graphs, which\nmaintain contextual consistency when an edge is edited, we are able to generate\nadditional \\textit{contextual edits} that ensure consistency of related\ninformation in the language model. Our experiments demonstrate significant\nimprovements in multi-hop question answering while maintaining the general\neffectiveness and scalability of model edits.'}","['Elan Markowitz', 'Anil Ramakrishna', 'Ninareh Mehrabi', 'Charith Peris', 'Rahul Gupta', 'Kai-Wei Chang', 'Aram Galstyan']",{'name': 'Aram Galstyan'},Aram Galstyan,,"[{'href': 'http://arxiv.org/abs/2502.10626v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10626v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10626v1,None,http://arxiv.org/abs/2502.10626v1,,,17956,0
http://arxiv.org/abs/2502.10642v1,True,2025-02-15T02:38:58Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=2, tm_min=38, tm_sec=58, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T02:38:58Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=2, tm_min=38, tm_sec=58, tm_wday=5, tm_yday=46, tm_isdst=0)","Demographic User Modeling for Social Robotics with Multimodal
  Pre-trained Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Demographic User Modeling for Social Robotics with Multimodal\n  Pre-trained Models'}","This paper investigates the performance of multimodal pre-trained models in
user profiling tasks based on visual-linguistic demographic data. These models
are critical for adapting to the needs and preferences of human users in social
robotics, thereby providing personalized responses and enhancing interaction
quality. First, we introduce two datasets specifically curated to represent
demographic characteristics derived from user facial images. Next, we evaluate
the performance of a prominent contrastive multimodal pre-trained model, CLIP,
on these datasets, both in its out-of-the-box state and after fine-tuning.
Initial results indicate that CLIP performs suboptimal in matching images to
demographic descriptions without fine-tuning. Although fine-tuning
significantly enhances its predictive capacity, the model continues to exhibit
limitations in effectively generalizing subtle demographic nuances. To address
this, we propose adopting a masked image modeling strategy to improve
generalization and better capture subtle demographic attributes. This approach
offers a pathway for enhancing demographic sensitivity in multimodal user
modeling tasks.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'This paper investigates the performance of multimodal pre-trained models in\nuser profiling tasks based on visual-linguistic demographic data. These models\nare critical for adapting to the needs and preferences of human users in social\nrobotics, thereby providing personalized responses and enhancing interaction\nquality. First, we introduce two datasets specifically curated to represent\ndemographic characteristics derived from user facial images. Next, we evaluate\nthe performance of a prominent contrastive multimodal pre-trained model, CLIP,\non these datasets, both in its out-of-the-box state and after fine-tuning.\nInitial results indicate that CLIP performs suboptimal in matching images to\ndemographic descriptions without fine-tuning. Although fine-tuning\nsignificantly enhances its predictive capacity, the model continues to exhibit\nlimitations in effectively generalizing subtle demographic nuances. To address\nthis, we propose adopting a masked image modeling strategy to improve\ngeneralization and better capture subtle demographic attributes. This approach\noffers a pathway for enhancing demographic sensitivity in multimodal user\nmodeling tasks.'}","['Hamed Rahimi', 'Mouad Abrini', 'Mahdi Khoramshahi', 'Mohamed Chetouani']",{'name': 'Mohamed Chetouani'},Mohamed Chetouani,,"[{'href': 'http://arxiv.org/abs/2502.10642v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10642v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10642v1,None,http://arxiv.org/abs/2502.10642v1,,,2,0
http://arxiv.org/abs/2502.10689v1,True,2025-02-15T06:33:02Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=6, tm_min=33, tm_sec=2, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T06:33:02Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=6, tm_min=33, tm_sec=2, tm_wday=5, tm_yday=46, tm_isdst=0)",Self-Explaining Hypergraph Neural Networks for Diagnosis Prediction,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Self-Explaining Hypergraph Neural Networks for Diagnosis Prediction'}","The burgeoning volume of electronic health records (EHRs) has enabled deep
learning models to excel in predictive healthcare. However, for high-stakes
applications such as diagnosis prediction, model interpretability remains
paramount. Existing deep learning diagnosis prediction models with intrinsic
interpretability often assign attention weights to every past diagnosis or
hospital visit, providing explanations lacking flexibility and succinctness. In
this paper, we introduce SHy, a self-explaining hypergraph neural network
model, designed to offer personalized, concise and faithful explanations that
allow for interventions from clinical experts. By modeling each patient as a
unique hypergraph and employing a message-passing mechanism, SHy captures
higher-order disease interactions and extracts distinct temporal phenotypes as
personalized explanations. It also addresses the incompleteness of the EHR data
by accounting for essential false negatives in the original diagnosis record. A
qualitative case study and extensive quantitative evaluations on two real-world
EHR datasets demonstrate the superior predictive performance and
interpretability of SHy over existing state-of-the-art models.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The burgeoning volume of electronic health records (EHRs) has enabled deep\nlearning models to excel in predictive healthcare. However, for high-stakes\napplications such as diagnosis prediction, model interpretability remains\nparamount. Existing deep learning diagnosis prediction models with intrinsic\ninterpretability often assign attention weights to every past diagnosis or\nhospital visit, providing explanations lacking flexibility and succinctness. In\nthis paper, we introduce SHy, a self-explaining hypergraph neural network\nmodel, designed to offer personalized, concise and faithful explanations that\nallow for interventions from clinical experts. By modeling each patient as a\nunique hypergraph and employing a message-passing mechanism, SHy captures\nhigher-order disease interactions and extracts distinct temporal phenotypes as\npersonalized explanations. It also addresses the incompleteness of the EHR data\nby accounting for essential false negatives in the original diagnosis record. A\nqualitative case study and extensive quantitative evaluations on two real-world\nEHR datasets demonstrate the superior predictive performance and\ninterpretability of SHy over existing state-of-the-art models.'}","['Leisheng Yu', 'Yanxiao Cai', 'Minxing Zhang', 'Xia Hu']",{'name': 'Xia Hu'},Xia Hu,,"[{'href': 'http://arxiv.org/abs/2502.10689v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10689v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10689v1,None,http://arxiv.org/abs/2502.10689v1,,,1,0
http://arxiv.org/abs/2502.10694v1,True,2025-02-15T06:58:57Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=6, tm_min=58, tm_sec=57, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T06:58:57Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=6, tm_min=58, tm_sec=57, tm_wday=5, tm_yday=46, tm_isdst=0)","Simulations of Common Unsupervised Domain Adaptation Algorithms for
  Image Classification","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Simulations of Common Unsupervised Domain Adaptation Algorithms for\n  Image Classification'}","Traditional machine learning assumes that training and test sets are derived
from the same distribution; however, this assumption does not always hold in
practical applications. This distribution disparity can lead to severe
performance drops when the trained model is used in new data sets. Domain
adaptation (DA) is a machine learning technique that aims to address this
problem by reducing the differences between domains. This paper presents
simulation-based algorithms of recent DA techniques, mainly related to
unsupervised domain adaptation (UDA), where labels are available only in the
source domain. Our study compares these techniques with public data sets and
diverse characteristics, highlighting their respective strengths and drawbacks.
For example, Safe Self-Refinement for Transformer-based DA (SSRT) achieved the
highest accuracy (91.6\%) in the office-31 data set during our simulations,
however, the accuracy dropped to 72.4\% in the Office-Home data set when using
limited batch sizes. In addition to improving the reader's comprehension of
recent techniques in DA, our study also highlights challenges and upcoming
directions for research in this domain. The codes are available at
https://github.com/AIPMLab/Domain_Adaptation.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Traditional machine learning assumes that training and test sets are derived\nfrom the same distribution; however, this assumption does not always hold in\npractical applications. This distribution disparity can lead to severe\nperformance drops when the trained model is used in new data sets. Domain\nadaptation (DA) is a machine learning technique that aims to address this\nproblem by reducing the differences between domains. This paper presents\nsimulation-based algorithms of recent DA techniques, mainly related to\nunsupervised domain adaptation (UDA), where labels are available only in the\nsource domain. Our study compares these techniques with public data sets and\ndiverse characteristics, highlighting their respective strengths and drawbacks.\nFor example, Safe Self-Refinement for Transformer-based DA (SSRT) achieved the\nhighest accuracy (91.6\\%) in the office-31 data set during our simulations,\nhowever, the accuracy dropped to 72.4\\% in the Office-Home data set when using\nlimited batch sizes. In addition to improving the reader's comprehension of\nrecent techniques in DA, our study also highlights challenges and upcoming\ndirections for research in this domain. The codes are available at\nhttps://github.com/AIPMLab/Domain_Adaptation.""}","['Ahmad Chaddad', 'Yihang Wu', 'Yuchen Jiang', 'Ahmed Bouridane', 'Christian Desrosiers']",{'name': 'Christian Desrosiers'},Christian Desrosiers,Accepted in IEEE TIM,"[{'title': 'doi', 'href': 'http://dx.doi.org/10.1109/TIM.2025.3527531', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2502.10694v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10694v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10694v1,None,http://arxiv.org/abs/2502.10694v1,,10.1109/TIM.2025.3527531,80,0
http://arxiv.org/abs/2502.10698v1,True,2025-02-15T07:05:55Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=7, tm_min=5, tm_sec=55, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T07:05:55Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=7, tm_min=5, tm_sec=55, tm_wday=5, tm_yday=46, tm_isdst=0)",Superpose Singular Features for Model Merging,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Superpose Singular Features for Model Merging'}","Model merging is a critical technique for combining the capabilities of
multiple fine-tuned models without requiring additional training. While
existing methods treat parameters as vectors, they overlook the intrinsic
structure of linear transformation matrices - the core components that comprise
the majority of model parameters. These matrices are fundamental to neural
networks, mapping input representations to output features through linear
combinations. Motivated by the linear representation hypothesis, we introduce
task matrix and propose to Superpose Features from Task Matrix (SFTM), a novel
approach that superposes features from individual task models into a merged
model. SFTM employs singular value decomposition to identify feature bases of
linear transformation matrices and solves a linear system to optimally combine
them while preserving input-output mappings from individual task models.
Extensive experiments on vision transformers and language models demonstrate
that our method consistently outperforms existing methods, achieving superior
performance and enhanced out-of-distribution generalization.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Model merging is a critical technique for combining the capabilities of\nmultiple fine-tuned models without requiring additional training. While\nexisting methods treat parameters as vectors, they overlook the intrinsic\nstructure of linear transformation matrices - the core components that comprise\nthe majority of model parameters. These matrices are fundamental to neural\nnetworks, mapping input representations to output features through linear\ncombinations. Motivated by the linear representation hypothesis, we introduce\ntask matrix and propose to Superpose Features from Task Matrix (SFTM), a novel\napproach that superposes features from individual task models into a merged\nmodel. SFTM employs singular value decomposition to identify feature bases of\nlinear transformation matrices and solves a linear system to optimally combine\nthem while preserving input-output mappings from individual task models.\nExtensive experiments on vision transformers and language models demonstrate\nthat our method consistently outperforms existing methods, achieving superior\nperformance and enhanced out-of-distribution generalization.'}","['Haiquan Qiu', 'You Wu', 'Quanming Yao']",{'name': 'Quanming Yao'},Quanming Yao,"14 pages, 1 figures","[{'href': 'http://arxiv.org/abs/2502.10698v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10698v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10698v1,None,http://arxiv.org/abs/2502.10698v1,,,0,0
http://arxiv.org/abs/2502.10704v1,True,2025-02-15T07:27:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=7, tm_min=27, tm_sec=15, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T07:27:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=7, tm_min=27, tm_sec=15, tm_wday=5, tm_yday=46, tm_isdst=0)","Occlusion-aware Non-Rigid Point Cloud Registration via Unsupervised
  Neural Deformation Correntropy","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Occlusion-aware Non-Rigid Point Cloud Registration via Unsupervised\n  Neural Deformation Correntropy'}","Non-rigid alignment of point clouds is crucial for scene understanding,
reconstruction, and various computer vision and robotics tasks. Recent
advancements in implicit deformation networks for non-rigid registration have
significantly reduced the reliance on large amounts of annotated training data.
However, existing state-of-the-art methods still face challenges in handling
occlusion scenarios. To address this issue, this paper introduces an innovative
unsupervised method called Occlusion-Aware Registration (OAR) for non-rigidly
aligning point clouds. The key innovation of our method lies in the utilization
of the adaptive correntropy function as a localized similarity measure,
enabling us to treat individual points distinctly. In contrast to previous
approaches that solely minimize overall deviations between two shapes, we
combine unsupervised implicit neural representations with the maximum
correntropy criterion to optimize the deformation of unoccluded regions. This
effectively avoids collapsed, tearing, and other physically implausible
results. Moreover, we present a theoretical analysis and establish the
relationship between the maximum correntropy criterion and the commonly used
Chamfer distance, highlighting that the correntropy-induced metric can be
served as a more universal measure for point cloud analysis. Additionally, we
introduce locally linear reconstruction to ensure that regions lacking
correspondences between shapes still undergo physically natural deformations.
Our method achieves superior or competitive performance compared to existing
approaches, particularly when dealing with occluded geometries. We also
demonstrate the versatility of our method in challenging tasks such as large
deformations, shape interpolation, and shape completion under occlusion
disturbances.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Non-rigid alignment of point clouds is crucial for scene understanding,\nreconstruction, and various computer vision and robotics tasks. Recent\nadvancements in implicit deformation networks for non-rigid registration have\nsignificantly reduced the reliance on large amounts of annotated training data.\nHowever, existing state-of-the-art methods still face challenges in handling\nocclusion scenarios. To address this issue, this paper introduces an innovative\nunsupervised method called Occlusion-Aware Registration (OAR) for non-rigidly\naligning point clouds. The key innovation of our method lies in the utilization\nof the adaptive correntropy function as a localized similarity measure,\nenabling us to treat individual points distinctly. In contrast to previous\napproaches that solely minimize overall deviations between two shapes, we\ncombine unsupervised implicit neural representations with the maximum\ncorrentropy criterion to optimize the deformation of unoccluded regions. This\neffectively avoids collapsed, tearing, and other physically implausible\nresults. Moreover, we present a theoretical analysis and establish the\nrelationship between the maximum correntropy criterion and the commonly used\nChamfer distance, highlighting that the correntropy-induced metric can be\nserved as a more universal measure for point cloud analysis. Additionally, we\nintroduce locally linear reconstruction to ensure that regions lacking\ncorrespondences between shapes still undergo physically natural deformations.\nOur method achieves superior or competitive performance compared to existing\napproaches, particularly when dealing with occluded geometries. We also\ndemonstrate the versatility of our method in challenging tasks such as large\ndeformations, shape interpolation, and shape completion under occlusion\ndisturbances.'}","['Mingyang Zhao', 'Gaofeng Meng', 'Dong-Ming Yan']",{'name': 'Dong-Ming Yan'},Dong-Ming Yan,[ICLR 2025] Project and code at: https://github.com/zikai1/OAReg,"[{'href': 'http://arxiv.org/abs/2502.10704v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10704v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10704v1,None,http://arxiv.org/abs/2502.10704v1,,,141,0
http://arxiv.org/abs/2502.10706v2,True,2025-02-19T02:41:12Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=2, tm_min=41, tm_sec=12, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-15T07:40:14Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=7, tm_min=40, tm_sec=14, tm_wday=5, tm_yday=46, tm_isdst=0)","Raising the Bar in Graph OOD Generalization: Invariant Learning Beyond
  Explicit Environment Modeling","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Raising the Bar in Graph OOD Generalization: Invariant Learning Beyond\n  Explicit Environment Modeling'}","Out-of-distribution (OOD) generalization has emerged as a critical challenge
in graph learning, as real-world graph data often exhibit diverse and shifting
environments that traditional models fail to generalize across. A promising
solution to address this issue is graph invariant learning (GIL), which aims to
learn invariant representations by disentangling label-correlated invariant
subgraphs from environment-specific subgraphs. However, existing GIL methods
face two major challenges: (1) the difficulty of capturing and modeling diverse
environments in graph data, and (2) the semantic cliff, where invariant
subgraphs from different classes are difficult to distinguish, leading to poor
class separability and increased misclassifications. To tackle these
challenges, we propose a novel method termed Multi-Prototype Hyperspherical
Invariant Learning (MPHIL), which introduces two key innovations: (1)
hyperspherical invariant representation extraction, enabling robust and highly
discriminative hyperspherical invariant feature extraction, and (2)
multi-prototype hyperspherical classification, which employs class prototypes
as intermediate variables to eliminate the need for explicit environment
modeling in GIL and mitigate the semantic cliff issue. Derived from the
theoretical framework of GIL, we introduce two novel objective functions: the
invariant prototype matching loss to ensure samples are matched to the correct
class prototypes, and the prototype separation loss to increase the distinction
between prototypes of different classes in the hyperspherical space. Extensive
experiments on 11 OOD generalization benchmark datasets demonstrate that MPHIL
achieves state-of-the-art performance, significantly outperforming existing
methods across graph data from various domains and with different distribution
shifts.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Out-of-distribution (OOD) generalization has emerged as a critical challenge\nin graph learning, as real-world graph data often exhibit diverse and shifting\nenvironments that traditional models fail to generalize across. A promising\nsolution to address this issue is graph invariant learning (GIL), which aims to\nlearn invariant representations by disentangling label-correlated invariant\nsubgraphs from environment-specific subgraphs. However, existing GIL methods\nface two major challenges: (1) the difficulty of capturing and modeling diverse\nenvironments in graph data, and (2) the semantic cliff, where invariant\nsubgraphs from different classes are difficult to distinguish, leading to poor\nclass separability and increased misclassifications. To tackle these\nchallenges, we propose a novel method termed Multi-Prototype Hyperspherical\nInvariant Learning (MPHIL), which introduces two key innovations: (1)\nhyperspherical invariant representation extraction, enabling robust and highly\ndiscriminative hyperspherical invariant feature extraction, and (2)\nmulti-prototype hyperspherical classification, which employs class prototypes\nas intermediate variables to eliminate the need for explicit environment\nmodeling in GIL and mitigate the semantic cliff issue. Derived from the\ntheoretical framework of GIL, we introduce two novel objective functions: the\ninvariant prototype matching loss to ensure samples are matched to the correct\nclass prototypes, and the prototype separation loss to increase the distinction\nbetween prototypes of different classes in the hyperspherical space. Extensive\nexperiments on 11 OOD generalization benchmark datasets demonstrate that MPHIL\nachieves state-of-the-art performance, significantly outperforming existing\nmethods across graph data from various domains and with different distribution\nshifts.'}","['Xu Shen', 'Yixin Liu', 'Yili Wang', 'Rui Miao', 'Yiwei Dai', 'Shirui Pan', 'Xin Wang']",{'name': 'Xin Wang'},Xin Wang,,"[{'href': 'http://arxiv.org/abs/2502.10706v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10706v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10706v2,None,http://arxiv.org/abs/2502.10706v2,,,208,0
http://arxiv.org/abs/2502.10707v1,True,2025-02-15T07:40:57Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=7, tm_min=40, tm_sec=57, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T07:40:57Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=7, tm_min=40, tm_sec=57, tm_wday=5, tm_yday=46, tm_isdst=0)","Reading Your Heart: Learning ECG Words and Sentences via Pre-training
  ECG Language Model","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Reading Your Heart: Learning ECG Words and Sentences via Pre-training\n  ECG Language Model'}","Electrocardiogram (ECG) is essential for the clinical diagnosis of
arrhythmias and other heart diseases, but deep learning methods based on ECG
often face limitations due to the need for high-quality annotations. Although
previous ECG self-supervised learning (eSSL) methods have made significant
progress in representation learning from unannotated ECG data, they typically
treat ECG signals as ordinary time-series data, segmenting the signals using
fixed-size and fixed-step time windows, which often ignore the form and rhythm
characteristics and latent semantic relationships in ECG signals. In this work,
we introduce a novel perspective on ECG signals, treating heartbeats as words
and rhythms as sentences. Based on this perspective, we first designed the
QRS-Tokenizer, which generates semantically meaningful ECG sentences from the
raw ECG signals. Building on these, we then propose HeartLang, a novel
self-supervised learning framework for ECG language processing, learning
general representations at form and rhythm levels. Additionally, we construct
the largest heartbeat-based ECG vocabulary to date, which will further advance
the development of ECG language processing. We evaluated HeartLang across six
public ECG datasets, where it demonstrated robust competitiveness against other
eSSL methods. Our data and code are publicly available at
https://github.com/PKUDigitalHealth/HeartLang.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Electrocardiogram (ECG) is essential for the clinical diagnosis of\narrhythmias and other heart diseases, but deep learning methods based on ECG\noften face limitations due to the need for high-quality annotations. Although\nprevious ECG self-supervised learning (eSSL) methods have made significant\nprogress in representation learning from unannotated ECG data, they typically\ntreat ECG signals as ordinary time-series data, segmenting the signals using\nfixed-size and fixed-step time windows, which often ignore the form and rhythm\ncharacteristics and latent semantic relationships in ECG signals. In this work,\nwe introduce a novel perspective on ECG signals, treating heartbeats as words\nand rhythms as sentences. Based on this perspective, we first designed the\nQRS-Tokenizer, which generates semantically meaningful ECG sentences from the\nraw ECG signals. Building on these, we then propose HeartLang, a novel\nself-supervised learning framework for ECG language processing, learning\ngeneral representations at form and rhythm levels. Additionally, we construct\nthe largest heartbeat-based ECG vocabulary to date, which will further advance\nthe development of ECG language processing. We evaluated HeartLang across six\npublic ECG datasets, where it demonstrated robust competitiveness against other\neSSL methods. Our data and code are publicly available at\nhttps://github.com/PKUDigitalHealth/HeartLang.'}","['Jiarui Jin', 'Haoyu Wang', 'Hongyan Li', 'Jun Li', 'Jiahui Pan', 'Shenda Hong']",{'name': 'Shenda Hong'},Shenda Hong,"21 pages, 8 figures, accepted by International Conference on Learning
  Representations 2025","[{'href': 'http://arxiv.org/abs/2502.10707v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10707v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10707v1,None,http://arxiv.org/abs/2502.10707v1,,,1996,0
http://arxiv.org/abs/2502.10709v1,True,2025-02-15T07:45:20Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=7, tm_min=45, tm_sec=20, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T07:45:20Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=7, tm_min=45, tm_sec=20, tm_wday=5, tm_yday=46, tm_isdst=0)",An Empirical Analysis of Uncertainty in Large Language Model Evaluations,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'An Empirical Analysis of Uncertainty in Large Language Model Evaluations'}","As LLM-as-a-Judge emerges as a new paradigm for assessing large language
models (LLMs), concerns have been raised regarding the alignment, bias, and
stability of LLM evaluators. While substantial work has focused on alignment
and bias, little research has concentrated on the stability of LLM evaluators.
In this paper, we conduct extensive experiments involving 9 widely used LLM
evaluators across 2 different evaluation settings to investigate the
uncertainty in model-based LLM evaluations. We pinpoint that LLM evaluators
exhibit varying uncertainty based on model families and sizes. With careful
comparative analyses, we find that employing special prompting strategies,
whether during inference or post-training, can alleviate evaluation uncertainty
to some extent. By utilizing uncertainty to enhance LLM's reliability and
detection capability in Out-Of-Distribution (OOD) data, we further fine-tune an
uncertainty-aware LLM evaluator named ConfiLM using a human-annotated
fine-tuning set and assess ConfiLM's OOD evaluation ability on a manually
designed test set sourced from the 2024 Olympics. Experimental results
demonstrate that incorporating uncertainty as additional information during the
fine-tuning phase can largely improve the model's evaluation performance in OOD
scenarios. The code and data are released at:
https://github.com/hasakiXie123/LLM-Evaluator-Uncertainty.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""As LLM-as-a-Judge emerges as a new paradigm for assessing large language\nmodels (LLMs), concerns have been raised regarding the alignment, bias, and\nstability of LLM evaluators. While substantial work has focused on alignment\nand bias, little research has concentrated on the stability of LLM evaluators.\nIn this paper, we conduct extensive experiments involving 9 widely used LLM\nevaluators across 2 different evaluation settings to investigate the\nuncertainty in model-based LLM evaluations. We pinpoint that LLM evaluators\nexhibit varying uncertainty based on model families and sizes. With careful\ncomparative analyses, we find that employing special prompting strategies,\nwhether during inference or post-training, can alleviate evaluation uncertainty\nto some extent. By utilizing uncertainty to enhance LLM's reliability and\ndetection capability in Out-Of-Distribution (OOD) data, we further fine-tune an\nuncertainty-aware LLM evaluator named ConfiLM using a human-annotated\nfine-tuning set and assess ConfiLM's OOD evaluation ability on a manually\ndesigned test set sourced from the 2024 Olympics. Experimental results\ndemonstrate that incorporating uncertainty as additional information during the\nfine-tuning phase can largely improve the model's evaluation performance in OOD\nscenarios. The code and data are released at:\nhttps://github.com/hasakiXie123/LLM-Evaluator-Uncertainty.""}","['Qiujie Xie', 'Qingqiu Li', 'Zhuohao Yu', 'Yuejie Zhang', 'Yue Zhang', 'Linyi Yang']",{'name': 'Linyi Yang'},Linyi Yang,ICLR 2025,"[{'href': 'http://arxiv.org/abs/2502.10709v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10709v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10709v1,None,http://arxiv.org/abs/2502.10709v1,,,2557,0
http://arxiv.org/abs/2502.10712v1,True,2025-02-15T07:56:58Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=7, tm_min=56, tm_sec=58, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T07:56:58Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=7, tm_min=56, tm_sec=58, tm_wday=5, tm_yday=46, tm_isdst=0)",FuncGenFoil: Airfoil Generation and Editing Model in Function Space,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'FuncGenFoil: Airfoil Generation and Editing Model in Function Space'}","Aircraft manufacturing is the jewel in the crown of industry, among which
generating high-fidelity airfoil geometries with controllable and editable
representations remains a fundamental challenge. While existing
deep-learning-based methods rely on predefined parametric function families,
e.g., B\'ezier curves and discrete point-based representations, they suffer
from inherent trade-offs between expressiveness and resolution flexibility. To
tackle this challenge, we introduce FuncGenFoil, a novel function-space
generative model that directly learns functional airfoil geometries. Our method
inherits both the advantages of arbitrary resolution sampling and the
smoothness of parametric functions, as well as the strong expressiveness of
discrete point-based functions. Empirical evaluations on the AFBench dataset
demonstrate that FuncGenFoil improves upon state-of-the-art methods in airfoil
generation by achieving a relative -74.4 label error reduction and +23.2
diversity increase on the AF-200K dataset. Our results highlight the advantages
of function-space modeling for aerodynamic shape optimization, offering a
powerful and flexible framework for high-fidelity airfoil design. Our code will
be released.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Aircraft manufacturing is the jewel in the crown of industry, among which\ngenerating high-fidelity airfoil geometries with controllable and editable\nrepresentations remains a fundamental challenge. While existing\ndeep-learning-based methods rely on predefined parametric function families,\ne.g., B\\'ezier curves and discrete point-based representations, they suffer\nfrom inherent trade-offs between expressiveness and resolution flexibility. To\ntackle this challenge, we introduce FuncGenFoil, a novel function-space\ngenerative model that directly learns functional airfoil geometries. Our method\ninherits both the advantages of arbitrary resolution sampling and the\nsmoothness of parametric functions, as well as the strong expressiveness of\ndiscrete point-based functions. Empirical evaluations on the AFBench dataset\ndemonstrate that FuncGenFoil improves upon state-of-the-art methods in airfoil\ngeneration by achieving a relative -74.4 label error reduction and +23.2\ndiversity increase on the AF-200K dataset. Our results highlight the advantages\nof function-space modeling for aerodynamic shape optimization, offering a\npowerful and flexible framework for high-fidelity airfoil design. Our code will\nbe released.""}","['Jinouwen Zhang', 'Junjie Ren', 'Aobo Yang', 'Yan Lu', 'Lu Chen', 'Hairun Xie', 'Jing Wang', 'Miao Zhang', 'Wanli Ouyang', 'Shixiang Tang']",{'name': 'Shixiang Tang'},Shixiang Tang,,"[{'href': 'http://arxiv.org/abs/2502.10712v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10712v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10712v1,None,http://arxiv.org/abs/2502.10712v1,,,125,0
http://arxiv.org/abs/2502.10723v1,True,2025-02-15T08:26:49Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=8, tm_min=26, tm_sec=49, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T08:26:49Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=8, tm_min=26, tm_sec=49, tm_wday=5, tm_yday=46, tm_isdst=0)","A Mathematics Framework of Artificial Shifted Population Risk and Its
  Further Understanding Related to Consistency Regularization","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A Mathematics Framework of Artificial Shifted Population Risk and Its\n  Further Understanding Related to Consistency Regularization'}","Data augmentation is an important technique in training deep neural networks
as it enhances their ability to generalize and remain robust. While data
augmentation is commonly used to expand the sample size and act as a
consistency regularization term, there is a lack of research on the
relationship between them. To address this gap, this paper introduces a more
comprehensive mathematical framework for data augmentation. Through this
framework, we establish that the expected risk of the shifted population is the
sum of the original population risk and a gap term, which can be interpreted as
a consistency regularization term. The paper also provides a theoretical
understanding of this gap, highlighting its negative effects on the early
stages of training. We also propose a method to mitigate these effects. To
validate our approach, we conducted experiments using same data augmentation
techniques and computing resources under several scenarios, including standard
training, out-of-distribution, and imbalanced classification. The results
demonstrate that our methods surpass compared methods under all scenarios in
terms of generalization ability and convergence stability. We provide our code
implementation at the following link: https://github.com/ydlsfhll/ASPR.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Data augmentation is an important technique in training deep neural networks\nas it enhances their ability to generalize and remain robust. While data\naugmentation is commonly used to expand the sample size and act as a\nconsistency regularization term, there is a lack of research on the\nrelationship between them. To address this gap, this paper introduces a more\ncomprehensive mathematical framework for data augmentation. Through this\nframework, we establish that the expected risk of the shifted population is the\nsum of the original population risk and a gap term, which can be interpreted as\na consistency regularization term. The paper also provides a theoretical\nunderstanding of this gap, highlighting its negative effects on the early\nstages of training. We also propose a method to mitigate these effects. To\nvalidate our approach, we conducted experiments using same data augmentation\ntechniques and computing resources under several scenarios, including standard\ntraining, out-of-distribution, and imbalanced classification. The results\ndemonstrate that our methods surpass compared methods under all scenarios in\nterms of generalization ability and convergence stability. We provide our code\nimplementation at the following link: https://github.com/ydlsfhll/ASPR.'}","['Xiliang Yang', 'Shenyang Deng', 'Shicong Liu', 'Yuanchi Suo', 'Wing. W. Y NG', 'Jianjun Zhang']",{'name': 'Jianjun Zhang'},Jianjun Zhang,,"[{'href': 'http://arxiv.org/abs/2502.10723v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10723v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10723v1,None,http://arxiv.org/abs/2502.10723v1,,,430,0
http://arxiv.org/abs/2502.10725v1,True,2025-02-15T08:28:58Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=8, tm_min=28, tm_sec=58, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T08:28:58Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=8, tm_min=28, tm_sec=58, tm_wday=5, tm_yday=46, tm_isdst=0)",PropNet: a White-Box and Human-Like Network for Sentence Representation,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'PropNet: a White-Box and Human-Like Network for Sentence Representation'}","Transformer-based embedding methods have dominated the field of sentence
representation in recent years. Although they have achieved remarkable
performance on NLP missions, such as semantic textual similarity (STS) tasks,
their black-box nature and large-data-driven training style have raised
concerns, including issues related to bias, trust, and safety. Many efforts
have been made to improve the interpretability of embedding models, but these
problems have not been fundamentally resolved. To achieve inherent
interpretability, we propose a purely white-box and human-like sentence
representation network, PropNet. Inspired by findings from cognitive science,
PropNet constructs a hierarchical network based on the propositions contained
in a sentence. While experiments indicate that PropNet has a significant gap
compared to state-of-the-art (SOTA) embedding models in STS tasks, case studies
reveal substantial room for improvement. Additionally, PropNet enables us to
analyze and understand the human cognitive processes underlying STS benchmarks.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Transformer-based embedding methods have dominated the field of sentence\nrepresentation in recent years. Although they have achieved remarkable\nperformance on NLP missions, such as semantic textual similarity (STS) tasks,\ntheir black-box nature and large-data-driven training style have raised\nconcerns, including issues related to bias, trust, and safety. Many efforts\nhave been made to improve the interpretability of embedding models, but these\nproblems have not been fundamentally resolved. To achieve inherent\ninterpretability, we propose a purely white-box and human-like sentence\nrepresentation network, PropNet. Inspired by findings from cognitive science,\nPropNet constructs a hierarchical network based on the propositions contained\nin a sentence. While experiments indicate that PropNet has a significant gap\ncompared to state-of-the-art (SOTA) embedding models in STS tasks, case studies\nreveal substantial room for improvement. Additionally, PropNet enables us to\nanalyze and understand the human cognitive processes underlying STS benchmarks.'}",['Fei Yang'],{'name': 'Fei Yang'},Fei Yang,,"[{'href': 'http://arxiv.org/abs/2502.10725v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10725v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10725v1,None,http://arxiv.org/abs/2502.10725v1,,,0,0
http://arxiv.org/abs/2502.10732v1,True,2025-02-15T09:01:31Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=9, tm_min=1, tm_sec=31, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T09:01:31Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=9, tm_min=1, tm_sec=31, tm_wday=5, tm_yday=46, tm_isdst=0)","Rule-Bottleneck Reinforcement Learning: Joint Explanation and Decision
  Optimization for Resource Allocation with Language Agents","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Rule-Bottleneck Reinforcement Learning: Joint Explanation and Decision\n  Optimization for Resource Allocation with Language Agents'}","Deep Reinforcement Learning (RL) is remarkably effective in addressing
sequential resource allocation problems in domains such as healthcare, public
policy, and resource management. However, deep RL policies often lack
transparency and adaptability, challenging their deployment alongside human
decision-makers. In contrast, Language Agents, powered by large language models
(LLMs), provide human-understandable reasoning but may struggle with effective
decision making. To bridge this gap, we propose Rule-Bottleneck Reinforcement
Learning (RBRL), a novel framework that jointly optimizes decision and
explanations. At each step, RBRL generates candidate rules with an LLM, selects
among them using an attention-based RL policy, and determines the environment
action with an explanation via chain-of-thought reasoning. The RL rule
selection is optimized using the environment rewards and an explainability
metric judged by the LLM. Evaluations in real-world scenarios highlight RBRL's
competitive performance with deep RL and efficiency gains over LLM fine-tuning.
A survey further confirms the enhanced quality of its explanations.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Deep Reinforcement Learning (RL) is remarkably effective in addressing\nsequential resource allocation problems in domains such as healthcare, public\npolicy, and resource management. However, deep RL policies often lack\ntransparency and adaptability, challenging their deployment alongside human\ndecision-makers. In contrast, Language Agents, powered by large language models\n(LLMs), provide human-understandable reasoning but may struggle with effective\ndecision making. To bridge this gap, we propose Rule-Bottleneck Reinforcement\nLearning (RBRL), a novel framework that jointly optimizes decision and\nexplanations. At each step, RBRL generates candidate rules with an LLM, selects\namong them using an attention-based RL policy, and determines the environment\naction with an explanation via chain-of-thought reasoning. The RL rule\nselection is optimized using the environment rewards and an explainability\nmetric judged by the LLM. Evaluations in real-world scenarios highlight RBRL's\ncompetitive performance with deep RL and efficiency gains over LLM fine-tuning.\nA survey further confirms the enhanced quality of its explanations.""}","['Mauricio Tec', 'Guojun Xiong', 'Haichuan Wang', 'Francesca Dominici', 'Milind Tambe']",{'name': 'Milind Tambe'},Milind Tambe,,"[{'href': 'http://arxiv.org/abs/2502.10732v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10732v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10732v1,None,http://arxiv.org/abs/2502.10732v1,,,113,0
http://arxiv.org/abs/2502.10749v1,True,2025-02-15T10:18:46Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=10, tm_min=18, tm_sec=46, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T10:18:46Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=10, tm_min=18, tm_sec=46, tm_wday=5, tm_yday=46, tm_isdst=0)","LoRE-Merging: Exploring Low-Rank Estimation For Large Language Model
  Merging","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'LoRE-Merging: Exploring Low-Rank Estimation For Large Language Model\n  Merging'}","While most current approaches rely on further training techniques, such as
fine-tuning or reinforcement learning, to enhance model capacities, model
merging stands out for its ability of improving models without requiring any
additional training. In this paper, we propose a unified framework for model
merging based on low-rank estimation of task vectors without the need for
access to the base model, named \textsc{LoRE-Merging}. Our approach is
motivated by the observation that task vectors from fine-tuned models
frequently exhibit a limited number of dominant singular values, making
low-rank estimations less prone to interference. We implement the method by
formulating the merging problem as an optimization problem. Extensive empirical
experiments demonstrate the effectiveness of our framework in mitigating
interference and preserving task-specific information, thereby advancing the
state-of-the-art performance in model merging techniques.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'While most current approaches rely on further training techniques, such as\nfine-tuning or reinforcement learning, to enhance model capacities, model\nmerging stands out for its ability of improving models without requiring any\nadditional training. In this paper, we propose a unified framework for model\nmerging based on low-rank estimation of task vectors without the need for\naccess to the base model, named \\textsc{LoRE-Merging}. Our approach is\nmotivated by the observation that task vectors from fine-tuned models\nfrequently exhibit a limited number of dominant singular values, making\nlow-rank estimations less prone to interference. We implement the method by\nformulating the merging problem as an optimization problem. Extensive empirical\nexperiments demonstrate the effectiveness of our framework in mitigating\ninterference and preserving task-specific information, thereby advancing the\nstate-of-the-art performance in model merging techniques.'}","['Zehua Liu', 'Han Wu', 'Yuxuan Yao', 'Ruifeng She', 'Xiongwei Han', 'Tao Zhong', 'Mingxuan Yuan']",{'name': 'Mingxuan Yuan'},Mingxuan Yuan,,"[{'href': 'http://arxiv.org/abs/2502.10749v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10749v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10749v1,None,http://arxiv.org/abs/2502.10749v1,,,31,0
http://arxiv.org/abs/2502.10750v1,True,2025-02-15T10:21:10Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=10, tm_min=21, tm_sec=10, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T10:21:10Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=10, tm_min=21, tm_sec=10, tm_wday=5, tm_yday=46, tm_isdst=0)","Human-Centric Community Detection in Hybrid Metaverse Networks with
  Integrated AI Entities","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Human-Centric Community Detection in Hybrid Metaverse Networks with\n  Integrated AI Entities'}","Community detection is a cornerstone problem in social network analysis
(SNA), aimed at identifying cohesive communities with minimal external links.
However, the rise of generative AI and Metaverse introduce complexities by
creating hybrid human-AI social networks (denoted by HASNs), where traditional
methods fall short, especially in human-centric settings. This paper introduces
a novel community detection problem in HASNs (denoted by MetaCD), which seeks
to enhance human connectivity within communities while reducing the presence of
AI nodes. Effective processing of MetaCD poses challenges due to the delicate
trade-off between excluding certain AI nodes and maintaining community
structure. To address this, we propose CUSA, an innovative framework
incorporating AI-aware clustering techniques that navigate this trade-off by
selectively retaining AI nodes that contribute to community integrity.
Furthermore, given the scarcity of real-world HASNs, we devise four strategies
for synthesizing these networks under various hypothetical scenarios. Empirical
evaluations on real social networks, reconfigured as HASNs, demonstrate the
effectiveness and practicality of our approach compared to traditional non-deep
learning and graph neural network (GNN)-based methods.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Community detection is a cornerstone problem in social network analysis\n(SNA), aimed at identifying cohesive communities with minimal external links.\nHowever, the rise of generative AI and Metaverse introduce complexities by\ncreating hybrid human-AI social networks (denoted by HASNs), where traditional\nmethods fall short, especially in human-centric settings. This paper introduces\na novel community detection problem in HASNs (denoted by MetaCD), which seeks\nto enhance human connectivity within communities while reducing the presence of\nAI nodes. Effective processing of MetaCD poses challenges due to the delicate\ntrade-off between excluding certain AI nodes and maintaining community\nstructure. To address this, we propose CUSA, an innovative framework\nincorporating AI-aware clustering techniques that navigate this trade-off by\nselectively retaining AI nodes that contribute to community integrity.\nFurthermore, given the scarcity of real-world HASNs, we devise four strategies\nfor synthesizing these networks under various hypothetical scenarios. Empirical\nevaluations on real social networks, reconfigured as HASNs, demonstrate the\neffectiveness and practicality of our approach compared to traditional non-deep\nlearning and graph neural network (GNN)-based methods.'}","['Shih-Hsuan Chiu', 'Ya-Wen Teng', 'De-Nian Yang', 'Ming-Syan Chen']",{'name': 'Ming-Syan Chen'},Ming-Syan Chen,"15 pages, Accepted for publication in the ACM WWW 2025","[{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3696410.3714679', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2502.10750v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10750v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10750v1,None,http://arxiv.org/abs/2502.10750v1,,10.1145/3696410.3714679,63,0
http://arxiv.org/abs/2502.10802v1,True,2025-02-15T13:52:30Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=13, tm_min=52, tm_sec=30, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T13:52:30Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=13, tm_min=52, tm_sec=30, tm_wday=5, tm_yday=46, tm_isdst=0)","CoCoEvo: Co-Evolution of Programs and Test Cases to Enhance Code
  Generation","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'CoCoEvo: Co-Evolution of Programs and Test Cases to Enhance Code\n  Generation'}","Large Language Models (LLMs) have shown remarkable performance in automated
code generation. However, existing approaches often rely heavily on pre-defined
test cases, which become impractical in scenarios where such cases are
unavailable. While prior works explore filtering techniques between programs
and test cases, they overlook the refinement of test cases. To address this
limitation, we introduce CoCoEvo, a novel LLM-based co-evolution framework that
simultaneously evolves programs and test cases. CoCoEvo eliminates the
dependency on pre-defined test cases by generating both programs and test cases
directly from natural language problem descriptions and function headers. The
framework employs specialized evolutionary operators, including LLM-based
crossover and mutation operators for program evolution, along with a test case
generation operator for test case evolution. Additionally, we propose
optimization strategies such as a crossover rate scheduler to balance
exploration and convergence, and a multi-objective optimization method for test
case selection. Experimental results on multiple state-of-the-art LLMs
demonstrate that CoCoEvo surpasses existing methods, achieving state-of-the-art
performance in automated code generation and testing. These results underscore
the potential of co-evolutionary techniques in advancing the field of automated
programming.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Language Models (LLMs) have shown remarkable performance in automated\ncode generation. However, existing approaches often rely heavily on pre-defined\ntest cases, which become impractical in scenarios where such cases are\nunavailable. While prior works explore filtering techniques between programs\nand test cases, they overlook the refinement of test cases. To address this\nlimitation, we introduce CoCoEvo, a novel LLM-based co-evolution framework that\nsimultaneously evolves programs and test cases. CoCoEvo eliminates the\ndependency on pre-defined test cases by generating both programs and test cases\ndirectly from natural language problem descriptions and function headers. The\nframework employs specialized evolutionary operators, including LLM-based\ncrossover and mutation operators for program evolution, along with a test case\ngeneration operator for test case evolution. Additionally, we propose\noptimization strategies such as a crossover rate scheduler to balance\nexploration and convergence, and a multi-objective optimization method for test\ncase selection. Experimental results on multiple state-of-the-art LLMs\ndemonstrate that CoCoEvo surpasses existing methods, achieving state-of-the-art\nperformance in automated code generation and testing. These results underscore\nthe potential of co-evolutionary techniques in advancing the field of automated\nprogramming.'}","['Kefan Li', 'Hongyue Yu', 'Tingyu Guo', 'Shijie Cao', 'Yuan Yuan']",{'name': 'Yuan Yuan'},Yuan Yuan,,"[{'href': 'http://arxiv.org/abs/2502.10802v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10802v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.SE', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.SE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10802v1,None,http://arxiv.org/abs/2502.10802v1,,,24,0
http://arxiv.org/abs/2502.10816v2,True,2025-02-18T04:47:55Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=4, tm_min=47, tm_sec=55, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-15T14:42:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=14, tm_min=42, tm_sec=42, tm_wday=5, tm_yday=46, tm_isdst=0)",BalanceBenchmark: A Survey for Imbalanced Learning,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'BalanceBenchmark: A Survey for Imbalanced Learning'}","Multimodal learning has gained attention for its capacity to integrate
information from different modalities. However, it is often hindered by the
multimodal imbalance problem, where certain modality dominates while others
remain underutilized. Although recent studies have proposed various methods to
alleviate this problem, they lack comprehensive and fair comparisons. In this
paper, we systematically categorize various mainstream multimodal imbalance
algorithms into four groups based on the strategies they employ to mitigate
imbalance. To facilitate a comprehensive evaluation of these methods, we
introduce BalanceBenchmark, a benchmark including multiple widely used
multidimensional datasets and evaluation metrics from three perspectives:
performance, imbalance degree, and complexity. To ensure fair comparisons, we
have developed a modular and extensible toolkit that standardizes the
experimental workflow across different methods. Based on the experiments using
BalanceBenchmark, we have identified several key insights into the
characteristics and advantages of different method groups in terms of
performance, balance degree and computational complexity. We expect such
analysis could inspire more efficient approaches to address the imbalance
problem in the future, as well as foundation models. The code of the toolkit is
available at https://github.com/GeWu-Lab/BalanceBenchmark.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Multimodal learning has gained attention for its capacity to integrate\ninformation from different modalities. However, it is often hindered by the\nmultimodal imbalance problem, where certain modality dominates while others\nremain underutilized. Although recent studies have proposed various methods to\nalleviate this problem, they lack comprehensive and fair comparisons. In this\npaper, we systematically categorize various mainstream multimodal imbalance\nalgorithms into four groups based on the strategies they employ to mitigate\nimbalance. To facilitate a comprehensive evaluation of these methods, we\nintroduce BalanceBenchmark, a benchmark including multiple widely used\nmultidimensional datasets and evaluation metrics from three perspectives:\nperformance, imbalance degree, and complexity. To ensure fair comparisons, we\nhave developed a modular and extensible toolkit that standardizes the\nexperimental workflow across different methods. Based on the experiments using\nBalanceBenchmark, we have identified several key insights into the\ncharacteristics and advantages of different method groups in terms of\nperformance, balance degree and computational complexity. We expect such\nanalysis could inspire more efficient approaches to address the imbalance\nproblem in the future, as well as foundation models. The code of the toolkit is\navailable at https://github.com/GeWu-Lab/BalanceBenchmark.'}","['Shaoxuan Xu', 'Menglu Cui', 'Chengxiang Huang', 'Hongfa Wang', 'DiHu']",{'name': 'DiHu'},DiHu,"9 pages, 3 figures","[{'href': 'http://arxiv.org/abs/2502.10816v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10816v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10816v2,None,http://arxiv.org/abs/2502.10816v2,,,0,0
http://arxiv.org/abs/2502.10818v1,True,2025-02-15T14:43:41Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=14, tm_min=43, tm_sec=41, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T14:43:41Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=14, tm_min=43, tm_sec=41, tm_wday=5, tm_yday=46, tm_isdst=0)","On Vanishing Gradients, Over-Smoothing, and Over-Squashing in GNNs:
  Bridging Recurrent and Graph Learning","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'On Vanishing Gradients, Over-Smoothing, and Over-Squashing in GNNs:\n  Bridging Recurrent and Graph Learning'}","Graph Neural Networks (GNNs) are models that leverage the graph structure to
transmit information between nodes, typically through the message-passing
operation. While widely successful, this approach is well known to suffer from
the over-smoothing and over-squashing phenomena, which result in
representational collapse as the number of layers increases and insensitivity
to the information contained at distant and poorly connected nodes,
respectively. In this paper, we present a unified view of these problems
through the lens of vanishing gradients, using ideas from linear control theory
for our analysis. We propose an interpretation of GNNs as recurrent models and
empirically demonstrate that a simple state-space formulation of a GNN
effectively alleviates over-smoothing and over-squashing at no extra trainable
parameter cost. Further, we show theoretically and empirically that (i) GNNs
are by design prone to extreme gradient vanishing even after a few layers; (ii)
Over-smoothing is directly related to the mechanism causing vanishing
gradients; (iii) Over-squashing is most easily alleviated by a combination of
graph rewiring and vanishing gradient mitigation. We believe our work will help
bridge the gap between the recurrent and graph neural network literature and
will unlock the design of new deep and performant GNNs.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Graph Neural Networks (GNNs) are models that leverage the graph structure to\ntransmit information between nodes, typically through the message-passing\noperation. While widely successful, this approach is well known to suffer from\nthe over-smoothing and over-squashing phenomena, which result in\nrepresentational collapse as the number of layers increases and insensitivity\nto the information contained at distant and poorly connected nodes,\nrespectively. In this paper, we present a unified view of these problems\nthrough the lens of vanishing gradients, using ideas from linear control theory\nfor our analysis. We propose an interpretation of GNNs as recurrent models and\nempirically demonstrate that a simple state-space formulation of a GNN\neffectively alleviates over-smoothing and over-squashing at no extra trainable\nparameter cost. Further, we show theoretically and empirically that (i) GNNs\nare by design prone to extreme gradient vanishing even after a few layers; (ii)\nOver-smoothing is directly related to the mechanism causing vanishing\ngradients; (iii) Over-squashing is most easily alleviated by a combination of\ngraph rewiring and vanishing gradient mitigation. We believe our work will help\nbridge the gap between the recurrent and graph neural network literature and\nwill unlock the design of new deep and performant GNNs.'}","['lvaro Arroyo', 'Alessio Gravina', 'Benjamin Gutteridge', 'Federico Barbero', 'Claudio Gallicchio', 'Xiaowen Dong', 'Michael Bronstein', 'Pierre Vandergheynst']",{'name': 'Pierre Vandergheynst'},Pierre Vandergheynst,,"[{'href': 'http://arxiv.org/abs/2502.10818v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10818v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10818v1,None,http://arxiv.org/abs/2502.10818v1,,,490,0
http://arxiv.org/abs/2502.10825v1,True,2025-02-15T15:01:04Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=15, tm_min=1, tm_sec=4, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T15:01:04Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=15, tm_min=1, tm_sec=4, tm_wday=5, tm_yday=46, tm_isdst=0)",MITRE ATT&CK Applications in Cybersecurity and The Way Forward,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'MITRE ATT&CK Applications in Cybersecurity and The Way Forward'}","The MITRE ATT&CK framework is a widely adopted tool for enhancing
cybersecurity, supporting threat intelligence, incident response, attack
modeling, and vulnerability prioritization. This paper synthesizes research on
its application across these domains by analyzing 417 peer-reviewed
publications. We identify commonly used adversarial tactics, techniques, and
procedures (TTPs) and examine the integration of natural language processing
(NLP) and machine learning (ML) with ATT&CK to improve threat detection and
response. Additionally, we explore the interoperability of ATT&CK with other
frameworks, such as the Cyber Kill Chain, NIST guidelines, and STRIDE,
highlighting its versatility. The paper further evaluates the framework from
multiple perspectives, including its effectiveness, validation methods, and
sector-specific challenges, particularly in industrial control systems (ICS)
and healthcare. We conclude by discussing current limitations and proposing
future research directions to enhance the applicability of ATT&CK in dynamic
cybersecurity environments.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The MITRE ATT&CK framework is a widely adopted tool for enhancing\ncybersecurity, supporting threat intelligence, incident response, attack\nmodeling, and vulnerability prioritization. This paper synthesizes research on\nits application across these domains by analyzing 417 peer-reviewed\npublications. We identify commonly used adversarial tactics, techniques, and\nprocedures (TTPs) and examine the integration of natural language processing\n(NLP) and machine learning (ML) with ATT&CK to improve threat detection and\nresponse. Additionally, we explore the interoperability of ATT&CK with other\nframeworks, such as the Cyber Kill Chain, NIST guidelines, and STRIDE,\nhighlighting its versatility. The paper further evaluates the framework from\nmultiple perspectives, including its effectiveness, validation methods, and\nsector-specific challenges, particularly in industrial control systems (ICS)\nand healthcare. We conclude by discussing current limitations and proposing\nfuture research directions to enhance the applicability of ATT&CK in dynamic\ncybersecurity environments.'}","['Yuning Jiang', 'Qiaoran Meng', 'Feiyang Shang', 'Nay Oo', 'Le Thi Hong Minh', 'Hoon Wei Lim', 'Biplab Sikdar']",{'name': 'Biplab Sikdar'},Biplab Sikdar,37 pages,"[{'href': 'http://arxiv.org/abs/2502.10825v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10825v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68M25 (Primary) 68T99 (Secondary)', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10825v1,None,http://arxiv.org/abs/2502.10825v1,,,190,0
http://arxiv.org/abs/2502.10852v1,True,2025-02-15T16:53:10Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=16, tm_min=53, tm_sec=10, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T16:53:10Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=16, tm_min=53, tm_sec=10, tm_wday=5, tm_yday=46, tm_isdst=0)","Multilingual Encoder Knows more than You Realize: Shared Weights
  Pretraining for Extremely Low-Resource Languages","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Multilingual Encoder Knows more than You Realize: Shared Weights\n  Pretraining for Extremely Low-Resource Languages'}","While multilingual language models like XLM-R have advanced multilingualism
in NLP, they still perform poorly in extremely low-resource languages. This
situation is exacerbated by the fact that modern LLMs such as LLaMA and Qwen
support far fewer languages than XLM-R, making text generation models
non-existent for many languages in the world. To tackle this challenge, we
propose a novel framework for adapting multilingual encoders to text generation
in extremely low-resource languages. By reusing the weights between the encoder
and the decoder, our framework allows the model to leverage the learned
semantic space of the encoder, enabling efficient learning and effective
generalization in low-resource languages. Applying this framework to four
Chinese minority languages, we present XLM-SWCM, and demonstrate its superior
performance on various downstream tasks even when compared with much larger
models.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'While multilingual language models like XLM-R have advanced multilingualism\nin NLP, they still perform poorly in extremely low-resource languages. This\nsituation is exacerbated by the fact that modern LLMs such as LLaMA and Qwen\nsupport far fewer languages than XLM-R, making text generation models\nnon-existent for many languages in the world. To tackle this challenge, we\npropose a novel framework for adapting multilingual encoders to text generation\nin extremely low-resource languages. By reusing the weights between the encoder\nand the decoder, our framework allows the model to leverage the learned\nsemantic space of the encoder, enabling efficient learning and effective\ngeneralization in low-resource languages. Applying this framework to four\nChinese minority languages, we present XLM-SWCM, and demonstrate its superior\nperformance on various downstream tasks even when compared with much larger\nmodels.'}","['Zeli Su', 'Ziyin Zhang', 'Guixian Xu', 'Jianing Liu', 'XU Han', 'Ting Zhang', 'Yushuang Dong']",{'name': 'Yushuang Dong'},Yushuang Dong,,"[{'href': 'http://arxiv.org/abs/2502.10852v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10852v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10852v1,None,http://arxiv.org/abs/2502.10852v1,,,110,0
http://arxiv.org/abs/2502.10858v2,True,2025-02-18T07:58:19Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=7, tm_min=58, tm_sec=19, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-15T16:59:59Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=16, tm_min=59, tm_sec=59, tm_wday=5, tm_yday=46, tm_isdst=0)",Is Depth All You Need? An Exploration of Iterative Reasoning in LLMs,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Is Depth All You Need? An Exploration of Iterative Reasoning in LLMs'}","Deep iterative chain-of-thought (CoT) reasoning enables LLMs to tackle
complex tasks by progressively activating relevant pre-trained knowledge.
However, it faces challenges in ensuring continual improvement and determining
a stopping criterion. In this paper, we investigate whether the relevant
knowledge that contributes directly to solving the given question can be
activated from the initial reasoning path, thus circumventing the need for
iterative refinement. Our experiments reveal that increasing the diversity of
initial reasoning paths can achieve comparable or superior performance, a
concept we term \textit{breadth reasoning}. However, existing breadth reasoning
approaches, such as self-consistency, offer limited diversity. To address this
limitation, we propose a simple yet effective method that enhances reasoning
breadth by integrating contextual exploration with reduced sampling randomness.
Extensive experiments demonstrate that our approach significantly outperforms
deep iterative reasoning. Our code is provided in
https://github.com/zongqianwu/breadth.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Deep iterative chain-of-thought (CoT) reasoning enables LLMs to tackle\ncomplex tasks by progressively activating relevant pre-trained knowledge.\nHowever, it faces challenges in ensuring continual improvement and determining\na stopping criterion. In this paper, we investigate whether the relevant\nknowledge that contributes directly to solving the given question can be\nactivated from the initial reasoning path, thus circumventing the need for\niterative refinement. Our experiments reveal that increasing the diversity of\ninitial reasoning paths can achieve comparable or superior performance, a\nconcept we term \\textit{breadth reasoning}. However, existing breadth reasoning\napproaches, such as self-consistency, offer limited diversity. To address this\nlimitation, we propose a simple yet effective method that enhances reasoning\nbreadth by integrating contextual exploration with reduced sampling randomness.\nExtensive experiments demonstrate that our approach significantly outperforms\ndeep iterative reasoning. Our code is provided in\nhttps://github.com/zongqianwu/breadth.'}","['Zongqian Wu', 'Tianyu Li', 'Baoduo Xu', 'Jiaying Yang', 'Mengmeng Zhan', 'Xiaofeng Zhu', 'Lei Feng']",{'name': 'Lei Feng'},Lei Feng,"22 pages, 7 figures","[{'href': 'http://arxiv.org/abs/2502.10858v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10858v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10858v2,None,http://arxiv.org/abs/2502.10858v2,,,136,0
http://arxiv.org/abs/2502.10867v1,True,2025-02-15T17:52:11Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=17, tm_min=52, tm_sec=11, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T17:52:11Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=17, tm_min=52, tm_sec=11, tm_wday=5, tm_yday=46, tm_isdst=0)",A Tutorial on LLM Reasoning: Relevant Methods behind ChatGPT o1,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A Tutorial on LLM Reasoning: Relevant Methods behind ChatGPT o1'}","OpenAI o1 has shown that applying reinforcement learning to integrate
reasoning steps directly during inference can significantly improve a model's
reasoning capabilities. This result is exciting as the field transitions from
the conventional autoregressive method of generating answers to a more
deliberate approach that models the slow-thinking process through step-by-step
reasoning training. Reinforcement learning plays a key role in both the model's
training and decoding processes. In this article, we present a comprehensive
formulation of reasoning problems and investigate the use of both model-based
and model-free approaches to better support this slow-thinking framework.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""OpenAI o1 has shown that applying reinforcement learning to integrate\nreasoning steps directly during inference can significantly improve a model's\nreasoning capabilities. This result is exciting as the field transitions from\nthe conventional autoregressive method of generating answers to a more\ndeliberate approach that models the slow-thinking process through step-by-step\nreasoning training. Reinforcement learning plays a key role in both the model's\ntraining and decoding processes. In this article, we present a comprehensive\nformulation of reasoning problems and investigate the use of both model-based\nand model-free approaches to better support this slow-thinking framework.""}",['Jun Wang'],{'name': 'Jun Wang'},Jun Wang,,"[{'href': 'http://arxiv.org/abs/2502.10867v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10867v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10867v1,None,http://arxiv.org/abs/2502.10867v1,,,0,0
http://arxiv.org/abs/2502.10920v1,True,2025-02-15T22:38:40Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=22, tm_min=38, tm_sec=40, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T22:38:40Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=22, tm_min=38, tm_sec=40, tm_wday=5, tm_yday=46, tm_isdst=0)",Do Deepfake Detectors Work in Reality?,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Do Deepfake Detectors Work in Reality?'}","Deepfakes, particularly those involving faceswap-based manipulations, have
sparked significant societal concern due to their increasing realism and
potential for misuse. Despite rapid advancements in generative models,
detection methods have not kept pace, creating a critical gap in defense
strategies. This disparity is further amplified by the disconnect between
academic research and real-world applications, which often prioritize different
objectives and evaluation criteria. In this study, we take a pivotal step
toward bridging this gap by presenting a novel observation: the post-processing
step of super-resolution, commonly employed in real-world scenarios,
substantially undermines the effectiveness of existing deepfake detection
methods. To substantiate this claim, we introduce and publish the first
real-world faceswap dataset, collected from popular online faceswap platforms.
We then qualitatively evaluate the performance of state-of-the-art deepfake
detectors on real-world deepfakes, revealing that their accuracy approaches the
level of random guessing. Furthermore, we quantitatively demonstrate the
significant performance degradation caused by common post-processing
techniques. By addressing this overlooked challenge, our study underscores a
critical avenue for enhancing the robustness and practical applicability of
deepfake detection methods in real-world settings.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Deepfakes, particularly those involving faceswap-based manipulations, have\nsparked significant societal concern due to their increasing realism and\npotential for misuse. Despite rapid advancements in generative models,\ndetection methods have not kept pace, creating a critical gap in defense\nstrategies. This disparity is further amplified by the disconnect between\nacademic research and real-world applications, which often prioritize different\nobjectives and evaluation criteria. In this study, we take a pivotal step\ntoward bridging this gap by presenting a novel observation: the post-processing\nstep of super-resolution, commonly employed in real-world scenarios,\nsubstantially undermines the effectiveness of existing deepfake detection\nmethods. To substantiate this claim, we introduce and publish the first\nreal-world faceswap dataset, collected from popular online faceswap platforms.\nWe then qualitatively evaluate the performance of state-of-the-art deepfake\ndetectors on real-world deepfakes, revealing that their accuracy approaches the\nlevel of random guessing. Furthermore, we quantitatively demonstrate the\nsignificant performance degradation caused by common post-processing\ntechniques. By addressing this overlooked challenge, our study underscores a\ncritical avenue for enhancing the robustness and practical applicability of\ndeepfake detection methods in real-world settings.'}","['Simiao Ren', 'Hengwei Xu', 'Tsang Ng', 'Kidus Zewde', 'Shengkai Jiang', 'Ramini Desai', 'Disha Patil', 'Ning-Yau Cheng', 'Yining Zhou', 'Ragavi Muthukrishnan']",{'name': 'Ragavi Muthukrishnan'},Ragavi Muthukrishnan,,"[{'href': 'http://arxiv.org/abs/2502.10920v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10920v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10920v1,None,http://arxiv.org/abs/2502.10920v1,,,0,0
http://arxiv.org/abs/2502.10931v1,True,2025-02-15T23:43:18Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=23, tm_min=43, tm_sec=18, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T23:43:18Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=23, tm_min=43, tm_sec=18, tm_wday=5, tm_yday=46, tm_isdst=0)","D-CIPHER: Dynamic Collaborative Intelligent Agents with Planning and
  Heterogeneous Execution for Enhanced Reasoning in Offensive Security","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'D-CIPHER: Dynamic Collaborative Intelligent Agents with Planning and\n  Heterogeneous Execution for Enhanced Reasoning in Offensive Security'}","Large Language Models (LLMs) have been used in cybersecurity in many ways,
including their recent use as intelligent agent systems for autonomous security
analysis. Capture the Flag (CTF) challenges serve as benchmarks for assessing
the automated task-planning abilities of LLM agents across various
cybersecurity skill sets. Early attempts to apply LLMs for solving CTF
challenges relied on single-agent systems, where feedback was restricted to a
single reasoning-action loop. This approach proved inadequate for handling
complex CTF tasks. Drawing inspiration from real-world CTF competitions, where
teams of experts collaborate, we introduce the D-CIPHER multi-agent LLM
framework for collaborative CTF challenge solving. D-CIPHER integrates agents
with distinct roles, enabling dynamic feedback loops to enhance reasoning on
CTF challenges. It introduces the Planner-Executor agent system, consisting of
a Planner agent for overall problem-solving along with multiple heterogeneous
Executor agents for individual tasks, facilitating efficient allocation of
responsibilities among the LLMs. Additionally, D-CIPHER incorporates an
Auto-prompter agent, which improves problem-solving by exploring the challenge
environment and generating a highly relevant initial prompt. We evaluate
D-CIPHER on CTF benchmarks using multiple LLM models and conduct comprehensive
studies to highlight the impact of our enhancements. Our results demonstrate
that the multi-agent D-CIPHER system achieves a significant improvement in
challenges solved, setting a state-of-the-art performance on three benchmarks:
22.0% on NYU CTF Bench, 22.5% on Cybench, and 44.0% on HackTheBox. D-CIPHER is
available at https://github.com/NYU-LLM-CTF/nyuctf_agents as the
nyuctf_multiagent package.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Language Models (LLMs) have been used in cybersecurity in many ways,\nincluding their recent use as intelligent agent systems for autonomous security\nanalysis. Capture the Flag (CTF) challenges serve as benchmarks for assessing\nthe automated task-planning abilities of LLM agents across various\ncybersecurity skill sets. Early attempts to apply LLMs for solving CTF\nchallenges relied on single-agent systems, where feedback was restricted to a\nsingle reasoning-action loop. This approach proved inadequate for handling\ncomplex CTF tasks. Drawing inspiration from real-world CTF competitions, where\nteams of experts collaborate, we introduce the D-CIPHER multi-agent LLM\nframework for collaborative CTF challenge solving. D-CIPHER integrates agents\nwith distinct roles, enabling dynamic feedback loops to enhance reasoning on\nCTF challenges. It introduces the Planner-Executor agent system, consisting of\na Planner agent for overall problem-solving along with multiple heterogeneous\nExecutor agents for individual tasks, facilitating efficient allocation of\nresponsibilities among the LLMs. Additionally, D-CIPHER incorporates an\nAuto-prompter agent, which improves problem-solving by exploring the challenge\nenvironment and generating a highly relevant initial prompt. We evaluate\nD-CIPHER on CTF benchmarks using multiple LLM models and conduct comprehensive\nstudies to highlight the impact of our enhancements. Our results demonstrate\nthat the multi-agent D-CIPHER system achieves a significant improvement in\nchallenges solved, setting a state-of-the-art performance on three benchmarks:\n22.0% on NYU CTF Bench, 22.5% on Cybench, and 44.0% on HackTheBox. D-CIPHER is\navailable at https://github.com/NYU-LLM-CTF/nyuctf_agents as the\nnyuctf_multiagent package.'}","['Meet Udeshi', 'Minghao Shao', 'Haoran Xi', 'Nanda Rani', 'Kimberly Milner', 'Venkata Sai Charan Putrevu', 'Brendan Dolan-Gavitt', 'Sandeep Kumar Shukla', 'Prashanth Krishnamurthy', 'Farshad Khorrami', 'Ramesh Karri', 'Muhammad Shafique']",{'name': 'Muhammad Shafique'},Muhammad Shafique,,"[{'href': 'http://arxiv.org/abs/2502.10931v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10931v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10931v1,None,http://arxiv.org/abs/2502.10931v1,,,13176,0
http://arxiv.org/abs/2502.10940v1,True,2025-02-16T01:05:16Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=1, tm_min=5, tm_sec=16, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T01:05:16Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=1, tm_min=5, tm_sec=16, tm_wday=6, tm_yday=47, tm_isdst=0)",CoLA: Compute-Efficient Pre-Training of LLMs via Low-Rank Activation,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'CoLA: Compute-Efficient Pre-Training of LLMs via Low-Rank Activation'}","Large language models (LLMs) are revolutionizing many science and engineering
fields. However, their huge model sizes impose extremely demanding needs of
computational resources in the pre-training stage. Although low-rank
factorizations can reduce model parameters, their direct application in LLM
pre-training often lead to non-negligible performance loss. To address this
fundamental challenge, we introduce CoLA and its memory-efficient
implementation, CoLA-M. We leverage the low-rank structure observed widely in
model activations, enforcing non-linear transformations between factorized
weight matrices to reduce model size, boost model capacity and training
efficiency. Experiments on LLaMA models with 60 million to 7 billion parameters
show that CoLA reduces the computing cost by $\bf 2\pmb{\times}$ and improves
training throughput by $\bf 1.86\pmb{\times}$ while maintaining full-rank level
performance. CoLA-M further squeezes memory cost without sacrificing
throughput, offering a pre-training approach with collectively superior
parameter, computing, and memory efficiency. The LLMs produced are also $\bf
2\pmb{\times}$ smaller, enabling faster inference with lower memory cost on
resource-constrained platforms","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large language models (LLMs) are revolutionizing many science and engineering\nfields. However, their huge model sizes impose extremely demanding needs of\ncomputational resources in the pre-training stage. Although low-rank\nfactorizations can reduce model parameters, their direct application in LLM\npre-training often lead to non-negligible performance loss. To address this\nfundamental challenge, we introduce CoLA and its memory-efficient\nimplementation, CoLA-M. We leverage the low-rank structure observed widely in\nmodel activations, enforcing non-linear transformations between factorized\nweight matrices to reduce model size, boost model capacity and training\nefficiency. Experiments on LLaMA models with 60 million to 7 billion parameters\nshow that CoLA reduces the computing cost by $\\bf 2\\pmb{\\times}$ and improves\ntraining throughput by $\\bf 1.86\\pmb{\\times}$ while maintaining full-rank level\nperformance. CoLA-M further squeezes memory cost without sacrificing\nthroughput, offering a pre-training approach with collectively superior\nparameter, computing, and memory efficiency. The LLMs produced are also $\\bf\n2\\pmb{\\times}$ smaller, enabling faster inference with lower memory cost on\nresource-constrained platforms'}","['Ziyue Liu', 'Ruijie Zhang', 'Zhengyang Wang', 'Zi Yang', 'Paul Hovland', 'Bogdan Nicolae', 'Franck Cappello', 'Zheng Zhang']",{'name': 'Zheng Zhang'},Zheng Zhang,Preprint,"[{'href': 'http://arxiv.org/abs/2502.10940v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10940v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10940v1,None,http://arxiv.org/abs/2502.10940v1,,,78,0
http://arxiv.org/abs/2502.10953v1,True,2025-02-16T02:11:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=2, tm_min=11, tm_sec=36, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T02:11:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=2, tm_min=11, tm_sec=36, tm_wday=6, tm_yday=47, tm_isdst=0)","Empirical evaluation of LLMs in predicting fixes of Configuration bugs
  in Smart Home System","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Empirical evaluation of LLMs in predicting fixes of Configuration bugs\n  in Smart Home System'}","This empirical study evaluates the effectiveness of Large Language Models
(LLMs) in predicting fixes for configuration bugs in smart home systems. The
research analyzes three prominent LLMs - GPT-4, GPT-4o (GPT-4 Turbo), and
Claude 3.5 Sonnet - using four distinct prompt designs to assess their ability
to identify appropriate fix strategies and generate correct solutions. The
study utilized a dataset of 129 debugging issues from the Home Assistant
Community, focusing on 21 randomly selected cases for in-depth analysis.
Results demonstrate that GPT-4 and Claude 3.5 Sonnet achieved 80\% accuracy in
strategy prediction when provided with both bug descriptions and original
scripts. GPT-4 exhibited consistent performance across different prompt types,
while GPT-4o showed advantages in speed and cost-effectiveness despite slightly
lower accuracy. The findings reveal that prompt design significantly impacts
model performance, with comprehensive prompts containing both description and
original script yielding the best results. This research provides valuable
insights for improving automated bug fixing in smart home system configurations
and demonstrates the potential of LLMs in addressing configuration-related
challenges.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'This empirical study evaluates the effectiveness of Large Language Models\n(LLMs) in predicting fixes for configuration bugs in smart home systems. The\nresearch analyzes three prominent LLMs - GPT-4, GPT-4o (GPT-4 Turbo), and\nClaude 3.5 Sonnet - using four distinct prompt designs to assess their ability\nto identify appropriate fix strategies and generate correct solutions. The\nstudy utilized a dataset of 129 debugging issues from the Home Assistant\nCommunity, focusing on 21 randomly selected cases for in-depth analysis.\nResults demonstrate that GPT-4 and Claude 3.5 Sonnet achieved 80\\% accuracy in\nstrategy prediction when provided with both bug descriptions and original\nscripts. GPT-4 exhibited consistent performance across different prompt types,\nwhile GPT-4o showed advantages in speed and cost-effectiveness despite slightly\nlower accuracy. The findings reveal that prompt design significantly impacts\nmodel performance, with comprehensive prompts containing both description and\noriginal script yielding the best results. This research provides valuable\ninsights for improving automated bug fixing in smart home system configurations\nand demonstrates the potential of LLMs in addressing configuration-related\nchallenges.'}","['Sheikh Moonwara Anjum Monisha', 'Atul Bharadwaj']",{'name': 'Atul Bharadwaj'},Atul Bharadwaj,,"[{'href': 'http://arxiv.org/abs/2502.10953v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10953v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.SE', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.SE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10953v1,None,http://arxiv.org/abs/2502.10953v1,,,4,0
http://arxiv.org/abs/2502.10961v1,True,2025-02-16T02:47:41Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=2, tm_min=47, tm_sec=41, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T02:47:41Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=2, tm_min=47, tm_sec=41, tm_wday=6, tm_yday=47, tm_isdst=0)","Graders should cheat: privileged information enables expert-level
  automated evaluations","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Graders should cheat: privileged information enables expert-level\n  automated evaluations'}","Auto-evaluating language models (LMs), i.e., using a grader LM to evaluate
the candidate LM, is an appealing way to accelerate the evaluation process and
the cost associated with it. But this presents a paradox: how can we trust the
grader LM, which is presumably weaker than the candidate LM, to assess problems
that are beyond the frontier of the capabilities of either model or both? For
instance, today's LMs struggle on graduate-level physics and Olympiad-level
math, making them unreliable graders in these domains.
  We show that providing privileged information -- such as ground-truth
solutions or problem-specific guidelines -- improves automated evaluations on
such frontier problems. This approach offers two key advantages. First, it
expands the range of problems where LMs graders apply. Specifically, weaker
models can now rate the predictions of stronger models. Second, privileged
information can be used to devise easier variations of challenging problems
which improves the separability of different LMs on tasks where their
performance is generally low. With this approach, general-purpose LM graders
match the state of the art performance on RewardBench, surpassing almost all
the specially-tuned models. LM graders also outperform individual human raters
on Vibe-Eval, and approach human expert graders on Olympiad-level math
problems.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Auto-evaluating language models (LMs), i.e., using a grader LM to evaluate\nthe candidate LM, is an appealing way to accelerate the evaluation process and\nthe cost associated with it. But this presents a paradox: how can we trust the\ngrader LM, which is presumably weaker than the candidate LM, to assess problems\nthat are beyond the frontier of the capabilities of either model or both? For\ninstance, today's LMs struggle on graduate-level physics and Olympiad-level\nmath, making them unreliable graders in these domains.\n  We show that providing privileged information -- such as ground-truth\nsolutions or problem-specific guidelines -- improves automated evaluations on\nsuch frontier problems. This approach offers two key advantages. First, it\nexpands the range of problems where LMs graders apply. Specifically, weaker\nmodels can now rate the predictions of stronger models. Second, privileged\ninformation can be used to devise easier variations of challenging problems\nwhich improves the separability of different LMs on tasks where their\nperformance is generally low. With this approach, general-purpose LM graders\nmatch the state of the art performance on RewardBench, surpassing almost all\nthe specially-tuned models. LM graders also outperform individual human raters\non Vibe-Eval, and approach human expert graders on Olympiad-level math\nproblems.""}","['Jin Peng Zhou', 'Sbastien M. R. Arnold', 'Nan Ding', 'Kilian Q. Weinberger', 'Nan Hua', 'Fei Sha']",{'name': 'Fei Sha'},Fei Sha,,"[{'href': 'http://arxiv.org/abs/2502.10961v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10961v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10961v1,None,http://arxiv.org/abs/2502.10961v1,,,81790,0
http://arxiv.org/abs/2502.10966v1,True,2025-02-16T02:58:57Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=2, tm_min=58, tm_sec=57, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T02:58:57Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=2, tm_min=58, tm_sec=57, tm_wday=6, tm_yday=47, tm_isdst=0)","Neural Networks Remember More: The Power of Parameter Isolation and
  Combination","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Neural Networks Remember More: The Power of Parameter Isolation and\n  Combination'}","Catastrophic forgetting is a pervasive issue for pre-trained language models
(PLMs) during continual learning, where models lose previously acquired
knowledge when sequentially trained on a series of tasks. The model's ability
to retain old tasks is referred to as stability, while its adaptability to new
tasks is called plasticity. Therefore, the key to solving this problem is to
find a trade-off between the plasticity and stability of the model. To address
this issue, in this paper, we propose a novel method to achieve a balance
between model stability and plasticity, thereby mitigating catastrophic
forgetting. More specifically, our proposed approach leverages parameter
isolation and a subsequent combination strategy. Initially, in the training
stage, the model adapts to each downstream task via a parameter isolation
method to prevent potential interference among different tasks. We then combine
all trained parameters, which contain acquired knowledge, using the task
arithmetic method and finally apply them to the backbone model. Empirical
evaluations on continual language learning benchmarks substantiate the
effectiveness of our approach, revealing a marked enhancement over existing
state-of-the-art approaches.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Catastrophic forgetting is a pervasive issue for pre-trained language models\n(PLMs) during continual learning, where models lose previously acquired\nknowledge when sequentially trained on a series of tasks. The model's ability\nto retain old tasks is referred to as stability, while its adaptability to new\ntasks is called plasticity. Therefore, the key to solving this problem is to\nfind a trade-off between the plasticity and stability of the model. To address\nthis issue, in this paper, we propose a novel method to achieve a balance\nbetween model stability and plasticity, thereby mitigating catastrophic\nforgetting. More specifically, our proposed approach leverages parameter\nisolation and a subsequent combination strategy. Initially, in the training\nstage, the model adapts to each downstream task via a parameter isolation\nmethod to prevent potential interference among different tasks. We then combine\nall trained parameters, which contain acquired knowledge, using the task\narithmetic method and finally apply them to the backbone model. Empirical\nevaluations on continual language learning benchmarks substantiate the\neffectiveness of our approach, revealing a marked enhancement over existing\nstate-of-the-art approaches.""}","['Biqing Zeng', 'Zehan Li', 'Aladdin Ayesh']",{'name': 'Aladdin Ayesh'},Aladdin Ayesh,,"[{'href': 'http://arxiv.org/abs/2502.10966v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10966v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10966v1,None,http://arxiv.org/abs/2502.10966v1,,,2103,0
http://arxiv.org/abs/2502.10978v1,True,2025-02-16T03:46:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=3, tm_min=46, tm_sec=37, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T03:46:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=3, tm_min=46, tm_sec=37, tm_wday=6, tm_yday=47, tm_isdst=0)",Agentic LLM Framework for Adaptive Decision Discourse,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Agentic LLM Framework for Adaptive Decision Discourse'}","Effective decision-making in complex systems requires synthesizing diverse
perspectives to address multifaceted challenges under uncertainty. This study
introduces a real-world inspired agentic Large Language Models (LLMs)
framework, to simulate and enhance decision discourse-the deliberative process
through which actionable strategies are collaboratively developed. Unlike
traditional decision-support tools, the framework emphasizes dialogue,
trade-off exploration, and the emergent synergies generated by interactions
among agents embodying distinct personas. These personas simulate diverse
stakeholder roles, each bringing unique priorities, expertise, and value-driven
reasoning to the table. The framework incorporates adaptive and self-governing
mechanisms, enabling agents to dynamically summon additional expertise and
refine their assembly to address evolving challenges. An illustrative
hypothetical example focused on extreme flooding in a Midwestern township
demonstrates the framework's ability to navigate uncertainty, balance competing
priorities, and propose mitigation and adaptation strategies by considering
social, economic, and environmental dimensions. Results reveal how the
breadth-first exploration of alternatives fosters robust and equitable
recommendation pathways. This framework transforms how decisions are approached
in high-stakes scenarios and can be incorporated in digital environments. It
not only augments decision-makers' capacity to tackle complexity but also sets
a foundation for scalable and context-aware AI-driven recommendations. This
research explores novel and alternate routes leveraging agentic LLMs for
adaptive, collaborative, and equitable recommendation processes, with
implications across domains where uncertainty and complexity converge.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Effective decision-making in complex systems requires synthesizing diverse\nperspectives to address multifaceted challenges under uncertainty. This study\nintroduces a real-world inspired agentic Large Language Models (LLMs)\nframework, to simulate and enhance decision discourse-the deliberative process\nthrough which actionable strategies are collaboratively developed. Unlike\ntraditional decision-support tools, the framework emphasizes dialogue,\ntrade-off exploration, and the emergent synergies generated by interactions\namong agents embodying distinct personas. These personas simulate diverse\nstakeholder roles, each bringing unique priorities, expertise, and value-driven\nreasoning to the table. The framework incorporates adaptive and self-governing\nmechanisms, enabling agents to dynamically summon additional expertise and\nrefine their assembly to address evolving challenges. An illustrative\nhypothetical example focused on extreme flooding in a Midwestern township\ndemonstrates the framework's ability to navigate uncertainty, balance competing\npriorities, and propose mitigation and adaptation strategies by considering\nsocial, economic, and environmental dimensions. Results reveal how the\nbreadth-first exploration of alternatives fosters robust and equitable\nrecommendation pathways. This framework transforms how decisions are approached\nin high-stakes scenarios and can be incorporated in digital environments. It\nnot only augments decision-makers' capacity to tackle complexity but also sets\na foundation for scalable and context-aware AI-driven recommendations. This\nresearch explores novel and alternate routes leveraging agentic LLMs for\nadaptive, collaborative, and equitable recommendation processes, with\nimplications across domains where uncertainty and complexity converge.""}","['Antoine Dolant', 'Praveen Kumar']",{'name': 'Praveen Kumar'},Praveen Kumar,"24 pages, 4 figures, 1 appendix","[{'href': 'http://arxiv.org/abs/2502.10978v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10978v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10978v1,None,http://arxiv.org/abs/2502.10978v1,,,4,0
http://arxiv.org/abs/2502.11006v1,True,2025-02-16T06:16:00Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=6, tm_min=16, tm_sec=0, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T06:16:00Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=6, tm_min=16, tm_sec=0, tm_wday=6, tm_yday=47, tm_isdst=0)","Prompt Inject Detection with Generative Explanation as an Investigative
  Tool","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Prompt Inject Detection with Generative Explanation as an Investigative\n  Tool'}","Large Language Models (LLMs) are vulnerable to adversarial prompt based
injects. These injects could jailbreak or exploit vulnerabilities within these
models with explicit prompt requests leading to undesired responses. In the
context of investigating prompt injects, the challenge is the sheer volume of
input prompts involved that are likely to be largely benign. This investigative
challenge is further complicated by the semantics and subjectivity of the input
prompts involved in the LLM conversation with its user and the context of the
environment to which the conversation is being carried out. Hence, the
challenge for AI security investigators would be two-fold. The first is to
identify adversarial prompt injects and then to assess whether the input prompt
is contextually benign or adversarial. For the first step, this could be done
using existing AI security solutions like guardrails to detect and protect the
LLMs. Guardrails have been developed using a variety of approaches. A popular
approach is to use signature based. Another popular approach to develop AI
models to classify such prompts include the use of NLP based models like a
language model. However, in the context of conducting an AI security
investigation of prompt injects, these guardrails lack the ability to aid
investigators in triaging or assessing the identified input prompts. In this
applied research exploration, we explore the use of a text generation
capabilities of LLM to detect prompt injects and generate explanation for its
detections to aid AI security investigators in assessing and triaging of such
prompt inject detections. The practical benefit of such a tool is to ease the
task of conducting investigation into prompt injects.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Language Models (LLMs) are vulnerable to adversarial prompt based\ninjects. These injects could jailbreak or exploit vulnerabilities within these\nmodels with explicit prompt requests leading to undesired responses. In the\ncontext of investigating prompt injects, the challenge is the sheer volume of\ninput prompts involved that are likely to be largely benign. This investigative\nchallenge is further complicated by the semantics and subjectivity of the input\nprompts involved in the LLM conversation with its user and the context of the\nenvironment to which the conversation is being carried out. Hence, the\nchallenge for AI security investigators would be two-fold. The first is to\nidentify adversarial prompt injects and then to assess whether the input prompt\nis contextually benign or adversarial. For the first step, this could be done\nusing existing AI security solutions like guardrails to detect and protect the\nLLMs. Guardrails have been developed using a variety of approaches. A popular\napproach is to use signature based. Another popular approach to develop AI\nmodels to classify such prompts include the use of NLP based models like a\nlanguage model. However, in the context of conducting an AI security\ninvestigation of prompt injects, these guardrails lack the ability to aid\ninvestigators in triaging or assessing the identified input prompts. In this\napplied research exploration, we explore the use of a text generation\ncapabilities of LLM to detect prompt injects and generate explanation for its\ndetections to aid AI security investigators in assessing and triaging of such\nprompt inject detections. The practical benefit of such a tool is to ease the\ntask of conducting investigation into prompt injects.'}","['Jonathan Pan', 'Swee Liang Wong', 'Yidi Yuan', 'Xin Wei Chia']",{'name': 'Xin Wei Chia'},Xin Wei Chia,"5 pages, 4 tables, 3 diagrams","[{'href': 'http://arxiv.org/abs/2502.11006v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11006v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11006v1,None,http://arxiv.org/abs/2502.11006v1,,,16,0
http://arxiv.org/abs/2502.11013v2,True,2025-02-19T06:27:18Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=6, tm_min=27, tm_sec=18, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-16T06:35:26Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=6, tm_min=35, tm_sec=26, tm_wday=6, tm_yday=47, tm_isdst=0)","Collaborative Deterministic-Diffusion Model for Probabilistic Urban
  Spatiotemporal Prediction","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Collaborative Deterministic-Diffusion Model for Probabilistic Urban\n  Spatiotemporal Prediction'}","Accurate prediction of urban spatiotemporal dynamics is essential for
enhancing urban management and decision-making. Existing spatiotemporal
prediction models are predominantly deterministic, focusing on primary
spatiotemporal patterns. However, those dynamics are highly complex, exhibiting
multi-modal distributions that are challenging for deterministic models to
capture. In this paper, we highlight the critical role of probabilistic
prediction in capturing the uncertainties and complexities inherent in
spatiotemporal data. While mainstream probabilistic models can capture
uncertainty, they struggle with accurately learning primary patterns and often
suffer from computational inefficiency. To address these challenges, we propose
CoST, which collaborates deterministic and probabilistic models to improve both
predictive accuracy and the ability to handle uncertainty. To achieve this, we
design a mean-residual decomposition framework, where the mean value is modeled
by a deterministic model, and the residual variations are learned by a
probabilistic model, specifically diffusion models. Moreover, we introduce a
scale-aware diffusion process, which better accounts for spatially
heterogeneous dynamics across different regions. Extensive experiments on eight
real-world datasets demonstrate that CoST significantly outperforms existing
methods in both deterministic and probabilistic metrics, achieving a 20%
improvement with low computational cost. CoST bridges the gap between
deterministic precision and probabilistic uncertainty, making a significant
advancement in the field of urban spatiotemporal prediction.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Accurate prediction of urban spatiotemporal dynamics is essential for\nenhancing urban management and decision-making. Existing spatiotemporal\nprediction models are predominantly deterministic, focusing on primary\nspatiotemporal patterns. However, those dynamics are highly complex, exhibiting\nmulti-modal distributions that are challenging for deterministic models to\ncapture. In this paper, we highlight the critical role of probabilistic\nprediction in capturing the uncertainties and complexities inherent in\nspatiotemporal data. While mainstream probabilistic models can capture\nuncertainty, they struggle with accurately learning primary patterns and often\nsuffer from computational inefficiency. To address these challenges, we propose\nCoST, which collaborates deterministic and probabilistic models to improve both\npredictive accuracy and the ability to handle uncertainty. To achieve this, we\ndesign a mean-residual decomposition framework, where the mean value is modeled\nby a deterministic model, and the residual variations are learned by a\nprobabilistic model, specifically diffusion models. Moreover, we introduce a\nscale-aware diffusion process, which better accounts for spatially\nheterogeneous dynamics across different regions. Extensive experiments on eight\nreal-world datasets demonstrate that CoST significantly outperforms existing\nmethods in both deterministic and probabilistic metrics, achieving a 20%\nimprovement with low computational cost. CoST bridges the gap between\ndeterministic precision and probabilistic uncertainty, making a significant\nadvancement in the field of urban spatiotemporal prediction.'}","['Zhi Sheng', 'Yuan Yuan', 'Yudi Zhang', 'Depeng Jin', 'Yong Li']",{'name': 'Yong Li'},Yong Li,,"[{'href': 'http://arxiv.org/abs/2502.11013v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11013v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11013v2,None,http://arxiv.org/abs/2502.11013v2,,,464,0
http://arxiv.org/abs/2502.11018v1,True,2025-02-16T07:06:00Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=7, tm_min=6, tm_sec=0, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T07:06:00Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=7, tm_min=6, tm_sec=0, tm_wday=6, tm_yday=47, tm_isdst=0)",GRIFFIN: Effective Token Alignment for Faster Speculative Decoding,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'GRIFFIN: Effective Token Alignment for Faster Speculative Decoding'}","Speculative decoding accelerates inference in large language models (LLMs) by
generating multiple draft tokens simultaneously. However, existing methods
often struggle with token misalignment between the training and decoding
phases, limiting their performance. To address this, we propose GRIFFIN, a
novel framework that incorporates a token-alignable training strategy and a
token-alignable draft model to mitigate misalignment. The training strategy
employs a loss masking mechanism to exclude highly misaligned tokens during
training, preventing them from negatively impacting the draft model's
optimization. The token-alignable draft model introduces input tokens to
correct inconsistencies in generated features. Experiments on LLaMA-series and
Vicuna models demonstrate that GRIFFIN achieves an average acceptance length
improvement of over 7\% and a speedup ratio exceeding 8%, outperforming current
SoTAs as shown in Fig. 1 (a) and (b).","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Speculative decoding accelerates inference in large language models (LLMs) by\ngenerating multiple draft tokens simultaneously. However, existing methods\noften struggle with token misalignment between the training and decoding\nphases, limiting their performance. To address this, we propose GRIFFIN, a\nnovel framework that incorporates a token-alignable training strategy and a\ntoken-alignable draft model to mitigate misalignment. The training strategy\nemploys a loss masking mechanism to exclude highly misaligned tokens during\ntraining, preventing them from negatively impacting the draft model's\noptimization. The token-alignable draft model introduces input tokens to\ncorrect inconsistencies in generated features. Experiments on LLaMA-series and\nVicuna models demonstrate that GRIFFIN achieves an average acceptance length\nimprovement of over 7\\% and a speedup ratio exceeding 8%, outperforming current\nSoTAs as shown in Fig. 1 (a) and (b).""}","['Shijing Hu', 'Jingyang Li', 'Xingyu Xie', 'Zhihui Lu', 'Kim-Chuan Toh', 'Pan Zhou']",{'name': 'Pan Zhou'},Pan Zhou,,"[{'href': 'http://arxiv.org/abs/2502.11018v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11018v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11018v1,None,http://arxiv.org/abs/2502.11018v1,,,153,0
http://arxiv.org/abs/2502.11019v1,True,2025-02-16T07:06:17Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=7, tm_min=6, tm_sec=17, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T07:06:17Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=7, tm_min=6, tm_sec=17, tm_wday=6, tm_yday=47, tm_isdst=0)","Unlocking the Power of Function Vectors for Characterizing and
  Mitigating Catastrophic Forgetting in Continual Instruction Tuning","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Unlocking the Power of Function Vectors for Characterizing and\n  Mitigating Catastrophic Forgetting in Continual Instruction Tuning'}","Catastrophic forgetting (CF) poses a significant challenge in machine
learning, where a model forgets previously learned information upon learning
new tasks. Despite the advanced capabilities of Large Language Models (LLMs),
they continue to face challenges with CF during continual learning. The
majority of existing research focuses on analyzing forgetting patterns through
a singular training sequence, thereby overlooking the intricate effects that
diverse tasks have on model behavior. Our study explores CF across various
settings, discovering that model forgetting is influenced by both the specific
training tasks and the models themselves. To this end, we interpret forgetting
by examining the function vector (FV), a compact representation of functions in
LLMs, offering a model-dependent indicator for the occurrence of CF. Through
theoretical and empirical analyses, we demonstrated that CF in LLMs primarily
stems from biases in function activation rather than the overwriting of task
processing functions. Leveraging these insights, we propose a novel function
vector guided training methodology, incorporating a regularization technique to
stabilize the FV and mitigate forgetting. Empirical tests on four benchmarks
confirm the effectiveness of our proposed training method, substantiating our
theoretical framework concerning CF and model function dynamics. We plan to
make our code publicly accessible in the near future.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Catastrophic forgetting (CF) poses a significant challenge in machine\nlearning, where a model forgets previously learned information upon learning\nnew tasks. Despite the advanced capabilities of Large Language Models (LLMs),\nthey continue to face challenges with CF during continual learning. The\nmajority of existing research focuses on analyzing forgetting patterns through\na singular training sequence, thereby overlooking the intricate effects that\ndiverse tasks have on model behavior. Our study explores CF across various\nsettings, discovering that model forgetting is influenced by both the specific\ntraining tasks and the models themselves. To this end, we interpret forgetting\nby examining the function vector (FV), a compact representation of functions in\nLLMs, offering a model-dependent indicator for the occurrence of CF. Through\ntheoretical and empirical analyses, we demonstrated that CF in LLMs primarily\nstems from biases in function activation rather than the overwriting of task\nprocessing functions. Leveraging these insights, we propose a novel function\nvector guided training methodology, incorporating a regularization technique to\nstabilize the FV and mitigate forgetting. Empirical tests on four benchmarks\nconfirm the effectiveness of our proposed training method, substantiating our\ntheoretical framework concerning CF and model function dynamics. We plan to\nmake our code publicly accessible in the near future.'}","['Gangwei Jiang', 'Caigao Jiang', 'Zhaoyi Li', 'Siqiao Xue', 'Jun Zhou', 'Linqi Song', 'Defu Lian', 'Yin Wei']",{'name': 'Yin Wei'},Yin Wei,10pages,"[{'href': 'http://arxiv.org/abs/2502.11019v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11019v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11019v1,None,http://arxiv.org/abs/2502.11019v1,,,698,0
http://arxiv.org/abs/2502.11020v1,True,2025-02-16T07:07:38Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=7, tm_min=7, tm_sec=38, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T07:07:38Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=7, tm_min=7, tm_sec=38, tm_wday=6, tm_yday=47, tm_isdst=0)","TUMLU: A Unified and Native Language Understanding Benchmark for Turkic
  Languages","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'TUMLU: A Unified and Native Language Understanding Benchmark for Turkic\n  Languages'}","Being able to thoroughly assess massive multi-task language understanding
(MMLU) capabilities is essential for advancing the applicability of
multilingual language models. However, preparing such benchmarks in high
quality native language is often costly and therefore limits the
representativeness of evaluation datasets. While recent efforts focused on
building more inclusive MMLU benchmarks, these are conventionally built using
machine translation from high-resource languages, which may introduce errors
and fail to account for the linguistic and cultural intricacies of the target
languages. In this paper, we address the lack of native language MMLU benchmark
especially in the under-represented Turkic language family with distinct
morphosyntactic and cultural characteristics. We propose two benchmarks for
Turkic language MMLU: TUMLU is a comprehensive, multilingual, and natively
developed language understanding benchmark specifically designed for Turkic
languages. It consists of middle- and high-school level questions spanning 11
academic subjects in Azerbaijani, Crimean Tatar, Karakalpak, Kazakh, Tatar,
Turkish, Uyghur, and Uzbek. We also present TUMLU-mini, a more concise,
balanced, and manually verified subset of the dataset. Using this dataset, we
systematically evaluate a diverse range of open and proprietary multilingual
large language models (LLMs), including Claude, Gemini, GPT, and LLaMA,
offering an in-depth analysis of their performance across different languages,
subjects, and alphabets. To promote further research and development in
multilingual language understanding, we release TUMLU-mini and all
corresponding evaluation scripts.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Being able to thoroughly assess massive multi-task language understanding\n(MMLU) capabilities is essential for advancing the applicability of\nmultilingual language models. However, preparing such benchmarks in high\nquality native language is often costly and therefore limits the\nrepresentativeness of evaluation datasets. While recent efforts focused on\nbuilding more inclusive MMLU benchmarks, these are conventionally built using\nmachine translation from high-resource languages, which may introduce errors\nand fail to account for the linguistic and cultural intricacies of the target\nlanguages. In this paper, we address the lack of native language MMLU benchmark\nespecially in the under-represented Turkic language family with distinct\nmorphosyntactic and cultural characteristics. We propose two benchmarks for\nTurkic language MMLU: TUMLU is a comprehensive, multilingual, and natively\ndeveloped language understanding benchmark specifically designed for Turkic\nlanguages. It consists of middle- and high-school level questions spanning 11\nacademic subjects in Azerbaijani, Crimean Tatar, Karakalpak, Kazakh, Tatar,\nTurkish, Uyghur, and Uzbek. We also present TUMLU-mini, a more concise,\nbalanced, and manually verified subset of the dataset. Using this dataset, we\nsystematically evaluate a diverse range of open and proprietary multilingual\nlarge language models (LLMs), including Claude, Gemini, GPT, and LLaMA,\noffering an in-depth analysis of their performance across different languages,\nsubjects, and alphabets. To promote further research and development in\nmultilingual language understanding, we release TUMLU-mini and all\ncorresponding evaluation scripts.'}","['Jafar Isbarov', 'Arofat Akhundjanova', 'Mammad Hajili', 'Kavsar Huseynova', 'Dmitry Gaynullin', 'Anar Rzayev', 'Osman Tursun', 'Ilshat Saetov', 'Rinat Kharisov', 'Saule Belginova', 'Ariana Kenbayeva', 'Amina Alisheva', 'Aizirek Turdubaeva', 'Abdullatif Kksal', 'Samir Rustamov', 'Duygu Ataman']",{'name': 'Duygu Ataman'},Duygu Ataman,,"[{'href': 'http://arxiv.org/abs/2502.11020v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11020v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11020v1,None,http://arxiv.org/abs/2502.11020v1,,,995,0
http://arxiv.org/abs/2502.11022v1,True,2025-02-16T07:12:47Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=7, tm_min=12, tm_sec=47, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T07:12:47Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=7, tm_min=12, tm_sec=47, tm_wday=6, tm_yday=47, tm_isdst=0)","MultiTEND: A Multilingual Benchmark for Natural Language to NoSQL Query
  Translation","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'MultiTEND: A Multilingual Benchmark for Natural Language to NoSQL Query\n  Translation'}","Natural language interfaces for NoSQL databases are increasingly vital in the
big data era, enabling users to interact with complex, unstructured data
without deep technical expertise. However, most recent advancements focus on
English, leaving a gap for multilingual support. This paper introduces
MultiTEND, the first and largest multilingual benchmark for natural language to
NoSQL query generation, covering six languages: English, German, French,
Russian, Japanese and Mandarin Chinese. Using MultiTEND, we analyze challenges
in translating natural language to NoSQL queries across diverse linguistic
structures, including lexical and syntactic differences. Experiments show that
performance accuracy in both English and non-English settings remains
relatively low, with a 4%-6% gap across scenarios like fine-tuned SLM,
zero-shot LLM, and RAG for LLM. To address the aforementioned challenges, we
introduce MultiLink, a novel framework that bridges the multilingual input to
NoSQL query generation gap through a Parallel Linking Process. It breaks down
the task into multiple steps, integrating parallel multilingual processing,
Chain-of-Thought (CoT) reasoning, and Retrieval-Augmented Generation (RAG) to
tackle lexical and structural challenges inherent in multilingual NoSQL
generation. MultiLink shows enhancements in all metrics for every language
against the top baseline, boosting execution accuracy by about 15% for English
and averaging a 10% improvement for non-English languages.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Natural language interfaces for NoSQL databases are increasingly vital in the\nbig data era, enabling users to interact with complex, unstructured data\nwithout deep technical expertise. However, most recent advancements focus on\nEnglish, leaving a gap for multilingual support. This paper introduces\nMultiTEND, the first and largest multilingual benchmark for natural language to\nNoSQL query generation, covering six languages: English, German, French,\nRussian, Japanese and Mandarin Chinese. Using MultiTEND, we analyze challenges\nin translating natural language to NoSQL queries across diverse linguistic\nstructures, including lexical and syntactic differences. Experiments show that\nperformance accuracy in both English and non-English settings remains\nrelatively low, with a 4%-6% gap across scenarios like fine-tuned SLM,\nzero-shot LLM, and RAG for LLM. To address the aforementioned challenges, we\nintroduce MultiLink, a novel framework that bridges the multilingual input to\nNoSQL query generation gap through a Parallel Linking Process. It breaks down\nthe task into multiple steps, integrating parallel multilingual processing,\nChain-of-Thought (CoT) reasoning, and Retrieval-Augmented Generation (RAG) to\ntackle lexical and structural challenges inherent in multilingual NoSQL\ngeneration. MultiLink shows enhancements in all metrics for every language\nagainst the top baseline, boosting execution accuracy by about 15% for English\nand averaging a 10% improvement for non-English languages.'}","['Zhiqian Qin', 'Yuanfeng Song', 'Jinwei Lu', 'Yuanwei Song', 'Shuaimin Li', 'Chen Jason Zhang']",{'name': 'Chen Jason Zhang'},Chen Jason Zhang,,"[{'href': 'http://arxiv.org/abs/2502.11022v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11022v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11022v1,None,http://arxiv.org/abs/2502.11022v1,,,37,0
http://arxiv.org/abs/2502.11028v1,True,2025-02-16T07:46:09Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=7, tm_min=46, tm_sec=9, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T07:46:09Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=7, tm_min=46, tm_sec=9, tm_wday=6, tm_yday=47, tm_isdst=0)","Mind the Confidence Gap: Overconfidence, Calibration, and Distractor
  Effects in Large Language Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Mind the Confidence Gap: Overconfidence, Calibration, and Distractor\n  Effects in Large Language Models'}","Large Language Models (LLMs) demonstrate impressive performance across
diverse tasks, yet confidence calibration remains a challenge. Miscalibration -
where models are overconfident or underconfident - poses risks, particularly in
high-stakes applications. This paper presents an empirical study on LLM
calibration, examining how model size, distractors, and question types affect
confidence alignment. We introduce an evaluation framework to measure
overconfidence and investigate whether multiple-choice formats mitigate or
worsen miscalibration. Our findings show that while larger models (e.g.,
GPT-4o) are better calibrated overall, they are more prone to distraction,
whereas smaller models benefit more from answer choices but struggle with
uncertainty estimation. Unlike prior work, which primarily reports
miscalibration trends, we provide actionable insights into failure modes and
conditions that worsen overconfidence. These findings highlight the need for
calibration-aware interventions and improved uncertainty estimation methods.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Language Models (LLMs) demonstrate impressive performance across\ndiverse tasks, yet confidence calibration remains a challenge. Miscalibration -\nwhere models are overconfident or underconfident - poses risks, particularly in\nhigh-stakes applications. This paper presents an empirical study on LLM\ncalibration, examining how model size, distractors, and question types affect\nconfidence alignment. We introduce an evaluation framework to measure\noverconfidence and investigate whether multiple-choice formats mitigate or\nworsen miscalibration. Our findings show that while larger models (e.g.,\nGPT-4o) are better calibrated overall, they are more prone to distraction,\nwhereas smaller models benefit more from answer choices but struggle with\nuncertainty estimation. Unlike prior work, which primarily reports\nmiscalibration trends, we provide actionable insights into failure modes and\nconditions that worsen overconfidence. These findings highlight the need for\ncalibration-aware interventions and improved uncertainty estimation methods.'}",['Prateek Chhikara'],{'name': 'Prateek Chhikara'},Prateek Chhikara,,"[{'href': 'http://arxiv.org/abs/2502.11028v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11028v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11028v1,None,http://arxiv.org/abs/2502.11028v1,,,461,0
http://arxiv.org/abs/2502.11051v1,True,2025-02-16T09:23:50Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=9, tm_min=23, tm_sec=50, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T09:23:50Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=9, tm_min=23, tm_sec=50, tm_wday=6, tm_yday=47, tm_isdst=0)","MMUNLEARNER: Reformulating Multimodal Machine Unlearning in the Era of
  Multimodal Large Language Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'MMUNLEARNER: Reformulating Multimodal Machine Unlearning in the Era of\n  Multimodal Large Language Models'}","Recent progress in Machine Unlearning (MU) has introduced solutions for the
selective removal of private or sensitive information encoded within deep
neural networks. Nonetheless, MU for Multimodal Large Language Models (MLLMs)
remains in its nascent phase. Therefore, we propose to reformulate the task of
multimodal MU in the era of MLLMs, which aims to erase only the visual patterns
associated with a given entity while preserving the corresponding textual
knowledge encoded within the original parameters of the language model
backbone. Furthermore, we develop a novel geometry-constrained gradient descent
method MMUnlearner. It updates the weights of MLLMs with a weight saliency map
jointly restricted by the remaining concepts and textual knowledge during
unlearning, thereby preserving parameters essential for non-target knowledge.
Extensive experiments demonstrate that MMUnlearner surpasses baselines that
finetuning MLLMs with VQA data directly through Gradient Ascent (GA) or
Negative Preference Optimization (NPO), across all evaluation dimensions. Our
code will be released upon acceptance.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Recent progress in Machine Unlearning (MU) has introduced solutions for the\nselective removal of private or sensitive information encoded within deep\nneural networks. Nonetheless, MU for Multimodal Large Language Models (MLLMs)\nremains in its nascent phase. Therefore, we propose to reformulate the task of\nmultimodal MU in the era of MLLMs, which aims to erase only the visual patterns\nassociated with a given entity while preserving the corresponding textual\nknowledge encoded within the original parameters of the language model\nbackbone. Furthermore, we develop a novel geometry-constrained gradient descent\nmethod MMUnlearner. It updates the weights of MLLMs with a weight saliency map\njointly restricted by the remaining concepts and textual knowledge during\nunlearning, thereby preserving parameters essential for non-target knowledge.\nExtensive experiments demonstrate that MMUnlearner surpasses baselines that\nfinetuning MLLMs with VQA data directly through Gradient Ascent (GA) or\nNegative Preference Optimization (NPO), across all evaluation dimensions. Our\ncode will be released upon acceptance.'}","['Jiahao Huo', 'Yibo Yan', 'Xu Zheng', 'Yuanhuiyi Lyu', 'Xin Zou', 'Zhihua Wei', 'Xuming Hu']",{'name': 'Xuming Hu'},Xuming Hu,,"[{'href': 'http://arxiv.org/abs/2502.11051v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11051v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11051v1,None,http://arxiv.org/abs/2502.11051v1,,,225,0
http://arxiv.org/abs/2502.11059v1,True,2025-02-16T09:57:50Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=9, tm_min=57, tm_sec=50, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T09:57:50Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=9, tm_min=57, tm_sec=50, tm_wday=6, tm_yday=47, tm_isdst=0)","ClimateLLM: Efficient Weather Forecasting via Frequency-Aware Large
  Language Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'ClimateLLM: Efficient Weather Forecasting via Frequency-Aware Large\n  Language Models'}","Weather forecasting is crucial for public safety, disaster prevention and
mitigation, agricultural production, and energy management, with global
relevance. Although deep learning has significantly advanced weather
prediction, current methods face critical limitations: (i) they often struggle
to capture both dynamic temporal dependencies and short-term abrupt changes,
making extreme weather modeling difficult; (ii) they incur high computational
costs due to extensive training and resource requirements; (iii) they have
limited adaptability to multi-scale frequencies, leading to challenges when
separating global trends from local fluctuations. To address these issues, we
propose ClimateLLM, a foundation model for weather forecasting. It captures
spatiotemporal dependencies via a cross-temporal and cross-spatial
collaborative modeling framework that integrates Fourier-based frequency
decomposition with Large Language Models (LLMs) to strengthen spatial and
temporal modeling. Our framework uses a Mixture-of-Experts (MoE) mechanism that
adaptively processes different frequency components, enabling efficient
handling of both global signals and localized extreme events. In addition, we
introduce a cross-temporal and cross-spatial dynamic prompting mechanism,
allowing LLMs to incorporate meteorological patterns across multiple scales
effectively. Extensive experiments on real-world datasets show that ClimateLLM
outperforms state-of-the-art approaches in accuracy and efficiency, as a
scalable solution for global weather forecasting.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Weather forecasting is crucial for public safety, disaster prevention and\nmitigation, agricultural production, and energy management, with global\nrelevance. Although deep learning has significantly advanced weather\nprediction, current methods face critical limitations: (i) they often struggle\nto capture both dynamic temporal dependencies and short-term abrupt changes,\nmaking extreme weather modeling difficult; (ii) they incur high computational\ncosts due to extensive training and resource requirements; (iii) they have\nlimited adaptability to multi-scale frequencies, leading to challenges when\nseparating global trends from local fluctuations. To address these issues, we\npropose ClimateLLM, a foundation model for weather forecasting. It captures\nspatiotemporal dependencies via a cross-temporal and cross-spatial\ncollaborative modeling framework that integrates Fourier-based frequency\ndecomposition with Large Language Models (LLMs) to strengthen spatial and\ntemporal modeling. Our framework uses a Mixture-of-Experts (MoE) mechanism that\nadaptively processes different frequency components, enabling efficient\nhandling of both global signals and localized extreme events. In addition, we\nintroduce a cross-temporal and cross-spatial dynamic prompting mechanism,\nallowing LLMs to incorporate meteorological patterns across multiple scales\neffectively. Extensive experiments on real-world datasets show that ClimateLLM\noutperforms state-of-the-art approaches in accuracy and efficiency, as a\nscalable solution for global weather forecasting.'}","['Shixuan Li', 'Wei Yang', 'Peiyu Zhang', 'Xiongye Xiao', 'Defu Cao', 'Yuehan Qin', 'Xiaole Zhang', 'Yue Zhao', 'Paul Bogdan']",{'name': 'Paul Bogdan'},Paul Bogdan,,"[{'href': 'http://arxiv.org/abs/2502.11059v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11059v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11059v1,None,http://arxiv.org/abs/2502.11059v1,,,48,0
http://arxiv.org/abs/2502.11068v1,True,2025-02-16T10:30:01Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=10, tm_min=30, tm_sec=1, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T10:30:01Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=10, tm_min=30, tm_sec=1, tm_wday=6, tm_yday=47, tm_isdst=0)",Accelerating Anchors via Specialization and Feature Transformation,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Accelerating Anchors via Specialization and Feature Transformation'}","Anchors is a popular local model-agnostic explanation technique whose
applicability is limited by its computational inefficiency. To address this
limitation, we propose a pre-training-based approach to accelerate Anchors
without compromising the explanation quality. Our approach leverages the
iterative nature of Anchors' algorithm which gradually refines an explanation
until it is precise enough for a given input by providing a general explanation
that is obtained through pre-training as Anchors' initial explanation.
Specifically, we develop a two-step rule transformation process: the horizontal
transformation adapts a pre-trained explanation to the current input by
replacing features, and the vertical transformation refines the general
explanation until it is precise enough for the input. We evaluate our method
across tabular, text, and image datasets, demonstrating that it significantly
reduces explanation generation time while maintaining fidelity and
interpretability, thereby enabling the practical adoption of Anchors in
time-sensitive applications.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Anchors is a popular local model-agnostic explanation technique whose\napplicability is limited by its computational inefficiency. To address this\nlimitation, we propose a pre-training-based approach to accelerate Anchors\nwithout compromising the explanation quality. Our approach leverages the\niterative nature of Anchors' algorithm which gradually refines an explanation\nuntil it is precise enough for a given input by providing a general explanation\nthat is obtained through pre-training as Anchors' initial explanation.\nSpecifically, we develop a two-step rule transformation process: the horizontal\ntransformation adapts a pre-trained explanation to the current input by\nreplacing features, and the vertical transformation refines the general\nexplanation until it is precise enough for the input. We evaluate our method\nacross tabular, text, and image datasets, demonstrating that it significantly\nreduces explanation generation time while maintaining fidelity and\ninterpretability, thereby enabling the practical adoption of Anchors in\ntime-sensitive applications.""}","['Haonan Yu', 'Junhao Liu', 'Xin Zhang']",{'name': 'Xin Zhang'},Xin Zhang,,"[{'href': 'http://arxiv.org/abs/2502.11068v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11068v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11068v1,None,http://arxiv.org/abs/2502.11068v1,,,0,0
http://arxiv.org/abs/2502.11070v1,True,2025-02-16T10:33:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=10, tm_min=33, tm_sec=37, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T10:33:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=10, tm_min=33, tm_sec=37, tm_wday=6, tm_yday=47, tm_isdst=0)","A Survey on Vulnerability Prioritization: Taxonomy, Metrics, and
  Research Challenges","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A Survey on Vulnerability Prioritization: Taxonomy, Metrics, and\n  Research Challenges'}","In the highly interconnected digital landscape of today, safeguarding complex
infrastructures against cyber threats has become increasingly challenging due
to the exponential growth in the number and complexity of vulnerabilities.
Resource constraints necessitate effective vulnerability prioritization
strategies, focusing efforts on the most critical risks. This paper presents a
systematic literature review of 82 studies, introducing a novel taxonomy that
categorizes metrics into severity, exploitability, contextual factors,
predictive indicators, and aggregation methods. Our analysis reveals
significant gaps in existing approaches and challenges with multi-domain
applicability. By emphasizing the need for dynamic, context-aware metrics and
scalable solutions, we provide actionable insights to bridge the gap between
research and real-world applications. This work contributes to the field by
offering a comprehensive framework for evaluating vulnerability prioritization
methodologies and setting a research agenda to advance the state of practice.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'In the highly interconnected digital landscape of today, safeguarding complex\ninfrastructures against cyber threats has become increasingly challenging due\nto the exponential growth in the number and complexity of vulnerabilities.\nResource constraints necessitate effective vulnerability prioritization\nstrategies, focusing efforts on the most critical risks. This paper presents a\nsystematic literature review of 82 studies, introducing a novel taxonomy that\ncategorizes metrics into severity, exploitability, contextual factors,\npredictive indicators, and aggregation methods. Our analysis reveals\nsignificant gaps in existing approaches and challenges with multi-domain\napplicability. By emphasizing the need for dynamic, context-aware metrics and\nscalable solutions, we provide actionable insights to bridge the gap between\nresearch and real-world applications. This work contributes to the field by\noffering a comprehensive framework for evaluating vulnerability prioritization\nmethodologies and setting a research agenda to advance the state of practice.'}","['Yuning Jiang', 'Nay Oo', 'Qiaoran Meng', 'Hoon Wei Lim', 'Biplab Sikdar']",{'name': 'Biplab Sikdar'},Biplab Sikdar,,"[{'href': 'http://arxiv.org/abs/2502.11070v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11070v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11070v1,None,http://arxiv.org/abs/2502.11070v1,,,190,0
http://arxiv.org/abs/2502.11075v1,True,2025-02-16T10:48:28Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=10, tm_min=48, tm_sec=28, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T10:48:28Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=10, tm_min=48, tm_sec=28, tm_wday=6, tm_yday=47, tm_isdst=0)","Exposing Numeracy Gaps: A Benchmark to Evaluate Fundamental Numerical
  Abilities in Large Language Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Exposing Numeracy Gaps: A Benchmark to Evaluate Fundamental Numerical\n  Abilities in Large Language Models'}","Large Language Models (LLMs) have demonstrated impressive capabilities in
natural language processing tasks, such as text generation and semantic
understanding. However, their performance on numerical reasoning tasks, such as
basic arithmetic, numerical retrieval, and magnitude comparison, remains
surprisingly poor. This gap arises from their reliance on surface-level
statistical patterns rather than understanding numbers as continuous
magnitudes. Existing benchmarks primarily focus on either linguistic competence
or structured mathematical problem-solving, neglecting fundamental numerical
reasoning required in real-world scenarios. To bridge this gap, we propose
NumericBench, a comprehensive benchmark to evaluate six fundamental numerical
capabilities: number recognition, arithmetic operations, contextual retrieval,
comparison, summary, and logical reasoning. NumericBench includes datasets
ranging from synthetic number lists to the crawled real-world data, addressing
challenges like long contexts, noise, and multi-step reasoning. Extensive
experiments on state-of-the-art LLMs, including GPT-4 and DeepSeek, reveal
persistent weaknesses in numerical reasoning, highlighting the urgent need to
improve numerically-aware language modeling. The benchmark is released in:
https://github.com/TreeAI-Lab/NumericBench.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Language Models (LLMs) have demonstrated impressive capabilities in\nnatural language processing tasks, such as text generation and semantic\nunderstanding. However, their performance on numerical reasoning tasks, such as\nbasic arithmetic, numerical retrieval, and magnitude comparison, remains\nsurprisingly poor. This gap arises from their reliance on surface-level\nstatistical patterns rather than understanding numbers as continuous\nmagnitudes. Existing benchmarks primarily focus on either linguistic competence\nor structured mathematical problem-solving, neglecting fundamental numerical\nreasoning required in real-world scenarios. To bridge this gap, we propose\nNumericBench, a comprehensive benchmark to evaluate six fundamental numerical\ncapabilities: number recognition, arithmetic operations, contextual retrieval,\ncomparison, summary, and logical reasoning. NumericBench includes datasets\nranging from synthetic number lists to the crawled real-world data, addressing\nchallenges like long contexts, noise, and multi-step reasoning. Extensive\nexperiments on state-of-the-art LLMs, including GPT-4 and DeepSeek, reveal\npersistent weaknesses in numerical reasoning, highlighting the urgent need to\nimprove numerically-aware language modeling. The benchmark is released in:\nhttps://github.com/TreeAI-Lab/NumericBench.'}","['Haoyang Li', 'Xuejia Chen', 'Zhanchao XU', 'Darian Li', 'Nicole Hu', 'Fei Teng', 'Yiming Li', 'Luyu Qiu', 'Chen Jason Zhang', 'Qing Li', 'Lei Chen']",{'name': 'Lei Chen'},Lei Chen,,"[{'href': 'http://arxiv.org/abs/2502.11075v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11075v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11075v1,None,http://arxiv.org/abs/2502.11075v1,,,157,0
http://arxiv.org/abs/2502.11079v1,True,2025-02-16T11:02:50Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=11, tm_min=2, tm_sec=50, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T11:02:50Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=11, tm_min=2, tm_sec=50, tm_wday=6, tm_yday=47, tm_isdst=0)",Phantom: Subject-consistent video generation via cross-modal alignment,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Phantom: Subject-consistent video generation via cross-modal alignment'}","The continuous development of foundational models for video generation is
evolving into various applications, with subject-consistent video generation
still in the exploratory stage. We refer to this as Subject-to-Video, which
extracts subject elements from reference images and generates
subject-consistent video through textual instructions. We believe that the
essence of subject-to-video lies in balancing the dual-modal prompts of text
and image, thereby deeply and simultaneously aligning both text and visual
content. To this end, we propose Phantom, a unified video generation framework
for both single and multi-subject references. Building on existing
text-to-video and image-to-video architectures, we redesign the joint
text-image injection model and drive it to learn cross-modal alignment via
text-image-video triplet data. In particular, we emphasize subject consistency
in human generation, covering existing ID-preserving video generation while
offering enhanced advantages. The project homepage is here
https://phantom-video.github.io/Phantom/.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The continuous development of foundational models for video generation is\nevolving into various applications, with subject-consistent video generation\nstill in the exploratory stage. We refer to this as Subject-to-Video, which\nextracts subject elements from reference images and generates\nsubject-consistent video through textual instructions. We believe that the\nessence of subject-to-video lies in balancing the dual-modal prompts of text\nand image, thereby deeply and simultaneously aligning both text and visual\ncontent. To this end, we propose Phantom, a unified video generation framework\nfor both single and multi-subject references. Building on existing\ntext-to-video and image-to-video architectures, we redesign the joint\ntext-image injection model and drive it to learn cross-modal alignment via\ntext-image-video triplet data. In particular, we emphasize subject consistency\nin human generation, covering existing ID-preserving video generation while\noffering enhanced advantages. The project homepage is here\nhttps://phantom-video.github.io/Phantom/.'}","['Lijie Liu', 'Tianxiang Ma', 'Bingchuan Li', 'Zhuowei Chen', 'Jiawei Liu', 'Qian He', 'Xinglong Wu']",{'name': 'Xinglong Wu'},Xinglong Wu,,"[{'href': 'http://arxiv.org/abs/2502.11079v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11079v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11079v1,None,http://arxiv.org/abs/2502.11079v1,,,68,0
http://arxiv.org/abs/2502.11085v1,True,2025-02-16T11:46:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=11, tm_min=46, tm_sec=23, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T11:46:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=11, tm_min=46, tm_sec=23, tm_wday=6, tm_yday=47, tm_isdst=0)",Towards Data-Efficient Pretraining for Atomic Property Prediction,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Towards Data-Efficient Pretraining for Atomic Property Prediction'}","This paper challenges the recent paradigm in atomic property prediction that
links progress to growing dataset sizes and computational resources. We show
that pretraining on a carefully selected, task-relevant dataset can match or
even surpass large-scale pretraining, while using as little as 1/24th of the
computational cost. We introduce the Chemical Similarity Index (CSI), a novel
metric inspired by computer vision's Fr\'echet Inception Distance, for
molecular graphs which quantifies the alignment between upstream pretraining
datasets and downstream tasks. By selecting the most relevant dataset with
minimal CSI distance, we show that models pretrained on a smaller, focused
dataset consistently outperform those pretrained on massive, mixed datasets
such as JMP, even when those larger datasets include the relevant dataset.
Counterintuitively, we also find that indiscriminately adding more data can
degrade model performance when the additional data poorly aligns with the task
at hand. Our findings highlight that quality often outperforms quantity in
pretraining for atomic property prediction.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""This paper challenges the recent paradigm in atomic property prediction that\nlinks progress to growing dataset sizes and computational resources. We show\nthat pretraining on a carefully selected, task-relevant dataset can match or\neven surpass large-scale pretraining, while using as little as 1/24th of the\ncomputational cost. We introduce the Chemical Similarity Index (CSI), a novel\nmetric inspired by computer vision's Fr\\'echet Inception Distance, for\nmolecular graphs which quantifies the alignment between upstream pretraining\ndatasets and downstream tasks. By selecting the most relevant dataset with\nminimal CSI distance, we show that models pretrained on a smaller, focused\ndataset consistently outperform those pretrained on massive, mixed datasets\nsuch as JMP, even when those larger datasets include the relevant dataset.\nCounterintuitively, we also find that indiscriminately adding more data can\ndegrade model performance when the additional data poorly aligns with the task\nat hand. Our findings highlight that quality often outperforms quantity in\npretraining for atomic property prediction.""}","['Yasir Ghunaim', 'Hasan Abed Al Kader Hammoud', 'Bernard Ghanem']",{'name': 'Bernard Ghanem'},Bernard Ghanem,,"[{'href': 'http://arxiv.org/abs/2502.11085v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11085v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11085v1,None,http://arxiv.org/abs/2502.11085v1,,,1448,0
http://arxiv.org/abs/2502.11090v2,True,2025-02-18T03:05:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=3, tm_min=5, tm_sec=15, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-16T12:08:08Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=12, tm_min=8, tm_sec=8, tm_wday=6, tm_yday=47, tm_isdst=0)","SafeDialBench: A Fine-Grained Safety Benchmark for Large Language Models
  in Multi-Turn Dialogues with Diverse Jailbreak Attacks","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'SafeDialBench: A Fine-Grained Safety Benchmark for Large Language Models\n  in Multi-Turn Dialogues with Diverse Jailbreak Attacks'}","With the rapid advancement of Large Language Models (LLMs), the safety of
LLMs has been a critical concern requiring precise assessment. Current
benchmarks primarily concentrate on single-turn dialogues or a single jailbreak
attack method to assess the safety. Additionally, these benchmarks have not
taken into account the LLM's capability of identifying and handling unsafe
information in detail. To address these issues, we propose a fine-grained
benchmark SafeDialBench for evaluating the safety of LLMs across various
jailbreak attacks in multi-turn dialogues. Specifically, we design a two-tier
hierarchical safety taxonomy that considers 6 safety dimensions and generates
more than 4000 multi-turn dialogues in both Chinese and English under 22
dialogue scenarios. We employ 7 jailbreak attack strategies, such as reference
attack and purpose reverse, to enhance the dataset quality for dialogue
generation. Notably, we construct an innovative assessment framework of LLMs,
measuring capabilities in detecting, and handling unsafe information and
maintaining consistency when facing jailbreak attacks. Experimental results
across 17 LLMs reveal that Yi-34B-Chat and GLM4-9B-Chat demonstrate superior
safety performance, while Llama3.1-8B-Instruct and o3-mini exhibit safety
vulnerabilities.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""With the rapid advancement of Large Language Models (LLMs), the safety of\nLLMs has been a critical concern requiring precise assessment. Current\nbenchmarks primarily concentrate on single-turn dialogues or a single jailbreak\nattack method to assess the safety. Additionally, these benchmarks have not\ntaken into account the LLM's capability of identifying and handling unsafe\ninformation in detail. To address these issues, we propose a fine-grained\nbenchmark SafeDialBench for evaluating the safety of LLMs across various\njailbreak attacks in multi-turn dialogues. Specifically, we design a two-tier\nhierarchical safety taxonomy that considers 6 safety dimensions and generates\nmore than 4000 multi-turn dialogues in both Chinese and English under 22\ndialogue scenarios. We employ 7 jailbreak attack strategies, such as reference\nattack and purpose reverse, to enhance the dataset quality for dialogue\ngeneration. Notably, we construct an innovative assessment framework of LLMs,\nmeasuring capabilities in detecting, and handling unsafe information and\nmaintaining consistency when facing jailbreak attacks. Experimental results\nacross 17 LLMs reveal that Yi-34B-Chat and GLM4-9B-Chat demonstrate superior\nsafety performance, while Llama3.1-8B-Instruct and o3-mini exhibit safety\nvulnerabilities.""}","['Hongye Cao', 'Yanming Wang', 'Sijia Jing', 'Ziyue Peng', 'Zhixin Bai', 'Zhe Cao', 'Meng Fang', 'Fan Feng', 'Boyan Wang', 'Jiaheng Liu', 'Tianpei Yang', 'Jing Huo', 'Yang Gao', 'Fanyu Meng', 'Xi Yang', 'Chao Deng', 'Junlan Feng']",{'name': 'Junlan Feng'},Junlan Feng,,"[{'href': 'http://arxiv.org/abs/2502.11090v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11090v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11090v2,None,http://arxiv.org/abs/2502.11090v2,,,780,0
http://arxiv.org/abs/2502.11094v1,True,2025-02-16T12:14:17Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=12, tm_min=14, tm_sec=17, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T12:14:17Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=12, tm_min=14, tm_sec=17, tm_wday=6, tm_yday=47, tm_isdst=0)","SyncSpeech: Low-Latency and Efficient Dual-Stream Text-to-Speech based
  on Temporal Masked Transformer","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'SyncSpeech: Low-Latency and Efficient Dual-Stream Text-to-Speech based\n  on Temporal Masked Transformer'}","This paper presents a dual-stream text-to-speech (TTS) model, SyncSpeech,
capable of receiving streaming text input from upstream models while
simultaneously generating streaming speech, facilitating seamless interaction
with large language models. SyncSpeech has the following advantages: Low
latency, as it begins generating streaming speech upon receiving the second
text token; High efficiency, as it decodes all speech tokens corresponding to
the each arrived text token in one step. To achieve this, we propose a temporal
masked transformer as the backbone of SyncSpeech, combined with token-level
duration prediction to predict speech tokens and the duration for the next
step. Additionally, we design a two-stage training strategy to improve training
efficiency and the quality of generated speech. We evaluated the SyncSpeech on
both English and Mandarin datasets. Compared to the recent dual-stream TTS
models, SyncSpeech significantly reduces the first packet delay of speech
tokens and accelerates the real-time factor. Moreover, with the same data
scale, SyncSpeech achieves performance comparable to that of traditional
autoregressive-based TTS models in terms of both speech quality and robustness.
Speech samples are available at
https://SyncSpeech.github.io/}{https://SyncSpeech.github.io/.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'This paper presents a dual-stream text-to-speech (TTS) model, SyncSpeech,\ncapable of receiving streaming text input from upstream models while\nsimultaneously generating streaming speech, facilitating seamless interaction\nwith large language models. SyncSpeech has the following advantages: Low\nlatency, as it begins generating streaming speech upon receiving the second\ntext token; High efficiency, as it decodes all speech tokens corresponding to\nthe each arrived text token in one step. To achieve this, we propose a temporal\nmasked transformer as the backbone of SyncSpeech, combined with token-level\nduration prediction to predict speech tokens and the duration for the next\nstep. Additionally, we design a two-stage training strategy to improve training\nefficiency and the quality of generated speech. We evaluated the SyncSpeech on\nboth English and Mandarin datasets. Compared to the recent dual-stream TTS\nmodels, SyncSpeech significantly reduces the first packet delay of speech\ntokens and accelerates the real-time factor. Moreover, with the same data\nscale, SyncSpeech achieves performance comparable to that of traditional\nautoregressive-based TTS models in terms of both speech quality and robustness.\nSpeech samples are available at\nhttps://SyncSpeech.github.io/}{https://SyncSpeech.github.io/.'}","['Zhengyan Sheng', 'Zhihao Du', 'Shiliang Zhang', 'Zhijie Yan', 'Yexin Yang', 'Zhenhua Ling']",{'name': 'Zhenhua Ling'},Zhenhua Ling,,"[{'href': 'http://arxiv.org/abs/2502.11094v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11094v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.SD', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.SD', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11094v1,None,http://arxiv.org/abs/2502.11094v1,,,1001,0
http://arxiv.org/abs/2502.11096v1,True,2025-02-16T12:24:39Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=12, tm_min=24, tm_sec=39, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T12:24:39Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=12, tm_min=24, tm_sec=39, tm_wday=6, tm_yday=47, tm_isdst=0)","Mixture of Tunable Experts -- Behavior Modification of DeepSeek-R1 at
  Inference Time","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Mixture of Tunable Experts -- Behavior Modification of DeepSeek-R1 at\n  Inference Time'}","We present the Mixture-of-Tunable-Experts (MoTE), a method that extends the
Mixture-of-Experts architecture of Large Language Models (LLMs). Without
additional training, MoTE enables meaningful and focused behavior changes in
LLMs on-the-fly during inference time. By analyzing the digital LLM brain of
DeepSeek-R1 using a technique we dub 'functional Token Resonance Imaging'
(fTRI) -- inspired by fMRI and using prompts designed to elicit specific
behavior (e.g., 'What happened {time}{place}?') -- we empirically identify
distinctive experts associated with behaviors like refusal responses. Using
MoTE we are able to intervene and control such specific behavior. We switched
off the top 10 most refusal-relevant experts (0.07% of R1's 14,848 routed
experts), achieving a 52% refusal reduction on sensitive reference prompts
without performance degradation on MT-Bench. Random expert deactivation
resulted in smaller behavioral shifts with increased noise, whereas forced
expert activation led to significantly higher refusal rates. Our approach
shares similarities with sparse autoencoders (SAEs) in terms of explainability
and steerability. Unlike SAEs, MoTE does not require large training efforts, as
within MoEs with a vast number of experts, specialization already emerged
naturally during pretraining. Our findings suggest that significant functional
mechanisms in Mixture-of-Experts architectures can at least partially be
localized in a small number of specific experts, rather than being distributed
throughout the model's weights. Expert subgroups can be tuned to trigger
significant behavior variations, providing insights into the inner workings of
LLMs.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""We present the Mixture-of-Tunable-Experts (MoTE), a method that extends the\nMixture-of-Experts architecture of Large Language Models (LLMs). Without\nadditional training, MoTE enables meaningful and focused behavior changes in\nLLMs on-the-fly during inference time. By analyzing the digital LLM brain of\nDeepSeek-R1 using a technique we dub 'functional Token Resonance Imaging'\n(fTRI) -- inspired by fMRI and using prompts designed to elicit specific\nbehavior (e.g., 'What happened {time}{place}?') -- we empirically identify\ndistinctive experts associated with behaviors like refusal responses. Using\nMoTE we are able to intervene and control such specific behavior. We switched\noff the top 10 most refusal-relevant experts (0.07% of R1's 14,848 routed\nexperts), achieving a 52% refusal reduction on sensitive reference prompts\nwithout performance degradation on MT-Bench. Random expert deactivation\nresulted in smaller behavioral shifts with increased noise, whereas forced\nexpert activation led to significantly higher refusal rates. Our approach\nshares similarities with sparse autoencoders (SAEs) in terms of explainability\nand steerability. Unlike SAEs, MoTE does not require large training efforts, as\nwithin MoEs with a vast number of experts, specialization already emerged\nnaturally during pretraining. Our findings suggest that significant functional\nmechanisms in Mixture-of-Experts architectures can at least partially be\nlocalized in a small number of specific experts, rather than being distributed\nthroughout the model's weights. Expert subgroups can be tuned to trigger\nsignificant behavior variations, providing insights into the inner workings of\nLLMs.""}","['Robert Dahlke', 'Henrik Klagges', 'Dan Zecha', 'Benjamin Merkel', 'Sven Rohr', 'Fabian Klemm']",{'name': 'Fabian Klemm'},Fabian Klemm,,"[{'href': 'http://arxiv.org/abs/2502.11096v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11096v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11096v1,None,http://arxiv.org/abs/2502.11096v1,,,0,0
http://arxiv.org/abs/2502.11101v1,True,2025-02-16T12:33:16Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=12, tm_min=33, tm_sec=16, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T12:33:16Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=12, tm_min=33, tm_sec=16, tm_wday=6, tm_yday=47, tm_isdst=0)","CacheFocus: Dynamic Cache Re-Positioning for Efficient
  Retrieval-Augmented Generation","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'CacheFocus: Dynamic Cache Re-Positioning for Efficient\n  Retrieval-Augmented Generation'}","Large Language Models (LLMs) excel across a variety of language tasks yet are
constrained by limited input lengths and high computational costs. Existing
approaches\textemdash such as relative positional encodings (e.g., RoPE, ALiBi)
and sliding window mechanisms\textemdash partially alleviate these issues but
often require additional training or suffer from performance degradation with
longer inputs. In this paper, we introduce \textbf{\textit{CacheFocus}}, a
method that enhances length normalization and reduces inference latency without
any further training. Our approach leverages query-independent, offline caching
to efficiently reuse a Context KV Cache Store. We address the amplification of
abnormal token distributions problem by re-positioning cached keys and
introducing Layer-Adaptive Cache Pruning to discard low-relevance caches during
pre-filling. Additionally, our Adaptive Positional Allocation Strategy
dynamically reassigns cache positions to maximize the use of the available
positional encoding range. Experiments on the Natural Questions and TriviaQA
datasets demonstrate that CacheFocus outperforms alternative methods even when
inputs exceed the $4$K limit of the \texttt{LLaMA-2} model, emphasizing its
practical effectiveness for long-context LLMs. Moreover, even with large
maximum input length of \texttt{Qwen2}, the performance of CacheFocus shows
that it maintains consistent performance even as the number of documents
increases, effectively managing long-text generation without degradation.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Language Models (LLMs) excel across a variety of language tasks yet are\nconstrained by limited input lengths and high computational costs. Existing\napproaches\\textemdash such as relative positional encodings (e.g., RoPE, ALiBi)\nand sliding window mechanisms\\textemdash partially alleviate these issues but\noften require additional training or suffer from performance degradation with\nlonger inputs. In this paper, we introduce \\textbf{\\textit{CacheFocus}}, a\nmethod that enhances length normalization and reduces inference latency without\nany further training. Our approach leverages query-independent, offline caching\nto efficiently reuse a Context KV Cache Store. We address the amplification of\nabnormal token distributions problem by re-positioning cached keys and\nintroducing Layer-Adaptive Cache Pruning to discard low-relevance caches during\npre-filling. Additionally, our Adaptive Positional Allocation Strategy\ndynamically reassigns cache positions to maximize the use of the available\npositional encoding range. Experiments on the Natural Questions and TriviaQA\ndatasets demonstrate that CacheFocus outperforms alternative methods even when\ninputs exceed the $4$K limit of the \\texttt{LLaMA-2} model, emphasizing its\npractical effectiveness for long-context LLMs. Moreover, even with large\nmaximum input length of \\texttt{Qwen2}, the performance of CacheFocus shows\nthat it maintains consistent performance even as the number of documents\nincreases, effectively managing long-text generation without degradation.'}","['Kun-Hui Lee', 'Eunhwan Park', 'Donghoon Han', 'Seung-Hoon Na']",{'name': 'Seung-Hoon Na'},Seung-Hoon Na,11 pages (Work in progress),"[{'href': 'http://arxiv.org/abs/2502.11101v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11101v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11101v1,None,http://arxiv.org/abs/2502.11101v1,,,1,0
http://arxiv.org/abs/2502.11102v1,True,2025-02-16T12:38:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=12, tm_min=38, tm_sec=37, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T12:38:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=12, tm_min=38, tm_sec=37, tm_wday=6, tm_yday=47, tm_isdst=0)","OptMATH: A Scalable Bidirectional Data Synthesis Framework for
  Optimization Modeling","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'OptMATH: A Scalable Bidirectional Data Synthesis Framework for\n  Optimization Modeling'}","Despite the rapid development of large language models (LLMs), a fundamental
challenge persists: the lack of high-quality optimization modeling datasets
hampers LLMs' robust modeling of practical optimization problems from natural
language descriptions (NL). This data scarcity also contributes to the
generalization difficulties experienced by learning-based methods. To address
these challenges, we propose a scalable framework for synthesizing a
high-quality dataset, named OptMATH. Starting from curated seed data with
mathematical formulations (MF), this framework automatically generates problem
data (PD) with controllable complexity. Then, a back-translation step is
employed to obtain NL. To verify the correspondence between the NL and the PD,
a forward modeling step followed by rejection sampling is used. The accepted
pairs constitute the training part of OptMATH. Then a collection of rejected
pairs is identified and further filtered. This collection serves as a new
benchmark for optimization modeling, containing difficult instances whose
lengths are much longer than these of NL4OPT and MAMO. Through extensive
experiments, we demonstrate that models of various sizes (0.5B-32B parameters)
trained on OptMATH achieve superior results on multiple modeling benchmarks,
thereby validating the effectiveness and scalability of our approach.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Despite the rapid development of large language models (LLMs), a fundamental\nchallenge persists: the lack of high-quality optimization modeling datasets\nhampers LLMs' robust modeling of practical optimization problems from natural\nlanguage descriptions (NL). This data scarcity also contributes to the\ngeneralization difficulties experienced by learning-based methods. To address\nthese challenges, we propose a scalable framework for synthesizing a\nhigh-quality dataset, named OptMATH. Starting from curated seed data with\nmathematical formulations (MF), this framework automatically generates problem\ndata (PD) with controllable complexity. Then, a back-translation step is\nemployed to obtain NL. To verify the correspondence between the NL and the PD,\na forward modeling step followed by rejection sampling is used. The accepted\npairs constitute the training part of OptMATH. Then a collection of rejected\npairs is identified and further filtered. This collection serves as a new\nbenchmark for optimization modeling, containing difficult instances whose\nlengths are much longer than these of NL4OPT and MAMO. Through extensive\nexperiments, we demonstrate that models of various sizes (0.5B-32B parameters)\ntrained on OptMATH achieve superior results on multiple modeling benchmarks,\nthereby validating the effectiveness and scalability of our approach.""}","['Hongliang Lu', 'Zhonglin Xie', 'Yaoyu Wu', 'Can Ren', 'Yuxuan Chen', 'Zaiwen Wen']",{'name': 'Zaiwen Wen'},Zaiwen Wen,"This paper has 36 pages, 18 figures, and two co-first authors:
  Hongliang Lu and Zhonglin Xie","[{'href': 'http://arxiv.org/abs/2502.11102v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11102v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11102v1,None,http://arxiv.org/abs/2502.11102v1,,,0,0
http://arxiv.org/abs/2502.11107v1,True,2025-02-16T12:50:20Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=12, tm_min=50, tm_sec=20, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T12:50:20Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=12, tm_min=50, tm_sec=20, tm_wday=6, tm_yday=47, tm_isdst=0)","Revisiting Weak-to-Strong Generalization in Theory and Practice: Reverse
  KL vs. Forward KL","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Revisiting Weak-to-Strong Generalization in Theory and Practice: Reverse\n  KL vs. Forward KL'}","As large language models advance toward superhuman performance, ensuring
their alignment with human values and abilities grows increasingly complex.
Weak-to-strong generalization offers a promising approach by leveraging
predictions from weaker models to guide stronger systems, but its effectiveness
could be constrained by the inherent noise and inaccuracies in these weak
predictions. To address this, we propose a theoretically grounded approach that
replaces forward KL divergence-whose mass-covering behavior risks overfitting
to imperfect weak signals-with reverse KL divergence. Reverse KL divergence's
zero-forcing effect prioritizes high-confidence predictions, effectively
mitigating the influence of unreliable weak supervision. Theoretically, we
extend existing bounds and derive tighter lower bounds for both forward and
reverse KL divergence, establishing that reverse KL achieves at least
comparable guarantees to forward KL. Notably, when a sufficiently pre-trained
strong model is fine-tuned on the last layer, reverse KL uniquely guarantees
that it outperforms its weak supervisor by the magnitude of their
disagreement-a guarantee that forward KL cannot provide. Empirically, we
demonstrate that reverse KL and reverse cross-entropy enable strong models to
consistently outperform those trained with forward KL and standard
cross-entropy across most settings, highlighting the practical advantages of
these reverse losses.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""As large language models advance toward superhuman performance, ensuring\ntheir alignment with human values and abilities grows increasingly complex.\nWeak-to-strong generalization offers a promising approach by leveraging\npredictions from weaker models to guide stronger systems, but its effectiveness\ncould be constrained by the inherent noise and inaccuracies in these weak\npredictions. To address this, we propose a theoretically grounded approach that\nreplaces forward KL divergence-whose mass-covering behavior risks overfitting\nto imperfect weak signals-with reverse KL divergence. Reverse KL divergence's\nzero-forcing effect prioritizes high-confidence predictions, effectively\nmitigating the influence of unreliable weak supervision. Theoretically, we\nextend existing bounds and derive tighter lower bounds for both forward and\nreverse KL divergence, establishing that reverse KL achieves at least\ncomparable guarantees to forward KL. Notably, when a sufficiently pre-trained\nstrong model is fine-tuned on the last layer, reverse KL uniquely guarantees\nthat it outperforms its weak supervisor by the magnitude of their\ndisagreement-a guarantee that forward KL cannot provide. Empirically, we\ndemonstrate that reverse KL and reverse cross-entropy enable strong models to\nconsistently outperform those trained with forward KL and standard\ncross-entropy across most settings, highlighting the practical advantages of\nthese reverse losses.""}","['Wei Yao', 'Wenkai Yang', 'Ziqiao Wang', 'Yankai Lin', 'Yong Liu']",{'name': 'Yong Liu'},Yong Liu,,"[{'href': 'http://arxiv.org/abs/2502.11107v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11107v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11107v1,None,http://arxiv.org/abs/2502.11107v1,,,97,0
http://arxiv.org/abs/2502.11108v1,True,2025-02-16T12:52:28Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=12, tm_min=52, tm_sec=28, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T12:52:28Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=12, tm_min=52, tm_sec=28, tm_wday=6, tm_yday=47, tm_isdst=0)","Knowledge Graph-Driven Retrieval-Augmented Generation: Integrating
  Deepseek-R1 with Weaviate for Advanced Chatbot Applications","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Knowledge Graph-Driven Retrieval-Augmented Generation: Integrating\n  Deepseek-R1 with Weaviate for Advanced Chatbot Applications'}","Large language models (LLMs) have significantly advanced the field of natural
language generation. However, they frequently generate unverified outputs,
which compromises their reliability in critical applications. In this study, we
propose an innovative framework that combines structured biomedical knowledge
with LLMs through a retrieval-augmented generation technique. Our system
develops a thorough knowledge graph by identifying and refining causal
relationships and named entities from medical abstracts related to age-related
macular degeneration (AMD). Using a vector-based retrieval process and a
locally deployed language model, our framework produces responses that are both
contextually relevant and verifiable, with direct references to clinical
evidence. Experimental results show that this method notably decreases
hallucinations, enhances factual precision, and improves the clarity of
generated responses, providing a robust solution for advanced biomedical
chatbot applications.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large language models (LLMs) have significantly advanced the field of natural\nlanguage generation. However, they frequently generate unverified outputs,\nwhich compromises their reliability in critical applications. In this study, we\npropose an innovative framework that combines structured biomedical knowledge\nwith LLMs through a retrieval-augmented generation technique. Our system\ndevelops a thorough knowledge graph by identifying and refining causal\nrelationships and named entities from medical abstracts related to age-related\nmacular degeneration (AMD). Using a vector-based retrieval process and a\nlocally deployed language model, our framework produces responses that are both\ncontextually relevant and verifiable, with direct references to clinical\nevidence. Experimental results show that this method notably decreases\nhallucinations, enhances factual precision, and improves the clarity of\ngenerated responses, providing a robust solution for advanced biomedical\nchatbot applications.'}","['Alexandru Lecu', 'Adrian Groza', 'Lezan Hawizy']",{'name': 'Lezan Hawizy'},Lezan Hawizy,,"[{'title': 'doi', 'href': 'http://dx.doi.org/10.1016/j.procs.2024.10.219', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2502.11108v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11108v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11108v1,None,http://arxiv.org/abs/2502.11108v1,,10.1016/j.procs.2024.10.219,0,0
http://arxiv.org/abs/2502.11124v1,True,2025-02-16T13:45:10Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=13, tm_min=45, tm_sec=10, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T13:45:10Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=13, tm_min=45, tm_sec=10, tm_wday=6, tm_yday=47, tm_isdst=0)","AdaManip: Adaptive Articulated Object Manipulation Environments and
  Policy Learning","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'AdaManip: Adaptive Articulated Object Manipulation Environments and\n  Policy Learning'}","Articulated object manipulation is a critical capability for robots to
perform various tasks in real-world scenarios. Composed of multiple parts
connected by joints, articulated objects are endowed with diverse functional
mechanisms through complex relative motions. For example, a safe consists of a
door, a handle, and a lock, where the door can only be opened when the latch is
unlocked. The internal structure, such as the state of a lock or joint angle
constraints, cannot be directly observed from visual observation. Consequently,
successful manipulation of these objects requires adaptive adjustment based on
trial and error rather than a one-time visual inference. However, previous
datasets and simulation environments for articulated objects have primarily
focused on simple manipulation mechanisms where the complete manipulation
process can be inferred from the object's appearance. To enhance the diversity
and complexity of adaptive manipulation mechanisms, we build a novel
articulated object manipulation environment and equip it with 9 categories of
objects. Based on the environment and objects, we further propose an adaptive
demonstration collection and 3D visual diffusion-based imitation learning
pipeline that learns the adaptive manipulation policy. The effectiveness of our
designs and proposed method is validated through both simulation and real-world
experiments. Our project page is available at: https://adamanip.github.io","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Articulated object manipulation is a critical capability for robots to\nperform various tasks in real-world scenarios. Composed of multiple parts\nconnected by joints, articulated objects are endowed with diverse functional\nmechanisms through complex relative motions. For example, a safe consists of a\ndoor, a handle, and a lock, where the door can only be opened when the latch is\nunlocked. The internal structure, such as the state of a lock or joint angle\nconstraints, cannot be directly observed from visual observation. Consequently,\nsuccessful manipulation of these objects requires adaptive adjustment based on\ntrial and error rather than a one-time visual inference. However, previous\ndatasets and simulation environments for articulated objects have primarily\nfocused on simple manipulation mechanisms where the complete manipulation\nprocess can be inferred from the object's appearance. To enhance the diversity\nand complexity of adaptive manipulation mechanisms, we build a novel\narticulated object manipulation environment and equip it with 9 categories of\nobjects. Based on the environment and objects, we further propose an adaptive\ndemonstration collection and 3D visual diffusion-based imitation learning\npipeline that learns the adaptive manipulation policy. The effectiveness of our\ndesigns and proposed method is validated through both simulation and real-world\nexperiments. Our project page is available at: https://adamanip.github.io""}","['Yuanfei Wang', 'Xiaojie Zhang', 'Ruihai Wu', 'Yu Li', 'Yan Shen', 'Mingdong Wu', 'Zhaofeng He', 'Yizhou Wang', 'Hao Dong']",{'name': 'Hao Dong'},Hao Dong,ICLR 2025,"[{'href': 'http://arxiv.org/abs/2502.11124v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11124v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11124v1,None,http://arxiv.org/abs/2502.11124v1,,,121,0
http://arxiv.org/abs/2502.11132v1,True,2025-02-16T14:00:57Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=14, tm_min=0, tm_sec=57, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T14:00:57Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=14, tm_min=0, tm_sec=57, tm_wday=6, tm_yday=47, tm_isdst=0)","UNITE-FND: Reframing Multimodal Fake News Detection through Unimodal
  Scene Translation","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'UNITE-FND: Reframing Multimodal Fake News Detection through Unimodal\n  Scene Translation'}","Multimodal fake news detection typically demands complex architectures and
substantial computational resources, posing deployment challenges in real-world
settings. We introduce UNITE-FND, a novel framework that reframes multimodal
fake news detection as a unimodal text classification task. We propose six
specialized prompting strategies with Gemini 1.5 Pro, converting visual content
into structured textual descriptions, and enabling efficient text-only models
to preserve critical visual information. To benchmark our approach, we
introduce Uni-Fakeddit-55k, a curated dataset family of 55,000 samples each,
each processed through our multimodal-to-unimodal translation framework.
Experimental results demonstrate that UNITE-FND achieves 92.52% accuracy in
binary classification, surpassing prior multimodal models while reducing
computational costs by over 10x (TinyBERT variant: 14.5M parameters vs. 250M+
in SOTA models). Additionally, we propose a comprehensive suite of five novel
metrics to evaluate image-to-text conversion quality, ensuring optimal
information preservation. Our results demonstrate that structured text-based
representations can replace direct multimodal processing with minimal loss of
accuracy, making UNITE-FND a practical and scalable alternative for
resource-constrained environments.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Multimodal fake news detection typically demands complex architectures and\nsubstantial computational resources, posing deployment challenges in real-world\nsettings. We introduce UNITE-FND, a novel framework that reframes multimodal\nfake news detection as a unimodal text classification task. We propose six\nspecialized prompting strategies with Gemini 1.5 Pro, converting visual content\ninto structured textual descriptions, and enabling efficient text-only models\nto preserve critical visual information. To benchmark our approach, we\nintroduce Uni-Fakeddit-55k, a curated dataset family of 55,000 samples each,\neach processed through our multimodal-to-unimodal translation framework.\nExperimental results demonstrate that UNITE-FND achieves 92.52% accuracy in\nbinary classification, surpassing prior multimodal models while reducing\ncomputational costs by over 10x (TinyBERT variant: 14.5M parameters vs. 250M+\nin SOTA models). Additionally, we propose a comprehensive suite of five novel\nmetrics to evaluate image-to-text conversion quality, ensuring optimal\ninformation preservation. Our results demonstrate that structured text-based\nrepresentations can replace direct multimodal processing with minimal loss of\naccuracy, making UNITE-FND a practical and scalable alternative for\nresource-constrained environments.'}","['Arka Mukherjee', 'Shreya Ghosh']",{'name': 'Shreya Ghosh'},Shreya Ghosh,"28 pages, 16 figures","[{'href': 'http://arxiv.org/abs/2502.11132v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11132v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11132v1,None,http://arxiv.org/abs/2502.11132v1,,,0,0
http://arxiv.org/abs/2502.11134v1,True,2025-02-16T14:01:12Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=14, tm_min=1, tm_sec=12, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T14:01:12Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=14, tm_min=1, tm_sec=12, tm_wday=6, tm_yday=47, tm_isdst=0)","Solving Online Resource-Constrained Scheduling for Follow-Up Observation
  in Astronomy: a Reinforcement Learning Approach","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Solving Online Resource-Constrained Scheduling for Follow-Up Observation\n  in Astronomy: a Reinforcement Learning Approach'}","In the astronomical observation field, determining the allocation of
observation resources of the telescope array and planning follow-up
observations for targets of opportunity (ToOs) are indispensable components of
astronomical scientific discovery. This problem is computationally challenging,
given the online observation setting and the abundance of time-varying factors
that can affect whether an observation can be conducted. This paper presents
ROARS, a reinforcement learning approach for online astronomical
resource-constrained scheduling. To capture the structure of the astronomical
observation scheduling, we depict every schedule using a directed acyclic graph
(DAG), illustrating the dependency of timing between different observation
tasks within the schedule. Deep reinforcement learning is used to learn a
policy that can improve the feasible solution by iteratively local rewriting
until convergence. It can solve the challenge of obtaining a complete solution
directly from scratch in astronomical observation scenarios, due to the high
computational complexity resulting from numerous spatial and temporal
constraints. A simulation environment is developed based on real-world
scenarios for experiments, to evaluate the effectiveness of our proposed
scheduling approach. The experimental results show that ROARS surpasses 5
popular heuristics, adapts to various observation scenarios and learns
effective strategies with hindsight.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'In the astronomical observation field, determining the allocation of\nobservation resources of the telescope array and planning follow-up\nobservations for targets of opportunity (ToOs) are indispensable components of\nastronomical scientific discovery. This problem is computationally challenging,\ngiven the online observation setting and the abundance of time-varying factors\nthat can affect whether an observation can be conducted. This paper presents\nROARS, a reinforcement learning approach for online astronomical\nresource-constrained scheduling. To capture the structure of the astronomical\nobservation scheduling, we depict every schedule using a directed acyclic graph\n(DAG), illustrating the dependency of timing between different observation\ntasks within the schedule. Deep reinforcement learning is used to learn a\npolicy that can improve the feasible solution by iteratively local rewriting\nuntil convergence. It can solve the challenge of obtaining a complete solution\ndirectly from scratch in astronomical observation scenarios, due to the high\ncomputational complexity resulting from numerous spatial and temporal\nconstraints. A simulation environment is developed based on real-world\nscenarios for experiments, to evaluate the effectiveness of our proposed\nscheduling approach. The experimental results show that ROARS surpasses 5\npopular heuristics, adapts to various observation scenarios and learns\neffective strategies with hindsight.'}","['Yajie Zhang', 'Ce Yu', 'Chao Sun', 'Jizeng Wei', 'Junhan Ju', 'Shanjiang Tang']",{'name': 'Shanjiang Tang'},Shanjiang Tang,,"[{'href': 'http://arxiv.org/abs/2502.11134v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11134v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'astro-ph.IM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11134v1,None,http://arxiv.org/abs/2502.11134v1,,,108,0
http://arxiv.org/abs/2502.11137v2,True,2025-02-20T17:29:08Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=17, tm_min=29, tm_sec=8, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-16T14:05:54Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=14, tm_min=5, tm_sec=54, tm_wday=6, tm_yday=47, tm_isdst=0)",Safety Evaluation of DeepSeek Models in Chinese Contexts,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Safety Evaluation of DeepSeek Models in Chinese Contexts'}","Recently, the DeepSeek series of models, leveraging their exceptional
reasoning capabilities and open-source strategy, is reshaping the global AI
landscape. Despite these advantages, they exhibit significant safety
deficiencies. Research conducted by Robust Intelligence, a subsidiary of Cisco,
in collaboration with the University of Pennsylvania, revealed that DeepSeek-R1
has a 100\% attack success rate when processing harmful prompts. Additionally,
multiple safety companies and research institutions have confirmed critical
safety vulnerabilities in this model. As models demonstrating robust
performance in Chinese and English, DeepSeek models require equally crucial
safety assessments in both language contexts. However, current research has
predominantly focused on safety evaluations in English environments, leaving a
gap in comprehensive assessments of their safety performance in Chinese
contexts. In response to this gap, this study introduces CHiSafetyBench, a
Chinese-specific safety evaluation benchmark. This benchmark systematically
evaluates the safety of DeepSeek-R1 and DeepSeek-V3 in Chinese contexts,
revealing their performance across safety categories. The experimental results
quantify the deficiencies of these two models in Chinese contexts, providing
key insights for subsequent improvements. It should be noted that, despite our
efforts to establish a comprehensive, objective, and authoritative evaluation
benchmark, the selection of test samples, characteristics of data distribution,
and the setting of evaluation criteria may inevitably introduce certain biases
into the evaluation results. We will continuously optimize the evaluation
benchmark and periodically update this report to provide more comprehensive and
accurate assessment outcomes. Please refer to the latest version of the paper
for the most recent evaluation results and conclusions.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Recently, the DeepSeek series of models, leveraging their exceptional\nreasoning capabilities and open-source strategy, is reshaping the global AI\nlandscape. Despite these advantages, they exhibit significant safety\ndeficiencies. Research conducted by Robust Intelligence, a subsidiary of Cisco,\nin collaboration with the University of Pennsylvania, revealed that DeepSeek-R1\nhas a 100\\% attack success rate when processing harmful prompts. Additionally,\nmultiple safety companies and research institutions have confirmed critical\nsafety vulnerabilities in this model. As models demonstrating robust\nperformance in Chinese and English, DeepSeek models require equally crucial\nsafety assessments in both language contexts. However, current research has\npredominantly focused on safety evaluations in English environments, leaving a\ngap in comprehensive assessments of their safety performance in Chinese\ncontexts. In response to this gap, this study introduces CHiSafetyBench, a\nChinese-specific safety evaluation benchmark. This benchmark systematically\nevaluates the safety of DeepSeek-R1 and DeepSeek-V3 in Chinese contexts,\nrevealing their performance across safety categories. The experimental results\nquantify the deficiencies of these two models in Chinese contexts, providing\nkey insights for subsequent improvements. It should be noted that, despite our\nefforts to establish a comprehensive, objective, and authoritative evaluation\nbenchmark, the selection of test samples, characteristics of data distribution,\nand the setting of evaluation criteria may inevitably introduce certain biases\ninto the evaluation results. We will continuously optimize the evaluation\nbenchmark and periodically update this report to provide more comprehensive and\naccurate assessment outcomes. Please refer to the latest version of the paper\nfor the most recent evaluation results and conclusions.'}","['Wenjing Zhang', 'Xuejiao Lei', 'Zhaoxiang Liu', 'Ning Wang', 'Zhenhong Long', 'Peijun Yang', 'Jiaojiao Zhao', 'Minjie Hua', 'Chaoyang Ma', 'Kai Wang', 'Shiguo Lian']",{'name': 'Shiguo Lian'},Shiguo Lian,"12 pages, 2 tables, 7 figures","[{'href': 'http://arxiv.org/abs/2502.11137v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11137v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11137v2,None,http://arxiv.org/abs/2502.11137v2,,,139,0
http://arxiv.org/abs/2502.11147v1,True,2025-02-16T14:28:52Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=14, tm_min=28, tm_sec=52, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T14:28:52Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=14, tm_min=28, tm_sec=52, tm_wday=6, tm_yday=47, tm_isdst=0)","Efficient Long-Decoding Inference with Reasoning-Aware Attention
  Sparsity","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Efficient Long-Decoding Inference with Reasoning-Aware Attention\n  Sparsity'}","Large Language Models (LLMs) have demonstrated strong capabilities across
various domains, with recent advancements in challenging reasoning tasks such
as mathematics and programming. However, solving reasoning tasks often requires
long decoding chains (of thoughts), which incur $O(N)$ time and memory
consumption, where $N$ is the chain length. To mitigate $O(N)$ time and memory
consumption, existing sparsity-based algorithms propose retaining only the most
critical token's intermediate data (i.e., key-value cache) and discarding the
rest. However, these existing algorithms struggle with the ``impossible
trinity'' of accuracy, time, and memory. For example, the state-of-the-art
algorithm, Quest, achieves high accuracy with $O(L)$ time but $O(N)$ memory
($L$ is the cache budget, $L \ll N$). To address this issue, in this paper, we
identify a new attention pattern during the decode stage of reasoning tasks,
where milestone tokens (analogous to lemmas in mathematical proofs) emerge, are
utilized, and then become unimportant afterward. Based on this pattern, we
propose a new algorithm named RaaS that identifies and retains milestone tokens
only until they are no longer needed, achieving high accuracy with $O(L)$ time
and $O(L)$ memory complexity.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Large Language Models (LLMs) have demonstrated strong capabilities across\nvarious domains, with recent advancements in challenging reasoning tasks such\nas mathematics and programming. However, solving reasoning tasks often requires\nlong decoding chains (of thoughts), which incur $O(N)$ time and memory\nconsumption, where $N$ is the chain length. To mitigate $O(N)$ time and memory\nconsumption, existing sparsity-based algorithms propose retaining only the most\ncritical token's intermediate data (i.e., key-value cache) and discarding the\nrest. However, these existing algorithms struggle with the ``impossible\ntrinity'' of accuracy, time, and memory. For example, the state-of-the-art\nalgorithm, Quest, achieves high accuracy with $O(L)$ time but $O(N)$ memory\n($L$ is the cache budget, $L \\ll N$). To address this issue, in this paper, we\nidentify a new attention pattern during the decode stage of reasoning tasks,\nwhere milestone tokens (analogous to lemmas in mathematical proofs) emerge, are\nutilized, and then become unimportant afterward. Based on this pattern, we\npropose a new algorithm named RaaS that identifies and retains milestone tokens\nonly until they are no longer needed, achieving high accuracy with $O(L)$ time\nand $O(L)$ memory complexity.""}","['Junhao Hu', 'Wenrui Huang', 'Weidong Wang', 'Zhenwen Li', 'Tiancheng Hu', 'Zhixia Liu', 'Xusheng Chen', 'Tao Xie', 'Yizhou Shan']",{'name': 'Yizhou Shan'},Yizhou Shan,,"[{'href': 'http://arxiv.org/abs/2502.11147v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11147v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11147v1,None,http://arxiv.org/abs/2502.11147v1,,,261,0
http://arxiv.org/abs/2502.11149v2,True,2025-02-19T06:41:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=6, tm_min=41, tm_sec=42, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-16T14:50:49Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=14, tm_min=50, tm_sec=49, tm_wday=6, tm_yday=47, tm_isdst=0)",Large Language-Geometry Model: When LLM meets Equivariance,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Language-Geometry Model: When LLM meets Equivariance'}","Accurately predicting 3D structures and dynamics of physical systems is
crucial in scientific applications. Existing approaches that rely on geometric
Graph Neural Networks (GNNs) effectively enforce $\mathrm{E}(3)$-equivariance,
but they often fall in leveraging extensive broader information. While direct
application of Large Language Models (LLMs) can incorporate external knowledge,
they lack the capability for spatial reasoning with guaranteed equivariance. In
this paper, we propose EquiLLM, a novel framework for representing 3D physical
systems that seamlessly integrates E(3)-equivariance with LLM capabilities.
Specifically, EquiLLM comprises four key components: geometry-aware prompting,
an equivariant encoder, an LLM, and an equivariant adaptor. Essentially, the
LLM guided by the instructive prompt serves as a sophisticated invariant
feature processor, while 3D directional information is exclusively handled by
the equivariant encoder and adaptor modules. Experimental results demonstrate
that EquiLLM delivers significant improvements over previous methods across
molecular dynamics simulation, human motion simulation, and antibody design,
highlighting its promising generalizability.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Accurately predicting 3D structures and dynamics of physical systems is\ncrucial in scientific applications. Existing approaches that rely on geometric\nGraph Neural Networks (GNNs) effectively enforce $\\mathrm{E}(3)$-equivariance,\nbut they often fall in leveraging extensive broader information. While direct\napplication of Large Language Models (LLMs) can incorporate external knowledge,\nthey lack the capability for spatial reasoning with guaranteed equivariance. In\nthis paper, we propose EquiLLM, a novel framework for representing 3D physical\nsystems that seamlessly integrates E(3)-equivariance with LLM capabilities.\nSpecifically, EquiLLM comprises four key components: geometry-aware prompting,\nan equivariant encoder, an LLM, and an equivariant adaptor. Essentially, the\nLLM guided by the instructive prompt serves as a sophisticated invariant\nfeature processor, while 3D directional information is exclusively handled by\nthe equivariant encoder and adaptor modules. Experimental results demonstrate\nthat EquiLLM delivers significant improvements over previous methods across\nmolecular dynamics simulation, human motion simulation, and antibody design,\nhighlighting its promising generalizability.'}","['Zongzhao Li', 'Jiacheng Cen', 'Bing Su', 'Wenbing Huang', 'Tingyang Xu', 'Yu Rong', 'Deli Zhao']",{'name': 'Deli Zhao'},Deli Zhao,,"[{'href': 'http://arxiv.org/abs/2502.11149v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11149v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11149v2,None,http://arxiv.org/abs/2502.11149v2,,,57,0
http://arxiv.org/abs/2502.11155v1,True,2025-02-16T15:10:30Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=15, tm_min=10, tm_sec=30, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T15:10:30Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=15, tm_min=10, tm_sec=30, tm_wday=6, tm_yday=47, tm_isdst=0)","Uncertainty-Aware Search and Value Models: Mitigating Search Scaling
  Flaws in LLMs","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Uncertainty-Aware Search and Value Models: Mitigating Search Scaling\n  Flaws in LLMs'}","Value model-guided search is effective in steering the generation but suffers
from scaling flaws: Its superiority diminishes with larger sample sizes,
underperforming non-search baselines. This limitation arises from reliability
degradation in value models in unseen reasoning paths. To address this, we
propose an uncertainty-aware search framework that includes two key components:
(1) uncertainty-aware value models that incorporate uncertainty into
predictions, and (2) an uncertainty-aware selection process using the proposed
efficient Group Thompson Sampling algorithm. Experiments on GSM8K show that our
method mitigates search scaling flaws, achieving 90.5% coverage at 16 samples
compared to 85.8% for conventional value-guided search. This work establishes
the first systematic integration of uncertainty quantification in LLM search
paradigms.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Value model-guided search is effective in steering the generation but suffers\nfrom scaling flaws: Its superiority diminishes with larger sample sizes,\nunderperforming non-search baselines. This limitation arises from reliability\ndegradation in value models in unseen reasoning paths. To address this, we\npropose an uncertainty-aware search framework that includes two key components:\n(1) uncertainty-aware value models that incorporate uncertainty into\npredictions, and (2) an uncertainty-aware selection process using the proposed\nefficient Group Thompson Sampling algorithm. Experiments on GSM8K show that our\nmethod mitigates search scaling flaws, achieving 90.5% coverage at 16 samples\ncompared to 85.8% for conventional value-guided search. This work establishes\nthe first systematic integration of uncertainty quantification in LLM search\nparadigms.'}","['Fei Yu', 'Yingru Li', 'Benyou Wang']",{'name': 'Benyou Wang'},Benyou Wang,,"[{'href': 'http://arxiv.org/abs/2502.11155v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11155v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11155v1,None,http://arxiv.org/abs/2502.11155v1,,,47,0
http://arxiv.org/abs/2502.11164v1,True,2025-02-16T15:29:58Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=15, tm_min=29, tm_sec=58, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T15:29:58Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=15, tm_min=29, tm_sec=58, tm_wday=6, tm_yday=47, tm_isdst=0)","Quantifying the Capability Boundary of DeepSeek Models: An
  Application-Driven Performance Analysis","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Quantifying the Capability Boundary of DeepSeek Models: An\n  Application-Driven Performance Analysis'}","DeepSeek-R1, known for its low training cost and exceptional reasoning
capabilities, has achieved state-of-the-art performance on various benchmarks.
However, detailed evaluations from the perspective of real-world applications
are lacking, making it challenging for users to select the most suitable
DeepSeek models for their specific needs. To address this gap, we evaluate the
DeepSeek-V3, DeepSeek-R1, DeepSeek-R1-Distill-Qwen series, and
DeepSeek-R1-Distill-Llama series on A-Eval, an application-driven benchmark. By
comparing original instruction-tuned models with their distilled counterparts,
we analyze how reasoning enhancements impact performance across diverse
practical tasks. Our results show that reasoning-enhanced models, while
generally powerful, do not universally outperform across all tasks, with
performance gains varying significantly across tasks and models. To further
assist users in model selection, we quantify the capability boundary of
DeepSeek models through performance tier classifications and intuitive line
charts. Specific examples provide actionable insights to help users select and
deploy the most cost-effective DeepSeek models, ensuring optimal performance
and resource efficiency in real-world applications.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'DeepSeek-R1, known for its low training cost and exceptional reasoning\ncapabilities, has achieved state-of-the-art performance on various benchmarks.\nHowever, detailed evaluations from the perspective of real-world applications\nare lacking, making it challenging for users to select the most suitable\nDeepSeek models for their specific needs. To address this gap, we evaluate the\nDeepSeek-V3, DeepSeek-R1, DeepSeek-R1-Distill-Qwen series, and\nDeepSeek-R1-Distill-Llama series on A-Eval, an application-driven benchmark. By\ncomparing original instruction-tuned models with their distilled counterparts,\nwe analyze how reasoning enhancements impact performance across diverse\npractical tasks. Our results show that reasoning-enhanced models, while\ngenerally powerful, do not universally outperform across all tasks, with\nperformance gains varying significantly across tasks and models. To further\nassist users in model selection, we quantify the capability boundary of\nDeepSeek models through performance tier classifications and intuitive line\ncharts. Specific examples provide actionable insights to help users select and\ndeploy the most cost-effective DeepSeek models, ensuring optimal performance\nand resource efficiency in real-world applications.'}","['Shiguo Lian', 'Kaikai Zhao', 'Xuejiao Lei', 'Ning Wang', 'Zhenhong Long', 'Peijun Yang', 'Minjie Hua', 'Chaoyang Ma', 'Wen Liu', 'Kai Wang', 'Zhaoxiang Liu']",{'name': 'Zhaoxiang Liu'},Zhaoxiang Liu,,"[{'href': 'http://arxiv.org/abs/2502.11164v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11164v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11164v1,None,http://arxiv.org/abs/2502.11164v1,,,131,0
http://arxiv.org/abs/2502.11168v1,True,2025-02-16T15:38:33Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=15, tm_min=38, tm_sec=33, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T15:38:33Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=15, tm_min=38, tm_sec=33, tm_wday=6, tm_yday=47, tm_isdst=0)","Knowing Your Target: Target-Aware Transformer Makes Better
  Spatio-Temporal Video Grounding","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Knowing Your Target: Target-Aware Transformer Makes Better\n  Spatio-Temporal Video Grounding'}","Transformer has attracted increasing interest in STVG, owing to its
end-to-end pipeline and promising result. Existing Transformer-based STVG
approaches often leverage a set of object queries, which are initialized simply
using zeros and then gradually learn target position information via iterative
interactions with multimodal features, for spatial and temporal localization.
Despite simplicity, these zero object queries, due to lacking target-specific
cues, are hard to learn discriminative target information from interactions
with multimodal features in complicated scenarios (\e.g., with distractors or
occlusion), resulting in degradation. Addressing this, we introduce a novel
Target-Aware Transformer for STVG (TA-STVG), which seeks to adaptively generate
object queries via exploring target-specific cues from the given video-text
pair, for improving STVG. The key lies in two simple yet effective modules,
comprising text-guided temporal sampling (TTS) and attribute-aware spatial
activation (ASA), working in a cascade. The former focuses on selecting
target-relevant temporal cues from a video utilizing holistic text information,
while the latter aims at further exploiting the fine-grained visual attribute
information of the object from previous target-aware temporal cues, which is
applied for object query initialization. Compared to existing methods
leveraging zero-initialized queries, object queries in our TA-STVG, directly
generated from a given video-text pair, naturally carry target-specific cues,
making them adaptive and better interact with multimodal features for learning
more discriminative information to improve STVG. In our experiments on three
benchmarks, TA-STVG achieves state-of-the-art performance and significantly
outperforms the baseline, validating its efficacy.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Transformer has attracted increasing interest in STVG, owing to its\nend-to-end pipeline and promising result. Existing Transformer-based STVG\napproaches often leverage a set of object queries, which are initialized simply\nusing zeros and then gradually learn target position information via iterative\ninteractions with multimodal features, for spatial and temporal localization.\nDespite simplicity, these zero object queries, due to lacking target-specific\ncues, are hard to learn discriminative target information from interactions\nwith multimodal features in complicated scenarios (\\e.g., with distractors or\nocclusion), resulting in degradation. Addressing this, we introduce a novel\nTarget-Aware Transformer for STVG (TA-STVG), which seeks to adaptively generate\nobject queries via exploring target-specific cues from the given video-text\npair, for improving STVG. The key lies in two simple yet effective modules,\ncomprising text-guided temporal sampling (TTS) and attribute-aware spatial\nactivation (ASA), working in a cascade. The former focuses on selecting\ntarget-relevant temporal cues from a video utilizing holistic text information,\nwhile the latter aims at further exploiting the fine-grained visual attribute\ninformation of the object from previous target-aware temporal cues, which is\napplied for object query initialization. Compared to existing methods\nleveraging zero-initialized queries, object queries in our TA-STVG, directly\ngenerated from a given video-text pair, naturally carry target-specific cues,\nmaking them adaptive and better interact with multimodal features for learning\nmore discriminative information to improve STVG. In our experiments on three\nbenchmarks, TA-STVG achieves state-of-the-art performance and significantly\noutperforms the baseline, validating its efficacy.'}","['Xin Gu', 'Yaojie Shen', 'Chenxi Luo', 'Tiejian Luo', 'Yan Huang', 'Yuewei Lin', 'Heng Fan', 'Libo Zhang']",{'name': 'Libo Zhang'},Libo Zhang,,"[{'href': 'http://arxiv.org/abs/2502.11168v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11168v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11168v1,None,http://arxiv.org/abs/2502.11168v1,,,85,0
http://arxiv.org/abs/2502.11179v1,True,2025-02-16T15:59:06Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=15, tm_min=59, tm_sec=6, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T15:59:06Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=15, tm_min=59, tm_sec=6, tm_wday=6, tm_yday=47, tm_isdst=0)","RT-DEMT: A hybrid real-time acupoint detection model combining mamba and
  transformer","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'RT-DEMT: A hybrid real-time acupoint detection model combining mamba and\n  transformer'}","Traditional Chinese acupuncture methods often face controversy in clinical
practice due to their high subjectivity. Additionally, current
intelligent-assisted acupuncture systems have two major limitations: slow
acupoint localization speed and low accuracy. To address these limitations, a
new method leverages the excellent inference efficiency of the state-space
model Mamba, while retaining the advantages of the attention mechanism in the
traditional DETR architecture, to achieve efficient global information
integration and provide high-quality feature information for acupoint
localization tasks. Furthermore, by employing the concept of residual
likelihood estimation, it eliminates the need for complex upsampling processes,
thereby accelerating the acupoint localization task. Our method achieved
state-of-the-art (SOTA) accuracy on a private dataset of acupoints on the human
back, with an average Euclidean distance pixel error (EPE) of 7.792 and an
average time consumption of 10.05 milliseconds per localization task. Compared
to the second-best algorithm, our method improved both accuracy and speed by
approximately 14\%. This significant advancement not only enhances the efficacy
of acupuncture treatment but also demonstrates the commercial potential of
automated acupuncture robot systems. Access to our method is available at
https://github.com/Sohyu1/RT-DEMT","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Traditional Chinese acupuncture methods often face controversy in clinical\npractice due to their high subjectivity. Additionally, current\nintelligent-assisted acupuncture systems have two major limitations: slow\nacupoint localization speed and low accuracy. To address these limitations, a\nnew method leverages the excellent inference efficiency of the state-space\nmodel Mamba, while retaining the advantages of the attention mechanism in the\ntraditional DETR architecture, to achieve efficient global information\nintegration and provide high-quality feature information for acupoint\nlocalization tasks. Furthermore, by employing the concept of residual\nlikelihood estimation, it eliminates the need for complex upsampling processes,\nthereby accelerating the acupoint localization task. Our method achieved\nstate-of-the-art (SOTA) accuracy on a private dataset of acupoints on the human\nback, with an average Euclidean distance pixel error (EPE) of 7.792 and an\naverage time consumption of 10.05 milliseconds per localization task. Compared\nto the second-best algorithm, our method improved both accuracy and speed by\napproximately 14\\%. This significant advancement not only enhances the efficacy\nof acupuncture treatment but also demonstrates the commercial potential of\nautomated acupuncture robot systems. Access to our method is available at\nhttps://github.com/Sohyu1/RT-DEMT'}","['Shilong Yang', 'Qi Zang', 'Chulong Zhang', 'Lingfeng Huang', 'Yaoqin Xie']",{'name': 'Yaoqin Xie'},Yaoqin Xie,"10 pages, 3 figures","[{'href': 'http://arxiv.org/abs/2502.11179v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11179v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11179v1,None,http://arxiv.org/abs/2502.11179v1,,,112,0
http://arxiv.org/abs/2502.11181v1,True,2025-02-16T15:59:50Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=15, tm_min=59, tm_sec=50, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T15:59:50Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=15, tm_min=59, tm_sec=50, tm_wday=6, tm_yday=47, tm_isdst=0)","Improving Scientific Document Retrieval with Concept Coverage-based
  Query Set Generation","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Improving Scientific Document Retrieval with Concept Coverage-based\n  Query Set Generation'}","In specialized fields like the scientific domain, constructing large-scale
human-annotated datasets poses a significant challenge due to the need for
domain expertise. Recent methods have employed large language models to
generate synthetic queries, which serve as proxies for actual user queries.
However, they lack control over the content generated, often resulting in
incomplete coverage of academic concepts in documents. We introduce Concept
Coverage-based Query set Generation (CCQGen) framework, designed to generate a
set of queries with comprehensive coverage of the document's concepts. A key
distinction of CCQGen is that it adaptively adjusts the generation process
based on the previously generated queries. We identify concepts not
sufficiently covered by previous queries, and leverage them as conditions for
subsequent query generation. This approach guides each new query to complement
the previous ones, aiding in a thorough understanding of the document.
Extensive experiments demonstrate that CCQGen significantly enhances query
quality and retrieval performance.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""In specialized fields like the scientific domain, constructing large-scale\nhuman-annotated datasets poses a significant challenge due to the need for\ndomain expertise. Recent methods have employed large language models to\ngenerate synthetic queries, which serve as proxies for actual user queries.\nHowever, they lack control over the content generated, often resulting in\nincomplete coverage of academic concepts in documents. We introduce Concept\nCoverage-based Query set Generation (CCQGen) framework, designed to generate a\nset of queries with comprehensive coverage of the document's concepts. A key\ndistinction of CCQGen is that it adaptively adjusts the generation process\nbased on the previously generated queries. We identify concepts not\nsufficiently covered by previous queries, and leverage them as conditions for\nsubsequent query generation. This approach guides each new query to complement\nthe previous ones, aiding in a thorough understanding of the document.\nExtensive experiments demonstrate that CCQGen significantly enhances query\nquality and retrieval performance.""}","['SeongKu Kang', 'Bowen Jin', 'Wonbin Kweon', 'Yu Zhang', 'Dongha Lee', 'Jiawei Han', 'Hwanjo Yu']",{'name': 'Hwanjo Yu'},Hwanjo Yu,WSDM 2025,"[{'href': 'http://arxiv.org/abs/2502.11181v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11181v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11181v1,None,http://arxiv.org/abs/2502.11181v1,,,2192,0
http://arxiv.org/abs/2502.11187v1,True,2025-02-16T16:22:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=16, tm_min=22, tm_sec=23, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T16:22:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=16, tm_min=22, tm_sec=23, tm_wday=6, tm_yday=47, tm_isdst=0)",TituLLMs: A Family of Bangla LLMs with Comprehensive Benchmarking,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'TituLLMs: A Family of Bangla LLMs with Comprehensive Benchmarking'}","In this paper, we present TituLLMs, the first large pretrained Bangla LLMs,
available in 1B and 3B parameter sizes. Due to computational constraints during
both training and inference, we focused on smaller models. To train TituLLMs,
we collected a pretraining dataset of approximately 37 billion tokens. We
extended the Llama-3.2 tokenizer to incorporate language- and culture-specific
knowledge, which also enables faster training and inference. There was a lack
of benchmarking datasets to evaluate LLMs for Bangla. To address this gap, we
developed five benchmarking datasets. We benchmarked various LLMs, including
TituLLMs, and demonstrated that TituLLMs outperforms its initial multilingual
versions. However, this is not always the case, highlighting the complexities
of language adaptation. Our work lays the groundwork for adapting existing
multilingual open models to other low-resource languages. To facilitate broader
adoption and further research, we have made the TituLLMs models and
benchmarking datasets publicly available
(https://huggingface.co/collections/hishab/titulm-llama-family-6718d31fc1b83529276f490a).","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'In this paper, we present TituLLMs, the first large pretrained Bangla LLMs,\navailable in 1B and 3B parameter sizes. Due to computational constraints during\nboth training and inference, we focused on smaller models. To train TituLLMs,\nwe collected a pretraining dataset of approximately 37 billion tokens. We\nextended the Llama-3.2 tokenizer to incorporate language- and culture-specific\nknowledge, which also enables faster training and inference. There was a lack\nof benchmarking datasets to evaluate LLMs for Bangla. To address this gap, we\ndeveloped five benchmarking datasets. We benchmarked various LLMs, including\nTituLLMs, and demonstrated that TituLLMs outperforms its initial multilingual\nversions. However, this is not always the case, highlighting the complexities\nof language adaptation. Our work lays the groundwork for adapting existing\nmultilingual open models to other low-resource languages. To facilitate broader\nadoption and further research, we have made the TituLLMs models and\nbenchmarking datasets publicly available\n(https://huggingface.co/collections/hishab/titulm-llama-family-6718d31fc1b83529276f490a).'}","['Shahriar Kabir Nahin', 'Rabindra Nath Nandi', 'Sagor Sarker', 'Quazi Sarwar Muhtaseem', 'Md Kowsher', 'Apu Chandraw Shill', 'Md Ibrahim', 'Mehadi Hasan Menon', 'Tareq Al Muntasir', 'Firoj Alam']",{'name': 'Firoj Alam'},Firoj Alam,"LLMs, Benchmarking, Large Language Models, Bangla","[{'href': 'http://arxiv.org/abs/2502.11187v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11187v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'F.2.2; I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11187v1,None,http://arxiv.org/abs/2502.11187v1,,,152,0
http://arxiv.org/abs/2502.11195v1,True,2025-02-16T16:55:28Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=16, tm_min=55, tm_sec=28, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T16:55:28Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=16, tm_min=55, tm_sec=28, tm_wday=6, tm_yday=47, tm_isdst=0)","From Deception to Perception: The Surprising Benefits of Deepfakes for
  Detecting, Measuring, and Mitigating Bias","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'From Deception to Perception: The Surprising Benefits of Deepfakes for\n  Detecting, Measuring, and Mitigating Bias'}","While deepfake technologies have predominantly been criticized for potential
misuse, our study demonstrates their significant potential as tools for
detecting, measuring, and mitigating biases in key societal domains. By
employing deepfake technology to generate controlled facial images, we extend
the scope of traditional correspondence studies beyond mere textual
manipulations. This enhancement is crucial in scenarios such as pain
assessments, where subjective biases triggered by sensitive features in facial
images can profoundly affect outcomes. Our results reveal that deepfakes not
only maintain the effectiveness of correspondence studies but also introduce
groundbreaking advancements in bias measurement and correction techniques. This
study emphasizes the constructive role of deepfake technologies as essential
tools for advancing societal equity and fairness.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'While deepfake technologies have predominantly been criticized for potential\nmisuse, our study demonstrates their significant potential as tools for\ndetecting, measuring, and mitigating biases in key societal domains. By\nemploying deepfake technology to generate controlled facial images, we extend\nthe scope of traditional correspondence studies beyond mere textual\nmanipulations. This enhancement is crucial in scenarios such as pain\nassessments, where subjective biases triggered by sensitive features in facial\nimages can profoundly affect outcomes. Our results reveal that deepfakes not\nonly maintain the effectiveness of correspondence studies but also introduce\ngroundbreaking advancements in bias measurement and correction techniques. This\nstudy emphasizes the constructive role of deepfake technologies as essential\ntools for advancing societal equity and fairness.'}","['Yizhi Liu', 'Balaji Padmanabhan', 'Siva Viswanathan']",{'name': 'Siva Viswanathan'},Siva Viswanathan,,"[{'href': 'http://arxiv.org/abs/2502.11195v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11195v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.0; I.2.10; I.4.0; J.4; H.4; K.4.1; K.4.2', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11195v1,None,http://arxiv.org/abs/2502.11195v1,,,0,0
http://arxiv.org/abs/2502.11201v2,True,2025-02-18T06:48:28Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=6, tm_min=48, tm_sec=28, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-16T17:01:48Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=17, tm_min=1, tm_sec=48, tm_wday=6, tm_yday=47, tm_isdst=0)","Bridging the Gap: Enabling Natural Language Queries for NoSQL Databases
  through Text-to-NoSQL Translation","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Bridging the Gap: Enabling Natural Language Queries for NoSQL Databases\n  through Text-to-NoSQL Translation'}","NoSQL databases have become increasingly popular due to their outstanding
performance in handling large-scale, unstructured, and semi-structured data,
highlighting the need for user-friendly interfaces to bridge the gap between
non-technical users and complex database queries. In this paper, we introduce
the Text-to-NoSQL task, which aims to convert natural language queries into
NoSQL queries, thereby lowering the technical barrier for non-expert users. To
promote research in this area, we developed a novel automated dataset
construction process and released a large-scale and open-source dataset for
this task, named TEND (short for Text-to-NoSQL Dataset). Additionally, we
designed a SLM (Small Language Model)-assisted and RAG (Retrieval-augmented
Generation)-assisted multi-step framework called SMART, which is specifically
designed for Text-to-NoSQL conversion. To ensure comprehensive evaluation of
the models, we also introduced a detailed set of metrics that assess the
model's performance from both the query itself and its execution results. Our
experimental results demonstrate the effectiveness of our approach and
establish a benchmark for future research in this emerging field. We believe
that our contributions will pave the way for more accessible and intuitive
interactions with NoSQL databases.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""NoSQL databases have become increasingly popular due to their outstanding\nperformance in handling large-scale, unstructured, and semi-structured data,\nhighlighting the need for user-friendly interfaces to bridge the gap between\nnon-technical users and complex database queries. In this paper, we introduce\nthe Text-to-NoSQL task, which aims to convert natural language queries into\nNoSQL queries, thereby lowering the technical barrier for non-expert users. To\npromote research in this area, we developed a novel automated dataset\nconstruction process and released a large-scale and open-source dataset for\nthis task, named TEND (short for Text-to-NoSQL Dataset). Additionally, we\ndesigned a SLM (Small Language Model)-assisted and RAG (Retrieval-augmented\nGeneration)-assisted multi-step framework called SMART, which is specifically\ndesigned for Text-to-NoSQL conversion. To ensure comprehensive evaluation of\nthe models, we also introduced a detailed set of metrics that assess the\nmodel's performance from both the query itself and its execution results. Our\nexperimental results demonstrate the effectiveness of our approach and\nestablish a benchmark for future research in this emerging field. We believe\nthat our contributions will pave the way for more accessible and intuitive\ninteractions with NoSQL databases.""}","['Jinwei Lu', 'Yuanfeng Song', 'Zhiqian Qin', 'Haodi Zhang', 'Chen Zhang', 'Raymond Chi-Wing Wong']",{'name': 'Raymond Chi-Wing Wong'},Raymond Chi-Wing Wong,,"[{'href': 'http://arxiv.org/abs/2502.11201v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11201v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.DB', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.DB', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11201v2,None,http://arxiv.org/abs/2502.11201v2,,,0,0
http://arxiv.org/abs/2502.11221v1,True,2025-02-16T17:54:57Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=17, tm_min=54, tm_sec=57, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T17:54:57Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=17, tm_min=54, tm_sec=57, tm_wday=6, tm_yday=47, tm_isdst=0)",PlanGenLLMs: A Modern Survey of LLM Planning Capabilities,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'PlanGenLLMs: A Modern Survey of LLM Planning Capabilities'}","LLMs have immense potential for generating plans, transforming an initial
world state into a desired goal state. A large body of research has explored
the use of LLMs for various planning tasks, from web navigation to travel
planning and database querying. However, many of these systems are tailored to
specific problems, making it challenging to compare them or determine the best
approach for new tasks. There is also a lack of clear and consistent evaluation
criteria. Our survey aims to offer a comprehensive overview of current LLM
planners to fill this gap. It builds on foundational work by Kartam and Wilkins
(1990) and examines six key performance criteria: completeness, executability,
optimality, representation, generalization, and efficiency. For each, we
provide a thorough analysis of representative works and highlight their
strengths and weaknesses. Our paper also identifies crucial future directions,
making it a valuable resource for both practitioners and newcomers interested
in leveraging LLM planning to support agentic workflows.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'LLMs have immense potential for generating plans, transforming an initial\nworld state into a desired goal state. A large body of research has explored\nthe use of LLMs for various planning tasks, from web navigation to travel\nplanning and database querying. However, many of these systems are tailored to\nspecific problems, making it challenging to compare them or determine the best\napproach for new tasks. There is also a lack of clear and consistent evaluation\ncriteria. Our survey aims to offer a comprehensive overview of current LLM\nplanners to fill this gap. It builds on foundational work by Kartam and Wilkins\n(1990) and examines six key performance criteria: completeness, executability,\noptimality, representation, generalization, and efficiency. For each, we\nprovide a thorough analysis of representative works and highlight their\nstrengths and weaknesses. Our paper also identifies crucial future directions,\nmaking it a valuable resource for both practitioners and newcomers interested\nin leveraging LLM planning to support agentic workflows.'}","['Hui Wei', 'Zihao Zhang', 'Shenghua He', 'Tian Xia', 'Shijia Pan', 'Fei Liu']",{'name': 'Fei Liu'},Fei Liu,Preprint. Under review,"[{'href': 'http://arxiv.org/abs/2502.11221v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11221v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11221v1,None,http://arxiv.org/abs/2502.11221v1,,,12,0
http://arxiv.org/abs/2502.11225v1,True,2025-02-16T18:24:44Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=18, tm_min=24, tm_sec=44, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T18:24:44Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=18, tm_min=24, tm_sec=44, tm_wday=6, tm_yday=47, tm_isdst=0)","METAFOR: A Hybrid Metaheuristics Software Framework for Single-Objective
  Continuous Optimization Problems","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'METAFOR: A Hybrid Metaheuristics Software Framework for Single-Objective\n  Continuous Optimization Problems'}","Hybrid metaheuristics are powerful techniques for solving difficult
optimization problems that exploit the strengths of different approaches in a
single implementation. For algorithm designers, however, creating hybrid
metaheuristic implementations has become increasingly challenging due to the
vast number of design options available in the literature and the fact that
they often rely on their knowledge and intuition to come up with new algorithm
designs. In this paper, we propose a modular metaheuristic software framework,
called METAFOR, that can be coupled with an automatic algorithm configuration
tool to automatically design hybrid metaheuristics. METAFOR is specifically
designed to hybridize Particle Swarm Optimization, Differential Evolution and
Covariance Matrix Adaptation-Evolution Strategy, and includes a local search
module that allows their execution to be interleaved with a subordinate local
search. We use the configuration tool irace to automatically generate 17
different metaheuristic implementations and evaluate their performance on a
diverse set of continuous optimization problems. Our results show that, across
all the considered problem classes, automatically generated hybrid
implementations are able to outperform configured single-approach
implementations, while these latter offer advantages on specific classes of
functions. We provide useful insights on the type of hybridization that works
best for specific problem classes, the algorithm components that contribute to
the performance of the algorithms, and the advantages and disadvantages of two
well-known instance separation strategies, creating stratified training set
using a fix percentage and leave-one-class-out cross-validation.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Hybrid metaheuristics are powerful techniques for solving difficult\noptimization problems that exploit the strengths of different approaches in a\nsingle implementation. For algorithm designers, however, creating hybrid\nmetaheuristic implementations has become increasingly challenging due to the\nvast number of design options available in the literature and the fact that\nthey often rely on their knowledge and intuition to come up with new algorithm\ndesigns. In this paper, we propose a modular metaheuristic software framework,\ncalled METAFOR, that can be coupled with an automatic algorithm configuration\ntool to automatically design hybrid metaheuristics. METAFOR is specifically\ndesigned to hybridize Particle Swarm Optimization, Differential Evolution and\nCovariance Matrix Adaptation-Evolution Strategy, and includes a local search\nmodule that allows their execution to be interleaved with a subordinate local\nsearch. We use the configuration tool irace to automatically generate 17\ndifferent metaheuristic implementations and evaluate their performance on a\ndiverse set of continuous optimization problems. Our results show that, across\nall the considered problem classes, automatically generated hybrid\nimplementations are able to outperform configured single-approach\nimplementations, while these latter offer advantages on specific classes of\nfunctions. We provide useful insights on the type of hybridization that works\nbest for specific problem classes, the algorithm components that contribute to\nthe performance of the algorithms, and the advantages and disadvantages of two\nwell-known instance separation strategies, creating stratified training set\nusing a fix percentage and leave-one-class-out cross-validation.'}","['Christian Camacho-Villaln', 'Marco Dorigo', 'Thomas Sttzle']",{'name': 'Thomas Sttzle'},Thomas Sttzle,,"[{'href': 'http://arxiv.org/abs/2502.11225v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11225v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11225v1,None,http://arxiv.org/abs/2502.11225v1,,,3106,0
http://arxiv.org/abs/2502.11228v1,True,2025-02-16T18:46:10Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=18, tm_min=46, tm_sec=10, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T18:46:10Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=18, tm_min=46, tm_sec=10, tm_wday=6, tm_yday=47, tm_isdst=0)","Vendi-RAG: Adaptively Trading-Off Diversity And Quality Significantly
  Improves Retrieval Augmented Generation With LLMs","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Vendi-RAG: Adaptively Trading-Off Diversity And Quality Significantly\n  Improves Retrieval Augmented Generation With LLMs'}","Retrieval-augmented generation (RAG) enhances large language models (LLMs)
for domain-specific question-answering (QA) tasks by leveraging external
knowledge sources. However, traditional RAG systems primarily focus on
relevance-based retrieval and often struggle with redundancy, especially when
reasoning requires connecting information from multiple sources. This paper
introduces Vendi-RAG, a framework based on an iterative process that jointly
optimizes retrieval diversity and answer quality. This joint optimization leads
to significantly higher accuracy for multi-hop QA tasks. Vendi-RAG leverages
the Vendi Score (VS), a flexible similarity-based diversity metric, to promote
semantic diversity in document retrieval. It then uses an LLM judge that
evaluates candidate answers, generated after a reasoning step, and outputs a
score that the retriever uses to balance relevance and diversity among the
retrieved documents during each iteration. Experiments on three challenging
datasets -- HotpotQA, MuSiQue, and 2WikiMultiHopQA -- demonstrate Vendi-RAG's
effectiveness in multi-hop reasoning tasks. The framework achieves significant
accuracy improvements over traditional single-step and multi-step RAG
approaches, with accuracy increases reaching up to +4.2% on HotpotQA, +4.1% on
2WikiMultiHopQA, and +1.3% on MuSiQue compared to Adaptive-RAG, the current
best baseline. The benefits of Vendi-RAG are even more pronounced as the number
of retrieved documents increases. Finally, we evaluated Vendi-RAG across
different LLM backbones, including GPT-3.5, GPT-4, and GPT-4o-mini, and
observed consistent improvements, demonstrating that the framework's advantages
are model-agnostic.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Retrieval-augmented generation (RAG) enhances large language models (LLMs)\nfor domain-specific question-answering (QA) tasks by leveraging external\nknowledge sources. However, traditional RAG systems primarily focus on\nrelevance-based retrieval and often struggle with redundancy, especially when\nreasoning requires connecting information from multiple sources. This paper\nintroduces Vendi-RAG, a framework based on an iterative process that jointly\noptimizes retrieval diversity and answer quality. This joint optimization leads\nto significantly higher accuracy for multi-hop QA tasks. Vendi-RAG leverages\nthe Vendi Score (VS), a flexible similarity-based diversity metric, to promote\nsemantic diversity in document retrieval. It then uses an LLM judge that\nevaluates candidate answers, generated after a reasoning step, and outputs a\nscore that the retriever uses to balance relevance and diversity among the\nretrieved documents during each iteration. Experiments on three challenging\ndatasets -- HotpotQA, MuSiQue, and 2WikiMultiHopQA -- demonstrate Vendi-RAG's\neffectiveness in multi-hop reasoning tasks. The framework achieves significant\naccuracy improvements over traditional single-step and multi-step RAG\napproaches, with accuracy increases reaching up to +4.2% on HotpotQA, +4.1% on\n2WikiMultiHopQA, and +1.3% on MuSiQue compared to Adaptive-RAG, the current\nbest baseline. The benefits of Vendi-RAG are even more pronounced as the number\nof retrieved documents increases. Finally, we evaluated Vendi-RAG across\ndifferent LLM backbones, including GPT-3.5, GPT-4, and GPT-4o-mini, and\nobserved consistent improvements, demonstrating that the framework's advantages\nare model-agnostic.""}","['Mohammad Reza Rezaei', 'Adji Bousso Dieng']",{'name': 'Adji Bousso Dieng'},Adji Bousso Dieng,"A RAG pipeline that accounts for both diversity and answer quality
  and that can be used with any LLM backbone to solve complex multi-hop
  question-answering tasks","[{'href': 'http://arxiv.org/abs/2502.11228v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11228v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11228v1,None,http://arxiv.org/abs/2502.11228v1,,,97,0
http://arxiv.org/abs/2502.11244v1,True,2025-02-16T19:44:01Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=19, tm_min=44, tm_sec=1, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T19:44:01Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=19, tm_min=44, tm_sec=1, tm_wday=6, tm_yday=47, tm_isdst=0)","Soteria: Language-Specific Functional Parameter Steering for
  Multilingual Safety Alignment","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Soteria: Language-Specific Functional Parameter Steering for\n  Multilingual Safety Alignment'}","Ensuring consistent safety across multiple languages remains a significant
challenge for large language models (LLMs). We introduce Soteria, a lightweight
yet powerful strategy that locates and minimally adjusts the ""functional heads""
most responsible for harmful content generation in each language. By altering
only a fraction of parameters, Soteria drastically reduces policy violations
without sacrificing overall model performance, even in low-resource settings.
To rigorously evaluate our approach, we also present XThreatBench, a
specialized multilingual dataset capturing fine-grained harmful behaviors drawn
from real policy guidelines. Experiments with leading open-source LLMs (e.g.,
Llama, Qwen, Mistral) show that Soteria consistently improves safety metrics
across high-, mid-, and low-resource languages. These findings highlight a
promising path toward scalable, linguistically attuned, and ethically aligned
LLMs worldwide.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Ensuring consistent safety across multiple languages remains a significant\nchallenge for large language models (LLMs). We introduce Soteria, a lightweight\nyet powerful strategy that locates and minimally adjusts the ""functional heads""\nmost responsible for harmful content generation in each language. By altering\nonly a fraction of parameters, Soteria drastically reduces policy violations\nwithout sacrificing overall model performance, even in low-resource settings.\nTo rigorously evaluate our approach, we also present XThreatBench, a\nspecialized multilingual dataset capturing fine-grained harmful behaviors drawn\nfrom real policy guidelines. Experiments with leading open-source LLMs (e.g.,\nLlama, Qwen, Mistral) show that Soteria consistently improves safety metrics\nacross high-, mid-, and low-resource languages. These findings highlight a\npromising path toward scalable, linguistically attuned, and ethically aligned\nLLMs worldwide.'}","['Somnath Banerjee', 'Sayan Layek', 'Pratyush Chatterjee', 'Animesh Mukherjee', 'Rima Hazra']",{'name': 'Rima Hazra'},Rima Hazra,,"[{'href': 'http://arxiv.org/abs/2502.11244v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11244v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11244v1,None,http://arxiv.org/abs/2502.11244v1,,,73,0
http://arxiv.org/abs/2502.11245v1,True,2025-02-16T19:45:09Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=19, tm_min=45, tm_sec=9, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T19:45:09Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=19, tm_min=45, tm_sec=9, tm_wday=6, tm_yday=47, tm_isdst=0)","Shortcuts and Identifiability in Concept-based Models from a
  Neuro-Symbolic Lens","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Shortcuts and Identifiability in Concept-based Models from a\n  Neuro-Symbolic Lens'}","Concept-based Models are neural networks that learn a concept extractor to
map inputs to high-level concepts and an inference layer to translate these
into predictions. Ensuring these modules produce interpretable concepts and
behave reliably in out-of-distribution is crucial, yet the conditions for
achieving this remain unclear. We study this problem by establishing a novel
connection between Concept-based Models and reasoning shortcuts (RSs), a common
issue where models achieve high accuracy by learning low-quality concepts, even
when the inference layer is fixed and provided upfront. Specifically, we first
extend RSs to the more complex setting of Concept-based Models and then derive
theoretical conditions for identifying both the concepts and the inference
layer. Our empirical results highlight the impact of reasoning shortcuts and
show that existing methods, even when combined with multiple natural mitigation
strategies, often fail to meet these conditions in practice.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Concept-based Models are neural networks that learn a concept extractor to\nmap inputs to high-level concepts and an inference layer to translate these\ninto predictions. Ensuring these modules produce interpretable concepts and\nbehave reliably in out-of-distribution is crucial, yet the conditions for\nachieving this remain unclear. We study this problem by establishing a novel\nconnection between Concept-based Models and reasoning shortcuts (RSs), a common\nissue where models achieve high accuracy by learning low-quality concepts, even\nwhen the inference layer is fixed and provided upfront. Specifically, we first\nextend RSs to the more complex setting of Concept-based Models and then derive\ntheoretical conditions for identifying both the concepts and the inference\nlayer. Our empirical results highlight the impact of reasoning shortcuts and\nshow that existing methods, even when combined with multiple natural mitigation\nstrategies, often fail to meet these conditions in practice.'}","['Samuele Bortolotti', 'Emanuele Marconato', 'Paolo Morettin', 'Andrea Passerini', 'Stefano Teso']",{'name': 'Stefano Teso'},Stefano Teso,,"[{'href': 'http://arxiv.org/abs/2502.11245v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11245v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11245v1,None,http://arxiv.org/abs/2502.11245v1,,,1765,0
http://arxiv.org/abs/2502.11262v1,True,2025-02-16T20:33:59Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=20, tm_min=33, tm_sec=59, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T20:33:59Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=20, tm_min=33, tm_sec=59, tm_wday=6, tm_yday=47, tm_isdst=0)",Generating Skyline Datasets for Data Science Models,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Generating Skyline Datasets for Data Science Models'}","Preparing high-quality datasets required by various data-driven AI and
machine learning models has become a cornerstone task in data-driven analysis.
Conventional data discovery methods typically integrate datasets towards a
single pre-defined quality measure that may lead to bias for downstream tasks.
This paper introduces MODis, a framework that discovers datasets by optimizing
multiple user-defined, model-performance measures. Given a set of data sources
and a model, MODis selects and integrates data sources into a skyline dataset,
over which the model is expected to have the desired performance in all the
performance measures. We formulate MODis as a multi-goal finite state
transducer, and derive three feasible algorithms to generate skyline datasets.
Our first algorithm adopts a ""reduce-from-universal"" strategy, that starts with
a universal schema and iteratively prunes unpromising data. Our second
algorithm further reduces the cost with a bi-directional strategy that
interleaves data augmentation and reduction. We also introduce a
diversification algorithm to mitigate the bias in skyline datasets. We
experimentally verify the efficiency and effectiveness of our skyline data
discovery algorithms, and showcase their applications in optimizing data
science pipelines.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Preparing high-quality datasets required by various data-driven AI and\nmachine learning models has become a cornerstone task in data-driven analysis.\nConventional data discovery methods typically integrate datasets towards a\nsingle pre-defined quality measure that may lead to bias for downstream tasks.\nThis paper introduces MODis, a framework that discovers datasets by optimizing\nmultiple user-defined, model-performance measures. Given a set of data sources\nand a model, MODis selects and integrates data sources into a skyline dataset,\nover which the model is expected to have the desired performance in all the\nperformance measures. We formulate MODis as a multi-goal finite state\ntransducer, and derive three feasible algorithms to generate skyline datasets.\nOur first algorithm adopts a ""reduce-from-universal"" strategy, that starts with\na universal schema and iteratively prunes unpromising data. Our second\nalgorithm further reduces the cost with a bi-directional strategy that\ninterleaves data augmentation and reduction. We also introduce a\ndiversification algorithm to mitigate the bias in skyline datasets. We\nexperimentally verify the efficiency and effectiveness of our skyline data\ndiscovery algorithms, and showcase their applications in optimizing data\nscience pipelines.'}","['Mengying Wang', 'Hanchao Ma', 'Yiyang Bian', 'Yangxin Fan', 'Yinghui Wu']",{'name': 'Yinghui Wu'},Yinghui Wu,EDBT25,"[{'href': 'http://arxiv.org/abs/2502.11262v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11262v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.DB', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.DB', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11262v1,None,http://arxiv.org/abs/2502.11262v1,,,188,0
http://arxiv.org/abs/2502.11295v1,True,2025-02-16T22:34:59Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=22, tm_min=34, tm_sec=59, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T22:34:59Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=22, tm_min=34, tm_sec=59, tm_wday=6, tm_yday=47, tm_isdst=0)",Game-Of-Goals: Using adversarial games to achieve strategic resilience,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Game-Of-Goals: Using adversarial games to achieve strategic resilience'}","Our objective in this paper is to develop a machinery that makes a given
organizational strategic plan resilient to the actions of competitor agents
(adverse environmental actions). We assume that we are given a goal tree
representing strategic goals (can also be seen business requirements for a
software systems) with the assumption that competitor agents are behaving in a
maximally adversarial fashion(opposing actions against our sub goals or goals
in general). We use game tree search methods (such as minimax) to select an
optimal execution strategy(at a given point in time), such that it can maximize
our chances of achieving our (high level) strategic goals. Our machinery helps
us determine which path to follow(strategy selection) to achieve the best end
outcome. This is done by comparing alternative execution strategies available
to us via an evaluation function. Our evaluation function is based on the idea
that we want to make our execution plans defensible(future-proof) by selecting
execution strategies that make us least vulnerable to adversarial actions by
the competitor agents. i.e we want to select an execution strategy such that
its leaves minimum room(or options) for the adversary to cause
impediment/damage to our business goals/plans.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Our objective in this paper is to develop a machinery that makes a given\norganizational strategic plan resilient to the actions of competitor agents\n(adverse environmental actions). We assume that we are given a goal tree\nrepresenting strategic goals (can also be seen business requirements for a\nsoftware systems) with the assumption that competitor agents are behaving in a\nmaximally adversarial fashion(opposing actions against our sub goals or goals\nin general). We use game tree search methods (such as minimax) to select an\noptimal execution strategy(at a given point in time), such that it can maximize\nour chances of achieving our (high level) strategic goals. Our machinery helps\nus determine which path to follow(strategy selection) to achieve the best end\noutcome. This is done by comparing alternative execution strategies available\nto us via an evaluation function. Our evaluation function is based on the idea\nthat we want to make our execution plans defensible(future-proof) by selecting\nexecution strategies that make us least vulnerable to adversarial actions by\nthe competitor agents. i.e we want to select an execution strategy such that\nits leaves minimum room(or options) for the adversary to cause\nimpediment/damage to our business goals/plans.'}","['Aditya Ghose', 'Asjad Khan']",{'name': 'Asjad Khan'},Asjad Khan,,"[{'href': 'http://arxiv.org/abs/2502.11295v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11295v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11295v1,None,http://arxiv.org/abs/2502.11295v1,,,0,0
http://arxiv.org/abs/2502.11307v1,True,2025-02-16T23:10:57Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=23, tm_min=10, tm_sec=57, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T23:10:57Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=23, tm_min=10, tm_sec=57, tm_wday=6, tm_yday=47, tm_isdst=0)","Exploiting Point-Language Models with Dual-Prompts for 3D Anomaly
  Detection","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Exploiting Point-Language Models with Dual-Prompts for 3D Anomaly\n  Detection'}","Anomaly detection (AD) in 3D point clouds is crucial in a wide range of
industrial applications, especially in various forms of precision
manufacturing. Considering the industrial demand for reliable 3D AD, several
methods have been developed. However, most of these approaches typically
require training separate models for each category, which is memory-intensive
and lacks flexibility. In this paper, we propose a novel Point-Language model
with dual-prompts for 3D ANomaly dEtection (PLANE). The approach leverages
multi-modal prompts to extend the strong generalization capabilities of
pre-trained Point-Language Models (PLMs) to the domain of 3D point cloud AD,
achieving impressive detection performance across multiple categories using a
single model. Specifically, we propose a dual-prompt learning method,
incorporating both text and point cloud prompts. The method utilizes a dynamic
prompt creator module (DPCM) to produce sample-specific dynamic prompts, which
are then integrated with class-specific static prompts for each modality,
effectively driving the PLMs. Additionally, based on the characteristics of
point cloud data, we propose a pseudo 3D anomaly generation method (Ano3D) to
improve the model's detection capabilities in an unsupervised setting.
Experimental results demonstrate that the proposed method, which is under the
multi-class-one-model paradigm, achieves a +8.7%/+17% gain on anomaly detection
and localization performance as compared to the state-of-the-art
one-class-one-model methods for the Anomaly-ShapeNet dataset, and obtains
+4.3%/+4.1% gain for the Real3D-AD dataset. Code will be available upon
publication.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Anomaly detection (AD) in 3D point clouds is crucial in a wide range of\nindustrial applications, especially in various forms of precision\nmanufacturing. Considering the industrial demand for reliable 3D AD, several\nmethods have been developed. However, most of these approaches typically\nrequire training separate models for each category, which is memory-intensive\nand lacks flexibility. In this paper, we propose a novel Point-Language model\nwith dual-prompts for 3D ANomaly dEtection (PLANE). The approach leverages\nmulti-modal prompts to extend the strong generalization capabilities of\npre-trained Point-Language Models (PLMs) to the domain of 3D point cloud AD,\nachieving impressive detection performance across multiple categories using a\nsingle model. Specifically, we propose a dual-prompt learning method,\nincorporating both text and point cloud prompts. The method utilizes a dynamic\nprompt creator module (DPCM) to produce sample-specific dynamic prompts, which\nare then integrated with class-specific static prompts for each modality,\neffectively driving the PLMs. Additionally, based on the characteristics of\npoint cloud data, we propose a pseudo 3D anomaly generation method (Ano3D) to\nimprove the model's detection capabilities in an unsupervised setting.\nExperimental results demonstrate that the proposed method, which is under the\nmulti-class-one-model paradigm, achieves a +8.7%/+17% gain on anomaly detection\nand localization performance as compared to the state-of-the-art\none-class-one-model methods for the Anomaly-ShapeNet dataset, and obtains\n+4.3%/+4.1% gain for the Real3D-AD dataset. Code will be available upon\npublication.""}","['Jiaxiang Wang', 'Haote Xu', 'Xiaolu Chen', 'Haodi Xu', 'Yue Huang', 'Xinghao Ding', 'Xiaotong Tu']",{'name': 'Xiaotong Tu'},Xiaotong Tu,"10 pages, 7 figures","[{'href': 'http://arxiv.org/abs/2502.11307v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11307v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11307v1,None,http://arxiv.org/abs/2502.11307v1,,,9487,0
http://arxiv.org/abs/2502.11330v1,True,2025-02-17T01:05:31Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=1, tm_min=5, tm_sec=31, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T01:05:31Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=1, tm_min=5, tm_sec=31, tm_wday=0, tm_yday=48, tm_isdst=0)",System Message Generation for User Preferences using Open-Source Models,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'System Message Generation for User Preferences using Open-Source Models'}","System messages play a crucial role in interactions with large language
models (LLMs), often serving as prompts to initiate conversations. Through
system messages, users can assign specific roles, perform intended tasks,
incorporate background information, specify various output formats and
communication styles. Despite such versatility, publicly available data are
often lack system messages and subject to strict license constraints in the
industry field. Manual labeling of publicly available data with system messages
that align with user instructions demands significant resources. In view of
such challenges, our work introduces SysGen, a pipeline for generating system
messages with better aligned assistant responses from the supervised
fine-tuning dataset without system messages. Training on SysGen data has
demonstrated substantial improvements in the alignment of model responses with
system messages and user instructions, as demonstrated across various
open-source models on the Multifacet benchmark, while maintaining minimal
impact on other unseen benchmarks such as Open LLM Leaderboard 2. Our
qualitative analysis highlights the importance of diverse system messages to
ensure better adaptability across different contexts.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'System messages play a crucial role in interactions with large language\nmodels (LLMs), often serving as prompts to initiate conversations. Through\nsystem messages, users can assign specific roles, perform intended tasks,\nincorporate background information, specify various output formats and\ncommunication styles. Despite such versatility, publicly available data are\noften lack system messages and subject to strict license constraints in the\nindustry field. Manual labeling of publicly available data with system messages\nthat align with user instructions demands significant resources. In view of\nsuch challenges, our work introduces SysGen, a pipeline for generating system\nmessages with better aligned assistant responses from the supervised\nfine-tuning dataset without system messages. Training on SysGen data has\ndemonstrated substantial improvements in the alignment of model responses with\nsystem messages and user instructions, as demonstrated across various\nopen-source models on the Multifacet benchmark, while maintaining minimal\nimpact on other unseen benchmarks such as Open LLM Leaderboard 2. Our\nqualitative analysis highlights the importance of diverse system messages to\nensure better adaptability across different contexts.'}","['Minbyul Jeong', 'Jungho Cho', 'Minsoo Khang', 'Dawoon Jung', 'Teakgyu Hong']",{'name': 'Teakgyu Hong'},Teakgyu Hong,,"[{'href': 'http://arxiv.org/abs/2502.11330v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11330v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11330v1,None,http://arxiv.org/abs/2502.11330v1,,,381,0
http://arxiv.org/abs/2502.11333v1,True,2025-02-17T01:11:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=1, tm_min=11, tm_sec=42, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T01:11:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=1, tm_min=11, tm_sec=42, tm_wday=0, tm_yday=48, tm_isdst=0)",Inverse Flow and Consistency Models,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Inverse Flow and Consistency Models'}","Inverse generation problems, such as denoising without ground truth
observations, is a critical challenge in many scientific inquiries and
real-world applications. While recent advances in generative models like
diffusion models, conditional flow matching, and consistency models achieved
impressive results by casting generation as denoising problems, they cannot be
directly used for inverse generation without access to clean data. Here we
introduce Inverse Flow (IF), a novel framework that enables using these
generative models for inverse generation problems including denoising without
ground truth. Inverse Flow can be flexibly applied to nearly any continuous
noise distribution and allows complex dependencies. We propose two algorithms
for learning Inverse Flows, Inverse Flow Matching (IFM) and Inverse Consistency
Model (ICM). Notably, to derive the computationally efficient, simulation-free
inverse consistency model objective, we generalized consistency training to any
forward diffusion processes or conditional flows, which have applications
beyond denoising. We demonstrate the effectiveness of IF on synthetic and real
datasets, outperforming prior approaches while enabling noise distributions
that previous methods cannot support. Finally, we showcase applications of our
techniques to fluorescence microscopy and single-cell genomics data,
highlighting IF's utility in scientific problems. Overall, this work expands
the applications of powerful generative models to inversion generation
problems.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Inverse generation problems, such as denoising without ground truth\nobservations, is a critical challenge in many scientific inquiries and\nreal-world applications. While recent advances in generative models like\ndiffusion models, conditional flow matching, and consistency models achieved\nimpressive results by casting generation as denoising problems, they cannot be\ndirectly used for inverse generation without access to clean data. Here we\nintroduce Inverse Flow (IF), a novel framework that enables using these\ngenerative models for inverse generation problems including denoising without\nground truth. Inverse Flow can be flexibly applied to nearly any continuous\nnoise distribution and allows complex dependencies. We propose two algorithms\nfor learning Inverse Flows, Inverse Flow Matching (IFM) and Inverse Consistency\nModel (ICM). Notably, to derive the computationally efficient, simulation-free\ninverse consistency model objective, we generalized consistency training to any\nforward diffusion processes or conditional flows, which have applications\nbeyond denoising. We demonstrate the effectiveness of IF on synthetic and real\ndatasets, outperforming prior approaches while enabling noise distributions\nthat previous methods cannot support. Finally, we showcase applications of our\ntechniques to fluorescence microscopy and single-cell genomics data,\nhighlighting IF's utility in scientific problems. Overall, this work expands\nthe applications of powerful generative models to inversion generation\nproblems.""}","['Yuchen Zhang', 'Jian Zhou']",{'name': 'Jian Zhou'},Jian Zhou,,"[{'href': 'http://arxiv.org/abs/2502.11333v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11333v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11333v1,None,http://arxiv.org/abs/2502.11333v1,,,0,0
http://arxiv.org/abs/2502.11357v2,True,2025-02-19T01:38:06Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=1, tm_min=38, tm_sec=6, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-17T02:13:48Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=2, tm_min=13, tm_sec=48, tm_wday=0, tm_yday=48, tm_isdst=0)","Explorer: Scaling Exploration-driven Web Trajectory Synthesis for
  Multimodal Web Agents","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Explorer: Scaling Exploration-driven Web Trajectory Synthesis for\n  Multimodal Web Agents'}","Recent success in large multimodal models (LMMs) has sparked promising
applications of agents capable of autonomously completing complex web tasks.
While open-source LMM agents have made significant advances in offline
evaluation benchmarks, their performance still falls substantially short of
human-level capabilities in more realistic online settings. A key bottleneck is
the lack of diverse and large-scale trajectory-level datasets across various
domains, which are expensive to collect. In this paper, we address this
challenge by developing a scalable recipe to synthesize the largest and most
diverse trajectory-level dataset to date, containing over 94K successful
multimodal web trajectories, spanning 49K unique URLs, 720K screenshots, and
33M web elements. In particular, we leverage extensive web exploration and
refinement to obtain diverse task intents. The average cost is 28 cents per
successful trajectory, making it affordable to a wide range of users in the
community. Leveraging this dataset, we train Explorer, a multimodal web agent,
and demonstrate strong performance on both offline and online web agent
benchmarks such as Mind2Web-Live, Multimodal-Mind2Web, and MiniWob++.
Additionally, our experiments highlight data scaling as a key driver for
improving web agent capabilities. We hope this study makes state-of-the-art
LMM-based agent research at a larger scale more accessible.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Recent success in large multimodal models (LMMs) has sparked promising\napplications of agents capable of autonomously completing complex web tasks.\nWhile open-source LMM agents have made significant advances in offline\nevaluation benchmarks, their performance still falls substantially short of\nhuman-level capabilities in more realistic online settings. A key bottleneck is\nthe lack of diverse and large-scale trajectory-level datasets across various\ndomains, which are expensive to collect. In this paper, we address this\nchallenge by developing a scalable recipe to synthesize the largest and most\ndiverse trajectory-level dataset to date, containing over 94K successful\nmultimodal web trajectories, spanning 49K unique URLs, 720K screenshots, and\n33M web elements. In particular, we leverage extensive web exploration and\nrefinement to obtain diverse task intents. The average cost is 28 cents per\nsuccessful trajectory, making it affordable to a wide range of users in the\ncommunity. Leveraging this dataset, we train Explorer, a multimodal web agent,\nand demonstrate strong performance on both offline and online web agent\nbenchmarks such as Mind2Web-Live, Multimodal-Mind2Web, and MiniWob++.\nAdditionally, our experiments highlight data scaling as a key driver for\nimproving web agent capabilities. We hope this study makes state-of-the-art\nLMM-based agent research at a larger scale more accessible.'}","['Vardaan Pahuja', 'Yadong Lu', 'Corby Rosset', 'Boyu Gou', 'Arindam Mitra', 'Spencer Whitehead', 'Yu Su', 'Ahmed Awadallah']",{'name': 'Ahmed Awadallah'},Ahmed Awadallah,"24 pages, 7 figures","[{'href': 'http://arxiv.org/abs/2502.11357v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11357v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11357v2,None,http://arxiv.org/abs/2502.11357v2,,,3635,0
http://arxiv.org/abs/2502.11358v1,True,2025-02-17T02:15:46Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=2, tm_min=15, tm_sec=46, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T02:15:46Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=2, tm_min=15, tm_sec=46, tm_wday=0, tm_yday=48, tm_isdst=0)","Mimicking the Familiar: Dynamic Command Generation for Information Theft
  Attacks in LLM Tool-Learning System","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Mimicking the Familiar: Dynamic Command Generation for Information Theft\n  Attacks in LLM Tool-Learning System'}","Information theft attacks pose a significant risk to Large Language Model
(LLM) tool-learning systems. Adversaries can inject malicious commands through
compromised tools, manipulating LLMs to send sensitive information to these
tools, which leads to potential privacy breaches. However, existing attack
approaches are black-box oriented and rely on static commands that cannot adapt
flexibly to the changes in user queries and the invocation chain of tools. It
makes malicious commands more likely to be detected by LLM and leads to attack
failure. In this paper, we propose AutoCMD, a dynamic attack comment generation
approach for information theft attacks in LLM tool-learning systems. Inspired
by the concept of mimicking the familiar, AutoCMD is capable of inferring the
information utilized by upstream tools in the toolchain through learning on
open-source systems and reinforcement with target system examples, thereby
generating more targeted commands for information theft. The evaluation results
show that AutoCMD outperforms the baselines with +13.2% $ASR_{Theft}$, and can
be generalized to new tool-learning systems to expose their information leakage
risks. We also design four defense methods to effectively protect tool-learning
systems from the attack.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Information theft attacks pose a significant risk to Large Language Model\n(LLM) tool-learning systems. Adversaries can inject malicious commands through\ncompromised tools, manipulating LLMs to send sensitive information to these\ntools, which leads to potential privacy breaches. However, existing attack\napproaches are black-box oriented and rely on static commands that cannot adapt\nflexibly to the changes in user queries and the invocation chain of tools. It\nmakes malicious commands more likely to be detected by LLM and leads to attack\nfailure. In this paper, we propose AutoCMD, a dynamic attack comment generation\napproach for information theft attacks in LLM tool-learning systems. Inspired\nby the concept of mimicking the familiar, AutoCMD is capable of inferring the\ninformation utilized by upstream tools in the toolchain through learning on\nopen-source systems and reinforcement with target system examples, thereby\ngenerating more targeted commands for information theft. The evaluation results\nshow that AutoCMD outperforms the baselines with +13.2% $ASR_{Theft}$, and can\nbe generalized to new tool-learning systems to expose their information leakage\nrisks. We also design four defense methods to effectively protect tool-learning\nsystems from the attack.'}","['Ziyou Jiang', 'Mingyang Li', 'Guowei Yang', 'Junjie Wang', 'Yuekai Huang', 'Zhiyuan Chang', 'Qing Wang']",{'name': 'Qing Wang'},Qing Wang,"15 pages, 11 figures","[{'href': 'http://arxiv.org/abs/2502.11358v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11358v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11358v1,None,http://arxiv.org/abs/2502.11358v1,,,579,0
http://arxiv.org/abs/2502.11368v1,True,2025-02-17T02:31:56Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=2, tm_min=31, tm_sec=56, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T02:31:56Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=2, tm_min=31, tm_sec=56, tm_wday=0, tm_yday=48, tm_isdst=0)","LLMs can Perform Multi-Dimensional Analytic Writing Assessments: A Case
  Study of L2 Graduate-Level Academic English Writing","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'LLMs can Perform Multi-Dimensional Analytic Writing Assessments: A Case\n  Study of L2 Graduate-Level Academic English Writing'}","The paper explores the performance of LLMs in the context of
multi-dimensional analytic writing assessments, i.e. their ability to provide
both scores and comments based on multiple assessment criteria. Using a corpus
of literature reviews written by L2 graduate students and assessed by human
experts against 9 analytic criteria, we prompt several popular LLMs to perform
the same task under various conditions. To evaluate the quality of feedback
comments, we apply a novel feedback comment quality evaluation framework. This
framework is interpretable, cost-efficient, scalable, and reproducible,
compared to existing methods that rely on manual judgments. We find that LLMs
can generate reasonably good and generally reliable multi-dimensional analytic
assessments. We release our corpus for reproducibility.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The paper explores the performance of LLMs in the context of\nmulti-dimensional analytic writing assessments, i.e. their ability to provide\nboth scores and comments based on multiple assessment criteria. Using a corpus\nof literature reviews written by L2 graduate students and assessed by human\nexperts against 9 analytic criteria, we prompt several popular LLMs to perform\nthe same task under various conditions. To evaluate the quality of feedback\ncomments, we apply a novel feedback comment quality evaluation framework. This\nframework is interpretable, cost-efficient, scalable, and reproducible,\ncompared to existing methods that rely on manual judgments. We find that LLMs\ncan generate reasonably good and generally reliable multi-dimensional analytic\nassessments. We release our corpus for reproducibility.'}","['Zhengxiang Wang', 'Veronika Makarova', 'Zhi Li', 'Jordan Kodner', 'Owen Rambow']",{'name': 'Owen Rambow'},Owen Rambow,"26 pages, 6 figures, 15 tables","[{'href': 'http://arxiv.org/abs/2502.11368v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11368v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11368v1,None,http://arxiv.org/abs/2502.11368v1,,,181,0
http://arxiv.org/abs/2502.11381v1,True,2025-02-17T02:53:08Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=2, tm_min=53, tm_sec=8, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T02:53:08Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=2, tm_min=53, tm_sec=8, tm_wday=0, tm_yday=48, tm_isdst=0)","Without Paired Labeled Data: An End-to-End Self-Supervised Paradigm for
  UAV-View Geo-Localization","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Without Paired Labeled Data: An End-to-End Self-Supervised Paradigm for\n  UAV-View Geo-Localization'}","UAV-View Geo-Localization (UVGL) aims to ascertain the precise location of a
UAV by retrieving the most similar GPS-tagged satellite image. However,
existing methods predominantly rely on supervised learning paradigms that
necessitate annotated paired data for training, which incurs substantial
annotation costs and impedes large-scale deployment. To overcome this
limitation, we propose the Dynamic Memory-Driven and Neighborhood Information
Learning (DMNIL) network, a lightweight end-to-end self-supervised framework
for UAV-view geo-localization. The DMNIL framework utilizes a dual-path
clustering-based contrastive learning architecture as its baseline to model
intra-view structural relationships, enhancing feature consistency and
discriminability. Additionally, a dynamic memory-driven hierarchical learning
module is proposed to progressively mine local and global information,
reinforcing multi-level feature associations to improve model robustness. To
bridge the domain gap between UAV and satellite views, we design an
information-consistent evolutionary learning mechanism that systematically
explores latent correlations within intra-view neighborhoods and across
cross-view domains, ultimately constructing a unified cross-view feature
representation space. Extensive experiments on three benchmarks
(University-1652, SUES-200, and DenseUAV) demonstrate that DMNIL achieves
competitive performance against state-of-the-art supervised methods while
maintaining computational efficiency. Notably, this superiority is attained
without relying on paired training data, underscoring the framework's
practicality for real-world deployment. Codes will be released soon.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""UAV-View Geo-Localization (UVGL) aims to ascertain the precise location of a\nUAV by retrieving the most similar GPS-tagged satellite image. However,\nexisting methods predominantly rely on supervised learning paradigms that\nnecessitate annotated paired data for training, which incurs substantial\nannotation costs and impedes large-scale deployment. To overcome this\nlimitation, we propose the Dynamic Memory-Driven and Neighborhood Information\nLearning (DMNIL) network, a lightweight end-to-end self-supervised framework\nfor UAV-view geo-localization. The DMNIL framework utilizes a dual-path\nclustering-based contrastive learning architecture as its baseline to model\nintra-view structural relationships, enhancing feature consistency and\ndiscriminability. Additionally, a dynamic memory-driven hierarchical learning\nmodule is proposed to progressively mine local and global information,\nreinforcing multi-level feature associations to improve model robustness. To\nbridge the domain gap between UAV and satellite views, we design an\ninformation-consistent evolutionary learning mechanism that systematically\nexplores latent correlations within intra-view neighborhoods and across\ncross-view domains, ultimately constructing a unified cross-view feature\nrepresentation space. Extensive experiments on three benchmarks\n(University-1652, SUES-200, and DenseUAV) demonstrate that DMNIL achieves\ncompetitive performance against state-of-the-art supervised methods while\nmaintaining computational efficiency. Notably, this superiority is attained\nwithout relying on paired training data, underscoring the framework's\npracticality for real-world deployment. Codes will be released soon.""}","['Zhongwei Chen', 'Zhao-Xu Yang', 'Hai-Jun Rong']",{'name': 'Hai-Jun Rong'},Hai-Jun Rong,,"[{'href': 'http://arxiv.org/abs/2502.11381v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11381v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11381v1,None,http://arxiv.org/abs/2502.11381v1,,,1836,0
http://arxiv.org/abs/2502.11418v1,True,2025-02-17T04:17:27Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=4, tm_min=17, tm_sec=27, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T04:17:27Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=4, tm_min=17, tm_sec=27, tm_wday=0, tm_yday=48, tm_isdst=0)","TimeCAP: Learning to Contextualize, Augment, and Predict Time Series
  Events with Large Language Model Agents","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'TimeCAP: Learning to Contextualize, Augment, and Predict Time Series\n  Events with Large Language Model Agents'}","Time series data is essential in various applications, including climate
modeling, healthcare monitoring, and financial analytics. Understanding the
contextual information associated with real-world time series data is often
essential for accurate and reliable event predictions. In this paper, we
introduce TimeCAP, a time-series processing framework that creatively employs
Large Language Models (LLMs) as contextualizers of time series data, extending
their typical usage as predictors. TimeCAP incorporates two independent LLM
agents: one generates a textual summary capturing the context of the time
series, while the other uses this enriched summary to make more informed
predictions. In addition, TimeCAP employs a multi-modal encoder that synergizes
with the LLM agents, enhancing predictive performance through mutual
augmentation of inputs with in-context examples. Experimental results on
real-world datasets demonstrate that TimeCAP outperforms state-of-the-art
methods for time series event prediction, including those utilizing LLMs as
predictors, achieving an average improvement of 28.75% in F1 score.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Time series data is essential in various applications, including climate\nmodeling, healthcare monitoring, and financial analytics. Understanding the\ncontextual information associated with real-world time series data is often\nessential for accurate and reliable event predictions. In this paper, we\nintroduce TimeCAP, a time-series processing framework that creatively employs\nLarge Language Models (LLMs) as contextualizers of time series data, extending\ntheir typical usage as predictors. TimeCAP incorporates two independent LLM\nagents: one generates a textual summary capturing the context of the time\nseries, while the other uses this enriched summary to make more informed\npredictions. In addition, TimeCAP employs a multi-modal encoder that synergizes\nwith the LLM agents, enhancing predictive performance through mutual\naugmentation of inputs with in-context examples. Experimental results on\nreal-world datasets demonstrate that TimeCAP outperforms state-of-the-art\nmethods for time series event prediction, including those utilizing LLMs as\npredictors, achieving an average improvement of 28.75% in F1 score.'}","['Geon Lee', 'Wenchao Yu', 'Kijung Shin', 'Wei Cheng', 'Haifeng Chen']",{'name': 'Haifeng Chen'},Haifeng Chen,AAAI 2025,"[{'href': 'http://arxiv.org/abs/2502.11418v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11418v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11418v1,None,http://arxiv.org/abs/2502.11418v1,,,124,0
http://arxiv.org/abs/2502.11425v1,True,2025-02-17T04:37:07Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=4, tm_min=37, tm_sec=7, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T04:37:07Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=4, tm_min=37, tm_sec=7, tm_wday=0, tm_yday=48, tm_isdst=0)","Counterfactual-Consistency Prompting for Relative Temporal Understanding
  in Large Language Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Counterfactual-Consistency Prompting for Relative Temporal Understanding\n  in Large Language Models'}","Despite the advanced capabilities of large language models (LLMs), their
temporal reasoning ability remains underdeveloped. Prior works have highlighted
this limitation, particularly in maintaining temporal consistency when
understanding events. For example, models often confuse mutually exclusive
temporal relations like ``before'' and ``after'' between events and make
inconsistent predictions. In this work, we tackle the issue of temporal
inconsistency in LLMs by proposing a novel counterfactual prompting approach.
Our method generates counterfactual questions and enforces collective
constraints, enhancing the model's consistency. We evaluate our method on
multiple datasets, demonstrating significant improvements in event ordering for
explicit and implicit events and temporal commonsense understanding by
effectively addressing temporal inconsistencies.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Despite the advanced capabilities of large language models (LLMs), their\ntemporal reasoning ability remains underdeveloped. Prior works have highlighted\nthis limitation, particularly in maintaining temporal consistency when\nunderstanding events. For example, models often confuse mutually exclusive\ntemporal relations like ``before'' and ``after'' between events and make\ninconsistent predictions. In this work, we tackle the issue of temporal\ninconsistency in LLMs by proposing a novel counterfactual prompting approach.\nOur method generates counterfactual questions and enforces collective\nconstraints, enhancing the model's consistency. We evaluate our method on\nmultiple datasets, demonstrating significant improvements in event ordering for\nexplicit and implicit events and temporal commonsense understanding by\neffectively addressing temporal inconsistencies.""}","['Jongho Kim', 'Seung-won Hwang']",{'name': 'Seung-won Hwang'},Seung-won Hwang,Preprint,"[{'href': 'http://arxiv.org/abs/2502.11425v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11425v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11425v1,None,http://arxiv.org/abs/2502.11425v1,,,2,0
http://arxiv.org/abs/2502.11437v1,True,2025-02-17T04:50:45Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=4, tm_min=50, tm_sec=45, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T04:50:45Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=4, tm_min=50, tm_sec=45, tm_wday=0, tm_yday=48, tm_isdst=0)","Learning Dexterous Bimanual Catch Skills through Adversarial-Cooperative
  Heterogeneous-Agent Reinforcement Learning","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Learning Dexterous Bimanual Catch Skills through Adversarial-Cooperative\n  Heterogeneous-Agent Reinforcement Learning'}","Robotic catching has traditionally focused on single-handed systems, which
are limited in their ability to handle larger or more complex objects. In
contrast, bimanual catching offers significant potential for improved dexterity
and object handling but introduces new challenges in coordination and control.
In this paper, we propose a novel framework for learning dexterous bimanual
catching skills using Heterogeneous-Agent Reinforcement Learning (HARL). Our
approach introduces an adversarial reward scheme, where a throw agent increases
the difficulty of throws-adjusting speed-while a catch agent learns to
coordinate both hands to catch objects under these evolving conditions. We
evaluate the framework in simulated environments using 15 different objects,
demonstrating robustness and versatility in handling diverse objects. Our
method achieved approximately a 2x increase in catching reward compared to
single-agent baselines across 15 diverse objects.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Robotic catching has traditionally focused on single-handed systems, which\nare limited in their ability to handle larger or more complex objects. In\ncontrast, bimanual catching offers significant potential for improved dexterity\nand object handling but introduces new challenges in coordination and control.\nIn this paper, we propose a novel framework for learning dexterous bimanual\ncatching skills using Heterogeneous-Agent Reinforcement Learning (HARL). Our\napproach introduces an adversarial reward scheme, where a throw agent increases\nthe difficulty of throws-adjusting speed-while a catch agent learns to\ncoordinate both hands to catch objects under these evolving conditions. We\nevaluate the framework in simulated environments using 15 different objects,\ndemonstrating robustness and versatility in handling diverse objects. Our\nmethod achieved approximately a 2x increase in catching reward compared to\nsingle-agent baselines across 15 diverse objects.'}","['Taewoo Kim', 'Youngwoo Yoon', 'Jaehong Kim']",{'name': 'Jaehong Kim'},Jaehong Kim,ICRA 2025 Accepted,"[{'href': 'http://arxiv.org/abs/2502.11437v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11437v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11437v1,None,http://arxiv.org/abs/2502.11437v1,,,28,0
http://arxiv.org/abs/2502.11447v2,True,2025-02-19T06:45:25Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=6, tm_min=45, tm_sec=25, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-17T05:09:46Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=5, tm_min=9, tm_sec=46, tm_wday=0, tm_yday=48, tm_isdst=0)",Does Editing Provide Evidence for Localization?,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Does Editing Provide Evidence for Localization?'}","A basic aspiration for interpretability research in large language models is
to ""localize"" semantically meaningful behaviors to particular components within
the LLM. There are various heuristics for finding candidate locations within
the LLM. Once a candidate localization is found, it can be assessed by editing
the internal representations at the corresponding localization and checking
whether this induces model behavior that is consistent with the semantic
interpretation of the localization. The question we address here is: how strong
is the evidence provided by such edits? To evaluate the localization claim, we
want to assess the effect of the optimal intervention at a particular location.
The key new technical tool is a way of adapting LLM alignment techniques to
find such optimal localized edits. With this tool in hand, we give an example
where the edit-based evidence for localization appears strong, but where
localization clearly fails. Indeed, we find that optimal edits at random
localizations can be as effective as aligning the full model. In aggregate, our
results suggest that merely observing that localized edits induce targeted
changes in behavior provides little to no evidence that these locations
actually encode the target behavior.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A basic aspiration for interpretability research in large language models is\nto ""localize"" semantically meaningful behaviors to particular components within\nthe LLM. There are various heuristics for finding candidate locations within\nthe LLM. Once a candidate localization is found, it can be assessed by editing\nthe internal representations at the corresponding localization and checking\nwhether this induces model behavior that is consistent with the semantic\ninterpretation of the localization. The question we address here is: how strong\nis the evidence provided by such edits? To evaluate the localization claim, we\nwant to assess the effect of the optimal intervention at a particular location.\nThe key new technical tool is a way of adapting LLM alignment techniques to\nfind such optimal localized edits. With this tool in hand, we give an example\nwhere the edit-based evidence for localization appears strong, but where\nlocalization clearly fails. Indeed, we find that optimal edits at random\nlocalizations can be as effective as aligning the full model. In aggregate, our\nresults suggest that merely observing that localized edits induce targeted\nchanges in behavior provides little to no evidence that these locations\nactually encode the target behavior.'}","['Zihao Wang', 'Victor Veitch']",{'name': 'Victor Veitch'},Victor Veitch,,"[{'href': 'http://arxiv.org/abs/2502.11447v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11447v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7; I.2.6; F.1.1', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11447v2,None,http://arxiv.org/abs/2502.11447v2,,,10,0
http://arxiv.org/abs/2502.11450v1,True,2025-02-17T05:22:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=5, tm_min=22, tm_sec=23, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T05:22:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=5, tm_min=22, tm_sec=23, tm_wday=0, tm_yday=48, tm_isdst=0)",Fishing For Cheap And Efficient Pruners At Initialization,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Fishing For Cheap And Efficient Pruners At Initialization'}","Pruning offers a promising solution to mitigate the associated costs and
environmental impact of deploying large deep neural networks (DNNs).
Traditional approaches rely on computationally expensive trained models or
time-consuming iterative prune-retrain cycles, undermining their utility in
resource-constrained settings. To address this issue, we build upon the
established principles of saliency (LeCun et al., 1989) and connection
sensitivity (Lee et al., 2018) to tackle the challenging problem of one-shot
pruning neural networks (NNs) before training (PBT) at initialization. We
introduce Fisher-Taylor Sensitivity (FTS), a computationally cheap and
efficient pruning criterion based on the empirical Fisher Information Matrix
(FIM) diagonal, offering a viable alternative for integrating first- and
second-order information to identify a model's structurally important
parameters. Although the FIM-Hessian equivalency only holds for convergent
models that maximize the likelihood, recent studies (Karakida et al., 2019)
suggest that, even at initialization, the FIM captures essential geometric
information of parameters in overparameterized NNs, providing the basis for our
method. Finally, we demonstrate empirically that layer collapse, a critical
limitation of data-dependent pruning methodologies, is easily overcome by
pruning within a single training epoch after initialization. We perform
experiments on ResNet18 and VGG19 with CIFAR-10 and CIFAR-100, widely used
benchmarks in pruning research. Our method achieves competitive performance
against state-of-the-art techniques for one-shot PBT, even under extreme
sparsity conditions. Our code is made available to the public.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Pruning offers a promising solution to mitigate the associated costs and\nenvironmental impact of deploying large deep neural networks (DNNs).\nTraditional approaches rely on computationally expensive trained models or\ntime-consuming iterative prune-retrain cycles, undermining their utility in\nresource-constrained settings. To address this issue, we build upon the\nestablished principles of saliency (LeCun et al., 1989) and connection\nsensitivity (Lee et al., 2018) to tackle the challenging problem of one-shot\npruning neural networks (NNs) before training (PBT) at initialization. We\nintroduce Fisher-Taylor Sensitivity (FTS), a computationally cheap and\nefficient pruning criterion based on the empirical Fisher Information Matrix\n(FIM) diagonal, offering a viable alternative for integrating first- and\nsecond-order information to identify a model's structurally important\nparameters. Although the FIM-Hessian equivalency only holds for convergent\nmodels that maximize the likelihood, recent studies (Karakida et al., 2019)\nsuggest that, even at initialization, the FIM captures essential geometric\ninformation of parameters in overparameterized NNs, providing the basis for our\nmethod. Finally, we demonstrate empirically that layer collapse, a critical\nlimitation of data-dependent pruning methodologies, is easily overcome by\npruning within a single training epoch after initialization. We perform\nexperiments on ResNet18 and VGG19 with CIFAR-10 and CIFAR-100, widely used\nbenchmarks in pruning research. Our method achieves competitive performance\nagainst state-of-the-art techniques for one-shot PBT, even under extreme\nsparsity conditions. Our code is made available to the public.""}","['Ivo Gollini Navarrete', 'Nicolas Mauricio Cuadrado', 'Jose Renato Restom', 'Martin Tak', 'Samuel Horvth']",{'name': 'Samuel Horvth'},Samuel Horvth,"8 pages of main content (excluding references), 2 figures, 2 tables,
  1 algorithm, and 11 pages of appendix. Code available at
  https://github.com/Gollini/Fisher_Taylor_Sensitivity","[{'href': 'http://arxiv.org/abs/2502.11450v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11450v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T05', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.6; C.1.3', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11450v1,None,http://arxiv.org/abs/2502.11450v1,,,201,0
http://arxiv.org/abs/2502.11453v1,True,2025-02-17T05:28:04Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=5, tm_min=28, tm_sec=4, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T05:28:04Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=5, tm_min=28, tm_sec=4, tm_wday=0, tm_yday=48, tm_isdst=0)",Connector-S: A Survey of Connectors in Multi-modal Large Language Models,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Connector-S: A Survey of Connectors in Multi-modal Large Language Models'}","With the rapid advancements in multi-modal large language models (MLLMs),
connectors play a pivotal role in bridging diverse modalities and enhancing
model performance. However, the design and evolution of connectors have not
been comprehensively analyzed, leaving gaps in understanding how these
components function and hindering the development of more powerful connectors.
In this survey, we systematically review the current progress of connectors in
MLLMs and present a structured taxonomy that categorizes connectors into atomic
operations (mapping, compression, mixture of experts) and holistic designs
(multi-layer, multi-encoder, multi-modal scenarios), highlighting their
technical contributions and advancements. Furthermore, we discuss several
promising research frontiers and challenges, including high-resolution input,
dynamic compression, guide information selection, combination strategy, and
interpretability. This survey is intended to serve as a foundational reference
and a clear roadmap for researchers, providing valuable insights into the
design and optimization of next-generation connectors to enhance the
performance and adaptability of MLLMs.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'With the rapid advancements in multi-modal large language models (MLLMs),\nconnectors play a pivotal role in bridging diverse modalities and enhancing\nmodel performance. However, the design and evolution of connectors have not\nbeen comprehensively analyzed, leaving gaps in understanding how these\ncomponents function and hindering the development of more powerful connectors.\nIn this survey, we systematically review the current progress of connectors in\nMLLMs and present a structured taxonomy that categorizes connectors into atomic\noperations (mapping, compression, mixture of experts) and holistic designs\n(multi-layer, multi-encoder, multi-modal scenarios), highlighting their\ntechnical contributions and advancements. Furthermore, we discuss several\npromising research frontiers and challenges, including high-resolution input,\ndynamic compression, guide information selection, combination strategy, and\ninterpretability. This survey is intended to serve as a foundational reference\nand a clear roadmap for researchers, providing valuable insights into the\ndesign and optimization of next-generation connectors to enhance the\nperformance and adaptability of MLLMs.'}","['Xun Zhu', 'Zheng Zhang', 'Xi Chen', 'Yiming Shi', 'Miao Li', 'Ji Wu']",{'name': 'Ji Wu'},Ji Wu,,"[{'href': 'http://arxiv.org/abs/2502.11453v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11453v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11453v1,None,http://arxiv.org/abs/2502.11453v1,,,36,0
http://arxiv.org/abs/2502.11456v1,True,2025-02-17T05:29:50Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=5, tm_min=29, tm_sec=50, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T05:29:50Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=5, tm_min=29, tm_sec=50, tm_wday=0, tm_yday=48, tm_isdst=0)","Leveraging Labelled Data Knowledge: A Cooperative Rectification Learning
  Network for Semi-supervised 3D Medical Image Segmentation","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Leveraging Labelled Data Knowledge: A Cooperative Rectification Learning\n  Network for Semi-supervised 3D Medical Image Segmentation'}","Semi-supervised 3D medical image segmentation aims to achieve accurate
segmentation using few labelled data and numerous unlabelled data. The main
challenge in the design of semi-supervised learning methods consists in the
effective use of the unlabelled data for training. A promising solution
consists of ensuring consistent predictions across different views of the data,
where the efficacy of this strategy depends on the accuracy of the
pseudo-labels generated by the model for this consistency learning strategy. In
this paper, we introduce a new methodology to produce high-quality
pseudo-labels for a consistency learning strategy to address semi-supervised 3D
medical image segmentation. The methodology has three important contributions.
The first contribution is the Cooperative Rectification Learning Network (CRLN)
that learns multiple prototypes per class to be used as external knowledge
priors to adaptively rectify pseudo-labels at the voxel level. The second
contribution consists of the Dynamic Interaction Module (DIM) to facilitate
pairwise and cross-class interactions between prototypes and multi-resolution
image features, enabling the production of accurate voxel-level clues for
pseudo-label rectification. The third contribution is the Cooperative Positive
Supervision (CPS), which optimises uncertain representations to align with
unassertive representations of their class distributions, improving the model's
accuracy in classifying uncertain regions. Extensive experiments on three
public 3D medical segmentation datasets demonstrate the effectiveness and
superiority of our semi-supervised learning method.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Semi-supervised 3D medical image segmentation aims to achieve accurate\nsegmentation using few labelled data and numerous unlabelled data. The main\nchallenge in the design of semi-supervised learning methods consists in the\neffective use of the unlabelled data for training. A promising solution\nconsists of ensuring consistent predictions across different views of the data,\nwhere the efficacy of this strategy depends on the accuracy of the\npseudo-labels generated by the model for this consistency learning strategy. In\nthis paper, we introduce a new methodology to produce high-quality\npseudo-labels for a consistency learning strategy to address semi-supervised 3D\nmedical image segmentation. The methodology has three important contributions.\nThe first contribution is the Cooperative Rectification Learning Network (CRLN)\nthat learns multiple prototypes per class to be used as external knowledge\npriors to adaptively rectify pseudo-labels at the voxel level. The second\ncontribution consists of the Dynamic Interaction Module (DIM) to facilitate\npairwise and cross-class interactions between prototypes and multi-resolution\nimage features, enabling the production of accurate voxel-level clues for\npseudo-label rectification. The third contribution is the Cooperative Positive\nSupervision (CPS), which optimises uncertain representations to align with\nunassertive representations of their class distributions, improving the model's\naccuracy in classifying uncertain regions. Extensive experiments on three\npublic 3D medical segmentation datasets demonstrate the effectiveness and\nsuperiority of our semi-supervised learning method.""}","['Yanyan Wang', 'Kechen Song', 'Yuyuan Liu', 'Shuai Ma', 'Yunhui Yan', 'Gustavo Carneiro']",{'name': 'Gustavo Carneiro'},Gustavo Carneiro,Medical Image Analysis,"[{'title': 'doi', 'href': 'http://dx.doi.org/10.1016/j.media.2025.103461', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2502.11456v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11456v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11456v1,None,http://arxiv.org/abs/2502.11456v1,,10.1016/j.media.2025.103461,9485,0
http://arxiv.org/abs/2502.11457v1,True,2025-02-17T05:32:56Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=5, tm_min=32, tm_sec=56, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T05:32:56Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=5, tm_min=32, tm_sec=56, tm_wday=0, tm_yday=48, tm_isdst=0)","Aligning Sentence Simplification with ESL Learner's Proficiency for
  Language Acquisition","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Aligning Sentence Simplification with ESL Learner's Proficiency for\n  Language Acquisition""}","Text simplification is crucial for improving accessibility and comprehension
for English as a Second Language (ESL) learners. This study goes a step further
and aims to facilitate ESL learners' language acquisition by simplification.
Specifically, we propose simplifying complex sentences to appropriate levels
for learners while also increasing vocabulary coverage of the target level in
the simplifications. We achieve this without a parallel corpus by conducting
reinforcement learning on a large language model. Our method employs
token-level and sentence-level rewards, and iteratively trains the model on its
self-generated outputs to guide the model to search for simplification
hypotheses that satisfy the target attributes. Experiment results on CEFR-SP
and TurkCorpus datasets show that the proposed method can effectively increase
the frequency and diversity of vocabulary of the target level by more than
$20\%$ compared to baseline models, while maintaining high simplification
quality.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Text simplification is crucial for improving accessibility and comprehension\nfor English as a Second Language (ESL) learners. This study goes a step further\nand aims to facilitate ESL learners' language acquisition by simplification.\nSpecifically, we propose simplifying complex sentences to appropriate levels\nfor learners while also increasing vocabulary coverage of the target level in\nthe simplifications. We achieve this without a parallel corpus by conducting\nreinforcement learning on a large language model. Our method employs\ntoken-level and sentence-level rewards, and iteratively trains the model on its\nself-generated outputs to guide the model to search for simplification\nhypotheses that satisfy the target attributes. Experiment results on CEFR-SP\nand TurkCorpus datasets show that the proposed method can effectively increase\nthe frequency and diversity of vocabulary of the target level by more than\n$20\\%$ compared to baseline models, while maintaining high simplification\nquality.""}","['Guanlin Li', 'Yuki Arase', 'Noel Crespi']",{'name': 'Noel Crespi'},Noel Crespi,NAACL2025 main,"[{'href': 'http://arxiv.org/abs/2502.11457v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11457v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11457v1,None,http://arxiv.org/abs/2502.11457v1,,,12,0
http://arxiv.org/abs/2502.11458v1,True,2025-02-17T05:33:11Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=5, tm_min=33, tm_sec=11, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T05:33:11Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=5, tm_min=33, tm_sec=11, tm_wday=0, tm_yday=48, tm_isdst=0)","Towards Efficient Pre-training: Exploring FP4 Precision in Large
  Language Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Towards Efficient Pre-training: Exploring FP4 Precision in Large\n  Language Models'}","The burgeoning computational demands for training large language models
(LLMs) necessitate efficient methods, including quantized training, which
leverages low-bit arithmetic operations to reduce costs. While FP8 precision
has shown potential, leveraging FP4 remains challenging due to inherent
quantization errors and limited representation capability. Based on the
Transformer architecture, we present an FP4 training scheme for LLMs,
overcoming these obstacles through mixed-precision quantization strategies
tailed for different modules and training stages. This allows us to apply the
precision level suitable to distinct components within the model, ensuring that
multi-head attention and linear layers are handled appropriately. Our
pretraining recipe ensures stability in backpropagation by incorporating
fine-grained quantization methods with a target precision training schedule.
Experimental results demonstrate that our FP4 training scheme achieves accuracy
comparable to BF16 and FP8, with smaller theoretical computational cost. With
the advent of next-generation hardware supporting FP4, our method sets the
foundation for efficient ultra-low precision training.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The burgeoning computational demands for training large language models\n(LLMs) necessitate efficient methods, including quantized training, which\nleverages low-bit arithmetic operations to reduce costs. While FP8 precision\nhas shown potential, leveraging FP4 remains challenging due to inherent\nquantization errors and limited representation capability. Based on the\nTransformer architecture, we present an FP4 training scheme for LLMs,\novercoming these obstacles through mixed-precision quantization strategies\ntailed for different modules and training stages. This allows us to apply the\nprecision level suitable to distinct components within the model, ensuring that\nmulti-head attention and linear layers are handled appropriately. Our\npretraining recipe ensures stability in backpropagation by incorporating\nfine-grained quantization methods with a target precision training schedule.\nExperimental results demonstrate that our FP4 training scheme achieves accuracy\ncomparable to BF16 and FP8, with smaller theoretical computational cost. With\nthe advent of next-generation hardware supporting FP4, our method sets the\nfoundation for efficient ultra-low precision training.'}","['Jiecheng Zhou', 'Ding Tang', 'Rong Fu', 'Boni Hu', 'Haoran Xu', 'Yi Wang', 'Zhilin Pei', 'Zhongling Su', 'Liang Liu', 'Xingcheng Zhang', 'Weiming Zhang']",{'name': 'Weiming Zhang'},Weiming Zhang,"8 pages, 2 figure","[{'href': 'http://arxiv.org/abs/2502.11458v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11458v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11458v1,None,http://arxiv.org/abs/2502.11458v1,,,58,0
http://arxiv.org/abs/2502.11470v1,True,2025-02-17T06:01:06Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=6, tm_min=1, tm_sec=6, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T06:01:06Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=6, tm_min=1, tm_sec=6, tm_wday=0, tm_yday=48, tm_isdst=0)","Optimized detection of cyber-attacks on IoT networks via hybrid deep
  learning models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Optimized detection of cyber-attacks on IoT networks via hybrid deep\n  learning models'}","The rapid expansion of Internet of Things (IoT) devices has increased the
risk of cyber-attacks, making effective detection essential for securing IoT
networks. This work introduces a novel approach combining Self-Organizing Maps
(SOMs), Deep Belief Networks (DBNs), and Autoencoders to detect known and
previously unseen attack patterns. A comprehensive evaluation using simulated
and real-world traffic data is conducted, with models optimized via Particle
Swarm Optimization (PSO). The system achieves an accuracy of up to 99.99% and
Matthews Correlation Coefficient (MCC) values exceeding 99.50%. Experiments on
NSL-KDD, UNSW-NB15, and CICIoT2023 confirm the model's strong performance
across diverse attack types. These findings suggest that the proposed method
enhances IoT security by identifying emerging threats and adapting to evolving
attack strategies.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""The rapid expansion of Internet of Things (IoT) devices has increased the\nrisk of cyber-attacks, making effective detection essential for securing IoT\nnetworks. This work introduces a novel approach combining Self-Organizing Maps\n(SOMs), Deep Belief Networks (DBNs), and Autoencoders to detect known and\npreviously unseen attack patterns. A comprehensive evaluation using simulated\nand real-world traffic data is conducted, with models optimized via Particle\nSwarm Optimization (PSO). The system achieves an accuracy of up to 99.99% and\nMatthews Correlation Coefficient (MCC) values exceeding 99.50%. Experiments on\nNSL-KDD, UNSW-NB15, and CICIoT2023 confirm the model's strong performance\nacross diverse attack types. These findings suggest that the proposed method\nenhances IoT security by identifying emerging threats and adapting to evolving\nattack strategies.""}","['Ahmed Bensaoud', 'Jugal Kalita']",{'name': 'Jugal Kalita'},Jugal Kalita,,"[{'title': 'doi', 'href': 'http://dx.doi.org/10.1016/j.adhoc.2025.103770', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2502.11470v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11470v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11470v1,None,http://arxiv.org/abs/2502.11470v1,"Bensaoud, Ahmed, and Jugal Kalita. ""Optimized detection of
  cyber-attacks on IoT networks via hybrid deep learning models."" Ad Hoc
  Networks 170 (2025): 103770",10.1016/j.adhoc.2025.103770,419,0
http://arxiv.org/abs/2502.11481v1,True,2025-02-17T06:35:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=6, tm_min=35, tm_sec=37, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T06:35:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=6, tm_min=35, tm_sec=37, tm_wday=0, tm_yday=48, tm_isdst=0)","Variable-frame CNNLSTM for Breast Nodule Classification using Ultrasound
  Videos","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Variable-frame CNNLSTM for Breast Nodule Classification using Ultrasound\n  Videos'}","The intersection of medical imaging and artificial intelligence has become an
important research direction in intelligent medical treatment, particularly in
the analysis of medical images using deep learning for clinical diagnosis.
Despite the advances, existing keyframe classification methods lack extraction
of time series features, while ultrasonic video classification based on
three-dimensional convolution requires uniform frame numbers across patients,
resulting in poor feature extraction efficiency and model classification
performance. This study proposes a novel video classification method based on
CNN and LSTM, introducing NLP's long and short sentence processing scheme into
video classification for the first time. The method reduces CNN-extracted image
features to 1x512 dimension, followed by sorting and compressing feature
vectors for LSTM training. Specifically, feature vectors are sorted by patient
video frame numbers and populated with padding value 0 to form variable
batches, with invalid padding values compressed before LSTM training to
conserve computing resources. Experimental results demonstrate that our
variable-frame CNNLSTM method outperforms other approaches across all metrics,
showing improvements of 3-6% in F1 score and 1.5% in specificity compared to
keyframe methods. The variable-frame CNNLSTM also achieves better accuracy and
precision than equal-frame CNNLSTM. These findings validate the effectiveness
of our approach in classifying variable-frame ultrasound videos and suggest
potential applications in other medical imaging modalities.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""The intersection of medical imaging and artificial intelligence has become an\nimportant research direction in intelligent medical treatment, particularly in\nthe analysis of medical images using deep learning for clinical diagnosis.\nDespite the advances, existing keyframe classification methods lack extraction\nof time series features, while ultrasonic video classification based on\nthree-dimensional convolution requires uniform frame numbers across patients,\nresulting in poor feature extraction efficiency and model classification\nperformance. This study proposes a novel video classification method based on\nCNN and LSTM, introducing NLP's long and short sentence processing scheme into\nvideo classification for the first time. The method reduces CNN-extracted image\nfeatures to 1x512 dimension, followed by sorting and compressing feature\nvectors for LSTM training. Specifically, feature vectors are sorted by patient\nvideo frame numbers and populated with padding value 0 to form variable\nbatches, with invalid padding values compressed before LSTM training to\nconserve computing resources. Experimental results demonstrate that our\nvariable-frame CNNLSTM method outperforms other approaches across all metrics,\nshowing improvements of 3-6% in F1 score and 1.5% in specificity compared to\nkeyframe methods. The variable-frame CNNLSTM also achieves better accuracy and\nprecision than equal-frame CNNLSTM. These findings validate the effectiveness\nof our approach in classifying variable-frame ultrasound videos and suggest\npotential applications in other medical imaging modalities.""}","['Xiangxiang Cui', 'Zhongyu Li', 'Xiayue Fan', 'Peng Huang', 'Ying Wang', 'Meng Yang', 'Shi Chang', 'Jihua Zhu']",{'name': 'Jihua Zhu'},Jihua Zhu,,"[{'href': 'http://arxiv.org/abs/2502.11481v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11481v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11481v1,None,http://arxiv.org/abs/2502.11481v1,,,43,0
http://arxiv.org/abs/2502.11491v1,True,2025-02-17T06:53:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=6, tm_min=53, tm_sec=15, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T06:53:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=6, tm_min=53, tm_sec=15, tm_wday=0, tm_yday=48, tm_isdst=0)","Ontology-Guided Reverse Thinking Makes Large Language Models Stronger on
  Knowledge Graph Question Answering","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Ontology-Guided Reverse Thinking Makes Large Language Models Stronger on\n  Knowledge Graph Question Answering'}","Large language models (LLMs) have shown remarkable capabilities in natural
language processing. However, in knowledge graph question answering tasks
(KGQA), there remains the issue of answering questions that require multi-hop
reasoning. Existing methods rely on entity vector matching, but the purpose of
the question is abstract and difficult to match with specific entities. As a
result, it is difficult to establish reasoning paths to the purpose, which
leads to information loss and redundancy. To address this issue, inspired by
human reverse thinking, we propose Ontology-Guided Reverse Thinking (ORT), a
novel framework that constructs reasoning paths from purposes back to
conditions. ORT operates in three key phases: (1) using LLM to extract purpose
labels and condition labels, (2) constructing label reasoning paths based on
the KG ontology, and (3) using the label reasoning paths to guide knowledge
retrieval. Experiments on the WebQSP and CWQ datasets show that ORT achieves
state-of-the-art performance and significantly enhances the capability of LLMs
for KGQA.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large language models (LLMs) have shown remarkable capabilities in natural\nlanguage processing. However, in knowledge graph question answering tasks\n(KGQA), there remains the issue of answering questions that require multi-hop\nreasoning. Existing methods rely on entity vector matching, but the purpose of\nthe question is abstract and difficult to match with specific entities. As a\nresult, it is difficult to establish reasoning paths to the purpose, which\nleads to information loss and redundancy. To address this issue, inspired by\nhuman reverse thinking, we propose Ontology-Guided Reverse Thinking (ORT), a\nnovel framework that constructs reasoning paths from purposes back to\nconditions. ORT operates in three key phases: (1) using LLM to extract purpose\nlabels and condition labels, (2) constructing label reasoning paths based on\nthe KG ontology, and (3) using the label reasoning paths to guide knowledge\nretrieval. Experiments on the WebQSP and CWQ datasets show that ORT achieves\nstate-of-the-art performance and significantly enhances the capability of LLMs\nfor KGQA.'}","['Runxuan Liu', 'Bei Luo', 'Jiaqi Li', 'Baoxin Wang', 'Ming Liu', 'Dayong Wu', 'Shijin Wang', 'Bing Qin']",{'name': 'Bing Qin'},Bing Qin,,"[{'href': 'http://arxiv.org/abs/2502.11491v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11491v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11491v1,None,http://arxiv.org/abs/2502.11491v1,,,685,0
http://arxiv.org/abs/2502.11508v1,True,2025-02-17T07:17:27Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=7, tm_min=17, tm_sec=27, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T07:17:27Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=7, tm_min=17, tm_sec=27, tm_wday=0, tm_yday=48, tm_isdst=0)","Chinese Spelling Correction: A Comprehensive Survey of Progress,
  Challenges, and Opportunities","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Chinese Spelling Correction: A Comprehensive Survey of Progress,\n  Challenges, and Opportunities'}","Chinese Spelling Correction (CSC) is a critical task in natural language
processing, aimed at detecting and correcting spelling errors in Chinese text.
This survey provides a comprehensive overview of CSC, tracing its evolution
from pre-trained language models to large language models, and critically
analyzing their respective strengths and weaknesses in this domain. Moreover,
we further present a detailed examination of existing benchmark datasets,
highlighting their inherent challenges and limitations. Finally, we propose
promising future research directions, particularly focusing on leveraging the
potential of LLMs and their reasoning capabilities for improved CSC
performance. To the best of our knowledge, this is the first comprehensive
survey dedicated to the field of CSC. We believe this work will serve as a
valuable resource for researchers, fostering a deeper understanding of the
field and inspiring future advancements.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Chinese Spelling Correction (CSC) is a critical task in natural language\nprocessing, aimed at detecting and correcting spelling errors in Chinese text.\nThis survey provides a comprehensive overview of CSC, tracing its evolution\nfrom pre-trained language models to large language models, and critically\nanalyzing their respective strengths and weaknesses in this domain. Moreover,\nwe further present a detailed examination of existing benchmark datasets,\nhighlighting their inherent challenges and limitations. Finally, we propose\npromising future research directions, particularly focusing on leveraging the\npotential of LLMs and their reasoning capabilities for improved CSC\nperformance. To the best of our knowledge, this is the first comprehensive\nsurvey dedicated to the field of CSC. We believe this work will serve as a\nvaluable resource for researchers, fostering a deeper understanding of the\nfield and inspiring future advancements.'}","['Changchun Liu', 'Kai Zhang', 'Junzhe Jiang', 'Zixiao Kong', 'Qi Liu', 'Enhong Chen']",{'name': 'Enhong Chen'},Enhong Chen,,"[{'href': 'http://arxiv.org/abs/2502.11508v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11508v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11508v1,None,http://arxiv.org/abs/2502.11508v1,,,3,0
http://arxiv.org/abs/2502.11509v1,True,2025-02-17T07:17:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=7, tm_min=17, tm_sec=37, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T07:17:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=7, tm_min=17, tm_sec=37, tm_wday=0, tm_yday=48, tm_isdst=0)","DifCluE: Generating Counterfactual Explanations with Diffusion
  Autoencoders and modal clustering","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'DifCluE: Generating Counterfactual Explanations with Diffusion\n  Autoencoders and modal clustering'}","Generating multiple counterfactual explanations for different modes within a
class presents a significant challenge, as these modes are distinct yet
converge under the same classification. Diffusion probabilistic models (DPMs)
have demonstrated a strong ability to capture the underlying modes of data
distributions. In this paper, we harness the power of a Diffusion Autoencoder
to generate multiple distinct counterfactual explanations. By clustering in the
latent space, we uncover the directions corresponding to the different modes
within a class, enabling the generation of diverse and meaningful
counterfactuals. We introduce a novel methodology, DifCluE, which consistently
identifies these modes and produces more reliable counterfactual explanations.
Our experimental results demonstrate that DifCluE outperforms the current
state-of-the-art in generating multiple counterfactual explanations, offering a
significant advancement in model interpretability.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Generating multiple counterfactual explanations for different modes within a\nclass presents a significant challenge, as these modes are distinct yet\nconverge under the same classification. Diffusion probabilistic models (DPMs)\nhave demonstrated a strong ability to capture the underlying modes of data\ndistributions. In this paper, we harness the power of a Diffusion Autoencoder\nto generate multiple distinct counterfactual explanations. By clustering in the\nlatent space, we uncover the directions corresponding to the different modes\nwithin a class, enabling the generation of diverse and meaningful\ncounterfactuals. We introduce a novel methodology, DifCluE, which consistently\nidentifies these modes and produces more reliable counterfactual explanations.\nOur experimental results demonstrate that DifCluE outperforms the current\nstate-of-the-art in generating multiple counterfactual explanations, offering a\nsignificant advancement in model interpretability.'}","['Suparshva Jain', 'Amit Sangroya', 'Lovekesh Vig']",{'name': 'Lovekesh Vig'},Lovekesh Vig,,"[{'href': 'http://arxiv.org/abs/2502.11509v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11509v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11509v1,None,http://arxiv.org/abs/2502.11509v1,,,5424,0
http://arxiv.org/abs/2502.11513v1,True,2025-02-17T07:28:52Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=7, tm_min=28, tm_sec=52, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T07:28:52Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=7, tm_min=28, tm_sec=52, tm_wday=0, tm_yday=48, tm_isdst=0)","MaZO: Masked Zeroth-Order Optimization for Multi-Task Fine-Tuning of
  Large Language Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'MaZO: Masked Zeroth-Order Optimization for Multi-Task Fine-Tuning of\n  Large Language Models'}","Large language models have demonstrated exceptional capabilities across
diverse tasks, but their fine-tuning demands significant memory, posing
challenges for resource-constrained environments. Zeroth-order (ZO)
optimization provides a memory-efficient alternative by eliminating the need
for backpropagation. However, ZO optimization suffers from high gradient
variance, and prior research has largely focused on single-task learning,
leaving its application to multi-task learning unexplored. Multi-task learning
is crucial for leveraging shared knowledge across tasks to improve
generalization, yet it introduces unique challenges under ZO settings, such as
amplified gradient variance and collinearity. In this paper, we present MaZO,
the first framework specifically designed for multi-task LLM fine-tuning under
ZO optimization. MaZO tackles these challenges at the parameter level through
two key innovations: a weight importance metric to identify critical parameters
and a multi-task weight update mask to selectively update these parameters,
reducing the dimensionality of the parameter space and mitigating task
conflicts. Experiments demonstrate that MaZO achieves state-of-the-art
performance, surpassing even multi-task learning methods designed for
first-order optimization.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large language models have demonstrated exceptional capabilities across\ndiverse tasks, but their fine-tuning demands significant memory, posing\nchallenges for resource-constrained environments. Zeroth-order (ZO)\noptimization provides a memory-efficient alternative by eliminating the need\nfor backpropagation. However, ZO optimization suffers from high gradient\nvariance, and prior research has largely focused on single-task learning,\nleaving its application to multi-task learning unexplored. Multi-task learning\nis crucial for leveraging shared knowledge across tasks to improve\ngeneralization, yet it introduces unique challenges under ZO settings, such as\namplified gradient variance and collinearity. In this paper, we present MaZO,\nthe first framework specifically designed for multi-task LLM fine-tuning under\nZO optimization. MaZO tackles these challenges at the parameter level through\ntwo key innovations: a weight importance metric to identify critical parameters\nand a multi-task weight update mask to selectively update these parameters,\nreducing the dimensionality of the parameter space and mitigating task\nconflicts. Experiments demonstrate that MaZO achieves state-of-the-art\nperformance, surpassing even multi-task learning methods designed for\nfirst-order optimization.'}","['Zhen Zhang', 'Yifan Yang', 'Kai Zhen', 'Nathan Susanj', 'Athanasios Mouchtaris', 'Siegfried Kunzmann', 'Zheng Zhang']",{'name': 'Zheng Zhang'},Zheng Zhang,17 pages,"[{'href': 'http://arxiv.org/abs/2502.11513v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11513v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11513v1,None,http://arxiv.org/abs/2502.11513v1,,,346,0
http://arxiv.org/abs/2502.11519v1,True,2025-02-17T07:40:32Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=7, tm_min=40, tm_sec=32, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T07:40:32Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=7, tm_min=40, tm_sec=32, tm_wday=0, tm_yday=48, tm_isdst=0)","UniGO: A Unified Graph Neural Network for Modeling Opinion Dynamics on
  Graphs","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'UniGO: A Unified Graph Neural Network for Modeling Opinion Dynamics on\n  Graphs'}","Polarization and fragmentation in social media amplify user biases, making it
increasingly important to understand the evolution of opinions. Opinion
dynamics provide interpretability for studying opinion evolution, yet
incorporating these insights into predictive models remains challenging. This
challenge arises due to the inherent complexity of the diversity of opinion
fusion rules and the difficulty in capturing equilibrium states while avoiding
over-smoothing. This paper constructs a unified opinion dynamics model to
integrate different opinion fusion rules and generates corresponding synthetic
datasets. To fully leverage the advantages of unified opinion dynamics, we
introduces UniGO, a framework for modeling opinion evolution on graphs. Using a
coarsen-refine mechanism, UniGO efficiently models opinion dynamics through a
graph neural network, mitigating over-smoothing while preserving equilibrium
phenomena. UniGO leverages pretraining on synthetic datasets, which enhances
its ability to generalize to real-world scenarios, providing a viable paradigm
for applications of opinion dynamics. Experimental results on both synthetic
and real-world datasets demonstrate UniGO's effectiveness in capturing complex
opinion formation processes and predicting future evolution. The pretrained
model also shows strong generalization capability, validating the benefits of
using synthetic data to boost real-world performance.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Polarization and fragmentation in social media amplify user biases, making it\nincreasingly important to understand the evolution of opinions. Opinion\ndynamics provide interpretability for studying opinion evolution, yet\nincorporating these insights into predictive models remains challenging. This\nchallenge arises due to the inherent complexity of the diversity of opinion\nfusion rules and the difficulty in capturing equilibrium states while avoiding\nover-smoothing. This paper constructs a unified opinion dynamics model to\nintegrate different opinion fusion rules and generates corresponding synthetic\ndatasets. To fully leverage the advantages of unified opinion dynamics, we\nintroduces UniGO, a framework for modeling opinion evolution on graphs. Using a\ncoarsen-refine mechanism, UniGO efficiently models opinion dynamics through a\ngraph neural network, mitigating over-smoothing while preserving equilibrium\nphenomena. UniGO leverages pretraining on synthetic datasets, which enhances\nits ability to generalize to real-world scenarios, providing a viable paradigm\nfor applications of opinion dynamics. Experimental results on both synthetic\nand real-world datasets demonstrate UniGO's effectiveness in capturing complex\nopinion formation processes and predicting future evolution. The pretrained\nmodel also shows strong generalization capability, validating the benefits of\nusing synthetic data to boost real-world performance.""}","['Hao Li', 'Hao Jiang', 'Yuke Zheng', 'Hao Sun', 'Wenying Gong']",{'name': 'Wenying Gong'},Wenying Gong,WWW2025,"[{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3696410.3714636', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2502.11519v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11519v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11519v1,None,http://arxiv.org/abs/2502.11519v1,,10.1145/3696410.3714636,2,0
http://arxiv.org/abs/2502.11521v1,True,2025-02-17T07:45:03Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=7, tm_min=45, tm_sec=3, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T07:45:03Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=7, tm_min=45, tm_sec=3, tm_wday=0, tm_yday=48, tm_isdst=0)",DeFiScope: Detecting Various DeFi Price Manipulations with LLM Reasoning,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'DeFiScope: Detecting Various DeFi Price Manipulations with LLM Reasoning'}","DeFi (Decentralized Finance) is one of the most important applications of
today's cryptocurrencies and smart contracts. It manages hundreds of billions
in Total Value Locked (TVL) on-chain, yet it remains susceptible to common DeFi
price manipulation attacks. Despite state-of-the-art (SOTA) systems like
DeFiRanger and DeFort, we found that they are less effective to non-standard
price models in custom DeFi protocols, which account for 44.2% of the 95 DeFi
price manipulation attacks reported over the past three years.
  In this paper, we introduce the first LLM-based approach, DeFiScope, for
detecting DeFi price manipulation attacks in both standard and custom price
models. Our insight is that large language models (LLMs) have certain
intelligence to abstract price calculation from code and infer the trend of
token price changes based on the extracted price models. To further strengthen
LLMs in this aspect, we leverage Foundry to synthesize on-chain data and use it
to fine-tune a DeFi price-specific LLM. Together with the high-level DeFi
operations recovered from low-level transaction data, DeFiScope detects various
DeFi price manipulations according to systematically mined patterns.
Experimental results show that DeFiScope achieves a high precision of 96% and a
recall rate of 80%, significantly outperforming SOTA approaches. Moreover, we
evaluate DeFiScope's cost-effectiveness and demonstrate its practicality by
helping our industry partner confirm 147 real-world price manipulation attacks,
including discovering 81 previously unknown historical incidents.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""DeFi (Decentralized Finance) is one of the most important applications of\ntoday's cryptocurrencies and smart contracts. It manages hundreds of billions\nin Total Value Locked (TVL) on-chain, yet it remains susceptible to common DeFi\nprice manipulation attacks. Despite state-of-the-art (SOTA) systems like\nDeFiRanger and DeFort, we found that they are less effective to non-standard\nprice models in custom DeFi protocols, which account for 44.2% of the 95 DeFi\nprice manipulation attacks reported over the past three years.\n  In this paper, we introduce the first LLM-based approach, DeFiScope, for\ndetecting DeFi price manipulation attacks in both standard and custom price\nmodels. Our insight is that large language models (LLMs) have certain\nintelligence to abstract price calculation from code and infer the trend of\ntoken price changes based on the extracted price models. To further strengthen\nLLMs in this aspect, we leverage Foundry to synthesize on-chain data and use it\nto fine-tune a DeFi price-specific LLM. Together with the high-level DeFi\noperations recovered from low-level transaction data, DeFiScope detects various\nDeFi price manipulations according to systematically mined patterns.\nExperimental results show that DeFiScope achieves a high precision of 96% and a\nrecall rate of 80%, significantly outperforming SOTA approaches. Moreover, we\nevaluate DeFiScope's cost-effectiveness and demonstrate its practicality by\nhelping our industry partner confirm 147 real-world price manipulation attacks,\nincluding discovering 81 previously unknown historical incidents.""}","['Juantao Zhong', 'Daoyuan Wu', 'Ye Liu', 'Maoyi Xie', 'Yang Liu', 'Yi Li', 'Ning Liu']",{'name': 'Ning Liu'},Ning Liu,,"[{'href': 'http://arxiv.org/abs/2502.11521v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11521v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11521v1,None,http://arxiv.org/abs/2502.11521v1,,,151,0
http://arxiv.org/abs/2502.11537v2,True,2025-02-20T10:35:54Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=10, tm_min=35, tm_sec=54, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-17T08:06:10Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=8, tm_min=6, tm_sec=10, tm_wday=0, tm_yday=48, tm_isdst=0)",$\text{M}^{\text{3}}$: A Modular World Model over Streams of Tokens,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': '$\\text{M}^{\\text{3}}$: A Modular World Model over Streams of Tokens'}","Token-based world models emerged as a promising modular framework, modeling
dynamics over token streams while optimizing tokenization separately. While
successful in visual environments with discrete actions (e.g., Atari games),
their broader applicability remains uncertain. In this paper, we introduce
$\text{M}^{\text{3}}$, a $\textbf{m}$odular $\textbf{w}$orld $\textbf{m}$odel
that extends this framework, enabling flexible combinations of observation and
action modalities through independent modality-specific components.
$\text{M}^{\text{3}}$ integrates several improvements from existing literature
to enhance agent performance. Through extensive empirical evaluation across
diverse benchmarks, $\text{M}^{\text{3}}$ achieves state-of-the-art sample
efficiency for planning-free world models. Notably, among these methods, it is
the first to reach a human-level median score on Atari 100K, with superhuman
performance on 13 games. Our code and model weights are publicly available at
https://github.com/leor-c/M3.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Token-based world models emerged as a promising modular framework, modeling\ndynamics over token streams while optimizing tokenization separately. While\nsuccessful in visual environments with discrete actions (e.g., Atari games),\ntheir broader applicability remains uncertain. In this paper, we introduce\n$\\text{M}^{\\text{3}}$, a $\\textbf{m}$odular $\\textbf{w}$orld $\\textbf{m}$odel\nthat extends this framework, enabling flexible combinations of observation and\naction modalities through independent modality-specific components.\n$\\text{M}^{\\text{3}}$ integrates several improvements from existing literature\nto enhance agent performance. Through extensive empirical evaluation across\ndiverse benchmarks, $\\text{M}^{\\text{3}}$ achieves state-of-the-art sample\nefficiency for planning-free world models. Notably, among these methods, it is\nthe first to reach a human-level median score on Atari 100K, with superhuman\nperformance on 13 games. Our code and model weights are publicly available at\nhttps://github.com/leor-c/M3.'}","['Lior Cohen', 'Kaixin Wang', 'Bingyi Kang', 'Uri Gadot', 'Shie Mannor']",{'name': 'Shie Mannor'},Shie Mannor,,"[{'href': 'http://arxiv.org/abs/2502.11537v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11537v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11537v2,None,http://arxiv.org/abs/2502.11537v2,,,371,0
http://arxiv.org/abs/2502.11541v1,True,2025-02-17T08:12:49Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=8, tm_min=12, tm_sec=49, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T08:12:49Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=8, tm_min=12, tm_sec=49, tm_wday=0, tm_yday=48, tm_isdst=0)","MuSC: Improving Complex Instruction Following with Multi-granularity
  Self-Contrastive Training","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'MuSC: Improving Complex Instruction Following with Multi-granularity\n  Self-Contrastive Training'}","Complex instruction-following with elaborate constraints is imperative for
Large Language Models (LLMs). While existing methods have constructed data for
complex instruction alignment, they all rely on a more advanced model,
especially GPT-4, limiting their application. In this paper, we propose a
Multi-granularity Self-Contrastive Training (MuSC) framework, to improve the
complex instruction alignment without relying on a stronger model. Our method
is conducted on both coarse and fine granularity. On coarse-granularity, we
construct constraint-aware preference data based on instruction decomposition
and recombination. On fine-granularity, we perform token-aware preference
optimization with dynamic token-level supervision. Our method is evaluated on
open-sourced models, and experiment results show our method achieves
significant improvement on both complex and general instruction-following
benchmarks, surpassing previous self-alignment methods.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Complex instruction-following with elaborate constraints is imperative for\nLarge Language Models (LLMs). While existing methods have constructed data for\ncomplex instruction alignment, they all rely on a more advanced model,\nespecially GPT-4, limiting their application. In this paper, we propose a\nMulti-granularity Self-Contrastive Training (MuSC) framework, to improve the\ncomplex instruction alignment without relying on a stronger model. Our method\nis conducted on both coarse and fine granularity. On coarse-granularity, we\nconstruct constraint-aware preference data based on instruction decomposition\nand recombination. On fine-granularity, we perform token-aware preference\noptimization with dynamic token-level supervision. Our method is evaluated on\nopen-sourced models, and experiment results show our method achieves\nsignificant improvement on both complex and general instruction-following\nbenchmarks, surpassing previous self-alignment methods.'}","['Hui Huang', 'Jiaheng Liu', 'Yancheng He', 'Shilong Li', 'Bing Xu', 'Conghui Zhu', 'Muyun Yang', 'Tiejun Zhao']",{'name': 'Tiejun Zhao'},Tiejun Zhao,,"[{'href': 'http://arxiv.org/abs/2502.11541v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11541v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11541v1,None,http://arxiv.org/abs/2502.11541v1,,,654,0
http://arxiv.org/abs/2502.11559v1,True,2025-02-17T08:44:04Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=8, tm_min=44, tm_sec=4, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T08:44:04Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=8, tm_min=44, tm_sec=4, tm_wday=0, tm_yday=48, tm_isdst=0)","Auto-Search and Refinement: An Automated Framework for Gender Bias
  Mitigation in Large Language Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Auto-Search and Refinement: An Automated Framework for Gender Bias\n  Mitigation in Large Language Models'}","Pre-training large language models (LLMs) on vast text corpora enhances
natural language processing capabilities but risks encoding social biases,
particularly gender bias. While parameter-modification methods like fine-tuning
mitigate bias, they are resource-intensive, unsuitable for closed-source
models, and lack adaptability to evolving societal norms. Instruction-based
approaches offer flexibility but often compromise task performance. To address
these limitations, we propose $\textit{FaIRMaker}$, an automated and
model-independent framework that employs an $\textbf{auto-search and
refinement}$ paradigm to adaptively generate Fairwords, which act as
instructions integrated into input queries to reduce gender bias and enhance
response quality. Extensive experiments demonstrate that $\textit{FaIRMaker}$
automatically searches for and dynamically refines Fairwords, effectively
mitigating gender bias while preserving task integrity and ensuring
compatibility with both API-based and open-source LLMs.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Pre-training large language models (LLMs) on vast text corpora enhances\nnatural language processing capabilities but risks encoding social biases,\nparticularly gender bias. While parameter-modification methods like fine-tuning\nmitigate bias, they are resource-intensive, unsuitable for closed-source\nmodels, and lack adaptability to evolving societal norms. Instruction-based\napproaches offer flexibility but often compromise task performance. To address\nthese limitations, we propose $\\textit{FaIRMaker}$, an automated and\nmodel-independent framework that employs an $\\textbf{auto-search and\nrefinement}$ paradigm to adaptively generate Fairwords, which act as\ninstructions integrated into input queries to reduce gender bias and enhance\nresponse quality. Extensive experiments demonstrate that $\\textit{FaIRMaker}$\nautomatically searches for and dynamically refines Fairwords, effectively\nmitigating gender bias while preserving task integrity and ensuring\ncompatibility with both API-based and open-source LLMs.'}","['Yue Xu', 'Chengyan Fu', 'Li Xiong', 'Sibei Yang', 'Wenjie Wang']",{'name': 'Wenjie Wang'},Wenjie Wang,,"[{'href': 'http://arxiv.org/abs/2502.11559v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11559v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11559v1,None,http://arxiv.org/abs/2502.11559v1,,,19,0
http://arxiv.org/abs/2502.11560v1,True,2025-02-17T08:48:07Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=8, tm_min=48, tm_sec=7, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T08:48:07Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=8, tm_min=48, tm_sec=7, tm_wday=0, tm_yday=48, tm_isdst=0)",A Survey of Automatic Prompt Engineering: An Optimization Perspective,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A Survey of Automatic Prompt Engineering: An Optimization Perspective'}","The rise of foundation models has shifted focus from resource-intensive
fine-tuning to prompt engineering, a paradigm that steers model behavior
through input design rather than weight updates. While manual prompt
engineering faces limitations in scalability, adaptability, and cross-modal
alignment, automated methods, spanning foundation model (FM) based
optimization, evolutionary methods, gradient-based optimization, and
reinforcement learning, offer promising solutions. Existing surveys, however,
remain fragmented across modalities and methodologies. This paper presents the
first comprehensive survey on automated prompt engineering through a unified
optimization-theoretic lens. We formalize prompt optimization as a maximization
problem over discrete, continuous, and hybrid prompt spaces, systematically
organizing methods by their optimization variables (instructions, soft prompts,
exemplars), task-specific objectives, and computational frameworks. By bridging
theoretical formulation with practical implementations across text, vision, and
multimodal domains, this survey establishes a foundational framework for both
researchers and practitioners, while highlighting underexplored frontiers in
constrained optimization and agent-oriented prompt design.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The rise of foundation models has shifted focus from resource-intensive\nfine-tuning to prompt engineering, a paradigm that steers model behavior\nthrough input design rather than weight updates. While manual prompt\nengineering faces limitations in scalability, adaptability, and cross-modal\nalignment, automated methods, spanning foundation model (FM) based\noptimization, evolutionary methods, gradient-based optimization, and\nreinforcement learning, offer promising solutions. Existing surveys, however,\nremain fragmented across modalities and methodologies. This paper presents the\nfirst comprehensive survey on automated prompt engineering through a unified\noptimization-theoretic lens. We formalize prompt optimization as a maximization\nproblem over discrete, continuous, and hybrid prompt spaces, systematically\norganizing methods by their optimization variables (instructions, soft prompts,\nexemplars), task-specific objectives, and computational frameworks. By bridging\ntheoretical formulation with practical implementations across text, vision, and\nmultimodal domains, this survey establishes a foundational framework for both\nresearchers and practitioners, while highlighting underexplored frontiers in\nconstrained optimization and agent-oriented prompt design.'}","['Wenwu Li', 'Xiangfeng Wang', 'Wenhao Li', 'Bo Jin']",{'name': 'Bo Jin'},Bo Jin,"19 pages, 4 figures","[{'href': 'http://arxiv.org/abs/2502.11560v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11560v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11560v1,None,http://arxiv.org/abs/2502.11560v1,,,799,0
http://arxiv.org/abs/2502.11563v1,True,2025-02-17T08:52:45Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=8, tm_min=52, tm_sec=45, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T08:52:45Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=8, tm_min=52, tm_sec=45, tm_wday=0, tm_yday=48, tm_isdst=0)","Leader and Follower: Interactive Motion Generation under Trajectory
  Constraints","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Leader and Follower: Interactive Motion Generation under Trajectory\n  Constraints'}","With the rapid advancement of game and film production, generating
interactive motion from texts has garnered significant attention due to its
potential to revolutionize content creation processes. In many practical
applications, there is a need to impose strict constraints on the motion range
or trajectory of virtual characters. However, existing methods that rely solely
on textual input face substantial challenges in accurately capturing the user's
intent, particularly in specifying the desired trajectory. As a result, the
generated motions often lack plausibility and accuracy. Moreover, existing
trajectory - based methods for customized motion generation rely on retraining
for single - actor scenarios, which limits flexibility and adaptability to
different datasets, as well as interactivity in two-actor motions. To generate
interactive motion following specified trajectories, this paper decouples
complex motion into a Leader - Follower dynamic, inspired by role allocation in
partner dancing. Based on this framework, this paper explores the motion range
refinement process in interactive motion generation and proposes a
training-free approach, integrating a Pace Controller and a Kinematic
Synchronization Adapter. The framework enhances the ability of existing models
to generate motion that adheres to trajectory by controlling the leader's
movement and correcting the follower's motion to align with the leader.
Experimental results show that the proposed approach, by better leveraging
trajectory information, outperforms existing methods in both realism and
accuracy.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""With the rapid advancement of game and film production, generating\ninteractive motion from texts has garnered significant attention due to its\npotential to revolutionize content creation processes. In many practical\napplications, there is a need to impose strict constraints on the motion range\nor trajectory of virtual characters. However, existing methods that rely solely\non textual input face substantial challenges in accurately capturing the user's\nintent, particularly in specifying the desired trajectory. As a result, the\ngenerated motions often lack plausibility and accuracy. Moreover, existing\ntrajectory - based methods for customized motion generation rely on retraining\nfor single - actor scenarios, which limits flexibility and adaptability to\ndifferent datasets, as well as interactivity in two-actor motions. To generate\ninteractive motion following specified trajectories, this paper decouples\ncomplex motion into a Leader - Follower dynamic, inspired by role allocation in\npartner dancing. Based on this framework, this paper explores the motion range\nrefinement process in interactive motion generation and proposes a\ntraining-free approach, integrating a Pace Controller and a Kinematic\nSynchronization Adapter. The framework enhances the ability of existing models\nto generate motion that adheres to trajectory by controlling the leader's\nmovement and correcting the follower's motion to align with the leader.\nExperimental results show that the proposed approach, by better leveraging\ntrajectory information, outperforms existing methods in both realism and\naccuracy.""}","['Runqi Wang', 'Caoyuan Ma', 'Jian Zhao', 'Hanrui Xu', 'Dongfang Sun', 'Haoyang Chen', 'Lin Xiong', 'Zheng Wang', 'Xuelong Li']",{'name': 'Xuelong Li'},Xuelong Li,,"[{'href': 'http://arxiv.org/abs/2502.11563v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11563v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11563v1,None,http://arxiv.org/abs/2502.11563v1,,,14,0
http://arxiv.org/abs/2502.11573v1,True,2025-02-17T09:07:32Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=9, tm_min=7, tm_sec=32, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T09:07:32Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=9, tm_min=7, tm_sec=32, tm_wday=0, tm_yday=48, tm_isdst=0)","InfiR : Crafting Effective Small Language Models and Multimodal Small
  Language Models in Reasoning","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'InfiR : Crafting Effective Small Language Models and Multimodal Small\n  Language Models in Reasoning'}","Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs)
have made significant advancements in reasoning capabilities. However, they
still face challenges such as high computational demands and privacy concerns.
This paper focuses on developing efficient Small Language Models (SLMs) and
Multimodal Small Language Models (MSLMs) that retain competitive reasoning
abilities. We introduce a novel training pipeline that enhances reasoning
capabilities and facilitates deployment on edge devices, achieving
state-of-the-art performance while minimizing development costs. \InfR~ aims to
advance AI systems by improving reasoning, reducing adoption barriers, and
addressing privacy concerns through smaller model sizes. Resources are
available at https://github. com/Reallm-Labs/InfiR.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs)\nhave made significant advancements in reasoning capabilities. However, they\nstill face challenges such as high computational demands and privacy concerns.\nThis paper focuses on developing efficient Small Language Models (SLMs) and\nMultimodal Small Language Models (MSLMs) that retain competitive reasoning\nabilities. We introduce a novel training pipeline that enhances reasoning\ncapabilities and facilitates deployment on edge devices, achieving\nstate-of-the-art performance while minimizing development costs. \\InfR~ aims to\nadvance AI systems by improving reasoning, reducing adoption barriers, and\naddressing privacy concerns through smaller model sizes. Resources are\navailable at https://github. com/Reallm-Labs/InfiR.'}","['Congkai Xie', 'Shuo Cai', 'Wenjun Wang', 'Pengxiang Li', 'Zhijie Sang', 'Kejing Yang', 'Yiming Zhang', 'Zhen Li', 'Guanghao Zhu', 'Zeyu Liu', 'Yang Yu', 'Yuhang Liu', 'Su Lu', 'Baoyi He', 'Qi Zhou', 'Xiaotian Han', 'Jianbo Yuan', 'Shengyu Zhang', 'Fei Wu', 'Hongxia Yang']",{'name': 'Hongxia Yang'},Hongxia Yang,,"[{'href': 'http://arxiv.org/abs/2502.11573v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11573v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11573v1,None,http://arxiv.org/abs/2502.11573v1,,,422,0
http://arxiv.org/abs/2502.11578v1,True,2025-02-17T09:09:58Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=9, tm_min=9, tm_sec=58, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T09:09:58Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=9, tm_min=9, tm_sec=58, tm_wday=0, tm_yday=48, tm_isdst=0)","Language Complexity Measurement as a Noisy Zero-Shot Proxy for
  Evaluating LLM Performance","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Language Complexity Measurement as a Noisy Zero-Shot Proxy for\n  Evaluating LLM Performance'}","Large Language Models (LLMs) have made significant strides in natural
language generation but often face challenges in tasks requiring precise
calculations and structural analysis. This paper investigates the performance
of state-of-the-art LLMs on language complexity measurement tasks, through the
computation of the LIX readability metric and Average Dependency Distance
(ADD). Using Swedish high school and university-level essays, we evaluate the
models' abilities to compute LIX scores and perform dependency parsing,
comparing their results to established ground truths. Our findings reveal that
while all models demonstrate some capacity for these tasks, ChatGPT-o1-mini
performs most consistently, achieving the highest accuracy in both LIX
computation and dependency parsing. Additionally, we observe a strong
significant correlation -0.875 p 0.026 (N=6) between the models' accuracy in
computing LIX and their overall performance on the Massive Multitask Language
Understanding (MMLU) benchmark. These results suggest that language complexity
measurement abilities can serve as a noisy zero-shot proxies for assessing the
general capabilities of LLMs, providing a practical method for model evaluation
without the need for extensive benchmarking datasets.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Large Language Models (LLMs) have made significant strides in natural\nlanguage generation but often face challenges in tasks requiring precise\ncalculations and structural analysis. This paper investigates the performance\nof state-of-the-art LLMs on language complexity measurement tasks, through the\ncomputation of the LIX readability metric and Average Dependency Distance\n(ADD). Using Swedish high school and university-level essays, we evaluate the\nmodels' abilities to compute LIX scores and perform dependency parsing,\ncomparing their results to established ground truths. Our findings reveal that\nwhile all models demonstrate some capacity for these tasks, ChatGPT-o1-mini\nperforms most consistently, achieving the highest accuracy in both LIX\ncomputation and dependency parsing. Additionally, we observe a strong\nsignificant correlation -0.875 p 0.026 (N=6) between the models' accuracy in\ncomputing LIX and their overall performance on the Massive Multitask Language\nUnderstanding (MMLU) benchmark. These results suggest that language complexity\nmeasurement abilities can serve as a noisy zero-shot proxies for assessing the\ngeneral capabilities of LLMs, providing a practical method for model evaluation\nwithout the need for extensive benchmarking datasets.""}","['Birger Moell', 'Johan Boye']",{'name': 'Johan Boye'},Johan Boye,Submitted to ACL 2025,"[{'href': 'http://arxiv.org/abs/2502.11578v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11578v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11578v1,None,http://arxiv.org/abs/2502.11578v1,,,33,0
http://arxiv.org/abs/2502.11588v1,True,2025-02-17T09:21:53Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=9, tm_min=21, tm_sec=53, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T09:21:53Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=9, tm_min=21, tm_sec=53, tm_wday=0, tm_yday=48, tm_isdst=0)",A Unified Modeling Framework for Automated Penetration Testing,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A Unified Modeling Framework for Automated Penetration Testing'}","The integration of artificial intelligence into automated penetration testing
(AutoPT) has highlighted the necessity of simulation modeling for the training
of intelligent agents, due to its cost-efficiency and swift feedback
capabilities. Despite the proliferation of AutoPT research, there is a
recognized gap in the availability of a unified framework for simulation
modeling methods. This paper presents a systematic review and synthesis of
existing techniques, introducing MDCPM to categorize studies based on
literature objectives, network simulation complexity, dependency of technical
and tactical operations, and scenario feedback and variation. To bridge the gap
in unified method for multi-dimensional and multi-level simulation modeling,
dynamic environment modeling, and the scarcity of public datasets, we introduce
AutoPT-Sim, a novel modeling framework that based on policy automation and
encompasses the combination of all sub dimensions. AutoPT-Sim offers a
comprehensive approach to modeling network environments, attackers, and
defenders, transcending the constraints of static modeling and accommodating
networks of diverse scales. We publicly release a generated standard network
environment dataset and the code of Network Generator. By integrating publicly
available datasets flexibly, support is offered for various simulation modeling
levels focused on policy automation in MDCPM and the network generator help
researchers output customized target network data by adjusting parameters or
fine-tuning the network generator.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The integration of artificial intelligence into automated penetration testing\n(AutoPT) has highlighted the necessity of simulation modeling for the training\nof intelligent agents, due to its cost-efficiency and swift feedback\ncapabilities. Despite the proliferation of AutoPT research, there is a\nrecognized gap in the availability of a unified framework for simulation\nmodeling methods. This paper presents a systematic review and synthesis of\nexisting techniques, introducing MDCPM to categorize studies based on\nliterature objectives, network simulation complexity, dependency of technical\nand tactical operations, and scenario feedback and variation. To bridge the gap\nin unified method for multi-dimensional and multi-level simulation modeling,\ndynamic environment modeling, and the scarcity of public datasets, we introduce\nAutoPT-Sim, a novel modeling framework that based on policy automation and\nencompasses the combination of all sub dimensions. AutoPT-Sim offers a\ncomprehensive approach to modeling network environments, attackers, and\ndefenders, transcending the constraints of static modeling and accommodating\nnetworks of diverse scales. We publicly release a generated standard network\nenvironment dataset and the code of Network Generator. By integrating publicly\navailable datasets flexibly, support is offered for various simulation modeling\nlevels focused on policy automation in MDCPM and the network generator help\nresearchers output customized target network data by adjusting parameters or\nfine-tuning the network generator.'}","['Yunfei Wang', 'Shixuan Liu', 'Wenhao Wang', 'Changling Zhou', 'Chao Zhang', 'Jiandong Jin', 'Cheng Zhu']",{'name': 'Cheng Zhu'},Cheng Zhu,,"[{'href': 'http://arxiv.org/abs/2502.11588v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11588v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11588v1,None,http://arxiv.org/abs/2502.11588v1,,,20,0
http://arxiv.org/abs/2502.11596v1,True,2025-02-17T09:28:51Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=9, tm_min=28, tm_sec=51, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T09:28:51Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=9, tm_min=28, tm_sec=51, tm_wday=0, tm_yday=48, tm_isdst=0)",LLM Embeddings for Deep Learning on Tabular Data,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'LLM Embeddings for Deep Learning on Tabular Data'}","Tabular deep-learning methods require embedding numerical and categorical
input features into high-dimensional spaces before processing them. Existing
methods deal with this heterogeneous nature of tabular data by employing
separate type-specific encoding approaches. This limits the cross-table
transfer potential and the exploitation of pre-trained knowledge. We propose a
novel approach that first transforms tabular data into text, and then leverages
pre-trained representations from LLMs to encode this data, resulting in a
plug-and-play solution to improv ing deep-learning tabular methods. We
demonstrate that our approach improves accuracy over competitive models, such
as MLP, ResNet and FT-Transformer, by validating on seven classification
datasets.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Tabular deep-learning methods require embedding numerical and categorical\ninput features into high-dimensional spaces before processing them. Existing\nmethods deal with this heterogeneous nature of tabular data by employing\nseparate type-specific encoding approaches. This limits the cross-table\ntransfer potential and the exploitation of pre-trained knowledge. We propose a\nnovel approach that first transforms tabular data into text, and then leverages\npre-trained representations from LLMs to encode this data, resulting in a\nplug-and-play solution to improv ing deep-learning tabular methods. We\ndemonstrate that our approach improves accuracy over competitive models, such\nas MLP, ResNet and FT-Transformer, by validating on seven classification\ndatasets.'}","['Boshko Koloski', 'Andrei Margeloiu', 'Xiangjian Jiang', 'Bla krlj', 'Nikola Simidjievski', 'Mateja Jamnik']",{'name': 'Mateja Jamnik'},Mateja Jamnik,,"[{'href': 'http://arxiv.org/abs/2502.11596v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11596v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11596v1,None,http://arxiv.org/abs/2502.11596v1,,,2122,0
http://arxiv.org/abs/2502.11603v1,True,2025-02-17T09:43:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=9, tm_min=43, tm_sec=36, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T09:43:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=9, tm_min=43, tm_sec=36, tm_wday=0, tm_yday=48, tm_isdst=0)","DR.GAP: Mitigating Bias in Large Language Models using Gender-Aware
  Prompting with Demonstration and Reasoning","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'DR.GAP: Mitigating Bias in Large Language Models using Gender-Aware\n  Prompting with Demonstration and Reasoning'}","Large Language Models (LLMs) exhibit strong natural language processing
capabilities but also inherit and amplify societal biases, including gender
bias, raising fairness concerns. Existing debiasing methods face significant
limitations: parameter tuning requires access to model weights, prompt-based
approaches often degrade model utility, and optimization-based techniques lack
generalizability. To address these challenges, we propose DR.GAP (Demonstration
and Reasoning for Gender-Aware Prompting), an automated and model-agnostic
approach that mitigates gender bias while preserving model performance. DR.GAP
selects bias-revealing examples and generates structured reasoning to guide
models toward more impartial responses. Extensive experiments on coreference
resolution and QA tasks across multiple LLMs (GPT-3.5, Llama3, and
Llama2-Alpaca) demonstrate its effectiveness, generalization ability, and
robustness. DR.GAP can generalize to vision-language models (VLMs), achieving
significant bias reduction.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Language Models (LLMs) exhibit strong natural language processing\ncapabilities but also inherit and amplify societal biases, including gender\nbias, raising fairness concerns. Existing debiasing methods face significant\nlimitations: parameter tuning requires access to model weights, prompt-based\napproaches often degrade model utility, and optimization-based techniques lack\ngeneralizability. To address these challenges, we propose DR.GAP (Demonstration\nand Reasoning for Gender-Aware Prompting), an automated and model-agnostic\napproach that mitigates gender bias while preserving model performance. DR.GAP\nselects bias-revealing examples and generates structured reasoning to guide\nmodels toward more impartial responses. Extensive experiments on coreference\nresolution and QA tasks across multiple LLMs (GPT-3.5, Llama3, and\nLlama2-Alpaca) demonstrate its effectiveness, generalization ability, and\nrobustness. DR.GAP can generalize to vision-language models (VLMs), achieving\nsignificant bias reduction.'}","['Hongye Qiu', 'Yue Xu', 'Meikang Qiu', 'Wenjie Wang']",{'name': 'Wenjie Wang'},Wenjie Wang,,"[{'href': 'http://arxiv.org/abs/2502.11603v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11603v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11603v1,None,http://arxiv.org/abs/2502.11603v1,,,17,0
http://arxiv.org/abs/2502.11611v1,True,2025-02-17T09:55:32Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=9, tm_min=55, tm_sec=32, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T09:55:32Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=9, tm_min=55, tm_sec=32, tm_wday=0, tm_yday=48, tm_isdst=0)","Identifying Gender Stereotypes and Biases in Automated Translation from
  English to Italian using Similarity Networks","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Identifying Gender Stereotypes and Biases in Automated Translation from\n  English to Italian using Similarity Networks'}","This paper is a collaborative effort between Linguistics, Law, and Computer
Science to evaluate stereotypes and biases in automated translation systems. We
advocate gender-neutral translation as a means to promote gender inclusion and
improve the objectivity of machine translation. Our approach focuses on
identifying gender bias in English-to-Italian translations. First, we define
gender bias following human rights law and linguistics literature. Then we
proceed by identifying gender-specific terms such as she/lei and he/lui as key
elements. We then evaluate the cosine similarity between these target terms and
others in the dataset to reveal the model's perception of semantic relations.
Using numerical features, we effectively evaluate the intensity and direction
of the bias. Our findings provide tangible insights for developing and training
gender-neutral translation algorithms.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""This paper is a collaborative effort between Linguistics, Law, and Computer\nScience to evaluate stereotypes and biases in automated translation systems. We\nadvocate gender-neutral translation as a means to promote gender inclusion and\nimprove the objectivity of machine translation. Our approach focuses on\nidentifying gender bias in English-to-Italian translations. First, we define\ngender bias following human rights law and linguistics literature. Then we\nproceed by identifying gender-specific terms such as she/lei and he/lui as key\nelements. We then evaluate the cosine similarity between these target terms and\nothers in the dataset to reveal the model's perception of semantic relations.\nUsing numerical features, we effectively evaluate the intensity and direction\nof the bias. Our findings provide tangible insights for developing and training\ngender-neutral translation algorithms.""}","['Fatemeh Mohammadi', 'Marta Annamaria Tamborini', 'Paolo Ceravolo', 'Costanza Nardocci', 'Samira Maghool']",{'name': 'Samira Maghool'},Samira Maghool,,"[{'href': 'http://arxiv.org/abs/2502.11611v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11611v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11611v1,None,http://arxiv.org/abs/2502.11611v1,,,71,0
http://arxiv.org/abs/2502.11612v2,True,2025-02-18T09:33:28Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=9, tm_min=33, tm_sec=28, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-17T09:55:58Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=9, tm_min=55, tm_sec=58, tm_wday=0, tm_yday=48, tm_isdst=0)",Maximum Entropy Reinforcement Learning with Diffusion Policy,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Maximum Entropy Reinforcement Learning with Diffusion Policy'}","The Soft Actor-Critic (SAC) algorithm with a Gaussian policy has become a
mainstream implementation for realizing the Maximum Entropy Reinforcement
Learning (MaxEnt RL) objective, which incorporates entropy maximization to
encourage exploration and enhance policy robustness. While the Gaussian policy
performs well on simpler tasks, its exploration capacity and potential
performance in complex multi-goal RL environments are limited by its inherent
unimodality. In this paper, we employ the diffusion model, a powerful
generative model capable of capturing complex multimodal distributions, as the
policy representation to fulfill the MaxEnt RL objective, developing a method
named MaxEnt RL with Diffusion Policy (MaxEntDP). Our method enables efficient
exploration and brings the policy closer to the optimal MaxEnt policy.
Experimental results on Mujoco benchmarks show that MaxEntDP outperforms the
Gaussian policy and other generative models within the MaxEnt RL framework, and
performs comparably to other state-of-the-art diffusion-based online RL
algorithms. Our code is available at https://github.com/diffusionyes/MaxEntDP.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The Soft Actor-Critic (SAC) algorithm with a Gaussian policy has become a\nmainstream implementation for realizing the Maximum Entropy Reinforcement\nLearning (MaxEnt RL) objective, which incorporates entropy maximization to\nencourage exploration and enhance policy robustness. While the Gaussian policy\nperforms well on simpler tasks, its exploration capacity and potential\nperformance in complex multi-goal RL environments are limited by its inherent\nunimodality. In this paper, we employ the diffusion model, a powerful\ngenerative model capable of capturing complex multimodal distributions, as the\npolicy representation to fulfill the MaxEnt RL objective, developing a method\nnamed MaxEnt RL with Diffusion Policy (MaxEntDP). Our method enables efficient\nexploration and brings the policy closer to the optimal MaxEnt policy.\nExperimental results on Mujoco benchmarks show that MaxEntDP outperforms the\nGaussian policy and other generative models within the MaxEnt RL framework, and\nperforms comparably to other state-of-the-art diffusion-based online RL\nalgorithms. Our code is available at https://github.com/diffusionyes/MaxEntDP.'}","['Xiaoyi Dong', 'Jian Cheng', 'Xi Sheryl Zhang']",{'name': 'Xi Sheryl Zhang'},Xi Sheryl Zhang,"21 pages, 7 figures","[{'href': 'http://arxiv.org/abs/2502.11612v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11612v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11612v2,None,http://arxiv.org/abs/2502.11612v2,,,6,0
http://arxiv.org/abs/2502.11614v1,True,2025-02-17T09:56:46Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=9, tm_min=56, tm_sec=46, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T09:56:46Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=9, tm_min=56, tm_sec=46, tm_wday=0, tm_yday=48, tm_isdst=0)","Is Human-Like Text Liked by Humans? Multilingual Human Detection and
  Preference Against AI","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Is Human-Like Text Liked by Humans? Multilingual Human Detection and\n  Preference Against AI'}","Prior studies have shown that distinguishing text generated by large language
models (LLMs) from human-written one is highly challenging, and often no better
than random guessing. To verify the generalizability of this finding across
languages and domains, we perform an extensive case study to identify the upper
bound of human detection accuracy. Across 16 datasets covering 9 languages and
9 domains, 19 annotators achieved an average detection accuracy of 87.6%, thus
challenging previous conclusions. We find that major gaps between human and
machine text lie in concreteness, cultural nuances, and diversity. Prompting by
explicitly explaining the distinctions in the prompts can partially bridge the
gaps in over 50% of the cases. However, we also find that humans do not always
prefer human-written text, particularly when they cannot clearly identify its
source.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Prior studies have shown that distinguishing text generated by large language\nmodels (LLMs) from human-written one is highly challenging, and often no better\nthan random guessing. To verify the generalizability of this finding across\nlanguages and domains, we perform an extensive case study to identify the upper\nbound of human detection accuracy. Across 16 datasets covering 9 languages and\n9 domains, 19 annotators achieved an average detection accuracy of 87.6%, thus\nchallenging previous conclusions. We find that major gaps between human and\nmachine text lie in concreteness, cultural nuances, and diversity. Prompting by\nexplicitly explaining the distinctions in the prompts can partially bridge the\ngaps in over 50% of the cases. However, we also find that humans do not always\nprefer human-written text, particularly when they cannot clearly identify its\nsource.'}","['Yuxia Wang', 'Rui Xing', 'Jonibek Mansurov', 'Giovanni Puccetti', 'Zhuohan Xie', 'Minh Ngoc Ta', 'Jiahui Geng', 'Jinyan Su', 'Mervat Abassy', 'Saad El Dine Ahmed', 'Kareem Elozeiri', 'Nurkhan Laiyk', 'Maiya Goloburda', 'Tarek Mahmoud', 'Raj Vardhan Tomar', 'Alexander Aziz', 'Ryuto Koike', 'Masahiro Kaneko', 'Artem Shelmanov', 'Ekaterina Artemova', 'Vladislav Mikhailov', 'Akim Tsvigun', 'Alham Fikri Aji', 'Nizar Habash', 'Iryna Gurevych', 'Preslav Nakov']",{'name': 'Preslav Nakov'},Preslav Nakov,,"[{'href': 'http://arxiv.org/abs/2502.11614v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11614v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11614v1,None,http://arxiv.org/abs/2502.11614v1,,,13484,0
http://arxiv.org/abs/2502.11644v1,True,2025-02-17T10:38:00Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=10, tm_min=38, tm_sec=0, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T10:38:00Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=10, tm_min=38, tm_sec=0, tm_wday=0, tm_yday=48, tm_isdst=0)","InTec: integrated things-edge computing: a framework for distributing
  machine learning pipelines in edge AI systems","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'InTec: integrated things-edge computing: a framework for distributing\n  machine learning pipelines in edge AI systems'}","With the rapid expansion of the Internet of Things (IoT), sensors,
smartphones, and wearables have become integral to daily life, powering smart
applications in home automation, healthcare, and intelligent transportation.
However, these advancements face significant challenges due to latency and
bandwidth constraints imposed by traditional cloud based machine learning (ML)
frameworks. The need for innovative solutions is evident as cloud computing
struggles with increased latency and network congestion. Previous attempts to
offload parts of the ML pipeline to edge and cloud layers have yet to fully
resolve these issues, often worsening system response times and network
congestion due to the computational limitations of edge devices. In response to
these challenges, this study introduces the InTec (Integrated Things Edge
Computing) framework, a groundbreaking innovation in IoT architecture. Unlike
existing methods, InTec fully leverages the potential of a three tier
architecture by strategically distributing ML tasks across the Things, Edge,
and Cloud layers. This comprehensive approach enables real time data processing
at the point of data generation, significantly reducing latency, optimizing
network traffic, and enhancing system reliability. InTec effectiveness is
validated through empirical evaluation using the MHEALTH dataset for human
motion detection in smart homes, demonstrating notable improvements in key
metrics: an 81.56 percent reduction in response time, a 10.92 percent decrease
in network traffic, a 9.82 percent improvement in throughput, a 21.86 percent
reduction in edge energy consumption, and a 25.83 percent reduction in cloud
energy consumption. These advancements establish InTec as a new benchmark for
scalable, responsive, and energy efficient IoT applications, demonstrating its
potential to revolutionize how the ML pipeline is integrated into Edge AI (EI)
systems.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'With the rapid expansion of the Internet of Things (IoT), sensors,\nsmartphones, and wearables have become integral to daily life, powering smart\napplications in home automation, healthcare, and intelligent transportation.\nHowever, these advancements face significant challenges due to latency and\nbandwidth constraints imposed by traditional cloud based machine learning (ML)\nframeworks. The need for innovative solutions is evident as cloud computing\nstruggles with increased latency and network congestion. Previous attempts to\noffload parts of the ML pipeline to edge and cloud layers have yet to fully\nresolve these issues, often worsening system response times and network\ncongestion due to the computational limitations of edge devices. In response to\nthese challenges, this study introduces the InTec (Integrated Things Edge\nComputing) framework, a groundbreaking innovation in IoT architecture. Unlike\nexisting methods, InTec fully leverages the potential of a three tier\narchitecture by strategically distributing ML tasks across the Things, Edge,\nand Cloud layers. This comprehensive approach enables real time data processing\nat the point of data generation, significantly reducing latency, optimizing\nnetwork traffic, and enhancing system reliability. InTec effectiveness is\nvalidated through empirical evaluation using the MHEALTH dataset for human\nmotion detection in smart homes, demonstrating notable improvements in key\nmetrics: an 81.56 percent reduction in response time, a 10.92 percent decrease\nin network traffic, a 9.82 percent improvement in throughput, a 21.86 percent\nreduction in edge energy consumption, and a 25.83 percent reduction in cloud\nenergy consumption. These advancements establish InTec as a new benchmark for\nscalable, responsive, and energy efficient IoT applications, demonstrating its\npotential to revolutionize how the ML pipeline is integrated into Edge AI (EI)\nsystems.'}","['Habib Larian', 'Faramarz Safi-Esfahani']",{'name': 'Faramarz Safi-Esfahani'},Faramarz Safi-Esfahani,"For InTec framework implementation, see GitHub repository
  https://github.com/IDASLab/InTec_Framework","[{'title': 'doi', 'href': 'http://dx.doi.org/10.1007/s00607-024-01388-6', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2502.11644v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11644v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.DC', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.DC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68M14, 68T05', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11644v1,None,http://arxiv.org/abs/2502.11644v1,"Computing 107, 41 (2025)",10.1007/s00607-024-01388-6,474,0
http://arxiv.org/abs/2502.11647v1,True,2025-02-17T10:39:21Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=10, tm_min=39, tm_sec=21, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T10:39:21Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=10, tm_min=39, tm_sec=21, tm_wday=0, tm_yday=48, tm_isdst=0)","DELMAN: Dynamic Defense Against Large Language Model Jailbreaking with
  Model Editing","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'DELMAN: Dynamic Defense Against Large Language Model Jailbreaking with\n  Model Editing'}","Large Language Models (LLMs) are widely applied in decision making, but their
deployment is threatened by jailbreak attacks, where adversarial users
manipulate model behavior to bypass safety measures. Existing defense
mechanisms, such as safety fine-tuning and model editing, either require
extensive parameter modifications or lack precision, leading to performance
degradation on general tasks, which is unsuitable to post-deployment safety
alignment. To address these challenges, we propose DELMAN (Dynamic Editing for
LLMs JAilbreak DefeNse), a novel approach leveraging direct model editing for
precise, dynamic protection against jailbreak attacks. DELMAN directly updates
a minimal set of relevant parameters to neutralize harmful behaviors while
preserving the model's utility. To avoid triggering a safe response in benign
context, we incorporate KL-divergence regularization to ensure the updated
model remains consistent with the original model when processing benign
queries. Experimental results demonstrate that DELMAN outperforms baseline
methods in mitigating jailbreak attacks while preserving the model's utility,
and adapts seamlessly to new attack instances, providing a practical and
efficient solution for post-deployment model protection.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Large Language Models (LLMs) are widely applied in decision making, but their\ndeployment is threatened by jailbreak attacks, where adversarial users\nmanipulate model behavior to bypass safety measures. Existing defense\nmechanisms, such as safety fine-tuning and model editing, either require\nextensive parameter modifications or lack precision, leading to performance\ndegradation on general tasks, which is unsuitable to post-deployment safety\nalignment. To address these challenges, we propose DELMAN (Dynamic Editing for\nLLMs JAilbreak DefeNse), a novel approach leveraging direct model editing for\nprecise, dynamic protection against jailbreak attacks. DELMAN directly updates\na minimal set of relevant parameters to neutralize harmful behaviors while\npreserving the model's utility. To avoid triggering a safe response in benign\ncontext, we incorporate KL-divergence regularization to ensure the updated\nmodel remains consistent with the original model when processing benign\nqueries. Experimental results demonstrate that DELMAN outperforms baseline\nmethods in mitigating jailbreak attacks while preserving the model's utility,\nand adapts seamlessly to new attack instances, providing a practical and\nefficient solution for post-deployment model protection.""}","['Yi Wang', 'Fenghua Weng', 'Sibei Yang', 'Zhan Qin', 'Minlie Huang', 'Wenjie Wang']",{'name': 'Wenjie Wang'},Wenjie Wang,,"[{'href': 'http://arxiv.org/abs/2502.11647v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11647v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11647v1,None,http://arxiv.org/abs/2502.11647v1,,,0,0
http://arxiv.org/abs/2502.11649v1,True,2025-02-17T10:41:55Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=10, tm_min=41, tm_sec=55, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T10:41:55Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=10, tm_min=41, tm_sec=55, tm_wday=0, tm_yday=48, tm_isdst=0)",Competing LLM Agents in a Non-Cooperative Game of Opinion Polarisation,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Competing LLM Agents in a Non-Cooperative Game of Opinion Polarisation'}","We introduce a novel non-cooperative game to analyse opinion formation and
resistance, incorporating principles from social psychology such as
confirmation bias, resource constraints, and influence penalties. Our
simulation features Large Language Model (LLM) agents competing to influence a
population, with penalties imposed for generating messages that propagate or
counter misinformation. This framework integrates resource optimisation into
the agents' decision-making process. Our findings demonstrate that while higher
confirmation bias strengthens opinion alignment within groups, it also
exacerbates overall polarisation. Conversely, lower confirmation bias leads to
fragmented opinions and limited shifts in individual beliefs. Investing heavily
in a high-resource debunking strategy can initially align the population with
the debunking agent, but risks rapid resource depletion and diminished
long-term influence.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""We introduce a novel non-cooperative game to analyse opinion formation and\nresistance, incorporating principles from social psychology such as\nconfirmation bias, resource constraints, and influence penalties. Our\nsimulation features Large Language Model (LLM) agents competing to influence a\npopulation, with penalties imposed for generating messages that propagate or\ncounter misinformation. This framework integrates resource optimisation into\nthe agents' decision-making process. Our findings demonstrate that while higher\nconfirmation bias strengthens opinion alignment within groups, it also\nexacerbates overall polarisation. Conversely, lower confirmation bias leads to\nfragmented opinions and limited shifts in individual beliefs. Investing heavily\nin a high-resource debunking strategy can initially align the population with\nthe debunking agent, but risks rapid resource depletion and diminished\nlong-term influence.""}","['Amin Qasmi', 'Usman Naseem', 'Mehwish Nasim']",{'name': 'Mehwish Nasim'},Mehwish Nasim,,"[{'href': 'http://arxiv.org/abs/2502.11649v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11649v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.6; I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11649v1,None,http://arxiv.org/abs/2502.11649v1,,,21,0
http://arxiv.org/abs/2502.11651v1,True,2025-02-17T10:43:38Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=10, tm_min=43, tm_sec=38, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T10:43:38Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=10, tm_min=43, tm_sec=38, tm_wday=0, tm_yday=48, tm_isdst=0)","MMXU: A Multi-Modal and Multi-X-ray Understanding Dataset for Disease
  Progression","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'MMXU: A Multi-Modal and Multi-X-ray Understanding Dataset for Disease\n  Progression'}","Large vision-language models (LVLMs) have shown great promise in medical
applications, particularly in visual question answering (MedVQA) and diagnosis
from medical images. However, existing datasets and models often fail to
consider critical aspects of medical diagnostics, such as the integration of
historical records and the analysis of disease progression over time. In this
paper, we introduce MMXU (Multimodal and MultiX-ray Understanding), a novel
dataset for MedVQA that focuses on identifying changes in specific regions
between two patient visits. Unlike previous datasets that primarily address
single-image questions, MMXU enables multi-image questions, incorporating both
current and historical patient data. We demonstrate the limitations of current
LVLMs in identifying disease progression on MMXU-\textit{test}, even those that
perform well on traditional benchmarks. To address this, we propose a
MedRecord-Augmented Generation (MAG) approach, incorporating both global and
regional historical records. Our experiments show that integrating historical
records significantly enhances diagnostic accuracy by at least 20\%, bridging
the gap between current LVLMs and human expert performance. Additionally, we
fine-tune models with MAG on MMXU-\textit{dev}, which demonstrates notable
improvements. We hope this work could illuminate the avenue of advancing the
use of LVLMs in medical diagnostics by emphasizing the importance of historical
context in interpreting medical images. Our dataset is released at
\href{https://github.com/linjiemu/MMXU}{https://github.com/linjiemu/MMXU}.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large vision-language models (LVLMs) have shown great promise in medical\napplications, particularly in visual question answering (MedVQA) and diagnosis\nfrom medical images. However, existing datasets and models often fail to\nconsider critical aspects of medical diagnostics, such as the integration of\nhistorical records and the analysis of disease progression over time. In this\npaper, we introduce MMXU (Multimodal and MultiX-ray Understanding), a novel\ndataset for MedVQA that focuses on identifying changes in specific regions\nbetween two patient visits. Unlike previous datasets that primarily address\nsingle-image questions, MMXU enables multi-image questions, incorporating both\ncurrent and historical patient data. We demonstrate the limitations of current\nLVLMs in identifying disease progression on MMXU-\\textit{test}, even those that\nperform well on traditional benchmarks. To address this, we propose a\nMedRecord-Augmented Generation (MAG) approach, incorporating both global and\nregional historical records. Our experiments show that integrating historical\nrecords significantly enhances diagnostic accuracy by at least 20\\%, bridging\nthe gap between current LVLMs and human expert performance. Additionally, we\nfine-tune models with MAG on MMXU-\\textit{dev}, which demonstrates notable\nimprovements. We hope this work could illuminate the avenue of advancing the\nuse of LVLMs in medical diagnostics by emphasizing the importance of historical\ncontext in interpreting medical images. Our dataset is released at\n\\href{https://github.com/linjiemu/MMXU}{https://github.com/linjiemu/MMXU}.'}","['Linjie Mu', 'Zhongzhen Huang', 'Shengqian Qin', 'Yakun Zhu', 'Shaoting Zhang', 'Xiaofan Zhang']",{'name': 'Xiaofan Zhang'},Xiaofan Zhang,,"[{'href': 'http://arxiv.org/abs/2502.11651v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11651v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11651v1,None,http://arxiv.org/abs/2502.11651v1,,,459,0
http://arxiv.org/abs/2502.11681v2,True,2025-02-20T08:41:10Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=8, tm_min=41, tm_sec=10, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-17T11:16:19Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=11, tm_min=16, tm_sec=19, tm_wday=0, tm_yday=48, tm_isdst=0)","RIDE: Enhancing Large Language Model Alignment through Restyled
  In-Context Learning Demonstration Exemplars","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'RIDE: Enhancing Large Language Model Alignment through Restyled\n  In-Context Learning Demonstration Exemplars'}","Alignment tuning is crucial for ensuring large language models (LLMs) behave
ethically and helpfully. Current alignment approaches require high-quality
annotations and significant training resources. This paper proposes a low-cost,
tuning-free method using in-context learning (ICL) to enhance LLM alignment.
Through an analysis of high-quality ICL demos, we identified style as a key
factor influencing LLM alignment capabilities and explicitly restyled ICL
exemplars based on this stylistic framework. Additionally, we combined the
restyled demos to achieve a balance between the two conflicting aspects of LLM
alignment--factuality and safety. We packaged the restyled examples as prompts
to trigger few-shot learning, improving LLM alignment. Compared to the best
baseline approach, with an average score of 5.00 as the maximum, our method
achieves a maximum 0.10 increase on the Alpaca task (from 4.50 to 4.60), a 0.22
enhancement on the Just-eval benchmark (from 4.34 to 4.56), and a maximum
improvement of 0.32 (from 3.53 to 3.85) on the MT-Bench dataset. We release the
code and data at https://github.com/AnonymousCode-ComputerScience/RIDE.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Alignment tuning is crucial for ensuring large language models (LLMs) behave\nethically and helpfully. Current alignment approaches require high-quality\nannotations and significant training resources. This paper proposes a low-cost,\ntuning-free method using in-context learning (ICL) to enhance LLM alignment.\nThrough an analysis of high-quality ICL demos, we identified style as a key\nfactor influencing LLM alignment capabilities and explicitly restyled ICL\nexemplars based on this stylistic framework. Additionally, we combined the\nrestyled demos to achieve a balance between the two conflicting aspects of LLM\nalignment--factuality and safety. We packaged the restyled examples as prompts\nto trigger few-shot learning, improving LLM alignment. Compared to the best\nbaseline approach, with an average score of 5.00 as the maximum, our method\nachieves a maximum 0.10 increase on the Alpaca task (from 4.50 to 4.60), a 0.22\nenhancement on the Just-eval benchmark (from 4.34 to 4.56), and a maximum\nimprovement of 0.32 (from 3.53 to 3.85) on the MT-Bench dataset. We release the\ncode and data at https://github.com/AnonymousCode-ComputerScience/RIDE.'}","['Yuncheng Hua', 'Lizhen Qu', 'Zhuang Li', 'Hao Xue', 'Flora D. Salim', 'Gholamreza Haffari']",{'name': 'Gholamreza Haffari'},Gholamreza Haffari,"38 pages, 2 figures, 20 tables; The paper is under review in ARR","[{'href': 'http://arxiv.org/abs/2502.11681v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11681v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11681v2,None,http://arxiv.org/abs/2502.11681v2,,,13162,0
http://arxiv.org/abs/2502.11684v1,True,2025-02-17T11:22:24Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=11, tm_min=22, tm_sec=24, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T11:22:24Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=11, tm_min=22, tm_sec=24, tm_wday=0, tm_yday=48, tm_isdst=0)","MathFimer: Enhancing Mathematical Reasoning by Expanding Reasoning Steps
  through Fill-in-the-Middle Task","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'MathFimer: Enhancing Mathematical Reasoning by Expanding Reasoning Steps\n  through Fill-in-the-Middle Task'}","Mathematical reasoning represents a critical frontier in advancing large
language models (LLMs). While step-by-step approaches have emerged as the
dominant paradigm for mathematical problem-solving in LLMs, the quality of
reasoning steps in training data fundamentally constrains the performance of
the models. Recent studies has demonstrated that more detailed intermediate
steps can enhance model performance, yet existing methods for step expansion
either require more powerful external models or incur substantial computational
costs. In this paper, we introduce MathFimer, a novel framework for
mathematical reasoning step expansion inspired by the ""Fill-in-the-middle"" task
from code completion. By decomposing solution chains into prefix-suffix pairs
and training models to reconstruct missing intermediate steps, we develop a
specialized model, MathFimer-7B, on our carefully curated NuminaMath-FIM
dataset. We then apply these models to enhance existing mathematical reasoning
datasets by inserting detailed intermediate steps into their solution chains,
creating MathFimer-expanded versions. Through comprehensive experiments on
multiple mathematical reasoning datasets, including MathInstruct, MetaMathQA
and etc., we demonstrate that models trained on MathFimer-expanded data
consistently outperform their counterparts trained on original data across
various benchmarks such as GSM8K and MATH. Our approach offers a practical,
scalable solution for enhancing mathematical reasoning capabilities in LLMs
without relying on powerful external models or expensive inference procedures.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Mathematical reasoning represents a critical frontier in advancing large\nlanguage models (LLMs). While step-by-step approaches have emerged as the\ndominant paradigm for mathematical problem-solving in LLMs, the quality of\nreasoning steps in training data fundamentally constrains the performance of\nthe models. Recent studies has demonstrated that more detailed intermediate\nsteps can enhance model performance, yet existing methods for step expansion\neither require more powerful external models or incur substantial computational\ncosts. In this paper, we introduce MathFimer, a novel framework for\nmathematical reasoning step expansion inspired by the ""Fill-in-the-middle"" task\nfrom code completion. By decomposing solution chains into prefix-suffix pairs\nand training models to reconstruct missing intermediate steps, we develop a\nspecialized model, MathFimer-7B, on our carefully curated NuminaMath-FIM\ndataset. We then apply these models to enhance existing mathematical reasoning\ndatasets by inserting detailed intermediate steps into their solution chains,\ncreating MathFimer-expanded versions. Through comprehensive experiments on\nmultiple mathematical reasoning datasets, including MathInstruct, MetaMathQA\nand etc., we demonstrate that models trained on MathFimer-expanded data\nconsistently outperform their counterparts trained on original data across\nvarious benchmarks such as GSM8K and MATH. Our approach offers a practical,\nscalable solution for enhancing mathematical reasoning capabilities in LLMs\nwithout relying on powerful external models or expensive inference procedures.'}","['Yuchen Yan', 'Yongliang Shen', 'Yang Liu', 'Jin Jiang', 'Xin Xu', 'Mengdi Zhang', 'Jian Shao', 'Yueting Zhuang']",{'name': 'Yueting Zhuang'},Yueting Zhuang,,"[{'href': 'http://arxiv.org/abs/2502.11684v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11684v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11684v1,None,http://arxiv.org/abs/2502.11684v1,,,24,0
http://arxiv.org/abs/2502.11711v1,True,2025-02-17T11:53:58Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=11, tm_min=53, tm_sec=58, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T11:53:58Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=11, tm_min=53, tm_sec=58, tm_wday=0, tm_yday=48, tm_isdst=0)",Knowledge-aware contrastive heterogeneous molecular graph learning,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Knowledge-aware contrastive heterogeneous molecular graph learning'}","Molecular representation learning is pivotal in predicting molecular
properties and advancing drug design. Traditional methodologies, which
predominantly rely on homogeneous graph encoding, are limited by their
inability to integrate external knowledge and represent molecular structures
across different levels of granularity. To address these limitations, we
propose a paradigm shift by encoding molecular graphs into heterogeneous
structures, introducing a novel framework: Knowledge-aware Contrastive
Heterogeneous Molecular Graph Learning (KCHML). This approach leverages
contrastive learning to enrich molecular representations with embedded external
knowledge. KCHML conceptualizes molecules through three distinct graph
views-molecular, elemental, and pharmacological-enhanced by heterogeneous
molecular graphs and a dual message-passing mechanism. This design offers a
comprehensive representation for property prediction, as well as for downstream
tasks such as drug-drug interaction (DDI) prediction. Extensive benchmarking
demonstrates KCHML's superiority over state-of-the-art molecular property
prediction models, underscoring its ability to capture intricate molecular
features.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Molecular representation learning is pivotal in predicting molecular\nproperties and advancing drug design. Traditional methodologies, which\npredominantly rely on homogeneous graph encoding, are limited by their\ninability to integrate external knowledge and represent molecular structures\nacross different levels of granularity. To address these limitations, we\npropose a paradigm shift by encoding molecular graphs into heterogeneous\nstructures, introducing a novel framework: Knowledge-aware Contrastive\nHeterogeneous Molecular Graph Learning (KCHML). This approach leverages\ncontrastive learning to enrich molecular representations with embedded external\nknowledge. KCHML conceptualizes molecules through three distinct graph\nviews-molecular, elemental, and pharmacological-enhanced by heterogeneous\nmolecular graphs and a dual message-passing mechanism. This design offers a\ncomprehensive representation for property prediction, as well as for downstream\ntasks such as drug-drug interaction (DDI) prediction. Extensive benchmarking\ndemonstrates KCHML's superiority over state-of-the-art molecular property\nprediction models, underscoring its ability to capture intricate molecular\nfeatures.""}","['Mukun Chen', 'Jia Wu', 'Shirui Pan', 'Fu Lin', 'Bo Du', 'Xiuwen Gong', 'Wenbin Hu']",{'name': 'Wenbin Hu'},Wenbin Hu,,"[{'href': 'http://arxiv.org/abs/2502.11711v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11711v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11711v1,None,http://arxiv.org/abs/2502.11711v1,,,51,0
http://arxiv.org/abs/2502.11715v1,True,2025-02-17T12:00:28Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=12, tm_min=0, tm_sec=28, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T12:00:28Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=12, tm_min=0, tm_sec=28, tm_wday=0, tm_yday=48, tm_isdst=0)","Proactive Depot Discovery: A Generative Framework for Flexible
  Location-Routing","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Proactive Depot Discovery: A Generative Framework for Flexible\n  Location-Routing'}","The Location-Routing Problem (LRP), which combines the challenges of facility
(depot) locating and vehicle route planning, is critically constrained by the
reliance on predefined depot candidates, limiting the solution space and
potentially leading to suboptimal outcomes. Previous research on LRP without
predefined depots is scant and predominantly relies on heuristic algorithms
that iteratively attempt depot placements across a planar area. Such approaches
lack the ability to proactively generate depot locations that meet specific
geographic requirements, revealing a notable gap in current research landscape.
To bridge this gap, we propose a data-driven generative DRL framework, designed
to proactively generate depots for LRP without predefined depot candidates,
solely based on customer requests data which include geographic and demand
information. It can operate in two distinct modes: direct generation of exact
depot locations, and the creation of a multivariate Gaussian distribution for
flexible depots sampling. By extracting depots' geographic pattern from
customer requests data, our approach can dynamically respond to logistical
needs, identifying high-quality depot locations that further reduce total
routing costs compared to traditional methods. Extensive experiments
demonstrate that, for a same group of customer requests, compared with those
depots identified through random attempts, our framework can proactively
generate depots that lead to superior solution routes with lower routing cost.
The implications of our framework potentially extend into real-world
applications, particularly in emergency medical rescue and disaster relief
logistics, where rapid establishment and adjustment of depot locations are
paramount, showcasing its potential in addressing LRP for dynamic and
unpredictable environments.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""The Location-Routing Problem (LRP), which combines the challenges of facility\n(depot) locating and vehicle route planning, is critically constrained by the\nreliance on predefined depot candidates, limiting the solution space and\npotentially leading to suboptimal outcomes. Previous research on LRP without\npredefined depots is scant and predominantly relies on heuristic algorithms\nthat iteratively attempt depot placements across a planar area. Such approaches\nlack the ability to proactively generate depot locations that meet specific\ngeographic requirements, revealing a notable gap in current research landscape.\nTo bridge this gap, we propose a data-driven generative DRL framework, designed\nto proactively generate depots for LRP without predefined depot candidates,\nsolely based on customer requests data which include geographic and demand\ninformation. It can operate in two distinct modes: direct generation of exact\ndepot locations, and the creation of a multivariate Gaussian distribution for\nflexible depots sampling. By extracting depots' geographic pattern from\ncustomer requests data, our approach can dynamically respond to logistical\nneeds, identifying high-quality depot locations that further reduce total\nrouting costs compared to traditional methods. Extensive experiments\ndemonstrate that, for a same group of customer requests, compared with those\ndepots identified through random attempts, our framework can proactively\ngenerate depots that lead to superior solution routes with lower routing cost.\nThe implications of our framework potentially extend into real-world\napplications, particularly in emergency medical rescue and disaster relief\nlogistics, where rapid establishment and adjustment of depot locations are\nparamount, showcasing its potential in addressing LRP for dynamic and\nunpredictable environments.""}","['Site Qu', 'Guoqiang Hu']",{'name': 'Guoqiang Hu'},Guoqiang Hu,,"[{'href': 'http://arxiv.org/abs/2502.11715v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11715v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11715v1,None,http://arxiv.org/abs/2502.11715v1,,,0,0
http://arxiv.org/abs/2502.11736v1,True,2025-02-17T12:22:11Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=12, tm_min=22, tm_sec=11, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T12:22:11Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=12, tm_min=22, tm_sec=11, tm_wday=0, tm_yday=48, tm_isdst=0)",ReviewEval: An Evaluation Framework for AI-Generated Reviews,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'ReviewEval: An Evaluation Framework for AI-Generated Reviews'}","The escalating volume of academic research, coupled with a shortage of
qualified reviewers, necessitates innovative approaches to peer review. While
large language model (LLMs) offer potential for automating this process, their
current limitations include superficial critiques, hallucinations, and a lack
of actionable insights. This research addresses these challenges by introducing
a comprehensive evaluation framework for AI-generated reviews, that measures
alignment with human evaluations, verifies factual accuracy, assesses
analytical depth, and identifies actionable insights. We also propose a novel
alignment mechanism that tailors LLM-generated reviews to the unique evaluation
priorities of individual conferences and journals. To enhance the quality of
these reviews, we introduce a self-refinement loop that iteratively optimizes
the LLM's review prompts. Our framework establishes standardized metrics for
evaluating AI-based review systems, thereby bolstering the reliability of
AI-generated reviews in academic research.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""The escalating volume of academic research, coupled with a shortage of\nqualified reviewers, necessitates innovative approaches to peer review. While\nlarge language model (LLMs) offer potential for automating this process, their\ncurrent limitations include superficial critiques, hallucinations, and a lack\nof actionable insights. This research addresses these challenges by introducing\na comprehensive evaluation framework for AI-generated reviews, that measures\nalignment with human evaluations, verifies factual accuracy, assesses\nanalytical depth, and identifies actionable insights. We also propose a novel\nalignment mechanism that tailors LLM-generated reviews to the unique evaluation\npriorities of individual conferences and journals. To enhance the quality of\nthese reviews, we introduce a self-refinement loop that iteratively optimizes\nthe LLM's review prompts. Our framework establishes standardized metrics for\nevaluating AI-based review systems, thereby bolstering the reliability of\nAI-generated reviews in academic research.""}","['Chavvi Kirtani', 'Madhav Krishan Garg', 'Tejash Prasad', 'Tanmay Singhal', 'Murari Mandal', 'Dhruv Kumar']",{'name': 'Dhruv Kumar'},Dhruv Kumar,"Under review: 8 pages, 2 figures, 2 tables, 3 pages for appendix","[{'href': 'http://arxiv.org/abs/2502.11736v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11736v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11736v1,None,http://arxiv.org/abs/2502.11736v1,,,2,0
http://arxiv.org/abs/2502.11741v1,True,2025-02-17T12:28:11Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=12, tm_min=28, tm_sec=11, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T12:28:11Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=12, tm_min=28, tm_sec=11, tm_wday=0, tm_yday=48, tm_isdst=0)",SQL-o1: A Self-Reward Heuristic Dynamic Search Method for Text-to-SQL,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'SQL-o1: A Self-Reward Heuristic Dynamic Search Method for Text-to-SQL'}","The Text-to-SQL(Text2SQL) task aims to convert natural language queries into
executable SQL queries. Thanks to the application of large language models
(LLMs), significant progress has been made in this field. However, challenges
such as model scalability, limited generation space, and coherence issues in
SQL generation still persist. To address these issues, we propose SQL-o1, a
Self-Reward-based heuristic search method designed to enhance the reasoning
ability of LLMs in SQL query generation. SQL-o1 combines Monte Carlo Tree
Search (MCTS) for heuristic process-level search and constructs a Schema-Aware
dataset to help the model better understand database schemas. Extensive
experiments on the Bird and Spider datasets demonstrate that SQL-o1 improves
execution accuracy by 10.8\% on the complex Bird dataset compared to the latest
baseline methods, even outperforming GPT-4-based approaches. Additionally,
SQL-o1 excels in few-shot learning scenarios and shows strong cross-model
transferability. Our code is publicly available
at:https://github.com/ShuaiLyu0110/SQL-o1.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The Text-to-SQL(Text2SQL) task aims to convert natural language queries into\nexecutable SQL queries. Thanks to the application of large language models\n(LLMs), significant progress has been made in this field. However, challenges\nsuch as model scalability, limited generation space, and coherence issues in\nSQL generation still persist. To address these issues, we propose SQL-o1, a\nSelf-Reward-based heuristic search method designed to enhance the reasoning\nability of LLMs in SQL query generation. SQL-o1 combines Monte Carlo Tree\nSearch (MCTS) for heuristic process-level search and constructs a Schema-Aware\ndataset to help the model better understand database schemas. Extensive\nexperiments on the Bird and Spider datasets demonstrate that SQL-o1 improves\nexecution accuracy by 10.8\\% on the complex Bird dataset compared to the latest\nbaseline methods, even outperforming GPT-4-based approaches. Additionally,\nSQL-o1 excels in few-shot learning scenarios and shows strong cross-model\ntransferability. Our code is publicly available\nat:https://github.com/ShuaiLyu0110/SQL-o1.'}","['Shuai Lyu', 'Haoran Luo', 'Zhonghong Ou', 'Yifan Zhu', 'Xiaoran Shang', 'Yang Qin', 'Meina Song']",{'name': 'Meina Song'},Meina Song,"10 pages,4 figures","[{'href': 'http://arxiv.org/abs/2502.11741v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11741v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.DB', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.DB', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11741v1,None,http://arxiv.org/abs/2502.11741v1,,,37,0
http://arxiv.org/abs/2502.11749v1,True,2025-02-17T12:43:04Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=12, tm_min=43, tm_sec=4, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T12:43:04Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=12, tm_min=43, tm_sec=4, tm_wday=0, tm_yday=48, tm_isdst=0)","JotlasNet: Joint Tensor Low-Rank and Attention-based Sparse Unrolling
  Network for Accelerating Dynamic MRI","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'JotlasNet: Joint Tensor Low-Rank and Attention-based Sparse Unrolling\n  Network for Accelerating Dynamic MRI'}","Joint low-rank and sparse unrolling networks have shown superior performance
in dynamic MRI reconstruction. However, existing works mainly utilized matrix
low-rank priors, neglecting the tensor characteristics of dynamic MRI images,
and only a global threshold is applied for the sparse constraint to the
multi-channel data, limiting the flexibility of the network. Additionally, most
of them have inherently complex network structure, with intricate interactions
among variables. In this paper, we propose a novel deep unrolling network,
JotlasNet, for dynamic MRI reconstruction by jointly utilizing tensor low-rank
and attention-based sparse priors. Specifically, we utilize tensor low-rank
prior to exploit the structural correlations in high-dimensional data.
Convolutional neural networks are used to adaptively learn the low-rank and
sparse transform domains. A novel attention-based soft thresholding operator is
proposed to assign a unique learnable threshold to each channel of the data in
the CNN-learned sparse domain. The network is unrolled from the elaborately
designed composite splitting algorithm and thus features a simple yet efficient
parallel structure. Extensive experiments on two datasets (OCMR, CMRxRecon)
demonstrate the superior performance of JotlasNet in dynamic MRI
reconstruction.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Joint low-rank and sparse unrolling networks have shown superior performance\nin dynamic MRI reconstruction. However, existing works mainly utilized matrix\nlow-rank priors, neglecting the tensor characteristics of dynamic MRI images,\nand only a global threshold is applied for the sparse constraint to the\nmulti-channel data, limiting the flexibility of the network. Additionally, most\nof them have inherently complex network structure, with intricate interactions\namong variables. In this paper, we propose a novel deep unrolling network,\nJotlasNet, for dynamic MRI reconstruction by jointly utilizing tensor low-rank\nand attention-based sparse priors. Specifically, we utilize tensor low-rank\nprior to exploit the structural correlations in high-dimensional data.\nConvolutional neural networks are used to adaptively learn the low-rank and\nsparse transform domains. A novel attention-based soft thresholding operator is\nproposed to assign a unique learnable threshold to each channel of the data in\nthe CNN-learned sparse domain. The network is unrolled from the elaborately\ndesigned composite splitting algorithm and thus features a simple yet efficient\nparallel structure. Extensive experiments on two datasets (OCMR, CMRxRecon)\ndemonstrate the superior performance of JotlasNet in dynamic MRI\nreconstruction.'}","['Yinghao Zhang', 'Haiyan Gui', 'Ningdi Yang', 'Yue Hu']",{'name': 'Yue Hu'},Yue Hu,"13 pages, 7 figures, accepted by Magnetic Resonance Imaging","[{'title': 'doi', 'href': 'http://dx.doi.org/10.1016/j.mri.2025.110337', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2502.11749v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11749v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.4.5; I.2.6; I.4.1', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11749v1,None,http://arxiv.org/abs/2502.11749v1,Magnetic Resonance Imaging (2025):110337,10.1016/j.mri.2025.110337,38,0
http://arxiv.org/abs/2502.11751v1,True,2025-02-17T12:47:00Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=12, tm_min=47, tm_sec=0, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T12:47:00Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=12, tm_min=47, tm_sec=0, tm_wday=0, tm_yday=48, tm_isdst=0)","Language Models Can See Better: Visual Contrastive Decoding For LLM
  Multimodal Reasoning","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Language Models Can See Better: Visual Contrastive Decoding For LLM\n  Multimodal Reasoning'}","Although Large Language Models (LLMs) excel in reasoning and generation for
language tasks, they are not specifically designed for multimodal challenges.
Training Multimodal Large Language Models (MLLMs), however, is
resource-intensive and constrained by various training limitations. In this
paper, we propose the Modular-based Visual Contrastive Decoding (MVCD)
framework to move this obstacle. Our framework leverages LLMs' In-Context
Learning (ICL) capability and the proposed visual contrastive-example decoding
(CED), specifically tailored for this framework, without requiring any
additional training. By converting visual signals into text and focusing on
contrastive output distributions during decoding, we can highlight the new
information introduced by contextual examples, explore their connections, and
avoid over-reliance on prior encoded knowledge. MVCD enhances LLMs' visual
perception to make it see and reason over the input visuals. To demonstrate
MVCD's effectiveness, we conduct experiments with four LLMs across five
question answering datasets. Our results not only show consistent improvement
in model accuracy but well explain the effective components inside our decoding
strategy. Our code will be available at https://github.com/Pbhgit/MVCD.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Although Large Language Models (LLMs) excel in reasoning and generation for\nlanguage tasks, they are not specifically designed for multimodal challenges.\nTraining Multimodal Large Language Models (MLLMs), however, is\nresource-intensive and constrained by various training limitations. In this\npaper, we propose the Modular-based Visual Contrastive Decoding (MVCD)\nframework to move this obstacle. Our framework leverages LLMs' In-Context\nLearning (ICL) capability and the proposed visual contrastive-example decoding\n(CED), specifically tailored for this framework, without requiring any\nadditional training. By converting visual signals into text and focusing on\ncontrastive output distributions during decoding, we can highlight the new\ninformation introduced by contextual examples, explore their connections, and\navoid over-reliance on prior encoded knowledge. MVCD enhances LLMs' visual\nperception to make it see and reason over the input visuals. To demonstrate\nMVCD's effectiveness, we conduct experiments with four LLMs across five\nquestion answering datasets. Our results not only show consistent improvement\nin model accuracy but well explain the effective components inside our decoding\nstrategy. Our code will be available at https://github.com/Pbhgit/MVCD.""}","['Yuqi Pang', 'Bowen Yang', 'Haoqin Tu', 'Yun Cao', 'Zeyu Zhang']",{'name': 'Zeyu Zhang'},Zeyu Zhang,Accepted to ICASSP 2025,"[{'href': 'http://arxiv.org/abs/2502.11751v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11751v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11751v1,None,http://arxiv.org/abs/2502.11751v1,,,0,0
http://arxiv.org/abs/2502.11763v1,True,2025-02-17T12:55:41Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=12, tm_min=55, tm_sec=41, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T12:55:41Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=12, tm_min=55, tm_sec=41, tm_wday=0, tm_yday=48, tm_isdst=0)",Lightweight Deepfake Detection Based on Multi-Feature Fusion,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Lightweight Deepfake Detection Based on Multi-Feature Fusion'}","Deepfake technology utilizes deep learning based face manipulation techniques
to seamlessly replace faces in videos creating highly realistic but
artificially generated content. Although this technology has beneficial
applications in media and entertainment misuse of its capabilities may lead to
serious risks including identity theft cyberbullying and false information. The
integration of DL with visual cognition has resulted in important technological
improvements particularly in addressing privacy risks caused by artificially
generated deepfake images on digital media platforms. In this study we propose
an efficient and lightweight method for detecting deepfake images and videos
making it suitable for devices with limited computational resources. In order
to reduce the computational burden usually associated with DL models our method
integrates machine learning classifiers in combination with keyframing
approaches and texture analysis. Moreover the features extracted with a
histogram of oriented gradients (HOG) local binary pattern (LBP) and KAZE bands
were integrated to evaluate using random forest extreme gradient boosting extra
trees and support vector classifier algorithms. Our findings show a
feature-level fusion of HOG LBP and KAZE features improves accuracy to 92% and
96% on FaceForensics++ and Celeb-DFv2 respectively.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Deepfake technology utilizes deep learning based face manipulation techniques\nto seamlessly replace faces in videos creating highly realistic but\nartificially generated content. Although this technology has beneficial\napplications in media and entertainment misuse of its capabilities may lead to\nserious risks including identity theft cyberbullying and false information. The\nintegration of DL with visual cognition has resulted in important technological\nimprovements particularly in addressing privacy risks caused by artificially\ngenerated deepfake images on digital media platforms. In this study we propose\nan efficient and lightweight method for detecting deepfake images and videos\nmaking it suitable for devices with limited computational resources. In order\nto reduce the computational burden usually associated with DL models our method\nintegrates machine learning classifiers in combination with keyframing\napproaches and texture analysis. Moreover the features extracted with a\nhistogram of oriented gradients (HOG) local binary pattern (LBP) and KAZE bands\nwere integrated to evaluate using random forest extreme gradient boosting extra\ntrees and support vector classifier algorithms. Our findings show a\nfeature-level fusion of HOG LBP and KAZE features improves accuracy to 92% and\n96% on FaceForensics++ and Celeb-DFv2 respectively.'}","['Siddiqui Muhammad Yasir', 'Hyun Kim']",{'name': 'Hyun Kim'},Hyun Kim,,"[{'title': 'doi', 'href': 'http://dx.doi.org/10.3390/app15041954', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2502.11763v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11763v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11763v1,None,http://arxiv.org/abs/2502.11763v1,"Yasir, S.M.; Kim, H. Lightweight Deepfake Detection Based on
  Multi-Feature Fusion. Appl. Sci. 2025, 15, 1954",10.3390/app15041954,161,0
http://arxiv.org/abs/2502.11771v1,True,2025-02-17T13:00:44Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=13, tm_min=0, tm_sec=44, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T13:00:44Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=13, tm_min=0, tm_sec=44, tm_wday=0, tm_yday=48, tm_isdst=0)","The Validation Gap: A Mechanistic Analysis of How Language Models
  Compute Arithmetic but Fail to Validate It","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The Validation Gap: A Mechanistic Analysis of How Language Models\n  Compute Arithmetic but Fail to Validate It'}","The ability of large language models (LLMs) to validate their output and
identify potential errors is crucial for ensuring robustness and reliability.
However, current research indicates that LLMs struggle with self-correction,
encountering significant challenges in detecting errors. While studies have
explored methods to enhance self-correction in LLMs, relatively little
attention has been given to understanding the models' internal mechanisms
underlying error detection. In this paper, we present a mechanistic analysis of
error detection in LLMs, focusing on simple arithmetic problems. Through
circuit analysis, we identify the computational subgraphs responsible for
detecting arithmetic errors across four smaller-sized LLMs. Our findings reveal
that all models heavily rely on $\textit{consistency heads}$--attention heads
that assess surface-level alignment of numerical values in arithmetic
solutions. Moreover, we observe that the models' internal arithmetic
computation primarily occurs in higher layers, whereas validation takes place
in middle layers, before the final arithmetic results are fully encoded. This
structural dissociation between arithmetic computation and validation seems to
explain why current LLMs struggle to detect even simple arithmetic errors.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""The ability of large language models (LLMs) to validate their output and\nidentify potential errors is crucial for ensuring robustness and reliability.\nHowever, current research indicates that LLMs struggle with self-correction,\nencountering significant challenges in detecting errors. While studies have\nexplored methods to enhance self-correction in LLMs, relatively little\nattention has been given to understanding the models' internal mechanisms\nunderlying error detection. In this paper, we present a mechanistic analysis of\nerror detection in LLMs, focusing on simple arithmetic problems. Through\ncircuit analysis, we identify the computational subgraphs responsible for\ndetecting arithmetic errors across four smaller-sized LLMs. Our findings reveal\nthat all models heavily rely on $\\textit{consistency heads}$--attention heads\nthat assess surface-level alignment of numerical values in arithmetic\nsolutions. Moreover, we observe that the models' internal arithmetic\ncomputation primarily occurs in higher layers, whereas validation takes place\nin middle layers, before the final arithmetic results are fully encoded. This\nstructural dissociation between arithmetic computation and validation seems to\nexplain why current LLMs struggle to detect even simple arithmetic errors.""}","['Leonardo Bertolazzi', 'Philipp Mondorf', 'Barbara Plank', 'Raffaella Bernardi']",{'name': 'Raffaella Bernardi'},Raffaella Bernardi,"34 pages, 31 figures","[{'href': 'http://arxiv.org/abs/2502.11771v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11771v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11771v1,None,http://arxiv.org/abs/2502.11771v1,,,188,0
http://arxiv.org/abs/2502.11777v1,True,2025-02-17T13:11:35Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=13, tm_min=11, tm_sec=35, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T13:11:35Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=13, tm_min=11, tm_sec=35, tm_wday=0, tm_yday=48, tm_isdst=0)","Deep Neural Networks for Accurate Depth Estimation with Latent Space
  Features","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Deep Neural Networks for Accurate Depth Estimation with Latent Space\n  Features'}","Depth estimation plays a pivotal role in advancing human-robot interactions,
especially in indoor environments where accurate 3D scene reconstruction is
essential for tasks like navigation and object handling. Monocular depth
estimation, which relies on a single RGB camera, offers a more affordable
solution compared to traditional methods that use stereo cameras or LiDAR.
However, despite recent progress, many monocular approaches struggle with
accurately defining depth boundaries, leading to less precise reconstructions.
In response to these challenges, this study introduces a novel depth estimation
framework that leverages latent space features within a deep convolutional
neural network to enhance the precision of monocular depth maps. The proposed
model features dual encoder-decoder architecture, enabling both color-to-depth
and depth-to-depth transformations. This structure allows for refined depth
estimation through latent space encoding. To further improve the accuracy of
depth boundaries and local features, a new loss function is introduced. This
function combines latent loss with gradient loss, helping the model maintain
the integrity of depth boundaries. The framework is thoroughly tested using the
NYU Depth V2 dataset, where it sets a new benchmark, particularly excelling in
complex indoor scenarios. The results clearly show that this approach
effectively reduces depth ambiguities and blurring, making it a promising
solution for applications in human-robot interaction and 3D scene
reconstruction.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Depth estimation plays a pivotal role in advancing human-robot interactions,\nespecially in indoor environments where accurate 3D scene reconstruction is\nessential for tasks like navigation and object handling. Monocular depth\nestimation, which relies on a single RGB camera, offers a more affordable\nsolution compared to traditional methods that use stereo cameras or LiDAR.\nHowever, despite recent progress, many monocular approaches struggle with\naccurately defining depth boundaries, leading to less precise reconstructions.\nIn response to these challenges, this study introduces a novel depth estimation\nframework that leverages latent space features within a deep convolutional\nneural network to enhance the precision of monocular depth maps. The proposed\nmodel features dual encoder-decoder architecture, enabling both color-to-depth\nand depth-to-depth transformations. This structure allows for refined depth\nestimation through latent space encoding. To further improve the accuracy of\ndepth boundaries and local features, a new loss function is introduced. This\nfunction combines latent loss with gradient loss, helping the model maintain\nthe integrity of depth boundaries. The framework is thoroughly tested using the\nNYU Depth V2 dataset, where it sets a new benchmark, particularly excelling in\ncomplex indoor scenarios. The results clearly show that this approach\neffectively reduces depth ambiguities and blurring, making it a promising\nsolution for applications in human-robot interaction and 3D scene\nreconstruction.'}","['Siddiqui Muhammad Yasir', 'Hyunsik Ahn']",{'name': 'Hyunsik Ahn'},Hyunsik Ahn,,"[{'title': 'doi', 'href': 'http://dx.doi.org/10.3390/biomimetics9120747', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2502.11777v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11777v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11777v1,None,http://arxiv.org/abs/2502.11777v1,"Yasir, S.M.; Ahn, H. Deep Neural Networks for Accurate Depth
  Estimation with Latent Space Features. Biomimetics 2024, 9, 747",10.3390/biomimetics9120747,38,0
http://arxiv.org/abs/2502.11799v1,True,2025-02-17T13:42:12Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=13, tm_min=42, tm_sec=12, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T13:42:12Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=13, tm_min=42, tm_sec=12, tm_wday=0, tm_yday=48, tm_isdst=0)","Table-Critic: A Multi-Agent Framework for Collaborative Criticism and
  Refinement in Table Reasoning","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Table-Critic: A Multi-Agent Framework for Collaborative Criticism and\n  Refinement in Table Reasoning'}","Despite the remarkable capabilities of large language models (LLMs) in
various reasoning tasks, they still struggle with table reasoning tasks,
particularly in maintaining consistency throughout multi-step reasoning
processes. While existing approaches have explored various decomposition
strategies, they often lack effective mechanisms to identify and correct errors
in intermediate reasoning steps, leading to cascading error propagation. To
address these issues, we propose Table-Critic, a novel multi-agent framework
that facilitates collaborative criticism and iterative refinement of the
reasoning process until convergence to correct solutions. Our framework
consists of four specialized agents: a Judge for error identification, a Critic
for comprehensive critiques, a Refiner for process improvement, and a Curator
for pattern distillation. To effectively deal with diverse and unpredictable
error types, we introduce a self-evolving template tree that systematically
accumulates critique knowledge through experience-driven learning and guides
future reflections. Extensive experiments have demonstrated that Table-Critic
achieves substantial improvements over existing methods, achieving superior
accuracy and error correction rates while maintaining computational efficiency
and lower solution degradation rate.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Despite the remarkable capabilities of large language models (LLMs) in\nvarious reasoning tasks, they still struggle with table reasoning tasks,\nparticularly in maintaining consistency throughout multi-step reasoning\nprocesses. While existing approaches have explored various decomposition\nstrategies, they often lack effective mechanisms to identify and correct errors\nin intermediate reasoning steps, leading to cascading error propagation. To\naddress these issues, we propose Table-Critic, a novel multi-agent framework\nthat facilitates collaborative criticism and iterative refinement of the\nreasoning process until convergence to correct solutions. Our framework\nconsists of four specialized agents: a Judge for error identification, a Critic\nfor comprehensive critiques, a Refiner for process improvement, and a Curator\nfor pattern distillation. To effectively deal with diverse and unpredictable\nerror types, we introduce a self-evolving template tree that systematically\naccumulates critique knowledge through experience-driven learning and guides\nfuture reflections. Extensive experiments have demonstrated that Table-Critic\nachieves substantial improvements over existing methods, achieving superior\naccuracy and error correction rates while maintaining computational efficiency\nand lower solution degradation rate.'}","['Peiying Yu', 'Guoxin Chen', 'Jingjing Wang']",{'name': 'Jingjing Wang'},Jingjing Wang,,"[{'href': 'http://arxiv.org/abs/2502.11799v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11799v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11799v1,None,http://arxiv.org/abs/2502.11799v1,,,0,0
http://arxiv.org/abs/2502.11809v1,True,2025-02-17T13:54:02Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=13, tm_min=54, tm_sec=2, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T13:54:02Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=13, tm_min=54, tm_sec=2, tm_wday=0, tm_yday=48, tm_isdst=0)","Revealing Bias Formation in Deep Neural Networks Through the Geometric
  Mechanisms of Human Visual Decoupling","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Revealing Bias Formation in Deep Neural Networks Through the Geometric\n  Mechanisms of Human Visual Decoupling'}","Deep neural networks (DNNs) often exhibit biases toward certain categories
during object recognition, even under balanced training data conditions. The
intrinsic mechanisms underlying these biases remain unclear. Inspired by the
human visual system, which decouples object manifolds through hierarchical
processing to achieve object recognition, we propose a geometric analysis
framework linking the geometric complexity of class-specific perceptual
manifolds in DNNs to model bias. Our findings reveal that differences in
geometric complexity can lead to varying recognition capabilities across
categories, introducing biases. To support this analysis, we present the
Perceptual-Manifold-Geometry library, designed for calculating the geometric
properties of perceptual manifolds.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Deep neural networks (DNNs) often exhibit biases toward certain categories\nduring object recognition, even under balanced training data conditions. The\nintrinsic mechanisms underlying these biases remain unclear. Inspired by the\nhuman visual system, which decouples object manifolds through hierarchical\nprocessing to achieve object recognition, we propose a geometric analysis\nframework linking the geometric complexity of class-specific perceptual\nmanifolds in DNNs to model bias. Our findings reveal that differences in\ngeometric complexity can lead to varying recognition capabilities across\ncategories, introducing biases. To support this analysis, we present the\nPerceptual-Manifold-Geometry library, designed for calculating the geometric\nproperties of perceptual manifolds.'}","['Yanbiao Ma', 'Bowei Liu', 'Wei Dai', 'Jiayi Chen', 'Shuo Li']",{'name': 'Shuo Li'},Shuo Li,,"[{'href': 'http://arxiv.org/abs/2502.11809v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11809v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11809v1,None,http://arxiv.org/abs/2502.11809v1,,,0,0
http://arxiv.org/abs/2502.11831v1,True,2025-02-17T14:27:14Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=14, tm_min=27, tm_sec=14, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T14:27:14Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=14, tm_min=27, tm_sec=14, tm_wday=0, tm_yday=48, tm_isdst=0)","Intuitive physics understanding emerges from self-supervised pretraining
  on natural videos","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Intuitive physics understanding emerges from self-supervised pretraining\n  on natural videos'}","We investigate the emergence of intuitive physics understanding in
general-purpose deep neural network models trained to predict masked regions in
natural videos. Leveraging the violation-of-expectation framework, we find that
video prediction models trained to predict outcomes in a learned representation
space demonstrate an understanding of various intuitive physics properties,
such as object permanence and shape consistency. In contrast, video prediction
in pixel space and multimodal large language models, which reason through text,
achieve performance closer to chance. Our comparisons of these architectures
reveal that jointly learning an abstract representation space while predicting
missing parts of sensory input, akin to predictive coding, is sufficient to
acquire an understanding of intuitive physics, and that even models trained on
one week of unique video achieve above chance performance. This challenges the
idea that core knowledge -- a set of innate systems to help understand the
world -- needs to be hardwired to develop an understanding of intuitive
physics.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'We investigate the emergence of intuitive physics understanding in\ngeneral-purpose deep neural network models trained to predict masked regions in\nnatural videos. Leveraging the violation-of-expectation framework, we find that\nvideo prediction models trained to predict outcomes in a learned representation\nspace demonstrate an understanding of various intuitive physics properties,\nsuch as object permanence and shape consistency. In contrast, video prediction\nin pixel space and multimodal large language models, which reason through text,\nachieve performance closer to chance. Our comparisons of these architectures\nreveal that jointly learning an abstract representation space while predicting\nmissing parts of sensory input, akin to predictive coding, is sufficient to\nacquire an understanding of intuitive physics, and that even models trained on\none week of unique video achieve above chance performance. This challenges the\nidea that core knowledge -- a set of innate systems to help understand the\nworld -- needs to be hardwired to develop an understanding of intuitive\nphysics.'}","['Quentin Garrido', 'Nicolas Ballas', 'Mahmoud Assran', 'Adrien Bardes', 'Laurent Najman', 'Michael Rabbat', 'Emmanuel Dupoux', 'Yann LeCun']",{'name': 'Yann LeCun'},Yann LeCun,"24 pages,14 figures, 5 tables","[{'href': 'http://arxiv.org/abs/2502.11831v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11831v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11831v1,None,http://arxiv.org/abs/2502.11831v1,,,12009,0
http://arxiv.org/abs/2502.11863v1,True,2025-02-17T14:55:46Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=14, tm_min=55, tm_sec=46, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T14:55:46Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=14, tm_min=55, tm_sec=46, tm_wday=0, tm_yday=48, tm_isdst=0)",FedEAT: A Robustness Optimization Framework for Federated LLMs,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'FedEAT: A Robustness Optimization Framework for Federated LLMs'}","Significant advancements have been made by Large Language Models (LLMs) in
the domains of natural language understanding and automated content creation.
However, they still face persistent problems, including substantial
computational costs and inadequate availability of training data. The
combination of Federated Learning (FL) and LLMs (federated LLMs) offers a
solution by leveraging distributed data while protecting privacy, which
positions it as an ideal choice for sensitive domains. However, Federated LLMs
still suffer from robustness challenges, including data heterogeneity,
malicious clients, and adversarial attacks, which greatly hinder their
applications. We first introduce the robustness problems in federated LLMs, to
address these challenges, we propose FedEAT (Federated Embedding space
Adversarial Training), a novel framework that applies adversarial training in
the embedding space of client LLM and employs a robust aggregation approach,
specifically geometric median aggregation, to enhance the robustness of
Federated LLMs. Our experiments demonstrate that FedEAT effectively improves
the robustness of Federated LLMs with minimal performance loss.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Significant advancements have been made by Large Language Models (LLMs) in\nthe domains of natural language understanding and automated content creation.\nHowever, they still face persistent problems, including substantial\ncomputational costs and inadequate availability of training data. The\ncombination of Federated Learning (FL) and LLMs (federated LLMs) offers a\nsolution by leveraging distributed data while protecting privacy, which\npositions it as an ideal choice for sensitive domains. However, Federated LLMs\nstill suffer from robustness challenges, including data heterogeneity,\nmalicious clients, and adversarial attacks, which greatly hinder their\napplications. We first introduce the robustness problems in federated LLMs, to\naddress these challenges, we propose FedEAT (Federated Embedding space\nAdversarial Training), a novel framework that applies adversarial training in\nthe embedding space of client LLM and employs a robust aggregation approach,\nspecifically geometric median aggregation, to enhance the robustness of\nFederated LLMs. Our experiments demonstrate that FedEAT effectively improves\nthe robustness of Federated LLMs with minimal performance loss.'}","['Yahao Pang', 'Xingyuan Wu', 'Xiaojin Zhang', 'Wei Chen', 'Hai Jin']",{'name': 'Hai Jin'},Hai Jin,,"[{'href': 'http://arxiv.org/abs/2502.11863v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11863v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11863v1,None,http://arxiv.org/abs/2502.11863v1,,,16,0
http://arxiv.org/abs/2502.11881v1,True,2025-02-17T15:08:50Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=15, tm_min=8, tm_sec=50, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T15:08:50Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=15, tm_min=8, tm_sec=50, tm_wday=0, tm_yday=48, tm_isdst=0)",Hypothesis-Driven Theory-of-Mind Reasoning for Large Language Models,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Hypothesis-Driven Theory-of-Mind Reasoning for Large Language Models'}","Existing LLM reasoning methods have shown impressive capabilities across
various tasks, such as solving math and coding problems. However, applying
these methods to scenarios without ground-truth answers or rule-based
verification methods - such as tracking the mental states of an agent - remains
challenging. Inspired by the sequential Monte Carlo algorithm, we introduce
thought-tracing, an inference-time reasoning algorithm designed to trace the
mental states of specific agents by generating hypotheses and weighting them
based on observations without relying on ground-truth solutions to questions in
datasets. Our algorithm is modeled after the Bayesian theory-of-mind framework,
using LLMs to approximate probabilistic inference over agents' evolving mental
states based on their perceptions and actions. We evaluate thought-tracing on
diverse theory-of-mind benchmarks, demonstrating significant performance
improvements compared to baseline LLMs. Our experiments also reveal interesting
behaviors of the recent reasoning models - e.g., o1 and R1 - on theory-of-mind,
highlighting the difference of social reasoning compared to other domains.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Existing LLM reasoning methods have shown impressive capabilities across\nvarious tasks, such as solving math and coding problems. However, applying\nthese methods to scenarios without ground-truth answers or rule-based\nverification methods - such as tracking the mental states of an agent - remains\nchallenging. Inspired by the sequential Monte Carlo algorithm, we introduce\nthought-tracing, an inference-time reasoning algorithm designed to trace the\nmental states of specific agents by generating hypotheses and weighting them\nbased on observations without relying on ground-truth solutions to questions in\ndatasets. Our algorithm is modeled after the Bayesian theory-of-mind framework,\nusing LLMs to approximate probabilistic inference over agents' evolving mental\nstates based on their perceptions and actions. We evaluate thought-tracing on\ndiverse theory-of-mind benchmarks, demonstrating significant performance\nimprovements compared to baseline LLMs. Our experiments also reveal interesting\nbehaviors of the recent reasoning models - e.g., o1 and R1 - on theory-of-mind,\nhighlighting the difference of social reasoning compared to other domains.""}","['Hyunwoo Kim', 'Melanie Sclar', 'Tan Zhi-Xuan', 'Lance Ying', 'Sydney Levine', 'Yang Liu', 'Joshua B. Tenenbaum', 'Yejin Choi']",{'name': 'Yejin Choi'},Yejin Choi,,"[{'href': 'http://arxiv.org/abs/2502.11881v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11881v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11881v1,None,http://arxiv.org/abs/2502.11881v1,,,1926,0
http://arxiv.org/abs/2502.11895v1,True,2025-02-17T15:21:11Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=15, tm_min=21, tm_sec=11, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T15:21:11Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=15, tm_min=21, tm_sec=11, tm_wday=0, tm_yday=48, tm_isdst=0)","Continual Quantization-Aware Pre-Training: When to transition from
  16-bit to 1.58-bit pre-training for BitNet language models?","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Continual Quantization-Aware Pre-Training: When to transition from\n  16-bit to 1.58-bit pre-training for BitNet language models?'}","Large language models (LLMs) require immense resources for training and
inference. Quantization, a technique that reduces the precision of model
parameters, offers a promising solution for improving LLM efficiency and
sustainability. While post-training quantization methods typically achieve 4-8
bits per parameter, recent research suggests that training LLMs with 1.58 bits
per weight parameter from scratch can maintain model accuracy while greatly
reducing memory requirements and energy consumption at inference time. Here, we
investigate a training strategy for quantization-aware pre-training, where the
models are first trained with 16-bit precision and then transition into
1.58-bit quantization-aware training. Our results on 11 downstream tasks show
that this 16-to-1.58-bit training strategy is preferable over full 1.58-bit
training and leaves models closer to those which have undergone 16-bit
training. We further investigate the effects of retaining the optimizer state
at the transition point and gradually phasing in quantization strength --
finding that both techniques alleviate the magnitude of loss spikes, but also
that these effects can be compensated through further training.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large language models (LLMs) require immense resources for training and\ninference. Quantization, a technique that reduces the precision of model\nparameters, offers a promising solution for improving LLM efficiency and\nsustainability. While post-training quantization methods typically achieve 4-8\nbits per parameter, recent research suggests that training LLMs with 1.58 bits\nper weight parameter from scratch can maintain model accuracy while greatly\nreducing memory requirements and energy consumption at inference time. Here, we\ninvestigate a training strategy for quantization-aware pre-training, where the\nmodels are first trained with 16-bit precision and then transition into\n1.58-bit quantization-aware training. Our results on 11 downstream tasks show\nthat this 16-to-1.58-bit training strategy is preferable over full 1.58-bit\ntraining and leaves models closer to those which have undergone 16-bit\ntraining. We further investigate the effects of retaining the optimizer state\nat the transition point and gradually phasing in quantization strength --\nfinding that both techniques alleviate the magnitude of loss spikes, but also\nthat these effects can be compensated through further training.'}","['Jacob Nielsen', 'Peter Schneider-Kamp', 'Lukas Galke']",{'name': 'Lukas Galke'},Lukas Galke,,"[{'href': 'http://arxiv.org/abs/2502.11895v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11895v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11895v1,None,http://arxiv.org/abs/2502.11895v1,,,3169,0
http://arxiv.org/abs/2502.11896v1,True,2025-02-17T15:22:19Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=15, tm_min=22, tm_sec=19, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T15:22:19Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=15, tm_min=22, tm_sec=19, tm_wday=0, tm_yday=48, tm_isdst=0)","CAMEL: Continuous Action Masking Enabled by Large Language Models for
  Reinforcement Learning","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'CAMEL: Continuous Action Masking Enabled by Large Language Models for\n  Reinforcement Learning'}","Reinforcement learning (RL) in continuous action spaces encounters persistent
challenges, such as inefficient exploration and convergence to suboptimal
solutions. To address these limitations, we propose CAMEL, a novel framework
integrating LLM-generated suboptimal policies into the RL training pipeline.
CAMEL leverages dynamic action masking and an adaptive epsilon-masking
mechanism to guide exploration during early training stages while gradually
enabling agents to optimize policies independently. At the core of CAMEL lies
the integration of Python-executable suboptimal policies generated by LLMs
based on environment descriptions and task objectives. Although simplistic and
hard-coded, these policies offer valuable initial guidance for RL agents. To
effectively utilize these priors, CAMEL employs masking-aware optimization to
dynamically constrain the action space based on LLM outputs. Additionally,
epsilon-masking gradually reduces reliance on LLM-generated guidance, enabling
agents to transition from constrained exploration to autonomous policy
refinement. Experimental validation on Gymnasium MuJoCo environments
demonstrates the effectiveness of CAMEL. In Hopper-v4 and Ant-v4, LLM-generated
policies significantly improve sample efficiency, achieving performance
comparable to or surpassing expert masking baselines. For Walker2d-v4, where
LLMs struggle to accurately model bipedal gait dynamics, CAMEL maintains robust
RL performance without notable degradation, highlighting the framework's
adaptability across diverse tasks. While CAMEL shows promise in enhancing
sample efficiency and mitigating convergence challenges, these issues remain
open for further research. Future work aims to generalize CAMEL to multimodal
LLMs for broader observation-action spaces and automate policy evaluation,
reducing human intervention and enhancing scalability in RL training pipelines.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Reinforcement learning (RL) in continuous action spaces encounters persistent\nchallenges, such as inefficient exploration and convergence to suboptimal\nsolutions. To address these limitations, we propose CAMEL, a novel framework\nintegrating LLM-generated suboptimal policies into the RL training pipeline.\nCAMEL leverages dynamic action masking and an adaptive epsilon-masking\nmechanism to guide exploration during early training stages while gradually\nenabling agents to optimize policies independently. At the core of CAMEL lies\nthe integration of Python-executable suboptimal policies generated by LLMs\nbased on environment descriptions and task objectives. Although simplistic and\nhard-coded, these policies offer valuable initial guidance for RL agents. To\neffectively utilize these priors, CAMEL employs masking-aware optimization to\ndynamically constrain the action space based on LLM outputs. Additionally,\nepsilon-masking gradually reduces reliance on LLM-generated guidance, enabling\nagents to transition from constrained exploration to autonomous policy\nrefinement. Experimental validation on Gymnasium MuJoCo environments\ndemonstrates the effectiveness of CAMEL. In Hopper-v4 and Ant-v4, LLM-generated\npolicies significantly improve sample efficiency, achieving performance\ncomparable to or surpassing expert masking baselines. For Walker2d-v4, where\nLLMs struggle to accurately model bipedal gait dynamics, CAMEL maintains robust\nRL performance without notable degradation, highlighting the framework's\nadaptability across diverse tasks. While CAMEL shows promise in enhancing\nsample efficiency and mitigating convergence challenges, these issues remain\nopen for further research. Future work aims to generalize CAMEL to multimodal\nLLMs for broader observation-action spaces and automate policy evaluation,\nreducing human intervention and enhancing scalability in RL training pipelines.""}","['Yanxiao Zhao', 'Yangge Qian', 'Jingyang Shan', 'Xiaolin Qin']",{'name': 'Xiaolin Qin'},Xiaolin Qin,Accepted at RLDM 2025,"[{'href': 'http://arxiv.org/abs/2502.11896v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11896v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11896v1,None,http://arxiv.org/abs/2502.11896v1,,,7,0
http://arxiv.org/abs/2502.11897v1,True,2025-02-17T15:22:31Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=15, tm_min=22, tm_sec=31, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T15:22:31Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=15, tm_min=22, tm_sec=31, tm_wday=0, tm_yday=48, tm_isdst=0)",DLFR-VAE: Dynamic Latent Frame Rate VAE for Video Generation,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'DLFR-VAE: Dynamic Latent Frame Rate VAE for Video Generation'}","In this paper, we propose the Dynamic Latent Frame Rate VAE (DLFR-VAE), a
training-free paradigm that can make use of adaptive temporal compression in
latent space. While existing video generative models apply fixed compression
rates via pretrained VAE, we observe that real-world video content exhibits
substantial temporal non-uniformity, with high-motion segments containing more
information than static scenes. Based on this insight, DLFR-VAE dynamically
adjusts the latent frame rate according to the content complexity.
Specifically, DLFR-VAE comprises two core innovations: (1) A Dynamic Latent
Frame Rate Scheduler that partitions videos into temporal chunks and adaptively
determines optimal frame rates based on information-theoretic content
complexity, and (2) A training-free adaptation mechanism that transforms
pretrained VAE architectures into a dynamic VAE that can process features with
variable frame rates. Our simple but effective DLFR-VAE can function as a
plug-and-play module, seamlessly integrating with existing video generation
models and accelerating the video generation process.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'In this paper, we propose the Dynamic Latent Frame Rate VAE (DLFR-VAE), a\ntraining-free paradigm that can make use of adaptive temporal compression in\nlatent space. While existing video generative models apply fixed compression\nrates via pretrained VAE, we observe that real-world video content exhibits\nsubstantial temporal non-uniformity, with high-motion segments containing more\ninformation than static scenes. Based on this insight, DLFR-VAE dynamically\nadjusts the latent frame rate according to the content complexity.\nSpecifically, DLFR-VAE comprises two core innovations: (1) A Dynamic Latent\nFrame Rate Scheduler that partitions videos into temporal chunks and adaptively\ndetermines optimal frame rates based on information-theoretic content\ncomplexity, and (2) A training-free adaptation mechanism that transforms\npretrained VAE architectures into a dynamic VAE that can process features with\nvariable frame rates. Our simple but effective DLFR-VAE can function as a\nplug-and-play module, seamlessly integrating with existing video generation\nmodels and accelerating the video generation process.'}","['Zhihang Yuan', 'Siyuan Wang', 'Rui Xie', 'Hanling Zhang', 'Tongcheng Fang', 'Yuzhang Shang', 'Shengen Yan', 'Guohao Dai', 'Yu Wang']",{'name': 'Yu Wang'},Yu Wang,,"[{'href': 'http://arxiv.org/abs/2502.11897v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11897v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11897v1,None,http://arxiv.org/abs/2502.11897v1,,,1635,0
http://arxiv.org/abs/2502.11915v1,True,2025-02-17T15:31:27Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=15, tm_min=31, tm_sec=27, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T15:31:27Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=15, tm_min=31, tm_sec=27, tm_wday=0, tm_yday=48, tm_isdst=0)",On the robustness of ChatGPT in teaching Korean Mathematics,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'On the robustness of ChatGPT in teaching Korean Mathematics'}","ChatGPT, an Artificial Intelligence model, has the potential to revolutionize
education. However, its effectiveness in solving non-English questions remains
uncertain. This study evaluates ChatGPT's robustness using 586 Korean
mathematics questions. ChatGPT achieves 66.72% accuracy, correctly answering
391 out of 586 questions. We also assess its ability to rate mathematics
questions based on eleven criteria and perform a topic analysis. Our findings
show that ChatGPT's ratings align with educational theory and test-taker
perspectives. While ChatGPT performs well in question classification, it
struggles with non-English contexts, highlighting areas for improvement. Future
research should address linguistic biases and enhance accuracy across diverse
languages. Domain-specific optimizations and multilingual training could
improve ChatGPT's role in personalized education.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""ChatGPT, an Artificial Intelligence model, has the potential to revolutionize\neducation. However, its effectiveness in solving non-English questions remains\nuncertain. This study evaluates ChatGPT's robustness using 586 Korean\nmathematics questions. ChatGPT achieves 66.72% accuracy, correctly answering\n391 out of 586 questions. We also assess its ability to rate mathematics\nquestions based on eleven criteria and perform a topic analysis. Our findings\nshow that ChatGPT's ratings align with educational theory and test-taker\nperspectives. While ChatGPT performs well in question classification, it\nstruggles with non-English contexts, highlighting areas for improvement. Future\nresearch should address linguistic biases and enhance accuracy across diverse\nlanguages. Domain-specific optimizations and multilingual training could\nimprove ChatGPT's role in personalized education.""}","['Phuong-Nam Nguyen', 'Quang Nguyen-The', 'An Vu-Minh', 'Diep-Anh Nguyen', 'Xuan-Lam Pham']",{'name': 'Xuan-Lam Pham'},Xuan-Lam Pham,"21 pages, 12 figures, includes statistical analysis of ChatGPT's
  robustness in solving and rating multilingual mathematics questions. Focus on
  Korean CSAT Mathematics. Evaluates AI accuracy, rating effectiveness, and
  topic analysis","[{'href': 'http://arxiv.org/abs/2502.11915v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11915v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.HO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7; K.3.1; G.3', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11915v1,None,http://arxiv.org/abs/2502.11915v1,,,0,0
http://arxiv.org/abs/2502.11916v1,True,2025-02-17T15:31:59Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=15, tm_min=31, tm_sec=59, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T15:31:59Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=15, tm_min=31, tm_sec=59, tm_wday=0, tm_yday=48, tm_isdst=0)","EssayJudge: A Multi-Granular Benchmark for Assessing Automated Essay
  Scoring Capabilities of Multimodal Large Language Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'EssayJudge: A Multi-Granular Benchmark for Assessing Automated Essay\n  Scoring Capabilities of Multimodal Large Language Models'}","Automated Essay Scoring (AES) plays a crucial role in educational assessment
by providing scalable and consistent evaluations of writing tasks. However,
traditional AES systems face three major challenges: (1) reliance on
handcrafted features that limit generalizability, (2) difficulty in capturing
fine-grained traits like coherence and argumentation, and (3) inability to
handle multimodal contexts. In the era of Multimodal Large Language Models
(MLLMs), we propose EssayJudge, the first multimodal benchmark to evaluate AES
capabilities across lexical-, sentence-, and discourse-level traits. By
leveraging MLLMs' strengths in trait-specific scoring and multimodal context
understanding, EssayJudge aims to offer precise, context-rich evaluations
without manual feature engineering, addressing longstanding AES limitations.
Our experiments with 18 representative MLLMs reveal gaps in AES performance
compared to human evaluation, particularly in discourse-level traits,
highlighting the need for further advancements in MLLM-based AES research. Our
dataset and code will be available upon acceptance.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Automated Essay Scoring (AES) plays a crucial role in educational assessment\nby providing scalable and consistent evaluations of writing tasks. However,\ntraditional AES systems face three major challenges: (1) reliance on\nhandcrafted features that limit generalizability, (2) difficulty in capturing\nfine-grained traits like coherence and argumentation, and (3) inability to\nhandle multimodal contexts. In the era of Multimodal Large Language Models\n(MLLMs), we propose EssayJudge, the first multimodal benchmark to evaluate AES\ncapabilities across lexical-, sentence-, and discourse-level traits. By\nleveraging MLLMs' strengths in trait-specific scoring and multimodal context\nunderstanding, EssayJudge aims to offer precise, context-rich evaluations\nwithout manual feature engineering, addressing longstanding AES limitations.\nOur experiments with 18 representative MLLMs reveal gaps in AES performance\ncompared to human evaluation, particularly in discourse-level traits,\nhighlighting the need for further advancements in MLLM-based AES research. Our\ndataset and code will be available upon acceptance.""}","['Jiamin Su', 'Yibo Yan', 'Fangteng Fu', 'Han Zhang', 'Jingheng Ye', 'Xiang Liu', 'Jiahao Huo', 'Huiyu Zhou', 'Xuming Hu']",{'name': 'Xuming Hu'},Xuming Hu,JS and YY are co-first authors. XH is the corresponding author,"[{'href': 'http://arxiv.org/abs/2502.11916v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11916v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11916v1,None,http://arxiv.org/abs/2502.11916v1,,,146,0
http://arxiv.org/abs/2502.11937v1,True,2025-02-17T15:48:46Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=15, tm_min=48, tm_sec=46, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T15:48:46Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=15, tm_min=48, tm_sec=46, tm_wday=0, tm_yday=48, tm_isdst=0)","FitLight: Federated Imitation Learning for Plug-and-Play Autonomous
  Traffic Signal Control","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'FitLight: Federated Imitation Learning for Plug-and-Play Autonomous\n  Traffic Signal Control'}","Although Reinforcement Learning (RL)-based Traffic Signal Control (TSC)
methods have been extensively studied, their practical applications still raise
some serious issues such as high learning cost and poor generalizability. This
is because the ``trial-and-error'' training style makes RL agents extremely
dependent on the specific traffic environment, which also requires a long
convergence time. To address these issues, we propose a novel Federated
Imitation Learning (FIL)-based framework for multi-intersection TSC, named
FitLight, which allows RL agents to plug-and-play for any traffic environment
without additional pre-training cost. Unlike existing imitation learning
approaches that rely on pre-training RL agents with demonstrations, FitLight
allows real-time imitation learning and seamless transition to reinforcement
learning. Due to our proposed knowledge-sharing mechanism and novel hybrid
pressure-based agent design, RL agents can quickly find a best control policy
with only a few episodes. Moreover, for resource-constrained TSC scenarios,
FitLight supports model pruning and heterogeneous model aggregation, such that
RL agents can work on a micro-controller with merely 16{\it KB} RAM and 32{\it
KB} ROM. Extensive experiments demonstrate that, compared to state-of-the-art
methods, FitLight not only provides a superior starting point but also
converges to a better final solution on both real-world and synthetic datasets,
even under extreme resource limitations.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Although Reinforcement Learning (RL)-based Traffic Signal Control (TSC)\nmethods have been extensively studied, their practical applications still raise\nsome serious issues such as high learning cost and poor generalizability. This\nis because the ``trial-and-error'' training style makes RL agents extremely\ndependent on the specific traffic environment, which also requires a long\nconvergence time. To address these issues, we propose a novel Federated\nImitation Learning (FIL)-based framework for multi-intersection TSC, named\nFitLight, which allows RL agents to plug-and-play for any traffic environment\nwithout additional pre-training cost. Unlike existing imitation learning\napproaches that rely on pre-training RL agents with demonstrations, FitLight\nallows real-time imitation learning and seamless transition to reinforcement\nlearning. Due to our proposed knowledge-sharing mechanism and novel hybrid\npressure-based agent design, RL agents can quickly find a best control policy\nwith only a few episodes. Moreover, for resource-constrained TSC scenarios,\nFitLight supports model pruning and heterogeneous model aggregation, such that\nRL agents can work on a micro-controller with merely 16{\\it KB} RAM and 32{\\it\nKB} ROM. Extensive experiments demonstrate that, compared to state-of-the-art\nmethods, FitLight not only provides a superior starting point but also\nconverges to a better final solution on both real-world and synthetic datasets,\neven under extreme resource limitations.""}","['Yutong Ye', 'Yingbo Zhou', 'Zhusen Liu', 'Xiao Du', 'Hao Zhou', 'Xiang Lian', 'Mingsong Chen']",{'name': 'Mingsong Chen'},Mingsong Chen,,"[{'href': 'http://arxiv.org/abs/2502.11937v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11937v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11937v1,None,http://arxiv.org/abs/2502.11937v1,,,28,0
http://arxiv.org/abs/2502.11941v1,True,2025-02-17T15:52:22Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=15, tm_min=52, tm_sec=22, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T15:52:22Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=15, tm_min=52, tm_sec=22, tm_wday=0, tm_yday=48, tm_isdst=0)",Deep Spatio-Temporal Neural Network for Air Quality Reanalysis,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Deep Spatio-Temporal Neural Network for Air Quality Reanalysis'}","Air quality prediction is key to mitigating health impacts and guiding
decisions, yet existing models tend to focus on temporal trends while
overlooking spatial generalization. We propose AQ-Net, a spatiotemporal
reanalysis model for both observed and unobserved stations in the near future.
AQ-Net utilizes the LSTM and multi-head attention for the temporal regression.
We also propose a cyclic encoding technique to ensure continuous time
representation. To learn fine-grained spatial air quality estimation, we
incorporate AQ-Net with the neural kNN to explore feature-based interpolation,
such that we can fill the spatial gaps given coarse observation stations. To
demonstrate the efficiency of our model for spatiotemporal reanalysis, we use
data from 2013-2017 collected in northern China for PM2.5 analysis. Extensive
experiments show that AQ-Net excels in air quality reanalysis, highlighting the
potential of hybrid spatio-temporal models to better capture environmental
dynamics, especially in urban areas where both spatial and temporal variability
are critical.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Air quality prediction is key to mitigating health impacts and guiding\ndecisions, yet existing models tend to focus on temporal trends while\noverlooking spatial generalization. We propose AQ-Net, a spatiotemporal\nreanalysis model for both observed and unobserved stations in the near future.\nAQ-Net utilizes the LSTM and multi-head attention for the temporal regression.\nWe also propose a cyclic encoding technique to ensure continuous time\nrepresentation. To learn fine-grained spatial air quality estimation, we\nincorporate AQ-Net with the neural kNN to explore feature-based interpolation,\nsuch that we can fill the spatial gaps given coarse observation stations. To\ndemonstrate the efficiency of our model for spatiotemporal reanalysis, we use\ndata from 2013-2017 collected in northern China for PM2.5 analysis. Extensive\nexperiments show that AQ-Net excels in air quality reanalysis, highlighting the\npotential of hybrid spatio-temporal models to better capture environmental\ndynamics, especially in urban areas where both spatial and temporal variability\nare critical.'}","['Ammar Kheder', 'Benjamin Foreback', 'Lili Wang', 'Zhi-Song Liu', 'Michael Boy']",{'name': 'Michael Boy'},Michael Boy,,"[{'href': 'http://arxiv.org/abs/2502.11941v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11941v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11941v1,None,http://arxiv.org/abs/2502.11941v1,,,85,0
http://arxiv.org/abs/2502.11949v1,True,2025-02-17T16:02:54Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=16, tm_min=2, tm_sec=54, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T16:02:54Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=16, tm_min=2, tm_sec=54, tm_wday=0, tm_yday=48, tm_isdst=0)",Massively Scaling Explicit Policy-conditioned Value Functions,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Massively Scaling Explicit Policy-conditioned Value Functions'}","We introduce a scaling strategy for Explicit Policy-Conditioned Value
Functions (EPVFs) that significantly improves performance on challenging
continuous-control tasks. EPVFs learn a value function V({\theta}) that is
explicitly conditioned on the policy parameters, enabling direct gradient-based
updates to the parameters of any policy. However, EPVFs at scale struggle with
unrestricted parameter growth and efficient exploration in the policy parameter
space. To address these issues, we utilize massive parallelization with
GPU-based simulators, big batch sizes, weight clipping and scaled peturbations.
Our results show that EPVFs can be scaled to solve complex tasks, such as a
custom Ant environment, and can compete with state-of-the-art Deep
Reinforcement Learning (DRL) baselines like Proximal Policy Optimization (PPO)
and Soft Actor-Critic (SAC). We further explore action-based policy parameter
representations from previous work and specialized neural network architectures
to efficiently handle weight-space features, which have not been used in the
context of DRL before.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'We introduce a scaling strategy for Explicit Policy-Conditioned Value\nFunctions (EPVFs) that significantly improves performance on challenging\ncontinuous-control tasks. EPVFs learn a value function V({\\theta}) that is\nexplicitly conditioned on the policy parameters, enabling direct gradient-based\nupdates to the parameters of any policy. However, EPVFs at scale struggle with\nunrestricted parameter growth and efficient exploration in the policy parameter\nspace. To address these issues, we utilize massive parallelization with\nGPU-based simulators, big batch sizes, weight clipping and scaled peturbations.\nOur results show that EPVFs can be scaled to solve complex tasks, such as a\ncustom Ant environment, and can compete with state-of-the-art Deep\nReinforcement Learning (DRL) baselines like Proximal Policy Optimization (PPO)\nand Soft Actor-Critic (SAC). We further explore action-based policy parameter\nrepresentations from previous work and specialized neural network architectures\nto efficiently handle weight-space features, which have not been used in the\ncontext of DRL before.'}","['Nico Bohlinger', 'Jan Peters']",{'name': 'Jan Peters'},Jan Peters,,"[{'href': 'http://arxiv.org/abs/2502.11949v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11949v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11949v1,None,http://arxiv.org/abs/2502.11949v1,,,4,0
http://arxiv.org/abs/2502.11962v1,True,2025-02-17T16:10:30Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=16, tm_min=10, tm_sec=30, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T16:10:30Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=16, tm_min=10, tm_sec=30, tm_wday=0, tm_yday=48, tm_isdst=0)","Navigating the Helpfulness-Truthfulness Trade-Off with Uncertainty-Aware
  Instruction Fine-Tuning","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Navigating the Helpfulness-Truthfulness Trade-Off with Uncertainty-Aware\n  Instruction Fine-Tuning'}","Instruction Fine-tuning (IFT) can enhance the helpfulness of Large Language
Models (LLMs), but it may lower their truthfulness. This trade-off arises
because IFT steers LLMs to generate responses with long-tail knowledge that is
not well covered during pre-training, leading to more informative but less
truthful answers when generalizing to unseen tasks. In this paper, we
empirically demonstrate this helpfulness-truthfulness trade-off in IFT and
propose $\textbf{UNIT}$, a novel IFT paradigm to address it. UNIT teaches LLMs
to recognize their uncertainty and explicitly reflect it at the end of their
responses. Experimental results show that UNIT-tuned models maintain their
helpfulness while distinguishing between certain and uncertain claims, thereby
reducing hallucinations.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Instruction Fine-tuning (IFT) can enhance the helpfulness of Large Language\nModels (LLMs), but it may lower their truthfulness. This trade-off arises\nbecause IFT steers LLMs to generate responses with long-tail knowledge that is\nnot well covered during pre-training, leading to more informative but less\ntruthful answers when generalizing to unseen tasks. In this paper, we\nempirically demonstrate this helpfulness-truthfulness trade-off in IFT and\npropose $\\textbf{UNIT}$, a novel IFT paradigm to address it. UNIT teaches LLMs\nto recognize their uncertainty and explicitly reflect it at the end of their\nresponses. Experimental results show that UNIT-tuned models maintain their\nhelpfulness while distinguishing between certain and uncertain claims, thereby\nreducing hallucinations.'}","['Tianyi Wu', 'Jingwei Ni', 'Bryan Hooi', 'Jiaheng Zhang', 'Elliott Ash', 'See-Kiong Ng', 'Mrinmaya Sachan', 'Markus Leippold']",{'name': 'Markus Leippold'},Markus Leippold,,"[{'href': 'http://arxiv.org/abs/2502.11962v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11962v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11962v1,None,http://arxiv.org/abs/2502.11962v1,,,3855,0
http://arxiv.org/abs/2502.11965v1,True,2025-02-17T16:13:40Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=16, tm_min=13, tm_sec=40, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T16:13:40Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=16, tm_min=13, tm_sec=40, tm_wday=0, tm_yday=48, tm_isdst=0)",A MIMO Wireless Channel Foundation Model via CIR-CSI Consistency,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A MIMO Wireless Channel Foundation Model via CIR-CSI Consistency'}","In the field of artificial intelligence, self-supervised learning has
demonstrated superior generalization capabilities by leveraging large-scale
unlabeled datasets for pretraining, which is especially critical for wireless
communication models to adapt to a variety of scenarios. This paper
innovatively treats Channel State Information (CSI) and Channel Impulse
Response (CIR) as naturally aligned multi-modal data and proposes the first
MIMO wireless channel foundation model, named CSI-CLIP. By effectively
capturing the joint representations of both CIR and CSI, CSI-CLIP exhibits
remarkable adaptability across scenarios and robust feature extraction
capabilities. Experimental results show that in positioning task, CSI-CLIP
reduces the mean error distance by 22%; in beam management task, it increases
accuracy by 1% compared to traditional supervised methods, as well as in the
channel identification task. These improvements not only highlight the
potential and value of CSI-CLIP in integrating sensing and communication but
also demonstrate its significant advantages over existing techniques. Moreover,
viewing CSI and CIR as multi-modal pairs and contrastive learning for wireless
channel foundation model open up new research directions in the domain of MIMO
wireless communications.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'In the field of artificial intelligence, self-supervised learning has\ndemonstrated superior generalization capabilities by leveraging large-scale\nunlabeled datasets for pretraining, which is especially critical for wireless\ncommunication models to adapt to a variety of scenarios. This paper\ninnovatively treats Channel State Information (CSI) and Channel Impulse\nResponse (CIR) as naturally aligned multi-modal data and proposes the first\nMIMO wireless channel foundation model, named CSI-CLIP. By effectively\ncapturing the joint representations of both CIR and CSI, CSI-CLIP exhibits\nremarkable adaptability across scenarios and robust feature extraction\ncapabilities. Experimental results show that in positioning task, CSI-CLIP\nreduces the mean error distance by 22%; in beam management task, it increases\naccuracy by 1% compared to traditional supervised methods, as well as in the\nchannel identification task. These improvements not only highlight the\npotential and value of CSI-CLIP in integrating sensing and communication but\nalso demonstrate its significant advantages over existing techniques. Moreover,\nviewing CSI and CIR as multi-modal pairs and contrastive learning for wireless\nchannel foundation model open up new research directions in the domain of MIMO\nwireless communications.'}","['Jun Jiang', 'Wenjun Yu', 'Yunfan Li', 'Yuan Gao', 'Shugong Xu']",{'name': 'Shugong Xu'},Shugong Xu,"6 pages, 2025 ICMLCN accepted","[{'href': 'http://arxiv.org/abs/2502.11965v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11965v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'eess.SP', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'eess.SP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11965v1,None,http://arxiv.org/abs/2502.11965v1,,,0,0
http://arxiv.org/abs/2502.11968v1,True,2025-02-17T16:18:00Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=16, tm_min=18, tm_sec=0, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T16:18:00Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=16, tm_min=18, tm_sec=0, tm_wday=0, tm_yday=48, tm_isdst=0)",Theoretical Barriers in Bellman-Based Reinforcement Learning,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Theoretical Barriers in Bellman-Based Reinforcement Learning'}","Reinforcement Learning algorithms designed for high-dimensional spaces often
enforce the Bellman equation on a sampled subset of states, relying on
generalization to propagate knowledge across the state space. In this paper, we
identify and formalize a fundamental limitation of this common approach.
Specifically, we construct counterexample problems with a simple structure that
this approach fails to exploit. Our findings reveal that such algorithms can
neglect critical information about the problems, leading to inefficiencies.
Furthermore, we extend this negative result to another approach from the
literature: Hindsight Experience Replay learning state-to-state reachability.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Reinforcement Learning algorithms designed for high-dimensional spaces often\nenforce the Bellman equation on a sampled subset of states, relying on\ngeneralization to propagate knowledge across the state space. In this paper, we\nidentify and formalize a fundamental limitation of this common approach.\nSpecifically, we construct counterexample problems with a simple structure that\nthis approach fails to exploit. Our findings reveal that such algorithms can\nneglect critical information about the problems, leading to inefficiencies.\nFurthermore, we extend this negative result to another approach from the\nliterature: Hindsight Experience Replay learning state-to-state reachability.'}","['Brieuc Pinon', 'Raphal Jungers', 'Jean-Charles Delvenne']",{'name': 'Jean-Charles Delvenne'},Jean-Charles Delvenne,,"[{'href': 'http://arxiv.org/abs/2502.11968v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11968v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11968v1,None,http://arxiv.org/abs/2502.11968v1,,,687,0
http://arxiv.org/abs/2502.11995v1,True,2025-02-17T16:35:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=16, tm_min=35, tm_sec=15, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T16:35:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=16, tm_min=35, tm_sec=15, tm_wday=0, tm_yday=48, tm_isdst=0)",Presumed Cultural Identity: How Names Shape LLM Responses,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Presumed Cultural Identity: How Names Shape LLM Responses'}","Names are deeply tied to human identity. They can serve as markers of
individuality, cultural heritage, and personal history. However, using names as
a core indicator of identity can lead to over-simplification of complex
identities. When interacting with LLMs, user names are an important point of
information for personalisation. Names can enter chatbot conversations through
direct user input (requested by chatbots), as part of task contexts such as CV
reviews, or as built-in memory features that store user information for
personalisation. We study biases associated with names by measuring cultural
presumptions in the responses generated by LLMs when presented with common
suggestion-seeking queries, which might involve making assumptions about the
user. Our analyses demonstrate strong assumptions about cultural identity
associated with names present in LLM generations across multiple cultures. Our
work has implications for designing more nuanced personalisation systems that
avoid reinforcing stereotypes while maintaining meaningful customisation.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Names are deeply tied to human identity. They can serve as markers of\nindividuality, cultural heritage, and personal history. However, using names as\na core indicator of identity can lead to over-simplification of complex\nidentities. When interacting with LLMs, user names are an important point of\ninformation for personalisation. Names can enter chatbot conversations through\ndirect user input (requested by chatbots), as part of task contexts such as CV\nreviews, or as built-in memory features that store user information for\npersonalisation. We study biases associated with names by measuring cultural\npresumptions in the responses generated by LLMs when presented with common\nsuggestion-seeking queries, which might involve making assumptions about the\nuser. Our analyses demonstrate strong assumptions about cultural identity\nassociated with names present in LLM generations across multiple cultures. Our\nwork has implications for designing more nuanced personalisation systems that\navoid reinforcing stereotypes while maintaining meaningful customisation.'}","['Siddhesh Pawar', 'Arnav Arora', 'Lucie-Aime Kaffee', 'Isabelle Augenstein']",{'name': 'Isabelle Augenstein'},Isabelle Augenstein,"23 Pages, 13 Figures, 4 Tables","[{'href': 'http://arxiv.org/abs/2502.11995v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11995v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11995v1,None,http://arxiv.org/abs/2502.11995v1,,,1006,0
http://arxiv.org/abs/2502.12007v1,True,2025-02-17T16:43:47Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=16, tm_min=43, tm_sec=47, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T16:43:47Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=16, tm_min=43, tm_sec=47, tm_wday=0, tm_yday=48, tm_isdst=0)",Demographic Attributes Prediction from Speech Using WavLM Embeddings,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Demographic Attributes Prediction from Speech Using WavLM Embeddings'}","This paper introduces a general classifier based on WavLM features, to infer
demographic characteristics, such as age, gender, native language, education,
and country, from speech. Demographic feature prediction plays a crucial role
in applications like language learning, accessibility, and digital forensics,
enabling more personalized and inclusive technologies. Leveraging pretrained
models for embedding extraction, the proposed framework identifies key acoustic
and linguistic fea-tures associated with demographic attributes, achieving a
Mean Absolute Error (MAE) of 4.94 for age prediction and over 99.81% accuracy
for gender classification across various datasets. Our system improves upon
existing models by up to relative 30% in MAE and up to relative 10% in accuracy
and F1 scores across tasks, leveraging a diverse range of datasets and large
pretrained models to ensure robustness and generalizability. This study offers
new insights into speaker diversity and provides a strong foundation for future
research in speech-based demographic profiling.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'This paper introduces a general classifier based on WavLM features, to infer\ndemographic characteristics, such as age, gender, native language, education,\nand country, from speech. Demographic feature prediction plays a crucial role\nin applications like language learning, accessibility, and digital forensics,\nenabling more personalized and inclusive technologies. Leveraging pretrained\nmodels for embedding extraction, the proposed framework identifies key acoustic\nand linguistic fea-tures associated with demographic attributes, achieving a\nMean Absolute Error (MAE) of 4.94 for age prediction and over 99.81% accuracy\nfor gender classification across various datasets. Our system improves upon\nexisting models by up to relative 30% in MAE and up to relative 10% in accuracy\nand F1 scores across tasks, leveraging a diverse range of datasets and large\npretrained models to ensure robustness and generalizability. This study offers\nnew insights into speaker diversity and provides a strong foundation for future\nresearch in speech-based demographic profiling.'}","['Yuchen Yang', 'Thomas Thebaud', 'Najim Dehak']",{'name': 'Najim Dehak'},Najim Dehak,"6 pages, accepted by The Conference on Information Sciences and
  Systems (CISS)","[{'href': 'http://arxiv.org/abs/2502.12007v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12007v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12007v1,None,http://arxiv.org/abs/2502.12007v1,,,11423,0
http://arxiv.org/abs/2502.12022v1,True,2025-02-17T16:56:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=16, tm_min=56, tm_sec=23, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T16:56:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=16, tm_min=56, tm_sec=23, tm_wday=0, tm_yday=48, tm_isdst=0)","Teaching LLMs According to Their Aptitude: Adaptive Reasoning for
  Mathematical Problem Solving","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Teaching LLMs According to Their Aptitude: Adaptive Reasoning for\n  Mathematical Problem Solving'}","Existing approaches to mathematical reasoning with large language models
(LLMs) rely on Chain-of-Thought (CoT) for generalizability or Tool-Integrated
Reasoning (TIR) for precise computation. While efforts have been made to
combine these methods, they primarily rely on post-selection or predefined
strategies, leaving an open question: whether LLMs can autonomously adapt their
reasoning strategy based on their inherent capabilities. In this work, we
propose TATA (Teaching LLMs According to Their Aptitude), an adaptive framework
that enables LLMs to personalize their reasoning strategy spontaneously,
aligning it with their intrinsic aptitude. TATA incorporates base-LLM-aware
data selection during supervised fine-tuning (SFT) to tailor training data to
the model's unique abilities. This approach equips LLMs to autonomously
determine and apply the appropriate reasoning strategy at test time. We
evaluate TATA through extensive experiments on six mathematical reasoning
benchmarks, using both general-purpose and math-specialized LLMs. Empirical
results demonstrate that TATA effectively combines the complementary strengths
of CoT and TIR, achieving superior or comparable performance with improved
inference efficiency compared to TIR alone. Further analysis underscores the
critical role of aptitude-aware data selection in enabling LLMs to make
effective and adaptive reasoning decisions and align reasoning strategies with
model capabilities.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Existing approaches to mathematical reasoning with large language models\n(LLMs) rely on Chain-of-Thought (CoT) for generalizability or Tool-Integrated\nReasoning (TIR) for precise computation. While efforts have been made to\ncombine these methods, they primarily rely on post-selection or predefined\nstrategies, leaving an open question: whether LLMs can autonomously adapt their\nreasoning strategy based on their inherent capabilities. In this work, we\npropose TATA (Teaching LLMs According to Their Aptitude), an adaptive framework\nthat enables LLMs to personalize their reasoning strategy spontaneously,\naligning it with their intrinsic aptitude. TATA incorporates base-LLM-aware\ndata selection during supervised fine-tuning (SFT) to tailor training data to\nthe model's unique abilities. This approach equips LLMs to autonomously\ndetermine and apply the appropriate reasoning strategy at test time. We\nevaluate TATA through extensive experiments on six mathematical reasoning\nbenchmarks, using both general-purpose and math-specialized LLMs. Empirical\nresults demonstrate that TATA effectively combines the complementary strengths\nof CoT and TIR, achieving superior or comparable performance with improved\ninference efficiency compared to TIR alone. Further analysis underscores the\ncritical role of aptitude-aware data selection in enabling LLMs to make\neffective and adaptive reasoning decisions and align reasoning strategies with\nmodel capabilities.""}","['Xin Xu', 'Yan Xu', 'Tianhao Chen', 'Yuchen Yan', 'Chengwu Liu', 'Zaoyu Chen', 'Yufei Wang', 'Yichun Yin', 'Yasheng Wang', 'Lifeng Shang', 'Qun Liu']",{'name': 'Qun Liu'},Qun Liu,8 pages,"[{'href': 'http://arxiv.org/abs/2502.12022v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12022v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12022v1,None,http://arxiv.org/abs/2502.12022v1,,,468,0
http://arxiv.org/abs/2502.12025v1,True,2025-02-17T16:57:56Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=16, tm_min=57, tm_sec=56, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T16:57:56Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=16, tm_min=57, tm_sec=56, tm_wday=0, tm_yday=48, tm_isdst=0)","SafeChain: Safety of Language Models with Long Chain-of-Thought
  Reasoning Capabilities","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'SafeChain: Safety of Language Models with Long Chain-of-Thought\n  Reasoning Capabilities'}","Emerging large reasoning models (LRMs), such as DeepSeek-R1 models, leverage
long chain-of-thought (CoT) reasoning to generate structured intermediate
steps, enhancing their reasoning capabilities. However, long CoT does not
inherently guarantee safe outputs, potentially leading to harmful consequences
such as the introduction of security vulnerabilities in code or the spread of
misinformation. Current research on large language model (LLM) safety usually
focuses on short-answer responses, overlooking the long CoT style outputs of
LRMs. To bridge this gap, we conduct a systematic study of LRM safety. First,
we investigate safety evaluators calibrated against human annotations. Using
our newly developed metrics, we thoroughly assess the safety of 12
state-of-the-art LRMs on StrongReject and WildJailbreak datasets. Our results
show that LRMs are not safe compared to their reasoning advance. Further, we
perform a fine-grained analysis of the reasoning trace and final answer. We
find that three decoding strategies-ZeroThink, LessThink, and MoreThink-can
improve model safety without additional training. However, these strategies
either use constrained reasoning traces or incur high inference costs. To
better strengthen LRM safety, we introduce SafeChain, the first-of-its-kind
safety training dataset in CoT style. We fine-tune two LRMs with SafeChain,
showing that it not only enhances model safety but also preserves performance
across 6 reasoning benchmarks.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Emerging large reasoning models (LRMs), such as DeepSeek-R1 models, leverage\nlong chain-of-thought (CoT) reasoning to generate structured intermediate\nsteps, enhancing their reasoning capabilities. However, long CoT does not\ninherently guarantee safe outputs, potentially leading to harmful consequences\nsuch as the introduction of security vulnerabilities in code or the spread of\nmisinformation. Current research on large language model (LLM) safety usually\nfocuses on short-answer responses, overlooking the long CoT style outputs of\nLRMs. To bridge this gap, we conduct a systematic study of LRM safety. First,\nwe investigate safety evaluators calibrated against human annotations. Using\nour newly developed metrics, we thoroughly assess the safety of 12\nstate-of-the-art LRMs on StrongReject and WildJailbreak datasets. Our results\nshow that LRMs are not safe compared to their reasoning advance. Further, we\nperform a fine-grained analysis of the reasoning trace and final answer. We\nfind that three decoding strategies-ZeroThink, LessThink, and MoreThink-can\nimprove model safety without additional training. However, these strategies\neither use constrained reasoning traces or incur high inference costs. To\nbetter strengthen LRM safety, we introduce SafeChain, the first-of-its-kind\nsafety training dataset in CoT style. We fine-tune two LRMs with SafeChain,\nshowing that it not only enhances model safety but also preserves performance\nacross 6 reasoning benchmarks.'}","['Fengqing Jiang', 'Zhangchen Xu', 'Yuetai Li', 'Luyao Niu', 'Zhen Xiang', 'Bo Li', 'Bill Yuchen Lin', 'Radha Poovendran']",{'name': 'Radha Poovendran'},Radha Poovendran,,"[{'href': 'http://arxiv.org/abs/2502.12025v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12025v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12025v1,None,http://arxiv.org/abs/2502.12025v1,,,960,0
http://arxiv.org/abs/2502.12031v1,True,2025-02-17T17:02:26Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=17, tm_min=2, tm_sec=26, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T17:02:26Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=17, tm_min=2, tm_sec=26, tm_wday=0, tm_yday=48, tm_isdst=0)","Masked Latent Prediction and Classification for Self-Supervised Audio
  Representation Learning","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Masked Latent Prediction and Classification for Self-Supervised Audio\n  Representation Learning'}","Recently, self-supervised learning methods based on masked latent prediction
have proven to encode input data into powerful representations. However, during
training, the learned latent space can be further transformed to extract
higher-level information that could be more suited for downstream
classification tasks. Therefore, we propose a new method: MAsked latenT
Prediction And Classification (MATPAC), which is trained with two pretext tasks
solved jointly. As in previous work, the first pretext task is a masked latent
prediction task, ensuring a robust input representation in the latent space.
The second one is unsupervised classification, which utilises the latent
representations of the first pretext task to match probability distributions
between a teacher and a student. We validate the MATPAC method by comparing it
to other state-of-the-art proposals and conducting ablations studies. MATPAC
reaches state-of-the-art self-supervised learning results on reference audio
classification datasets such as OpenMIC, GTZAN, ESC-50 and US8K and outperforms
comparable supervised methods results for musical auto-tagging on
Magna-tag-a-tune.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Recently, self-supervised learning methods based on masked latent prediction\nhave proven to encode input data into powerful representations. However, during\ntraining, the learned latent space can be further transformed to extract\nhigher-level information that could be more suited for downstream\nclassification tasks. Therefore, we propose a new method: MAsked latenT\nPrediction And Classification (MATPAC), which is trained with two pretext tasks\nsolved jointly. As in previous work, the first pretext task is a masked latent\nprediction task, ensuring a robust input representation in the latent space.\nThe second one is unsupervised classification, which utilises the latent\nrepresentations of the first pretext task to match probability distributions\nbetween a teacher and a student. We validate the MATPAC method by comparing it\nto other state-of-the-art proposals and conducting ablations studies. MATPAC\nreaches state-of-the-art self-supervised learning results on reference audio\nclassification datasets such as OpenMIC, GTZAN, ESC-50 and US8K and outperforms\ncomparable supervised methods results for musical auto-tagging on\nMagna-tag-a-tune.'}","['Aurian Quelennec', 'Pierre Chouteau', 'Geoffroy Peeters', 'Slim Essid']",{'name': 'Slim Essid'},Slim Essid,"Copyright 2025 IEEE. Personal use of this material is permitted.
  Permission from IEEE must be obtained for all other uses, in any current or
  future media, including reprinting/republishing this material for advertising
  or promotional purposes, creating new collective works, for resale or
  redistribution to servers or lists, or reuse of any copyrighted component of
  this work in other works","[{'href': 'http://arxiv.org/abs/2502.12031v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12031v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.SD', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.SD', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12031v1,None,http://arxiv.org/abs/2502.12031v1,,,2649,0
http://arxiv.org/abs/2502.12064v1,True,2025-02-17T17:32:55Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=17, tm_min=32, tm_sec=55, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T17:32:55Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=17, tm_min=32, tm_sec=55, tm_wday=0, tm_yday=48, tm_isdst=0)",AI-generated Text Detection with a GLTR-based Approach,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'AI-generated Text Detection with a GLTR-based Approach'}","The rise of LLMs (Large Language Models) has contributed to the improved
performance and development of cutting-edge NLP applications. However, these
can also pose risks when used maliciously, such as spreading fake news, harmful
content, impersonating individuals, or facilitating school plagiarism, among
others. This is because LLMs can generate high-quality texts, which are
challenging to differentiate from those written by humans. GLTR, which stands
for Giant Language Model Test Room and was developed jointly by the MIT-IBM
Watson AI Lab and HarvardNLP, is a visual tool designed to help detect
machine-generated texts based on GPT-2, that highlights the words in text
depending on the probability that they were machine-generated. One limitation
of GLTR is that the results it returns can sometimes be ambiguous and lead to
confusion. This study aims to explore various ways to improve GLTR's
effectiveness for detecting AI-generated texts within the context of the
IberLef-AuTexTification 2023 shared task, in both English and Spanish
languages. Experiment results show that our GLTR-based GPT-2 model overcomes
the state-of-the-art models on the English dataset with a macro F1-score of
80.19%, except for the first ranking model (80.91%). However, for the Spanish
dataset, we obtained a macro F1-score of 66.20%, which differs by 4.57%
compared to the top-performing model.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""The rise of LLMs (Large Language Models) has contributed to the improved\nperformance and development of cutting-edge NLP applications. However, these\ncan also pose risks when used maliciously, such as spreading fake news, harmful\ncontent, impersonating individuals, or facilitating school plagiarism, among\nothers. This is because LLMs can generate high-quality texts, which are\nchallenging to differentiate from those written by humans. GLTR, which stands\nfor Giant Language Model Test Room and was developed jointly by the MIT-IBM\nWatson AI Lab and HarvardNLP, is a visual tool designed to help detect\nmachine-generated texts based on GPT-2, that highlights the words in text\ndepending on the probability that they were machine-generated. One limitation\nof GLTR is that the results it returns can sometimes be ambiguous and lead to\nconfusion. This study aims to explore various ways to improve GLTR's\neffectiveness for detecting AI-generated texts within the context of the\nIberLef-AuTexTification 2023 shared task, in both English and Spanish\nlanguages. Experiment results show that our GLTR-based GPT-2 model overcomes\nthe state-of-the-art models on the English dataset with a macro F1-score of\n80.19%, except for the first ranking model (80.91%). However, for the Spanish\ndataset, we obtained a macro F1-score of 66.20%, which differs by 4.57%\ncompared to the top-performing model.""}","['Luca Yan Wu', 'Isabel Segura-Bedmar']",{'name': 'Isabel Segura-Bedmar'},Isabel Segura-Bedmar,,"[{'href': 'http://arxiv.org/abs/2502.12064v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12064v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12064v1,None,http://arxiv.org/abs/2502.12064v1,,,2849,0
http://arxiv.org/abs/2502.12067v1,True,2025-02-17T17:37:26Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=17, tm_min=37, tm_sec=26, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T17:37:26Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=17, tm_min=37, tm_sec=26, tm_wday=0, tm_yday=48, tm_isdst=0)",TokenSkip: Controllable Chain-of-Thought Compression in LLMs,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'TokenSkip: Controllable Chain-of-Thought Compression in LLMs'}","Chain-of-Thought (CoT) has been proven effective in enhancing the reasoning
capabilities of large language models (LLMs). Recent advancements, such as
OpenAI's o1 and DeepSeek-R1, suggest that scaling up the length of CoT
sequences during inference could further boost LLM reasoning performance.
However, due to the autoregressive nature of LLM decoding, longer CoT outputs
lead to a linear increase in inference latency, adversely affecting user
experience, particularly when the CoT exceeds 10,000 tokens. To address this
limitation, we analyze the semantic importance of tokens within CoT outputs and
reveal that their contributions to reasoning vary. Building on this insight, we
propose TokenSkip, a simple yet effective approach that enables LLMs to
selectively skip less important tokens, allowing for controllable CoT
compression. Extensive experiments across various models and tasks demonstrate
the effectiveness of TokenSkip in reducing CoT token usage while preserving
strong reasoning performance. Notably, when applied to Qwen2.5-14B-Instruct,
TokenSkip reduces reasoning tokens by 40% (from 313 to 181) on GSM8K, with less
than a 0.4% performance drop.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Chain-of-Thought (CoT) has been proven effective in enhancing the reasoning\ncapabilities of large language models (LLMs). Recent advancements, such as\nOpenAI's o1 and DeepSeek-R1, suggest that scaling up the length of CoT\nsequences during inference could further boost LLM reasoning performance.\nHowever, due to the autoregressive nature of LLM decoding, longer CoT outputs\nlead to a linear increase in inference latency, adversely affecting user\nexperience, particularly when the CoT exceeds 10,000 tokens. To address this\nlimitation, we analyze the semantic importance of tokens within CoT outputs and\nreveal that their contributions to reasoning vary. Building on this insight, we\npropose TokenSkip, a simple yet effective approach that enables LLMs to\nselectively skip less important tokens, allowing for controllable CoT\ncompression. Extensive experiments across various models and tasks demonstrate\nthe effectiveness of TokenSkip in reducing CoT token usage while preserving\nstrong reasoning performance. Notably, when applied to Qwen2.5-14B-Instruct,\nTokenSkip reduces reasoning tokens by 40% (from 313 to 181) on GSM8K, with less\nthan a 0.4% performance drop.""}","['Heming Xia', 'Yongqi Li', 'Chak Tou Leong', 'Wenjie Wang', 'Wenjie Li']",{'name': 'Wenjie Li'},Wenjie Li,,"[{'href': 'http://arxiv.org/abs/2502.12067v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12067v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12067v1,None,http://arxiv.org/abs/2502.12067v1,,,357,0
http://arxiv.org/abs/2502.12088v2,True,2025-02-19T22:12:49Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=22, tm_min=12, tm_sec=49, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-17T18:04:39Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=4, tm_sec=39, tm_wday=0, tm_yday=48, tm_isdst=0)",Meta-Statistical Learning: Supervised Learning of Statistical Inference,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Meta-Statistical Learning: Supervised Learning of Statistical Inference'}","This work demonstrates that the tools and principles driving the success of
large language models (LLMs) can be repurposed to tackle distribution-level
tasks, where the goal is to predict properties of the data-generating
distribution rather than labels for individual datapoints. These tasks
encompass statistical inference problems such as parameter estimation,
hypothesis testing, or mutual information estimation. Framing these tasks
within traditional machine learning pipelines is challenging, as supervision is
typically tied to individual datapoint. We propose meta-statistical learning, a
framework inspired by multi-instance learning that reformulates statistical
inference tasks as supervised learning problems. In this approach, entire
datasets are treated as single inputs to neural networks, which predict
distribution-level parameters. Transformer-based architectures, without
positional encoding, provide a natural fit due to their permutation-invariance
properties. By training on large-scale synthetic datasets, meta-statistical
models can leverage the scalability and optimization infrastructure of
Transformer-based LLMs. We demonstrate the framework's versatility with
applications in hypothesis testing and mutual information estimation, showing
strong performance, particularly for small datasets where traditional neural
methods struggle.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""This work demonstrates that the tools and principles driving the success of\nlarge language models (LLMs) can be repurposed to tackle distribution-level\ntasks, where the goal is to predict properties of the data-generating\ndistribution rather than labels for individual datapoints. These tasks\nencompass statistical inference problems such as parameter estimation,\nhypothesis testing, or mutual information estimation. Framing these tasks\nwithin traditional machine learning pipelines is challenging, as supervision is\ntypically tied to individual datapoint. We propose meta-statistical learning, a\nframework inspired by multi-instance learning that reformulates statistical\ninference tasks as supervised learning problems. In this approach, entire\ndatasets are treated as single inputs to neural networks, which predict\ndistribution-level parameters. Transformer-based architectures, without\npositional encoding, provide a natural fit due to their permutation-invariance\nproperties. By training on large-scale synthetic datasets, meta-statistical\nmodels can leverage the scalability and optimization infrastructure of\nTransformer-based LLMs. We demonstrate the framework's versatility with\napplications in hypothesis testing and mutual information estimation, showing\nstrong performance, particularly for small datasets where traditional neural\nmethods struggle.""}","['Maxime Peyrard', 'Kyunghyun Cho']",{'name': 'Kyunghyun Cho'},Kyunghyun Cho,,"[{'href': 'http://arxiv.org/abs/2502.12088v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12088v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12088v2,None,http://arxiv.org/abs/2502.12088v2,,,0,0
http://arxiv.org/abs/2502.12094v1,True,2025-02-17T18:12:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=12, tm_sec=36, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T18:12:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=12, tm_sec=36, tm_wday=0, tm_yday=48, tm_isdst=0)",A Study on Leveraging Search and Self-Feedback for Agent Reasoning,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A Study on Leveraging Search and Self-Feedback for Agent Reasoning'}","Recent works have demonstrated that incorporating search during inference can
significantly improve reasoning capabilities of language agents. Some
approaches may make use of the ground truth or rely on model's own generated
feedback. The search algorithm uses this feedback to then produce values that
will update its criterion for exploring and exploiting various reasoning paths.
In this study, we investigate how search and model's self-feedback can be
leveraged for reasoning tasks. First, we explore differences in ground-truth
feedback and self-feedback during search for math reasoning. Second, we observe
limitations in applying search techniques to more complex tasks like
tool-calling and design domain-specific approaches to address these gaps. Our
experiments reveal challenges related to generalization when solely relying on
self-feedback during search. For search to work effectively, either access to
the ground-truth is needed or feedback mechanisms need to be carefully designed
for the specific task.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Recent works have demonstrated that incorporating search during inference can\nsignificantly improve reasoning capabilities of language agents. Some\napproaches may make use of the ground truth or rely on model's own generated\nfeedback. The search algorithm uses this feedback to then produce values that\nwill update its criterion for exploring and exploiting various reasoning paths.\nIn this study, we investigate how search and model's self-feedback can be\nleveraged for reasoning tasks. First, we explore differences in ground-truth\nfeedback and self-feedback during search for math reasoning. Second, we observe\nlimitations in applying search techniques to more complex tasks like\ntool-calling and design domain-specific approaches to address these gaps. Our\nexperiments reveal challenges related to generalization when solely relying on\nself-feedback during search. For search to work effectively, either access to\nthe ground-truth is needed or feedback mechanisms need to be carefully designed\nfor the specific task.""}","['Karthikeyan K', 'Michelle Yuan', 'Elman Mansimov', 'Katerina Margatina', 'Anurag Pratik', 'Daniele Bonadiman', 'Monica Sunkara', 'Yi Zhang', 'Yassine Benajiba']",{'name': 'Yassine Benajiba'},Yassine Benajiba,Under review,"[{'href': 'http://arxiv.org/abs/2502.12094v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12094v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12094v1,None,http://arxiv.org/abs/2502.12094v1,,,5522,0
http://arxiv.org/abs/2502.12102v1,True,2025-02-17T18:23:29Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=23, tm_sec=29, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T18:23:29Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=23, tm_sec=29, tm_wday=0, tm_yday=48, tm_isdst=0)",Relational Norms for Human-AI Cooperation,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Relational Norms for Human-AI Cooperation'}","How we should design and interact with social artificial intelligence depends
on the socio-relational role the AI is meant to emulate or occupy. In human
society, relationships such as teacher-student, parent-child, neighbors,
siblings, or employer-employee are governed by specific norms that prescribe or
proscribe cooperative functions including hierarchy, care, transaction, and
mating. These norms shape our judgments of what is appropriate for each
partner. For example, workplace norms may allow a boss to give orders to an
employee, but not vice versa, reflecting hierarchical and transactional
expectations. As AI agents and chatbots powered by large language models are
increasingly designed to serve roles analogous to human positions - such as
assistant, mental health provider, tutor, or romantic partner - it is
imperative to examine whether and how human relational norms should extend to
human-AI interactions. Our analysis explores how differences between AI systems
and humans, such as the absence of conscious experience and immunity to
fatigue, may affect an AI's capacity to fulfill relationship-specific functions
and adhere to corresponding norms. This analysis, which is a collaborative
effort by philosophers, psychologists, relationship scientists, ethicists,
legal experts, and AI researchers, carries important implications for AI
systems design, user behavior, and regulation. While we accept that AI systems
can offer significant benefits such as increased availability and consistency
in certain socio-relational roles, they also risk fostering unhealthy
dependencies or unrealistic expectations that could spill over into human-human
relationships. We propose that understanding and thoughtfully shaping (or
implementing) suitable human-AI relational norms will be crucial for ensuring
that human-AI interactions are ethical, trustworthy, and favorable to human
well-being.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""How we should design and interact with social artificial intelligence depends\non the socio-relational role the AI is meant to emulate or occupy. In human\nsociety, relationships such as teacher-student, parent-child, neighbors,\nsiblings, or employer-employee are governed by specific norms that prescribe or\nproscribe cooperative functions including hierarchy, care, transaction, and\nmating. These norms shape our judgments of what is appropriate for each\npartner. For example, workplace norms may allow a boss to give orders to an\nemployee, but not vice versa, reflecting hierarchical and transactional\nexpectations. As AI agents and chatbots powered by large language models are\nincreasingly designed to serve roles analogous to human positions - such as\nassistant, mental health provider, tutor, or romantic partner - it is\nimperative to examine whether and how human relational norms should extend to\nhuman-AI interactions. Our analysis explores how differences between AI systems\nand humans, such as the absence of conscious experience and immunity to\nfatigue, may affect an AI's capacity to fulfill relationship-specific functions\nand adhere to corresponding norms. This analysis, which is a collaborative\neffort by philosophers, psychologists, relationship scientists, ethicists,\nlegal experts, and AI researchers, carries important implications for AI\nsystems design, user behavior, and regulation. While we accept that AI systems\ncan offer significant benefits such as increased availability and consistency\nin certain socio-relational roles, they also risk fostering unhealthy\ndependencies or unrealistic expectations that could spill over into human-human\nrelationships. We propose that understanding and thoughtfully shaping (or\nimplementing) suitable human-AI relational norms will be crucial for ensuring\nthat human-AI interactions are ethical, trustworthy, and favorable to human\nwell-being.""}","['Brian D. Earp', 'Sebastian Porsdam Mann', 'Mateo Aboy', 'Edmond Awad', 'Monika Betzler', 'Marietjie Botes', 'Rachel Calcott', 'Mina Caraccio', 'Nick Chater', 'Mark Coeckelbergh', 'Mihaela Constantinescu', 'Hossein Dabbagh', 'Kate Devlin', 'Xiaojun Ding', 'Vilius Dranseika', 'Jim A. C. Everett', 'Ruiping Fan', 'Faisal Feroz', 'Kathryn B. Francis', 'Cindy Friedman', 'Orsolya Friedrich', 'Iason Gabriel', 'Ivar Hannikainen', 'Julie Hellmann', 'Arasj Khodadade Jahrome', 'Niranjan S. Janardhanan', 'Paul Jurcys', 'Andreas Kappes', 'Maryam Ali Khan', 'Gordon Kraft-Todd', 'Maximilian Kroner Dale', 'Simon M. Laham', 'Benjamin Lange', 'Muriel Leuenberger', 'Jonathan Lewis', 'Peng Liu', 'David M. Lyreskog', 'Matthijs Maas', 'John McMillan', 'Emilian Mihailov', 'Timo Minssen', 'Joshua Teperowski Monrad', 'Kathryn Muyskens', 'Simon Myers', 'Sven Nyholm', 'Alexa M. Owen', 'Anna Puzio', 'Christopher Register', 'Madeline G. Reinecke', 'Adam Safron', 'Henry Shevlin', 'Hayate Shimizu', 'Peter V. Treit', 'Cristina Voinea', 'Karen Yan', 'Anda Zahiu', 'Renwen Zhang', 'Hazem Zohny', 'Walter Sinnott-Armstrong', 'Ilina Singh', 'Julian Savulescu', 'Margaret S. Clark']",{'name': 'Margaret S. Clark'},Margaret S. Clark,"76 pages, 2 figures","[{'href': 'http://arxiv.org/abs/2502.12102v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12102v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.ET', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12102v1,None,http://arxiv.org/abs/2502.12102v1,,,13724,0
http://arxiv.org/abs/2502.12109v1,True,2025-02-17T18:31:57Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=31, tm_sec=57, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T18:31:57Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=31, tm_sec=57, tm_wday=0, tm_yday=48, tm_isdst=0)","Personality Structured Interview for Large Language Model Simulation in
  Personality Research","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Personality Structured Interview for Large Language Model Simulation in\n  Personality Research'}","Although psychometrics researchers have recently explored the use of large
language models (LLMs) as proxies for human participants, LLMs often fail to
generate heterogeneous data with human-like diversity, which diminishes their
value in advancing social science research. To address these challenges, we
explored the potential of the theory-informed Personality Structured Interview
(PSI) as a tool for simulating human responses in personality research. In this
approach, the simulation is grounded in nuanced real-human interview
transcripts that target the personality construct of interest. We have provided
a growing set of 357 structured interview transcripts from a representative
sample, each containing an individual's response to 32 open-ended questions
carefully designed to gather theory-based personality evidence. Additionally,
grounded in psychometric research, we have summarized an evaluation framework
to systematically validate LLM-generated psychometric data. Results from three
experiments demonstrate that well-designed structured interviews could improve
human-like heterogeneity in LLM-simulated personality data and predict
personality-related behavioral outcomes (i.e., organizational citizenship
behaviors and counterproductive work behavior). We further discuss the role of
theory-informed structured interviews in LLM-based simulation and outline a
general framework for designing structured interviews to simulate human-like
data for psychometric research.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Although psychometrics researchers have recently explored the use of large\nlanguage models (LLMs) as proxies for human participants, LLMs often fail to\ngenerate heterogeneous data with human-like diversity, which diminishes their\nvalue in advancing social science research. To address these challenges, we\nexplored the potential of the theory-informed Personality Structured Interview\n(PSI) as a tool for simulating human responses in personality research. In this\napproach, the simulation is grounded in nuanced real-human interview\ntranscripts that target the personality construct of interest. We have provided\na growing set of 357 structured interview transcripts from a representative\nsample, each containing an individual's response to 32 open-ended questions\ncarefully designed to gather theory-based personality evidence. Additionally,\ngrounded in psychometric research, we have summarized an evaluation framework\nto systematically validate LLM-generated psychometric data. Results from three\nexperiments demonstrate that well-designed structured interviews could improve\nhuman-like heterogeneity in LLM-simulated personality data and predict\npersonality-related behavioral outcomes (i.e., organizational citizenship\nbehaviors and counterproductive work behavior). We further discuss the role of\ntheory-informed structured interviews in LLM-based simulation and outline a\ngeneral framework for designing structured interviews to simulate human-like\ndata for psychometric research.""}","['Pengda Wang', 'Huiqi Zou', 'Hanjie Chen', 'Tianjun Sun', 'Ziang Xiao', 'Frederick L. Oswald']",{'name': 'Frederick L. Oswald'},Frederick L. Oswald,"41 Pages, 30 Tables, 5 Figures","[{'href': 'http://arxiv.org/abs/2502.12109v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12109v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12109v1,None,http://arxiv.org/abs/2502.12109v1,,,57,0
http://arxiv.org/abs/2502.12125v1,True,2025-02-17T18:47:01Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=47, tm_sec=1, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T18:47:01Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=47, tm_sec=1, tm_wday=0, tm_yday=48, tm_isdst=0)","Hypernym Bias: Unraveling Deep Classifier Training Dynamics through the
  Lens of Class Hierarchy","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Hypernym Bias: Unraveling Deep Classifier Training Dynamics through the\n  Lens of Class Hierarchy'}","We investigate the training dynamics of deep classifiers by examining how
hierarchical relationships between classes evolve during training. Through
extensive experiments, we argue that the learning process in classification
problems can be understood through the lens of label clustering. Specifically,
we observe that networks tend to distinguish higher-level (hypernym) categories
in the early stages of training, and learn more specific (hyponym) categories
later. We introduce a novel framework to track the evolution of the feature
manifold during training, revealing how the hierarchy of class relations
emerges and refines across the network layers. Our analysis demonstrates that
the learned representations closely align with the semantic structure of the
dataset, providing a quantitative description of the clustering process.
Notably, we show that in the hypernym label space, certain properties of neural
collapse appear earlier than in the hyponym label space, helping to bridge the
gap between the initial and terminal phases of learning. We believe our
findings offer new insights into the mechanisms driving hierarchical learning
in deep networks, paving the way for future advancements in understanding deep
learning dynamics.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'We investigate the training dynamics of deep classifiers by examining how\nhierarchical relationships between classes evolve during training. Through\nextensive experiments, we argue that the learning process in classification\nproblems can be understood through the lens of label clustering. Specifically,\nwe observe that networks tend to distinguish higher-level (hypernym) categories\nin the early stages of training, and learn more specific (hyponym) categories\nlater. We introduce a novel framework to track the evolution of the feature\nmanifold during training, revealing how the hierarchy of class relations\nemerges and refines across the network layers. Our analysis demonstrates that\nthe learned representations closely align with the semantic structure of the\ndataset, providing a quantitative description of the clustering process.\nNotably, we show that in the hypernym label space, certain properties of neural\ncollapse appear earlier than in the hyponym label space, helping to bridge the\ngap between the initial and terminal phases of learning. We believe our\nfindings offer new insights into the mechanisms driving hierarchical learning\nin deep networks, paving the way for future advancements in understanding deep\nlearning dynamics.'}","['Roman Malashin', 'Valeria Yachnaya', 'Alexander Mullin']",{'name': 'Alexander Mullin'},Alexander Mullin,,"[{'href': 'http://arxiv.org/abs/2502.12125v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12125v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12125v1,None,http://arxiv.org/abs/2502.12125v1,,,0,0
http://arxiv.org/abs/2502.12128v1,True,2025-02-17T18:49:13Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=49, tm_sec=13, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T18:49:13Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=49, tm_sec=13, tm_wday=0, tm_yday=48, tm_isdst=0)","LaM-SLidE: Latent Space Modeling of Spatial Dynamical Systems via Linked
  Entities","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'LaM-SLidE: Latent Space Modeling of Spatial Dynamical Systems via Linked\n  Entities'}","Generative models are spearheading recent progress in deep learning, showing
strong promise for trajectory sampling in dynamical systems as well. However,
while latent space modeling paradigms have transformed image and video
generation, similar approaches are more difficult for most dynamical systems.
Such systems -- from chemical molecule structures to collective human behavior
-- are described by interactions of entities, making them inherently linked to
connectivity patterns and the traceability of entities over time. Our approach,
LaM-SLidE (Latent Space Modeling of Spatial Dynamical Systems via Linked
Entities), combines the advantages of graph neural networks, i.e., the
traceability of entities across time-steps, with the efficiency and scalability
of recent advances in image and video generation, where pre-trained encoder and
decoder are frozen to enable generative modeling in the latent space. The core
idea of LaM-SLidE is to introduce identifier representations (IDs) to allow for
retrieval of entity properties, e.g., entity coordinates, from latent system
representations and thus enables traceability. Experimentally, across different
domains, we show that LaM-SLidE performs favorably in terms of speed, accuracy,
and generalizability. (Code is available at
https://github.com/ml-jku/LaM-SLidE)","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Generative models are spearheading recent progress in deep learning, showing\nstrong promise for trajectory sampling in dynamical systems as well. However,\nwhile latent space modeling paradigms have transformed image and video\ngeneration, similar approaches are more difficult for most dynamical systems.\nSuch systems -- from chemical molecule structures to collective human behavior\n-- are described by interactions of entities, making them inherently linked to\nconnectivity patterns and the traceability of entities over time. Our approach,\nLaM-SLidE (Latent Space Modeling of Spatial Dynamical Systems via Linked\nEntities), combines the advantages of graph neural networks, i.e., the\ntraceability of entities across time-steps, with the efficiency and scalability\nof recent advances in image and video generation, where pre-trained encoder and\ndecoder are frozen to enable generative modeling in the latent space. The core\nidea of LaM-SLidE is to introduce identifier representations (IDs) to allow for\nretrieval of entity properties, e.g., entity coordinates, from latent system\nrepresentations and thus enables traceability. Experimentally, across different\ndomains, we show that LaM-SLidE performs favorably in terms of speed, accuracy,\nand generalizability. (Code is available at\nhttps://github.com/ml-jku/LaM-SLidE)'}","['Florian Sestak', 'Artur Toshev', 'Andreas Frst', 'Gnter Klambauer', 'Andreas Mayr', 'Johannes Brandstetter']",{'name': 'Johannes Brandstetter'},Johannes Brandstetter,Project page: https://ml-jku.github.io/LaM-SLidE/,"[{'href': 'http://arxiv.org/abs/2502.12128v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12128v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12128v1,None,http://arxiv.org/abs/2502.12128v1,,,8769,0
http://arxiv.org/abs/2502.12145v1,True,2025-02-17T18:56:20Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=56, tm_sec=20, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T18:56:20Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=56, tm_sec=20, tm_wday=0, tm_yday=48, tm_isdst=0)","Fast or Better? Balancing Accuracy and Cost in Retrieval-Augmented
  Generation with Flexible User Control","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Fast or Better? Balancing Accuracy and Cost in Retrieval-Augmented\n  Generation with Flexible User Control'}","Retrieval-Augmented Generation (RAG) has emerged as a powerful approach to
mitigate large language model (LLM) hallucinations by incorporating external
knowledge retrieval. However, existing RAG frameworks often apply retrieval
indiscriminately,leading to inefficiencies-over-retrieving when unnecessary or
failing to retrieve iteratively when required for complex reasoning. Recent
adaptive retrieval strategies, though adaptively navigates these retrieval
strategies, predict only based on query complexity and lacks user-driven
flexibility, making them infeasible for diverse user application needs. In this
paper, we introduce a novel user-controllable RAG framework that enables
dynamic adjustment of the accuracy-cost trade-off. Our approach leverages two
classifiers: one trained to prioritize accuracy and another to prioritize
retrieval efficiency. Via an interpretable control parameter $\alpha$, users
can seamlessly navigate between minimal-cost retrieval and high-accuracy
retrieval based on their specific requirements. We empirically demonstrate that
our approach effectively balances accuracy, retrieval cost, and user
controllability, making it a practical and adaptable solution for real-world
applications.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Retrieval-Augmented Generation (RAG) has emerged as a powerful approach to\nmitigate large language model (LLM) hallucinations by incorporating external\nknowledge retrieval. However, existing RAG frameworks often apply retrieval\nindiscriminately,leading to inefficiencies-over-retrieving when unnecessary or\nfailing to retrieve iteratively when required for complex reasoning. Recent\nadaptive retrieval strategies, though adaptively navigates these retrieval\nstrategies, predict only based on query complexity and lacks user-driven\nflexibility, making them infeasible for diverse user application needs. In this\npaper, we introduce a novel user-controllable RAG framework that enables\ndynamic adjustment of the accuracy-cost trade-off. Our approach leverages two\nclassifiers: one trained to prioritize accuracy and another to prioritize\nretrieval efficiency. Via an interpretable control parameter $\\alpha$, users\ncan seamlessly navigate between minimal-cost retrieval and high-accuracy\nretrieval based on their specific requirements. We empirically demonstrate that\nour approach effectively balances accuracy, retrieval cost, and user\ncontrollability, making it a practical and adaptable solution for real-world\napplications.'}","['Jinyan Su', 'Jennifer Healey', 'Preslav Nakov', 'Claire Cardie']",{'name': 'Claire Cardie'},Claire Cardie,,"[{'href': 'http://arxiv.org/abs/2502.12145v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12145v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12145v1,None,http://arxiv.org/abs/2502.12145v1,,,8175,0
http://arxiv.org/abs/2502.12185v1,True,2025-02-15T02:43:22Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=2, tm_min=43, tm_sec=22, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T02:43:22Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=2, tm_min=43, tm_sec=22, tm_wday=5, tm_yday=46, tm_isdst=0)","Large Language Models for Extrapolative Modeling of Manufacturing
  Processes","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Language Models for Extrapolative Modeling of Manufacturing\n  Processes'}","Conventional predictive modeling of parametric relationships in manufacturing
processes is limited by the subjectivity of human expertise and intuition on
the one hand and by the cost and time of experimental data generation on the
other hand. This work addresses this issue by establishing a new Large Language
Model (LLM) framework. The novelty lies in combining automatic extraction of
process-relevant knowledge embedded in the literature with iterative model
refinement based on a small amount of experimental data. This approach is
evaluated on three distinct manufacturing processes that are based on
machining, deformation, and additive principles. The results show that for the
same small experimental data budget the models derived by our framework have
unexpectedly high extrapolative performance, often surpassing the capabilities
of conventional Machine Learning. Further, our approach eliminates manual
generation of initial models or expertise-dependent interpretation of the
literature. The results also reveal the importance of the nature of the
knowledge extracted from the literature and the significance of both the
knowledge extraction and model refinement components.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Conventional predictive modeling of parametric relationships in manufacturing\nprocesses is limited by the subjectivity of human expertise and intuition on\nthe one hand and by the cost and time of experimental data generation on the\nother hand. This work addresses this issue by establishing a new Large Language\nModel (LLM) framework. The novelty lies in combining automatic extraction of\nprocess-relevant knowledge embedded in the literature with iterative model\nrefinement based on a small amount of experimental data. This approach is\nevaluated on three distinct manufacturing processes that are based on\nmachining, deformation, and additive principles. The results show that for the\nsame small experimental data budget the models derived by our framework have\nunexpectedly high extrapolative performance, often surpassing the capabilities\nof conventional Machine Learning. Further, our approach eliminates manual\ngeneration of initial models or expertise-dependent interpretation of the\nliterature. The results also reveal the importance of the nature of the\nknowledge extracted from the literature and the significance of both the\nknowledge extraction and model refinement components.'}","['Kiarash Naghavi Khanghah', 'Anandkumar Patel', 'Rajiv Malhotra', 'Hongyi Xu']",{'name': 'Hongyi Xu'},Hongyi Xu,,"[{'href': 'http://arxiv.org/abs/2502.12185v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12185v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12185v1,None,http://arxiv.org/abs/2502.12185v1,,,2940,0
http://arxiv.org/abs/2502.12188v1,True,2025-02-15T08:04:00Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=8, tm_min=4, tm_sec=0, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T08:04:00Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=8, tm_min=4, tm_sec=0, tm_wday=5, tm_yday=46, tm_isdst=0)","Boosting Generalization in Diffusion-Based Neural Combinatorial Solver
  via Energy-guided Sampling","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Boosting Generalization in Diffusion-Based Neural Combinatorial Solver\n  via Energy-guided Sampling'}","Diffusion-based Neural Combinatorial Optimization (NCO) has demonstrated
effectiveness in solving NP-complete (NPC) problems by learning discrete
diffusion models for solution generation, eliminating hand-crafted domain
knowledge. Despite their success, existing NCO methods face significant
challenges in both cross-scale and cross-problem generalization, and high
training costs compared to traditional solvers. While recent studies have
introduced training-free guidance approaches that leverage pre-defined guidance
functions for zero-shot conditional generation, such methodologies have not
been extensively explored in combinatorial optimization. To bridge this gap, we
propose a general energy-guided sampling framework during inference time that
enhances both the cross-scale and cross-problem generalization capabilities of
diffusion-based NCO solvers without requiring additional training. We provide
theoretical analysis that helps understanding the cross-problem transfer
capability. Our experimental results demonstrate that a diffusion solver,
trained exclusively on the Traveling Salesman Problem (TSP), can achieve
competitive zero-shot solution generation on TSP variants, such as Prize
Collecting TSP (PCTSP) and the Orienteering Problem (OP), through energy-guided
sampling across different problem scales.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Diffusion-based Neural Combinatorial Optimization (NCO) has demonstrated\neffectiveness in solving NP-complete (NPC) problems by learning discrete\ndiffusion models for solution generation, eliminating hand-crafted domain\nknowledge. Despite their success, existing NCO methods face significant\nchallenges in both cross-scale and cross-problem generalization, and high\ntraining costs compared to traditional solvers. While recent studies have\nintroduced training-free guidance approaches that leverage pre-defined guidance\nfunctions for zero-shot conditional generation, such methodologies have not\nbeen extensively explored in combinatorial optimization. To bridge this gap, we\npropose a general energy-guided sampling framework during inference time that\nenhances both the cross-scale and cross-problem generalization capabilities of\ndiffusion-based NCO solvers without requiring additional training. We provide\ntheoretical analysis that helps understanding the cross-problem transfer\ncapability. Our experimental results demonstrate that a diffusion solver,\ntrained exclusively on the Traveling Salesman Problem (TSP), can achieve\ncompetitive zero-shot solution generation on TSP variants, such as Prize\nCollecting TSP (PCTSP) and the Orienteering Problem (OP), through energy-guided\nsampling across different problem scales.'}","['Haoyu Lei', 'Kaiwen Zhou', 'Yinchuan Li', 'Zhitang Chen', 'Farzan Farnia']",{'name': 'Farzan Farnia'},Farzan Farnia,,"[{'href': 'http://arxiv.org/abs/2502.12188v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12188v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12188v1,None,http://arxiv.org/abs/2502.12188v1,,,874,0
http://arxiv.org/abs/2502.12189v1,True,2025-02-15T08:20:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=8, tm_min=20, tm_sec=42, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T08:20:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=8, tm_min=20, tm_sec=42, tm_wday=5, tm_yday=46, tm_isdst=0)",Self-supervised Attribute-aware Dynamic Preference Ranking Alignment,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Self-supervised Attribute-aware Dynamic Preference Ranking Alignment'}","Reinforcement Learning from Human Feedback and its variants excel in aligning
with human intentions to generate helpful, harmless, and honest responses.
However, most of them rely on costly human-annotated pairwise comparisons for
supervised alignment, which is not suitable for list-level scenarios, such as
community question answering. Additionally, human preferences are influenced by
multiple intrinsic factors in responses, leading to decision-making
inconsistencies. Therefore, we propose \textbf{Se}lf-supervised
\textbf{A}ttribute-aware \textbf{d}ynamic \textbf{p}reference \textbf{ra}nking,
called \shortname. \ It quantifies preference differences between responses
based on Attribute-Perceptual Distance Factors (APDF) and dynamically
determines the list-wise alignment order. Furthermore, it achieves fine-grained
preference difference learning and enables precise alignment with the optimal
one. We specifically constructed a challenging code preference dataset named
StaCoCoQA, and introduced more cost-effective and scalable preference
evaluation metrics: PrefHit and PrefRecall. Extensive experimental results show
that SeAdpra exhibits superior performance and generalizability on both
StaCoCoQA and preference datasets from eight popular domains.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Reinforcement Learning from Human Feedback and its variants excel in aligning\nwith human intentions to generate helpful, harmless, and honest responses.\nHowever, most of them rely on costly human-annotated pairwise comparisons for\nsupervised alignment, which is not suitable for list-level scenarios, such as\ncommunity question answering. Additionally, human preferences are influenced by\nmultiple intrinsic factors in responses, leading to decision-making\ninconsistencies. Therefore, we propose \\textbf{Se}lf-supervised\n\\textbf{A}ttribute-aware \\textbf{d}ynamic \\textbf{p}reference \\textbf{ra}nking,\ncalled \\shortname. \\ It quantifies preference differences between responses\nbased on Attribute-Perceptual Distance Factors (APDF) and dynamically\ndetermines the list-wise alignment order. Furthermore, it achieves fine-grained\npreference difference learning and enables precise alignment with the optimal\none. We specifically constructed a challenging code preference dataset named\nStaCoCoQA, and introduced more cost-effective and scalable preference\nevaluation metrics: PrefHit and PrefRecall. Extensive experimental results show\nthat SeAdpra exhibits superior performance and generalizability on both\nStaCoCoQA and preference datasets from eight popular domains.'}","['Hongyu Yang', 'Qi Zhao', 'Zhenhua hu', 'Rui Li']",{'name': 'Rui Li'},Rui Li,,"[{'href': 'http://arxiv.org/abs/2502.12189v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12189v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12189v1,None,http://arxiv.org/abs/2502.12189v1,,,2,0
http://arxiv.org/abs/2502.12193v1,True,2025-02-15T09:28:52Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=9, tm_min=28, tm_sec=52, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T09:28:52Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=9, tm_min=28, tm_sec=52, tm_wday=5, tm_yday=46, tm_isdst=0)",AI and the Law: Evaluating ChatGPT's Performance in Legal Classification,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""AI and the Law: Evaluating ChatGPT's Performance in Legal Classification""}","The use of ChatGPT to analyze and classify evidence in criminal proceedings
has been a topic of ongoing discussion. However, to the best of our knowledge,
this issue has not been studied in the context of the Polish language. This
study addresses this research gap by evaluating the effectiveness of ChatGPT in
classifying legal cases under the Polish Penal Code. The results show excellent
binary classification accuracy, with all positive and negative cases correctly
categorized. In addition, a qualitative evaluation confirms that the legal
basis provided for each case, along with the relevant legal content, was
appropriate. The results obtained suggest that ChatGPT can effectively analyze
and classify evidence while applying the appropriate legal rules. In
conclusion, ChatGPT has the potential to assist interested parties in the
analysis of evidence and serve as a valuable legal resource for individuals
with less experience or knowledge in this area.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The use of ChatGPT to analyze and classify evidence in criminal proceedings\nhas been a topic of ongoing discussion. However, to the best of our knowledge,\nthis issue has not been studied in the context of the Polish language. This\nstudy addresses this research gap by evaluating the effectiveness of ChatGPT in\nclassifying legal cases under the Polish Penal Code. The results show excellent\nbinary classification accuracy, with all positive and negative cases correctly\ncategorized. In addition, a qualitative evaluation confirms that the legal\nbasis provided for each case, along with the relevant legal content, was\nappropriate. The results obtained suggest that ChatGPT can effectively analyze\nand classify evidence while applying the appropriate legal rules. In\nconclusion, ChatGPT has the potential to assist interested parties in the\nanalysis of evidence and serve as a valuable legal resource for individuals\nwith less experience or knowledge in this area.'}",['Pawel Weichbroth'],{'name': 'Pawel Weichbroth'},Pawel Weichbroth,15 pages; 1 figure; 2 tables; 32 references,"[{'href': 'http://arxiv.org/abs/2502.12193v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12193v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12193v1,None,http://arxiv.org/abs/2502.12193v1,,,0,0
http://arxiv.org/abs/2502.12197v1,True,2025-02-15T18:10:45Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=18, tm_min=10, tm_sec=45, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T18:10:45Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=18, tm_min=10, tm_sec=45, tm_wday=5, tm_yday=46, tm_isdst=0)",A Closer Look at System Prompt Robustness,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A Closer Look at System Prompt Robustness'}","System prompts have emerged as a critical control surface for specifying the
behavior of LLMs in chat and agent settings. Developers depend on system
prompts to specify important context, output format, personalities, guardrails,
content policies, and safety countermeasures, all of which require models to
robustly adhere to the system prompt, especially when facing conflicting or
adversarial user inputs. In practice, models often forget to consider relevant
guardrails or fail to resolve conflicting demands between the system and the
user. In this work, we study various methods for improving system prompt
robustness by creating realistic new evaluation and fine-tuning datasets based
on prompts collected from from OpenAI's GPT Store and HuggingFace's
HuggingChat. Our experiments assessing models with a panel of new and existing
benchmarks show that performance can be considerably improved with realistic
fine-tuning data, as well as inference-time interventions such as
classifier-free guidance. Finally, we analyze the results of recently released
reasoning models from OpenAI and DeepSeek, which show exciting but uneven
improvements on the benchmarks we study. Overall, current techniques fall short
of ensuring system prompt robustness and further study is warranted.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""System prompts have emerged as a critical control surface for specifying the\nbehavior of LLMs in chat and agent settings. Developers depend on system\nprompts to specify important context, output format, personalities, guardrails,\ncontent policies, and safety countermeasures, all of which require models to\nrobustly adhere to the system prompt, especially when facing conflicting or\nadversarial user inputs. In practice, models often forget to consider relevant\nguardrails or fail to resolve conflicting demands between the system and the\nuser. In this work, we study various methods for improving system prompt\nrobustness by creating realistic new evaluation and fine-tuning datasets based\non prompts collected from from OpenAI's GPT Store and HuggingFace's\nHuggingChat. Our experiments assessing models with a panel of new and existing\nbenchmarks show that performance can be considerably improved with realistic\nfine-tuning data, as well as inference-time interventions such as\nclassifier-free guidance. Finally, we analyze the results of recently released\nreasoning models from OpenAI and DeepSeek, which show exciting but uneven\nimprovements on the benchmarks we study. Overall, current techniques fall short\nof ensuring system prompt robustness and further study is warranted.""}","['Norman Mu', 'Jonathan Lu', 'Michael Lavery', 'David Wagner']",{'name': 'David Wagner'},David Wagner,Artifacts: https://github.com/normster/RealGuardrails,"[{'href': 'http://arxiv.org/abs/2502.12197v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12197v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12197v1,None,http://arxiv.org/abs/2502.12197v1,,,272,0
http://arxiv.org/abs/2502.12198v1,True,2025-02-16T00:30:39Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=0, tm_min=30, tm_sec=39, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T00:30:39Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=0, tm_min=30, tm_sec=39, tm_wday=6, tm_yday=47, tm_isdst=0)","Maximize Your Diffusion: A Study into Reward Maximization and Alignment
  for Diffusion-based Control","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Maximize Your Diffusion: A Study into Reward Maximization and Alignment\n  for Diffusion-based Control'}","Diffusion-based planning, learning, and control methods present a promising
branch of powerful and expressive decision-making solutions. Given the growing
interest, such methods have undergone numerous refinements over the past years.
However, despite these advancements, existing methods are limited in their
investigations regarding general methods for reward maximization within the
decision-making process. In this work, we study extensions of fine-tuning
approaches for control applications. Specifically, we explore extensions and
various design choices for four fine-tuning approaches: reward alignment
through reinforcement learning, direct preference optimization, supervised
fine-tuning, and cascading diffusion. We optimize their usage to merge these
independent efforts into one unified paradigm. We show the utility of such
propositions in offline RL settings and demonstrate empirical improvements over
a rich array of control tasks.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Diffusion-based planning, learning, and control methods present a promising\nbranch of powerful and expressive decision-making solutions. Given the growing\ninterest, such methods have undergone numerous refinements over the past years.\nHowever, despite these advancements, existing methods are limited in their\ninvestigations regarding general methods for reward maximization within the\ndecision-making process. In this work, we study extensions of fine-tuning\napproaches for control applications. Specifically, we explore extensions and\nvarious design choices for four fine-tuning approaches: reward alignment\nthrough reinforcement learning, direct preference optimization, supervised\nfine-tuning, and cascading diffusion. We optimize their usage to merge these\nindependent efforts into one unified paradigm. We show the utility of such\npropositions in offline RL settings and demonstrate empirical improvements over\na rich array of control tasks.'}","['Dom Huh', 'Prasant Mohapatra']",{'name': 'Prasant Mohapatra'},Prasant Mohapatra,,"[{'href': 'http://arxiv.org/abs/2502.12198v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12198v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12198v1,None,http://arxiv.org/abs/2502.12198v1,,,36,0
http://arxiv.org/abs/2502.12200v1,True,2025-02-16T05:50:12Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=5, tm_min=50, tm_sec=12, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T05:50:12Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=5, tm_min=50, tm_sec=12, tm_wday=6, tm_yday=47, tm_isdst=0)","Efficient and Effective Prompt Tuning via Prompt Decomposition and
  Compressed Outer Product","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Efficient and Effective Prompt Tuning via Prompt Decomposition and\n  Compressed Outer Product'}","Prompt tuning (PT) offers a cost-effective alternative to fine-tuning
large-scale pre-trained language models (PLMs), requiring only a few parameters
in soft prompt tokens added before the input text. However, existing PT
approaches face two significant issues: (i) They overlook intrinsic semantic
associations between soft prompt tokens, leading to high discreteness and
limited interactions, thus reducing the model's comprehension and effectiveness
in complex tasks. (ii) Due to the complexity of downstream tasks, long soft
prompt is necessitated to improve performance, but prompt length correlates
positively with memory usage and computational costs. Achieving high efficiency
and performance remains an ongoing challenge. To address these issues, we
propose a novel Low-parameters prompt tuning (LAMP) method, which leverages
prompt decomposition and compressed outer product. Specifically, the prompt
decomposition module employs Truncated SVD to reduce training parameters and
significantly lower the dimensionality of the soft prompt parameter space. It
then utilizes a compressed outer product module to facilitate multiple
interactions among prompt tokens, exploring their intrinsic associations to
enhance knowledge representation. Finally, LAMP uses average pooling to reduce
memory usage and training/inference time. Extensive experiments across six
architectures and eight datasets demonstrate that LAMP outperforms
state-of-the-art PT-based and LoRA-based methods in performance and efficiency.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Prompt tuning (PT) offers a cost-effective alternative to fine-tuning\nlarge-scale pre-trained language models (PLMs), requiring only a few parameters\nin soft prompt tokens added before the input text. However, existing PT\napproaches face two significant issues: (i) They overlook intrinsic semantic\nassociations between soft prompt tokens, leading to high discreteness and\nlimited interactions, thus reducing the model's comprehension and effectiveness\nin complex tasks. (ii) Due to the complexity of downstream tasks, long soft\nprompt is necessitated to improve performance, but prompt length correlates\npositively with memory usage and computational costs. Achieving high efficiency\nand performance remains an ongoing challenge. To address these issues, we\npropose a novel Low-parameters prompt tuning (LAMP) method, which leverages\nprompt decomposition and compressed outer product. Specifically, the prompt\ndecomposition module employs Truncated SVD to reduce training parameters and\nsignificantly lower the dimensionality of the soft prompt parameter space. It\nthen utilizes a compressed outer product module to facilitate multiple\ninteractions among prompt tokens, exploring their intrinsic associations to\nenhance knowledge representation. Finally, LAMP uses average pooling to reduce\nmemory usage and training/inference time. Extensive experiments across six\narchitectures and eight datasets demonstrate that LAMP outperforms\nstate-of-the-art PT-based and LoRA-based methods in performance and efficiency.""}","['Pengxiang Lan', 'Haoyu Xu', 'Enneng Yang', 'Yuliang Liang', 'Guibing Guo', 'Jianzhe Zhao', 'Xingwei Wang']",{'name': 'Xingwei Wang'},Xingwei Wang,,"[{'href': 'http://arxiv.org/abs/2502.12200v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12200v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12200v1,None,http://arxiv.org/abs/2502.12200v1,NAACL 2025 main conference,,581,0
http://arxiv.org/abs/2502.12204v1,True,2025-02-16T12:37:16Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=12, tm_min=37, tm_sec=16, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T12:37:16Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=12, tm_min=37, tm_sec=16, tm_wday=6, tm_yday=47, tm_isdst=0)","Predicting Depression in Screening Interviews from Interactive
  Multi-Theme Collaboration","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Predicting Depression in Screening Interviews from Interactive\n  Multi-Theme Collaboration'}","Automatic depression detection provides cues for early clinical intervention
by clinicians. Clinical interviews for depression detection involve dialogues
centered around multiple themes. Existing studies primarily design end-to-end
neural network models to capture the hierarchical structure of clinical
interview dialogues. However, these methods exhibit defects in modeling the
thematic content of clinical interviews: 1) they fail to capture intra-theme
and inter-theme correlation explicitly, and 2) they do not allow clinicians to
intervene and focus on themes of interest. To address these issues, this paper
introduces an interactive depression detection framework. This framework
leverages in-context learning techniques to identify themes in clinical
interviews and then models both intra-theme and inter-theme correlation.
Additionally, it employs AI-driven feedback to simulate the interests of
clinicians, enabling interactive adjustment of theme importance. PDIMC achieves
absolute improvements of 35\% and 12\% compared to the state-of-the-art on the
depression detection dataset DAIC-WOZ, which demonstrates the effectiveness of
modeling theme correlation and incorporating interactive external feedback.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Automatic depression detection provides cues for early clinical intervention\nby clinicians. Clinical interviews for depression detection involve dialogues\ncentered around multiple themes. Existing studies primarily design end-to-end\nneural network models to capture the hierarchical structure of clinical\ninterview dialogues. However, these methods exhibit defects in modeling the\nthematic content of clinical interviews: 1) they fail to capture intra-theme\nand inter-theme correlation explicitly, and 2) they do not allow clinicians to\nintervene and focus on themes of interest. To address these issues, this paper\nintroduces an interactive depression detection framework. This framework\nleverages in-context learning techniques to identify themes in clinical\ninterviews and then models both intra-theme and inter-theme correlation.\nAdditionally, it employs AI-driven feedback to simulate the interests of\nclinicians, enabling interactive adjustment of theme importance. PDIMC achieves\nabsolute improvements of 35\\% and 12\\% compared to the state-of-the-art on the\ndepression detection dataset DAIC-WOZ, which demonstrates the effectiveness of\nmodeling theme correlation and incorporating interactive external feedback.'}","['Xianbing Zhao', 'Yiqing Lyu', 'Di Wang', 'Buzhou Tang']",{'name': 'Buzhou Tang'},Buzhou Tang,,"[{'href': 'http://arxiv.org/abs/2502.12204v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12204v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12204v1,None,http://arxiv.org/abs/2502.12204v1,,,107,0
http://arxiv.org/abs/2502.12207v1,True,2025-02-16T19:00:55Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=19, tm_min=0, tm_sec=55, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T19:00:55Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=19, tm_min=0, tm_sec=55, tm_wday=6, tm_yday=47, tm_isdst=0)","PAR-AdvGAN: Improving Adversarial Attack Capability with Progressive
  Auto-Regression AdvGAN","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'PAR-AdvGAN: Improving Adversarial Attack Capability with Progressive\n  Auto-Regression AdvGAN'}","Deep neural networks have demonstrated remarkable performance across various
domains. However, they are vulnerable to adversarial examples, which can lead
to erroneous predictions. Generative Adversarial Networks (GANs) can leverage
the generators and discriminators model to quickly produce high-quality
adversarial examples. Since both modules train in a competitive and
simultaneous manner, GAN-based algorithms like AdvGAN can generate adversarial
examples with better transferability compared to traditional methods. However,
the generation of perturbations is usually limited to a single iteration,
preventing these examples from fully exploiting the potential of the methods.
To tackle this issue, we introduce a novel approach named Progressive
Auto-Regression AdvGAN (PAR-AdvGAN). It incorporates an auto-regressive
iteration mechanism within a progressive generation network to craft
adversarial examples with enhanced attack capability. We thoroughly evaluate
our PAR-AdvGAN method with a large-scale experiment, demonstrating its superior
performance over various state-of-the-art black-box adversarial attacks, as
well as the original AdvGAN.Moreover, PAR-AdvGAN significantly accelerates the
adversarial example generation, i.e., achieving the speeds of up to 335.5
frames per second on Inception-v3 model, outperforming the gradient-based
transferable attack algorithms. Our code is available at:
https://anonymous.4open.science/r/PAR-01BF/","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Deep neural networks have demonstrated remarkable performance across various\ndomains. However, they are vulnerable to adversarial examples, which can lead\nto erroneous predictions. Generative Adversarial Networks (GANs) can leverage\nthe generators and discriminators model to quickly produce high-quality\nadversarial examples. Since both modules train in a competitive and\nsimultaneous manner, GAN-based algorithms like AdvGAN can generate adversarial\nexamples with better transferability compared to traditional methods. However,\nthe generation of perturbations is usually limited to a single iteration,\npreventing these examples from fully exploiting the potential of the methods.\nTo tackle this issue, we introduce a novel approach named Progressive\nAuto-Regression AdvGAN (PAR-AdvGAN). It incorporates an auto-regressive\niteration mechanism within a progressive generation network to craft\nadversarial examples with enhanced attack capability. We thoroughly evaluate\nour PAR-AdvGAN method with a large-scale experiment, demonstrating its superior\nperformance over various state-of-the-art black-box adversarial attacks, as\nwell as the original AdvGAN.Moreover, PAR-AdvGAN significantly accelerates the\nadversarial example generation, i.e., achieving the speeds of up to 335.5\nframes per second on Inception-v3 model, outperforming the gradient-based\ntransferable attack algorithms. Our code is available at:\nhttps://anonymous.4open.science/r/PAR-01BF/'}","['Jiayu Zhang', 'Zhiyu Zhu', 'Xinyi Wang', 'Silin Liao', 'Zhibo Jin', 'Flora D. Salim', 'Huaming Chen']",{'name': 'Huaming Chen'},Huaming Chen,,"[{'href': 'http://arxiv.org/abs/2502.12207v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12207v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12207v1,None,http://arxiv.org/abs/2502.12207v1,,,186,0
http://arxiv.org/abs/2502.12213v1,True,2025-02-17T03:29:02Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=3, tm_min=29, tm_sec=2, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T03:29:02Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=3, tm_min=29, tm_sec=2, tm_wday=0, tm_yday=48, tm_isdst=0)","Spatiotemporal-aware Trend-Seasonality Decomposition Network for Traffic
  Flow Forecasting","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Spatiotemporal-aware Trend-Seasonality Decomposition Network for Traffic\n  Flow Forecasting'}","Traffic prediction is critical for optimizing travel scheduling and enhancing
public safety, yet the complex spatial and temporal dynamics within traffic
data present significant challenges for accurate forecasting. In this paper, we
introduce a novel model, the Spatiotemporal-aware Trend-Seasonality
Decomposition Network (STDN). This model begins by constructing a dynamic graph
structure to represent traffic flow and incorporates novel spatio-temporal
embeddings to jointly capture global traffic dynamics. The representations
learned are further refined by a specially designed trend-seasonality
decomposition module, which disentangles the trend-cyclical component and
seasonal component for each traffic node at different times within the graph.
These components are subsequently processed through an encoder-decoder network
to generate the final predictions. Extensive experiments conducted on
real-world traffic datasets demonstrate that STDN achieves superior performance
with remarkable computation cost. Furthermore, we have released a new traffic
dataset named JiNan, which features unique inner-city dynamics, thereby
enriching the scenario comprehensiveness in traffic prediction evaluation.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Traffic prediction is critical for optimizing travel scheduling and enhancing\npublic safety, yet the complex spatial and temporal dynamics within traffic\ndata present significant challenges for accurate forecasting. In this paper, we\nintroduce a novel model, the Spatiotemporal-aware Trend-Seasonality\nDecomposition Network (STDN). This model begins by constructing a dynamic graph\nstructure to represent traffic flow and incorporates novel spatio-temporal\nembeddings to jointly capture global traffic dynamics. The representations\nlearned are further refined by a specially designed trend-seasonality\ndecomposition module, which disentangles the trend-cyclical component and\nseasonal component for each traffic node at different times within the graph.\nThese components are subsequently processed through an encoder-decoder network\nto generate the final predictions. Extensive experiments conducted on\nreal-world traffic datasets demonstrate that STDN achieves superior performance\nwith remarkable computation cost. Furthermore, we have released a new traffic\ndataset named JiNan, which features unique inner-city dynamics, thereby\nenriching the scenario comprehensiveness in traffic prediction evaluation.'}","['Lingxiao Cao', 'Bin Wang', 'Guiyuan Jiang', 'Yanwei Yu', 'Junyu Dong']",{'name': 'Junyu Dong'},Junyu Dong,,"[{'href': 'http://arxiv.org/abs/2502.12213v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12213v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12213v1,None,http://arxiv.org/abs/2502.12213v1,,,15,0
http://arxiv.org/abs/2502.12214v1,True,2025-02-17T04:37:22Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=4, tm_min=37, tm_sec=22, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T04:37:22Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=4, tm_min=37, tm_sec=22, tm_wday=0, tm_yday=48, tm_isdst=0)","Zero Token-Driven Deep Thinking in LLMs: Unlocking the Full Potential of
  Existing Parameters via Cyclic Refinement","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Zero Token-Driven Deep Thinking in LLMs: Unlocking the Full Potential of\n  Existing Parameters via Cyclic Refinement'}","Resource limitations often constrain the parameter counts of Large Language
Models (LLMs), hindering their performance. While existing methods employ
parameter sharing to reuse the same parameter set under fixed budgets, such
approaches typically force each layer to assume multiple roles with a
predetermined number of iterations, restricting efficiency and adaptability. In
this work, we propose the Zero Token Transformer (ZTT), which features a
head-tail decoupled parameter cycling method. We disentangle the first (head)
and last (tail) layers from parameter cycling and iteratively refine only the
intermediate layers. Furthermore, we introduce a Zero-Token Mechanism, an
internal architectural component rather than an input token, to guide
layer-specific computation. At each cycle, the model retrieves a zero token
(with trainable key values) from a Zero-Token Pool, integrating it alongside
regular tokens in the attention mechanism. The corresponding attention scores
not only reflect each layer's computational importance but also enable dynamic
early exits without sacrificing overall model accuracy. Our approach achieves
superior performance under tight parameter budgets, effectively reduces
computational overhead via early exits, and can be readily applied to fine-tune
existing pre-trained models for enhanced efficiency and adaptability.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Resource limitations often constrain the parameter counts of Large Language\nModels (LLMs), hindering their performance. While existing methods employ\nparameter sharing to reuse the same parameter set under fixed budgets, such\napproaches typically force each layer to assume multiple roles with a\npredetermined number of iterations, restricting efficiency and adaptability. In\nthis work, we propose the Zero Token Transformer (ZTT), which features a\nhead-tail decoupled parameter cycling method. We disentangle the first (head)\nand last (tail) layers from parameter cycling and iteratively refine only the\nintermediate layers. Furthermore, we introduce a Zero-Token Mechanism, an\ninternal architectural component rather than an input token, to guide\nlayer-specific computation. At each cycle, the model retrieves a zero token\n(with trainable key values) from a Zero-Token Pool, integrating it alongside\nregular tokens in the attention mechanism. The corresponding attention scores\nnot only reflect each layer's computational importance but also enable dynamic\nearly exits without sacrificing overall model accuracy. Our approach achieves\nsuperior performance under tight parameter budgets, effectively reduces\ncomputational overhead via early exits, and can be readily applied to fine-tune\nexisting pre-trained models for enhanced efficiency and adaptability.""}","['Guanghao Li', 'Wenhao Jiang', 'Li Shen', 'Ming Tang', 'Chun Yuan']",{'name': 'Chun Yuan'},Chun Yuan,,"[{'href': 'http://arxiv.org/abs/2502.12214v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12214v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12214v1,None,http://arxiv.org/abs/2502.12214v1,,,0,0
http://arxiv.org/abs/2502.12222v1,True,2025-02-17T14:15:20Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=14, tm_min=15, tm_sec=20, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T14:15:20Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=14, tm_min=15, tm_sec=20, tm_wday=0, tm_yday=48, tm_isdst=0)","IMPACTX: Improving Model Performance by Appropriately predicting CorrecT
  eXplanations","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'IMPACTX: Improving Model Performance by Appropriately predicting CorrecT\n  eXplanations'}","The eXplainable Artificial Intelligence (XAI) research predominantly
concentrates to provide explainations about AI model decisions, especially Deep
Learning (DL) models. However, there is a growing interest in using XAI
techniques to automatically improve the performance of the AI systems
themselves.
  This paper proposes IMPACTX, a novel approach that leverages XAI as a fully
automated attention mechanism, without requiring external knowledge or human
feedback. Experimental results show that IMPACTX has improved performance
respect to the standalone ML model by integrating an attention mechanism based
an XAI method outputs during the model training. Furthermore, IMPACTX directly
provides proper feature attribution maps for the model's decisions, without
relying on external XAI methods during the inference process.
  Our proposal is evaluated using three widely recognized DL models
(EfficientNet-B2, MobileNet, and LeNet-5) along with three standard image
datasets: CIFAR-10, CIFAR-100, and STL-10. The results show that IMPACTX
consistently improves the performance of all the inspected DL models across all
evaluated datasets, and it directly provides appropriate explanations for its
responses.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""The eXplainable Artificial Intelligence (XAI) research predominantly\nconcentrates to provide explainations about AI model decisions, especially Deep\nLearning (DL) models. However, there is a growing interest in using XAI\ntechniques to automatically improve the performance of the AI systems\nthemselves.\n  This paper proposes IMPACTX, a novel approach that leverages XAI as a fully\nautomated attention mechanism, without requiring external knowledge or human\nfeedback. Experimental results show that IMPACTX has improved performance\nrespect to the standalone ML model by integrating an attention mechanism based\nan XAI method outputs during the model training. Furthermore, IMPACTX directly\nprovides proper feature attribution maps for the model's decisions, without\nrelying on external XAI methods during the inference process.\n  Our proposal is evaluated using three widely recognized DL models\n(EfficientNet-B2, MobileNet, and LeNet-5) along with three standard image\ndatasets: CIFAR-10, CIFAR-100, and STL-10. The results show that IMPACTX\nconsistently improves the performance of all the inspected DL models across all\nevaluated datasets, and it directly provides appropriate explanations for its\nresponses.""}","['Andrea Apicella', 'Salvatore Giugliano', 'Francesco Isgr', 'Roberto Prevete']",{'name': 'Roberto Prevete'},Roberto Prevete,in peer review,"[{'href': 'http://arxiv.org/abs/2502.12222v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12222v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12222v1,None,http://arxiv.org/abs/2502.12222v1,,,2455,0
http://arxiv.org/abs/2502.12224v1,True,2025-02-17T14:54:14Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=14, tm_min=54, tm_sec=14, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T14:54:14Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=14, tm_min=54, tm_sec=14, tm_wday=0, tm_yday=48, tm_isdst=0)",Accurate Expert Predictions in MoE Inference via Cross-Layer Gate,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Accurate Expert Predictions in MoE Inference via Cross-Layer Gate'}","Large Language Models (LLMs) have demonstrated impressive performance across
various tasks, and their application in edge scenarios has attracted
significant attention. However, sparse-activated Mixture-of-Experts (MoE)
models, which are well suited for edge scenarios, have received relatively
little attention due to their high memory demands. Offload-based methods have
been proposed to address this challenge, but they face difficulties with expert
prediction. Inaccurate expert predictions can result in prolonged inference
delays. To promote the application of MoE models in edge scenarios, we propose
Fate, an offloading system designed for MoE models to enable efficient
inference in resource-constrained environments. The key insight behind Fate is
that gate inputs from adjacent layers can be effectively used for expert
prefetching, achieving high prediction accuracy without additional GPU
overhead. Furthermore, Fate employs a shallow-favoring expert caching strategy
that increases the expert hit rate to 99\%. Additionally, Fate integrates
tailored quantization strategies for cache optimization and IO efficiency.
Experimental results show that, compared to Load on Demand and Expert
Activation Path-based method, Fate achieves up to 4.5x and 1.9x speedups in
prefill speed and up to 4.1x and 2.2x speedups in decoding speed, respectively,
while maintaining inference quality. Moreover, Fate's performance improvements
are scalable across different memory budgets.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Large Language Models (LLMs) have demonstrated impressive performance across\nvarious tasks, and their application in edge scenarios has attracted\nsignificant attention. However, sparse-activated Mixture-of-Experts (MoE)\nmodels, which are well suited for edge scenarios, have received relatively\nlittle attention due to their high memory demands. Offload-based methods have\nbeen proposed to address this challenge, but they face difficulties with expert\nprediction. Inaccurate expert predictions can result in prolonged inference\ndelays. To promote the application of MoE models in edge scenarios, we propose\nFate, an offloading system designed for MoE models to enable efficient\ninference in resource-constrained environments. The key insight behind Fate is\nthat gate inputs from adjacent layers can be effectively used for expert\nprefetching, achieving high prediction accuracy without additional GPU\noverhead. Furthermore, Fate employs a shallow-favoring expert caching strategy\nthat increases the expert hit rate to 99\\%. Additionally, Fate integrates\ntailored quantization strategies for cache optimization and IO efficiency.\nExperimental results show that, compared to Load on Demand and Expert\nActivation Path-based method, Fate achieves up to 4.5x and 1.9x speedups in\nprefill speed and up to 4.1x and 2.2x speedups in decoding speed, respectively,\nwhile maintaining inference quality. Moreover, Fate's performance improvements\nare scalable across different memory budgets.""}","['Zhiyuan Fang', 'Zicong Hong', 'Yuegui Huang', 'Yufeng Lyu', 'Wuhui Chen', 'Yue Yu', 'Fan Yu', 'Zibin Zheng']",{'name': 'Zibin Zheng'},Zibin Zheng,,"[{'href': 'http://arxiv.org/abs/2502.12224v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12224v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12224v1,None,http://arxiv.org/abs/2502.12224v1,,,1267,0
http://arxiv.org/abs/2502.12225v1,True,2025-02-17T15:14:10Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=15, tm_min=14, tm_sec=10, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T15:14:10Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=15, tm_min=14, tm_sec=10, tm_wday=0, tm_yday=48, tm_isdst=0)",Subjective Logic Encodings,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Subjective Logic Encodings'}","Many existing approaches for learning from labeled data assume the existence
of gold-standard labels. According to these approaches, inter-annotator
disagreement is seen as noise to be removed, either through refinement of
annotation guidelines, label adjudication, or label filtering. However,
annotator disagreement can rarely be totally eradicated, especially on more
subjective tasks such as sentiment analysis or hate speech detection where
disagreement is natural. Therefore, a new approach to learning from labeled
data, called data perspectivism, seeks to leverage inter-annotator disagreement
to learn models that stay true to the inherent uncertainty of the task by
treating annotations as opinions of the annotators, rather than gold-standard
facts. Despite this conceptual grounding, existing methods under data
perspectivism are limited to using disagreement as the sole source of
annotation uncertainty. To expand the possibilities of data perspectivism, we
introduce Subjective Logic Encodings (SLEs), a flexible framework for
constructing classification targets that explicitly encodes annotations as
opinions of the annotators. Based on Subjective Logic Theory, SLEs encode
labels as Dirichlet distributions and provide principled methods for encoding
and aggregating various types of annotation uncertainty -- annotator
confidence, reliability, and disagreement -- into the targets. We show that
SLEs are a generalization of other types of label encodings as well as how to
estimate models to predict SLEs using a distribution matching objective.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Many existing approaches for learning from labeled data assume the existence\nof gold-standard labels. According to these approaches, inter-annotator\ndisagreement is seen as noise to be removed, either through refinement of\nannotation guidelines, label adjudication, or label filtering. However,\nannotator disagreement can rarely be totally eradicated, especially on more\nsubjective tasks such as sentiment analysis or hate speech detection where\ndisagreement is natural. Therefore, a new approach to learning from labeled\ndata, called data perspectivism, seeks to leverage inter-annotator disagreement\nto learn models that stay true to the inherent uncertainty of the task by\ntreating annotations as opinions of the annotators, rather than gold-standard\nfacts. Despite this conceptual grounding, existing methods under data\nperspectivism are limited to using disagreement as the sole source of\nannotation uncertainty. To expand the possibilities of data perspectivism, we\nintroduce Subjective Logic Encodings (SLEs), a flexible framework for\nconstructing classification targets that explicitly encodes annotations as\nopinions of the annotators. Based on Subjective Logic Theory, SLEs encode\nlabels as Dirichlet distributions and provide principled methods for encoding\nand aggregating various types of annotation uncertainty -- annotator\nconfidence, reliability, and disagreement -- into the targets. We show that\nSLEs are a generalization of other types of label encodings as well as how to\nestimate models to predict SLEs using a distribution matching objective.'}",['Jake Vasilakes'],{'name': 'Jake Vasilakes'},Jake Vasilakes,"We make our code publicly available at
  https://github.com/jvasilakes/SLEncodings","[{'href': 'http://arxiv.org/abs/2502.12225v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12225v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12225v1,None,http://arxiv.org/abs/2502.12225v1,,,0,0
http://arxiv.org/abs/2502.12226v1,True,2025-02-17T15:26:16Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=15, tm_min=26, tm_sec=16, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T15:26:16Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=15, tm_min=26, tm_sec=16, tm_wday=0, tm_yday=48, tm_isdst=0)","On Creating a Causally Grounded Usable Rating Method for Assessing the
  Robustness of Foundation Models Supporting Time Series","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'On Creating a Causally Grounded Usable Rating Method for Assessing the\n  Robustness of Foundation Models Supporting Time Series'}","Foundation Models (FMs) have improved time series forecasting in various
sectors, such as finance, but their vulnerability to input disturbances can
hinder their adoption by stakeholders, such as investors and analysts. To
address this, we propose a causally grounded rating framework to study the
robustness of Foundational Models for Time Series (FMTS) with respect to input
perturbations. We evaluate our approach to the stock price prediction problem,
a well-studied problem with easily accessible public data, evaluating six
state-of-the-art (some multi-modal) FMTS across six prominent stocks spanning
three industries. The ratings proposed by our framework effectively assess the
robustness of FMTS and also offer actionable insights for model selection and
deployment. Within the scope of our study, we find that (1) multi-modal FMTS
exhibit better robustness and accuracy compared to their uni-modal versions
and, (2) FMTS pre-trained on time series forecasting task exhibit better
robustness and forecasting accuracy compared to general-purpose FMTS
pre-trained across diverse settings. Further, to validate our framework's
usability, we conduct a user study showcasing FMTS prediction errors along with
our computed ratings. The study confirmed that our ratings reduced the
difficulty for users in comparing the robustness of different systems.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Foundation Models (FMs) have improved time series forecasting in various\nsectors, such as finance, but their vulnerability to input disturbances can\nhinder their adoption by stakeholders, such as investors and analysts. To\naddress this, we propose a causally grounded rating framework to study the\nrobustness of Foundational Models for Time Series (FMTS) with respect to input\nperturbations. We evaluate our approach to the stock price prediction problem,\na well-studied problem with easily accessible public data, evaluating six\nstate-of-the-art (some multi-modal) FMTS across six prominent stocks spanning\nthree industries. The ratings proposed by our framework effectively assess the\nrobustness of FMTS and also offer actionable insights for model selection and\ndeployment. Within the scope of our study, we find that (1) multi-modal FMTS\nexhibit better robustness and accuracy compared to their uni-modal versions\nand, (2) FMTS pre-trained on time series forecasting task exhibit better\nrobustness and forecasting accuracy compared to general-purpose FMTS\npre-trained across diverse settings. Further, to validate our framework's\nusability, we conduct a user study showcasing FMTS prediction errors along with\nour computed ratings. The study confirmed that our ratings reduced the\ndifficulty for users in comparing the robustness of different systems.""}","['Kausik Lakkaraju', 'Rachneet Kaur', 'Parisa Zehtabi', 'Sunandita Patra', 'Siva Likitha Valluru', 'Zhen Zeng', 'Biplav Srivastava', 'Marco Valtorta']",{'name': 'Marco Valtorta'},Marco Valtorta,,"[{'href': 'http://arxiv.org/abs/2502.12226v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12226v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12226v1,None,http://arxiv.org/abs/2502.12226v1,,,462,0
http://arxiv.org/abs/2502.12227v1,True,2025-02-17T17:23:52Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=17, tm_min=23, tm_sec=52, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T17:23:52Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=17, tm_min=23, tm_sec=52, tm_wday=0, tm_yday=48, tm_isdst=0)",Identifying the Best Transition Law,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Identifying the Best Transition Law'}","Motivated by recursive learning in Markov Decision Processes, this paper
studies best-arm identification in bandit problems where each arm's reward is
drawn from a multinomial distribution with a known support. We compare the
performance { reached by strategies including notably LUCB without and with use
of this knowledge. } In the first case, we use classical non-parametric
approaches for the confidence intervals. In the second case, where a
probability distribution is to be estimated, we first use classical deviation
bounds (Hoeffding and Bernstein) on each dimension independently, and then the
Empirical Likelihood method (EL-LUCB) on the joint probability vector. The
effectiveness of these methods is demonstrated through simulations on scenarios
with varying levels of structural complexity.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Motivated by recursive learning in Markov Decision Processes, this paper\nstudies best-arm identification in bandit problems where each arm's reward is\ndrawn from a multinomial distribution with a known support. We compare the\nperformance { reached by strategies including notably LUCB without and with use\nof this knowledge. } In the first case, we use classical non-parametric\napproaches for the confidence intervals. In the second case, where a\nprobability distribution is to be estimated, we first use classical deviation\nbounds (Hoeffding and Bernstein) on each dimension independently, and then the\nEmpirical Likelihood method (EL-LUCB) on the joint probability vector. The\neffectiveness of these methods is demonstrated through simulations on scenarios\nwith varying levels of structural complexity.""}","['Mehrasa Ahmadipour', 'lise Crepon', 'Aurlien Garivier']",{'name': 'Aurlien Garivier'},Aurlien Garivier,,"[{'href': 'http://arxiv.org/abs/2502.12227v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12227v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12227v1,None,http://arxiv.org/abs/2502.12227v1,,,162,0
http://arxiv.org/abs/2502.12267v1,True,2025-02-17T19:07:41Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=19, tm_min=7, tm_sec=41, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T19:07:41Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=19, tm_min=7, tm_sec=41, tm_wday=0, tm_yday=48, tm_isdst=0)","NeuroStrata: Harnessing Neurosymbolic Paradigms for Improved Design,
  Testability, and Verifiability of Autonomous CPS","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'NeuroStrata: Harnessing Neurosymbolic Paradigms for Improved Design,\n  Testability, and Verifiability of Autonomous CPS'}","Autonomous cyber-physical systems (CPSs) leverage AI for perception,
planning, and control but face trust and safety certification challenges due to
inherent uncertainties. The neurosymbolic paradigm replaces stochastic layers
with interpretable symbolic AI, enabling determinism. While promising,
challenges like multisensor fusion, adaptability, and verification remain. This
paper introduces NeuroStrata, a neurosymbolic framework to enhance the testing
and verification of autonomous CPS. We outline its key components, present
early results, and detail future plans.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Autonomous cyber-physical systems (CPSs) leverage AI for perception,\nplanning, and control but face trust and safety certification challenges due to\ninherent uncertainties. The neurosymbolic paradigm replaces stochastic layers\nwith interpretable symbolic AI, enabling determinism. While promising,\nchallenges like multisensor fusion, adaptability, and verification remain. This\npaper introduces NeuroStrata, a neurosymbolic framework to enhance the testing\nand verification of autonomous CPS. We outline its key components, present\nearly results, and detail future plans.'}","['Xi Zheng', 'Ziyang Li', 'Ivan Ruchkin', 'Ruzica Piskac', 'Miroslav Pajic']",{'name': 'Miroslav Pajic'},Miroslav Pajic,,"[{'href': 'http://arxiv.org/abs/2502.12267v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12267v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.SE', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.SE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12267v1,None,http://arxiv.org/abs/2502.12267v1,,,1851,0
http://arxiv.org/abs/2502.12278v1,True,2025-02-17T19:28:06Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=19, tm_min=28, tm_sec=6, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T19:28:06Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=19, tm_min=28, tm_sec=6, tm_wday=0, tm_yday=48, tm_isdst=0)",Towards Practical First-Order Model Counting,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Towards Practical First-Order Model Counting'}","First-order model counting (FOMC) is the problem of counting the number of
models of a sentence in first-order logic. Since lifted inference techniques
rely on reductions to variants of FOMC, the design of scalable methods for FOMC
has attracted attention from both theoreticians and practitioners over the past
decade. Recently, a new approach based on first-order knowledge compilation was
proposed. This approach, called Crane, instead of simply providing the final
count, generates definitions of (possibly recursive) functions that can be
evaluated with different arguments to compute the model count for any domain
size. However, this approach is not fully automated, as it requires manual
evaluation of the constructed functions. The primary contribution of this work
is a fully automated compilation algorithm, called Gantry, which transforms the
function definitions into C++ code equipped with arbitrary-precision
arithmetic. These additions allow the new FOMC algorithm to scale to domain
sizes over 500,000 times larger than the current state of the art, as
demonstrated through experimental results.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'First-order model counting (FOMC) is the problem of counting the number of\nmodels of a sentence in first-order logic. Since lifted inference techniques\nrely on reductions to variants of FOMC, the design of scalable methods for FOMC\nhas attracted attention from both theoreticians and practitioners over the past\ndecade. Recently, a new approach based on first-order knowledge compilation was\nproposed. This approach, called Crane, instead of simply providing the final\ncount, generates definitions of (possibly recursive) functions that can be\nevaluated with different arguments to compute the model count for any domain\nsize. However, this approach is not fully automated, as it requires manual\nevaluation of the constructed functions. The primary contribution of this work\nis a fully automated compilation algorithm, called Gantry, which transforms the\nfunction definitions into C++ code equipped with arbitrary-precision\narithmetic. These additions allow the new FOMC algorithm to scale to domain\nsizes over 500,000 times larger than the current state of the art, as\ndemonstrated through experimental results.'}","['Ananth K. Kidambi', 'Guramrit Singh', 'Paulius Dilkas', 'Kuldeep S. Meel']",{'name': 'Kuldeep S. Meel'},Kuldeep S. Meel,"18 pages, 1 figure","[{'href': 'http://arxiv.org/abs/2502.12278v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12278v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LO', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12278v1,None,http://arxiv.org/abs/2502.12278v1,,,4047,0
http://arxiv.org/abs/2502.12280v1,True,2025-02-17T19:32:30Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=19, tm_min=32, tm_sec=30, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T19:32:30Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=19, tm_min=32, tm_sec=30, tm_wday=0, tm_yday=48, tm_isdst=0)","Connecting Large Language Model Agent to High Performance Computing
  Resource","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Connecting Large Language Model Agent to High Performance Computing\n  Resource'}","The Large Language Model agent workflow enables the LLM to invoke tool
functions to increase the performance on specific scientific domain questions.
To tackle large scale of scientific research, it requires access to computing
resource and parallel computing setup. In this work, we implemented Parsl to
the LangChain/LangGraph tool call setup, to bridge the gap between the LLM
agent to the computing resource. Two tool call implementations were set up and
tested on both local workstation and HPC environment on Polaris/ALCF. The first
implementation with Parsl-enabled LangChain tool node queues the tool functions
concurrently to the Parsl workers for parallel execution. The second
configuration is implemented by converting the tool functions into Parsl
ensemble functions, and is more suitable for large task on super computer
environment. The LLM agent workflow was prompted to run molecular dynamics
simulations, with different protein structure and simulation conditions. These
results showed the LLM agent tools were managed and executed concurrently by
Parsl on the available computing resource.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The Large Language Model agent workflow enables the LLM to invoke tool\nfunctions to increase the performance on specific scientific domain questions.\nTo tackle large scale of scientific research, it requires access to computing\nresource and parallel computing setup. In this work, we implemented Parsl to\nthe LangChain/LangGraph tool call setup, to bridge the gap between the LLM\nagent to the computing resource. Two tool call implementations were set up and\ntested on both local workstation and HPC environment on Polaris/ALCF. The first\nimplementation with Parsl-enabled LangChain tool node queues the tool functions\nconcurrently to the Parsl workers for parallel execution. The second\nconfiguration is implemented by converting the tool functions into Parsl\nensemble functions, and is more suitable for large task on super computer\nenvironment. The LLM agent workflow was prompted to run molecular dynamics\nsimulations, with different protein structure and simulation conditions. These\nresults showed the LLM agent tools were managed and executed concurrently by\nParsl on the available computing resource.'}","['Heng Ma', 'Alexander Brace', 'Carlo Siebenschuh', 'Greg Pauloski', 'Ian Foster', 'Arvind Ramanathan']",{'name': 'Arvind Ramanathan'},Arvind Ramanathan,"7 pages, 4 figures","[{'href': 'http://arxiv.org/abs/2502.12280v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12280v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.DC', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.DC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.11', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12280v1,None,http://arxiv.org/abs/2502.12280v1,,,52,0
http://arxiv.org/abs/2502.12304v1,True,2025-02-17T20:23:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=20, tm_min=23, tm_sec=42, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T20:23:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=20, tm_min=23, tm_sec=42, tm_wday=0, tm_yday=48, tm_isdst=0)","Warmup Generations: A Task-Agnostic Approach for Guiding
  Sequence-to-Sequence Learning with Unsupervised Initial State Generation","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Warmup Generations: A Task-Agnostic Approach for Guiding\n  Sequence-to-Sequence Learning with Unsupervised Initial State Generation'}","Traditional supervised fine-tuning (SFT) strategies for sequence-to-sequence
tasks often train models to directly generate the target output. Recent work
has shown that guiding models with intermediate steps, such as keywords,
outlines, or reasoning chains, can significantly improve performance,
coherence, and interpretability. However, these methods often depend on
predefined intermediate formats and annotated data, limiting their scalability
and generalizability. In this work, we introduce a task-agnostic framework that
enables models to generate intermediate ""warmup"" sequences. These warmup
sequences, serving as an initial state for subsequent generation, are optimized
to enhance the probability of generating the target sequence without relying on
external supervision or human-designed structures. Drawing inspiration from
reinforcement learning principles, our method iteratively refines these
intermediate steps to maximize their contribution to the final output, similar
to reward-driven optimization in reinforcement learning with human feedback.
Experimental results across tasks such as translation, summarization, and
multi-choice question answering for logical reasoning show that our approach
outperforms traditional SFT methods, and offers a scalable and flexible
solution for sequence-to-sequence tasks.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Traditional supervised fine-tuning (SFT) strategies for sequence-to-sequence\ntasks often train models to directly generate the target output. Recent work\nhas shown that guiding models with intermediate steps, such as keywords,\noutlines, or reasoning chains, can significantly improve performance,\ncoherence, and interpretability. However, these methods often depend on\npredefined intermediate formats and annotated data, limiting their scalability\nand generalizability. In this work, we introduce a task-agnostic framework that\nenables models to generate intermediate ""warmup"" sequences. These warmup\nsequences, serving as an initial state for subsequent generation, are optimized\nto enhance the probability of generating the target sequence without relying on\nexternal supervision or human-designed structures. Drawing inspiration from\nreinforcement learning principles, our method iteratively refines these\nintermediate steps to maximize their contribution to the final output, similar\nto reward-driven optimization in reinforcement learning with human feedback.\nExperimental results across tasks such as translation, summarization, and\nmulti-choice question answering for logical reasoning show that our approach\noutperforms traditional SFT methods, and offers a scalable and flexible\nsolution for sequence-to-sequence tasks.'}","['Senyu Li', 'Zipeng Sun', 'Jiayi Wang', 'Xue Liu', 'Pontus Stenetorp', 'Siva Reddy', 'David Ifeoluwa Adelani']",{'name': 'David Ifeoluwa Adelani'},David Ifeoluwa Adelani,,"[{'href': 'http://arxiv.org/abs/2502.12304v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12304v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12304v1,None,http://arxiv.org/abs/2502.12304v1,,,35,0
http://arxiv.org/abs/2502.12328v1,True,2025-02-17T21:19:45Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=21, tm_min=19, tm_sec=45, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T21:19:45Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=21, tm_min=19, tm_sec=45, tm_wday=0, tm_yday=48, tm_isdst=0)",LM Agents for Coordinating Multi-User Information Gathering,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'LM Agents for Coordinating Multi-User Information Gathering'}","This paper introduces PeopleJoin, a benchmark for evaluating LM-mediated
collaborative problem solving. Given a user request, PeopleJoin agents must
identify teammates who might be able to assist, converse with these teammates
to gather information, and finally compile a useful answer or summary for the
original user. PeopleJoin comprises two evaluation domains: PeopleJoin-QA,
focused on questions about tabular data, and PeopleJoin-DocCreation, focused on
document creation tasks. The two domains are adapted from existing NLP
benchmarks for database question answering and multi-document summarization;
here, however, the information needed to complete these tasks is distributed
across synthetic ``organizations'' of 2--20 users, simulating natural
multi-user collaboration scenarios. We implemented several popular LM agent
architectures, evaluating their accuracy and efficiency at completing tasks,
and highlight new research questions that can be studied using PeopleJoin.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""This paper introduces PeopleJoin, a benchmark for evaluating LM-mediated\ncollaborative problem solving. Given a user request, PeopleJoin agents must\nidentify teammates who might be able to assist, converse with these teammates\nto gather information, and finally compile a useful answer or summary for the\noriginal user. PeopleJoin comprises two evaluation domains: PeopleJoin-QA,\nfocused on questions about tabular data, and PeopleJoin-DocCreation, focused on\ndocument creation tasks. The two domains are adapted from existing NLP\nbenchmarks for database question answering and multi-document summarization;\nhere, however, the information needed to complete these tasks is distributed\nacross synthetic ``organizations'' of 2--20 users, simulating natural\nmulti-user collaboration scenarios. We implemented several popular LM agent\narchitectures, evaluating their accuracy and efficiency at completing tasks,\nand highlight new research questions that can be studied using PeopleJoin.""}","['Harsh Jhamtani', 'Jacob Andreas', 'Benjamin Van Durme']",{'name': 'Benjamin Van Durme'},Benjamin Van Durme,,"[{'href': 'http://arxiv.org/abs/2502.12328v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12328v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12328v1,None,http://arxiv.org/abs/2502.12328v1,,,1283,0
http://arxiv.org/abs/2502.12346v1,True,2025-02-17T22:20:31Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=22, tm_min=20, tm_sec=31, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T22:20:31Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=22, tm_min=20, tm_sec=31, tm_wday=0, tm_yday=48, tm_isdst=0)",QuZO: Quantized Zeroth-Order Fine-Tuning for Large Language Models,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'QuZO: Quantized Zeroth-Order Fine-Tuning for Large Language Models'}","Language Models (LLMs) are often quantized to lower precision to reduce the
memory cost and latency in inference. However, quantization often degrades
model performance, thus fine-tuning is required for various down-stream tasks.
Traditional fine-tuning methods such as stochastic gradient descent and Adam
optimization require backpropagation, which are error-prone in the
low-precision settings. To overcome these limitations, we propose the Quantized
Zeroth-Order (QuZO) framework, specifically designed for fine-tuning LLMs
through low-precision (e.g., 4- or 8-bit) forward passes. Our method can avoid
the error-prone low-precision straight-through estimator, and utilizes
optimized stochastic rounding to mitigate the increased bias. QuZO simplifies
the training process, while achieving results comparable to first-order methods
in ${\rm FP}8$ and superior accuracy in ${\rm INT}8$ and ${\rm INT}4$ training.
Experiments demonstrate that low-bit training QuZO achieves performance
comparable to MeZO optimization on GLUE, Multi-Choice, and Generation tasks,
while reducing memory cost by $2.94 \times$ in LLaMA2-7B fine-tuning compared
to quantized first-order methods.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Language Models (LLMs) are often quantized to lower precision to reduce the\nmemory cost and latency in inference. However, quantization often degrades\nmodel performance, thus fine-tuning is required for various down-stream tasks.\nTraditional fine-tuning methods such as stochastic gradient descent and Adam\noptimization require backpropagation, which are error-prone in the\nlow-precision settings. To overcome these limitations, we propose the Quantized\nZeroth-Order (QuZO) framework, specifically designed for fine-tuning LLMs\nthrough low-precision (e.g., 4- or 8-bit) forward passes. Our method can avoid\nthe error-prone low-precision straight-through estimator, and utilizes\noptimized stochastic rounding to mitigate the increased bias. QuZO simplifies\nthe training process, while achieving results comparable to first-order methods\nin ${\\rm FP}8$ and superior accuracy in ${\\rm INT}8$ and ${\\rm INT}4$ training.\nExperiments demonstrate that low-bit training QuZO achieves performance\ncomparable to MeZO optimization on GLUE, Multi-Choice, and Generation tasks,\nwhile reducing memory cost by $2.94 \\times$ in LLaMA2-7B fine-tuning compared\nto quantized first-order methods.'}","['Jiajun Zhou', 'Yifan Yang', 'Kai Zhen', 'Ziyue Liu', 'Yequan Zhao', 'Ershad Banijamali', 'Athanasios Mouchtaris', 'Ngai Wong', 'Zheng Zhang']",{'name': 'Zheng Zhang'},Zheng Zhang,,"[{'href': 'http://arxiv.org/abs/2502.12346v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12346v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12346v1,None,http://arxiv.org/abs/2502.12346v1,,,303,0
http://arxiv.org/abs/2502.12352v1,True,2025-02-17T22:35:16Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=22, tm_min=35, tm_sec=16, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T22:35:16Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=22, tm_min=35, tm_sec=16, tm_wday=0, tm_yday=48, tm_isdst=0)","Towards Mechanistic Interpretability of Graph Transformers via Attention
  Graphs","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Towards Mechanistic Interpretability of Graph Transformers via Attention\n  Graphs'}","We introduce Attention Graphs, a new tool for mechanistic interpretability of
Graph Neural Networks (GNNs) and Graph Transformers based on the mathematical
equivalence between message passing in GNNs and the self-attention mechanism in
Transformers. Attention Graphs aggregate attention matrices across Transformer
layers and heads to describe how information flows among input nodes. Through
experiments on homophilous and heterophilous node classification tasks, we
analyze Attention Graphs from a network science perspective and find that: (1)
When Graph Transformers are allowed to learn the optimal graph structure using
all-to-all attention among input nodes, the Attention Graphs learned by the
model do not tend to correlate with the input/original graph structure; and (2)
For heterophilous graphs, different Graph Transformer variants can achieve
similar performance while utilising distinct information flow patterns. Open
source code: https://github.com/batu-el/understanding-inductive-biases-of-gnns","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'We introduce Attention Graphs, a new tool for mechanistic interpretability of\nGraph Neural Networks (GNNs) and Graph Transformers based on the mathematical\nequivalence between message passing in GNNs and the self-attention mechanism in\nTransformers. Attention Graphs aggregate attention matrices across Transformer\nlayers and heads to describe how information flows among input nodes. Through\nexperiments on homophilous and heterophilous node classification tasks, we\nanalyze Attention Graphs from a network science perspective and find that: (1)\nWhen Graph Transformers are allowed to learn the optimal graph structure using\nall-to-all attention among input nodes, the Attention Graphs learned by the\nmodel do not tend to correlate with the input/original graph structure; and (2)\nFor heterophilous graphs, different Graph Transformer variants can achieve\nsimilar performance while utilising distinct information flow patterns. Open\nsource code: https://github.com/batu-el/understanding-inductive-biases-of-gnns'}","['Batu El', 'Deepro Choudhury', 'Pietro Li', 'Chaitanya K. Joshi']",{'name': 'Chaitanya K. Joshi'},Chaitanya K. Joshi,,"[{'href': 'http://arxiv.org/abs/2502.12352v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12352v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12352v1,None,http://arxiv.org/abs/2502.12352v1,,,1882,0
http://arxiv.org/abs/2502.12362v1,True,2025-02-17T22:56:56Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=22, tm_min=56, tm_sec=56, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T22:56:56Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=22, tm_min=56, tm_sec=56, tm_wday=0, tm_yday=48, tm_isdst=0)",Classifiers of Data Sharing Statements in Clinical Trial Records,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Classifiers of Data Sharing Statements in Clinical Trial Records'}","Digital individual participant data (IPD) from clinical trials are
increasingly distributed for potential scientific reuse. The identification of
available IPD, however, requires interpretations of textual data-sharing
statements (DSS) in large databases. Recent advancements in computational
linguistics include pre-trained language models that promise to simplify the
implementation of effective classifiers based on textual inputs. In a subset of
5,000 textual DSS from ClinicalTrials.gov, we evaluate how well classifiers
based on domain-specific pre-trained language models reproduce original
availability categories as well as manually annotated labels. Typical metrics
indicate that classifiers that predicted manual annotations outperformed those
that learned to output the original availability categories. This suggests that
the textual DSS descriptions contain applicable information that the
availability categories do not, and that such classifiers could thus aid the
automatic identification of available IPD in large trial databases.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Digital individual participant data (IPD) from clinical trials are\nincreasingly distributed for potential scientific reuse. The identification of\navailable IPD, however, requires interpretations of textual data-sharing\nstatements (DSS) in large databases. Recent advancements in computational\nlinguistics include pre-trained language models that promise to simplify the\nimplementation of effective classifiers based on textual inputs. In a subset of\n5,000 textual DSS from ClinicalTrials.gov, we evaluate how well classifiers\nbased on domain-specific pre-trained language models reproduce original\navailability categories as well as manually annotated labels. Typical metrics\nindicate that classifiers that predicted manual annotations outperformed those\nthat learned to output the original availability categories. This suggests that\nthe textual DSS descriptions contain applicable information that the\navailability categories do not, and that such classifiers could thus aid the\nautomatic identification of available IPD in large trial databases.'}","['Saber Jelodari Mamaghani', 'Cosima Strantz', 'Dennis Toddenroth']",{'name': 'Dennis Toddenroth'},Dennis Toddenroth,"Published in Proceedings of MIE 2024, IOS Press eBooks. Studies in
  Health Technology and Informatics, Vol. 316, pp. 834-838. Conference held in
  Athens, Greece","[{'title': 'doi', 'href': 'http://dx.doi.org/10.3233/SHTI240541', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2502.12362v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12362v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7; J.3', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12362v1,None,http://arxiv.org/abs/2502.12362v1,"Studies in Health Technology and Informatics, Vol. 316, pp.
  834-838, IOS Press, 2024",10.3233/SHTI240541,655,0
http://arxiv.org/abs/2502.12373v1,True,2025-02-17T23:24:18Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=23, tm_min=24, tm_sec=18, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T23:24:18Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=23, tm_min=24, tm_sec=18, tm_wday=0, tm_yday=48, tm_isdst=0)","Soft Robotics for Search and Rescue: Advancements, Challenges, and
  Future Directions","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Soft Robotics for Search and Rescue: Advancements, Challenges, and\n  Future Directions'}","Soft robotics has emerged as a transformative technology in Search and Rescue
(SAR) operations, addressing challenges in navigating complex, hazardous
environments that often limit traditional rigid robots. This paper critically
examines advancements in soft robotic technologies tailored for SAR
applications, focusing on their unique capabilities in adaptability, safety,
and efficiency. By leveraging bio-inspired designs, flexible materials, and
advanced locomotion mechanisms, such as crawling, rolling, and shape morphing,
soft robots demonstrate exceptional potential in disaster scenarios. However,
significant barriers persist, including material durability, power
inefficiency, sensor integration, and control complexity. This comprehensive
review highlights the current state of soft robotics in SAR, discusses
simulation methodologies and hardware validations, and introduces performance
metrics essential for their evaluation. By bridging the gap between theoretical
advancements and practical deployment, this study underscores the potential of
soft robotic systems to revolutionize SAR missions and advocates for continued
interdisciplinary innovation to overcome existing limitations.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Soft robotics has emerged as a transformative technology in Search and Rescue\n(SAR) operations, addressing challenges in navigating complex, hazardous\nenvironments that often limit traditional rigid robots. This paper critically\nexamines advancements in soft robotic technologies tailored for SAR\napplications, focusing on their unique capabilities in adaptability, safety,\nand efficiency. By leveraging bio-inspired designs, flexible materials, and\nadvanced locomotion mechanisms, such as crawling, rolling, and shape morphing,\nsoft robots demonstrate exceptional potential in disaster scenarios. However,\nsignificant barriers persist, including material durability, power\ninefficiency, sensor integration, and control complexity. This comprehensive\nreview highlights the current state of soft robotics in SAR, discusses\nsimulation methodologies and hardware validations, and introduces performance\nmetrics essential for their evaluation. By bridging the gap between theoretical\nadvancements and practical deployment, this study underscores the potential of\nsoft robotic systems to revolutionize SAR missions and advocates for continued\ninterdisciplinary innovation to overcome existing limitations.'}",['Abhishek Sebastian'],{'name': 'Abhishek Sebastian'},Abhishek Sebastian,,"[{'href': 'http://arxiv.org/abs/2502.12373v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12373v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12373v1,None,http://arxiv.org/abs/2502.12373v1,,,0,0
http://arxiv.org/abs/2502.12382v1,True,2025-02-17T23:41:10Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=23, tm_min=41, tm_sec=10, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T23:41:10Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=23, tm_min=41, tm_sec=10, tm_wday=0, tm_yday=48, tm_isdst=0)","Hybrid Machine Learning Models for Intrusion Detection in IoT:
  Leveraging a Real-World IoT Dataset","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Hybrid Machine Learning Models for Intrusion Detection in IoT:\n  Leveraging a Real-World IoT Dataset'}","The rapid growth of the Internet of Things (IoT) has revolutionized
industries, enabling unprecedented connectivity and functionality. However,
this expansion also increases vulnerabilities, exposing IoT networks to
increasingly sophisticated cyberattacks. Intrusion Detection Systems (IDS) are
crucial for mitigating these threats, and recent advancements in Machine
Learning (ML) offer promising avenues for improvement. This research explores a
hybrid approach, combining several standalone ML models such as Random Forest
(RF), XGBoost, K-Nearest Neighbors (KNN), and AdaBoost, in a voting-based
hybrid classifier for effective IoT intrusion detection. This ensemble method
leverages the strengths of individual algorithms to enhance accuracy and
address challenges related to data complexity and scalability. Using the
widely-cited IoT-23 dataset, a prominent benchmark in IoT cybersecurity
research, we evaluate our hybrid classifiers for both binary and multi-class
intrusion detection problems, ensuring a fair comparison with existing
literature. Results demonstrate that our proposed hybrid models, designed for
robustness and scalability, outperform standalone approaches in IoT
environments. This work contributes to the development of advanced, intelligent
IDS frameworks capable of addressing evolving cyber threats.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The rapid growth of the Internet of Things (IoT) has revolutionized\nindustries, enabling unprecedented connectivity and functionality. However,\nthis expansion also increases vulnerabilities, exposing IoT networks to\nincreasingly sophisticated cyberattacks. Intrusion Detection Systems (IDS) are\ncrucial for mitigating these threats, and recent advancements in Machine\nLearning (ML) offer promising avenues for improvement. This research explores a\nhybrid approach, combining several standalone ML models such as Random Forest\n(RF), XGBoost, K-Nearest Neighbors (KNN), and AdaBoost, in a voting-based\nhybrid classifier for effective IoT intrusion detection. This ensemble method\nleverages the strengths of individual algorithms to enhance accuracy and\naddress challenges related to data complexity and scalability. Using the\nwidely-cited IoT-23 dataset, a prominent benchmark in IoT cybersecurity\nresearch, we evaluate our hybrid classifiers for both binary and multi-class\nintrusion detection problems, ensuring a fair comparison with existing\nliterature. Results demonstrate that our proposed hybrid models, designed for\nrobustness and scalability, outperform standalone approaches in IoT\nenvironments. This work contributes to the development of advanced, intelligent\nIDS frameworks capable of addressing evolving cyber threats.'}","['Md Ahnaf Akif', 'Ismail Butun', 'Andre Williams', 'Imadeldin Mahgoub']",{'name': 'Imadeldin Mahgoub'},Imadeldin Mahgoub,"9 pages, 8 figures, 2 tables, journal submission","[{'href': 'http://arxiv.org/abs/2502.12382v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12382v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12382v1,None,http://arxiv.org/abs/2502.12382v1,,,8,0
http://arxiv.org/abs/2502.12386v1,True,2025-02-17T23:50:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=23, tm_min=50, tm_sec=36, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T23:50:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=23, tm_min=50, tm_sec=36, tm_wday=0, tm_yday=48, tm_isdst=0)","Bridging the Data Gap in AI Reliability Research and Establishing
  DR-AIR, a Comprehensive Data Repository for AI Reliability","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Bridging the Data Gap in AI Reliability Research and Establishing\n  DR-AIR, a Comprehensive Data Repository for AI Reliability'}","Artificial intelligence (AI) technology and systems have been advancing
rapidly. However, ensuring the reliability of these systems is crucial for
fostering public confidence in their use. This necessitates the modeling and
analysis of reliability data specific to AI systems. A major challenge in AI
reliability research, particularly for those in academia, is the lack of
readily available AI reliability data. To address this gap, this paper focuses
on conducting a comprehensive review of available AI reliability data and
establishing DR-AIR: a data repository for AI reliability. Specifically, we
introduce key measurements and data types for assessing AI reliability, along
with the methodologies used to collect these data. We also provide a detailed
description of the currently available datasets with illustrative examples.
Furthermore, we outline the setup of the DR-AIR repository and demonstrate its
practical applications. This repository provides easy access to datasets
specifically curated for AI reliability research. We believe these efforts will
significantly benefit the AI research community by facilitating access to
valuable reliability data and promoting collaboration across various academic
domains within AI. We conclude our paper with a call to action, encouraging the
research community to contribute and share AI reliability data to further
advance this critical field of study.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Artificial intelligence (AI) technology and systems have been advancing\nrapidly. However, ensuring the reliability of these systems is crucial for\nfostering public confidence in their use. This necessitates the modeling and\nanalysis of reliability data specific to AI systems. A major challenge in AI\nreliability research, particularly for those in academia, is the lack of\nreadily available AI reliability data. To address this gap, this paper focuses\non conducting a comprehensive review of available AI reliability data and\nestablishing DR-AIR: a data repository for AI reliability. Specifically, we\nintroduce key measurements and data types for assessing AI reliability, along\nwith the methodologies used to collect these data. We also provide a detailed\ndescription of the currently available datasets with illustrative examples.\nFurthermore, we outline the setup of the DR-AIR repository and demonstrate its\npractical applications. This repository provides easy access to datasets\nspecifically curated for AI reliability research. We believe these efforts will\nsignificantly benefit the AI research community by facilitating access to\nvaluable reliability data and promoting collaboration across various academic\ndomains within AI. We conclude our paper with a call to action, encouraging the\nresearch community to contribute and share AI reliability data to further\nadvance this critical field of study.'}","['Simin Zheng', 'Jared M. Clark', 'Fatemeh Salboukh', 'Priscila Silva', 'Karen da Mata', 'Fenglian Pan', 'Jie Min', 'Jiayi Lian', 'Caleb B. King', 'Lance Fiondella', 'Jian Liu', 'Xinwei Deng', 'Yili Hong']",{'name': 'Yili Hong'},Yili Hong,"34 pages, 12 figures","[{'href': 'http://arxiv.org/abs/2502.12386v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12386v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'stat.AP', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'stat.AP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12386v1,None,http://arxiv.org/abs/2502.12386v1,,,131,0
http://arxiv.org/abs/2502.12411v1,True,2025-02-18T01:14:46Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=1, tm_min=14, tm_sec=46, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T01:14:46Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=1, tm_min=14, tm_sec=46, tm_wday=1, tm_yday=49, tm_isdst=0)","Gradient Co-occurrence Analysis for Detecting Unsafe Prompts in Large
  Language Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Gradient Co-occurrence Analysis for Detecting Unsafe Prompts in Large\n  Language Models'}","Unsafe prompts pose significant safety risks to large language models (LLMs).
Existing methods for detecting unsafe prompts rely on data-driven fine-tuning
to train guardrail models, necessitating significant data and computational
resources. In contrast, recent few-shot gradient-based methods emerge,
requiring only few safe and unsafe reference prompts. A gradient-based approach
identifies unsafe prompts by analyzing consistent patterns of the gradients of
safety-critical parameters in LLMs. Although effective, its restriction to
directional similarity (cosine similarity) introduces ``directional bias'',
limiting its capability to identify unsafe prompts. To overcome this
limitation, we introduce GradCoo, a novel gradient co-occurrence analysis
method that expands the scope of safety-critical parameter identification to
include unsigned gradient similarity, thereby reducing the impact of
``directional bias'' and enhancing the accuracy of unsafe prompt detection.
Comprehensive experiments on the widely-used benchmark datasets ToxicChat and
XStest demonstrate that our proposed method can achieve state-of-the-art (SOTA)
performance compared to existing methods. Moreover, we confirm the
generalizability of GradCoo in detecting unsafe prompts across a range of LLM
base models with various sizes and origins.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Unsafe prompts pose significant safety risks to large language models (LLMs).\nExisting methods for detecting unsafe prompts rely on data-driven fine-tuning\nto train guardrail models, necessitating significant data and computational\nresources. In contrast, recent few-shot gradient-based methods emerge,\nrequiring only few safe and unsafe reference prompts. A gradient-based approach\nidentifies unsafe prompts by analyzing consistent patterns of the gradients of\nsafety-critical parameters in LLMs. Although effective, its restriction to\ndirectional similarity (cosine similarity) introduces ``directional bias'',\nlimiting its capability to identify unsafe prompts. To overcome this\nlimitation, we introduce GradCoo, a novel gradient co-occurrence analysis\nmethod that expands the scope of safety-critical parameter identification to\ninclude unsigned gradient similarity, thereby reducing the impact of\n``directional bias'' and enhancing the accuracy of unsafe prompt detection.\nComprehensive experiments on the widely-used benchmark datasets ToxicChat and\nXStest demonstrate that our proposed method can achieve state-of-the-art (SOTA)\nperformance compared to existing methods. Moreover, we confirm the\ngeneralizability of GradCoo in detecting unsafe prompts across a range of LLM\nbase models with various sizes and origins.""}","['Jingyuan Yang', 'Bowen Yan', 'Rongjun Li', 'Ziyu Zhou', 'Xin Chen', 'Zhiyong Feng', 'Wei Peng']",{'name': 'Wei Peng'},Wei Peng,,"[{'href': 'http://arxiv.org/abs/2502.12411v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12411v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12411v1,None,http://arxiv.org/abs/2502.12411v1,,,15,0
http://arxiv.org/abs/2502.12418v1,True,2025-02-18T01:36:10Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=1, tm_min=36, tm_sec=10, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T01:36:10Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=1, tm_min=36, tm_sec=10, tm_wday=1, tm_yday=49, tm_isdst=0)","Boosting Illuminant Estimation in Deep Color Constancy through Enhancing
  Brightness Robustness","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Boosting Illuminant Estimation in Deep Color Constancy through Enhancing\n  Brightness Robustness'}","Color constancy estimates illuminant chromaticity to correct color-biased
images. Recently, Deep Neural Network-driven Color Constancy (DNNCC) models
have made substantial advancements. Nevertheless, the potential risks in DNNCC
due to the vulnerability of deep neural networks have not yet been explored. In
this paper, we conduct the first investigation into the impact of a key factor
in color constancy-brightness-on DNNCC from a robustness perspective. Our
evaluation reveals that several mainstream DNNCC models exhibit high
sensitivity to brightness despite their focus on chromaticity estimation. This
sheds light on a potential limitation of existing DNNCC models: their
sensitivity to brightness may hinder performance given the widespread
brightness variations in real-world datasets. From the insights of our
analysis, we propose a simple yet effective brightness robustness enhancement
strategy for DNNCC models, termed BRE. The core of BRE is built upon the
adaptive step-size adversarial brightness augmentation technique, which
identifies high-risk brightness variation and generates augmented images via
explicit brightness adjustment. Subsequently, BRE develops a
brightness-robustness-aware model optimization strategy that integrates
adversarial brightness training and brightness contrastive loss, significantly
bolstering the brightness robustness of DNNCC models. BRE is
hyperparameter-free and can be integrated into existing DNNCC models, without
incurring additional overhead during the testing phase. Experiments on two
public color constancy datasets-ColorChecker and Cube+-demonstrate that the
proposed BRE consistently enhances the illuminant estimation performance of
existing DNNCC models, reducing the estimation error by an average of 5.04%
across six mainstream DNNCC models, underscoring the critical role of enhancing
brightness robustness in these models.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Color constancy estimates illuminant chromaticity to correct color-biased\nimages. Recently, Deep Neural Network-driven Color Constancy (DNNCC) models\nhave made substantial advancements. Nevertheless, the potential risks in DNNCC\ndue to the vulnerability of deep neural networks have not yet been explored. In\nthis paper, we conduct the first investigation into the impact of a key factor\nin color constancy-brightness-on DNNCC from a robustness perspective. Our\nevaluation reveals that several mainstream DNNCC models exhibit high\nsensitivity to brightness despite their focus on chromaticity estimation. This\nsheds light on a potential limitation of existing DNNCC models: their\nsensitivity to brightness may hinder performance given the widespread\nbrightness variations in real-world datasets. From the insights of our\nanalysis, we propose a simple yet effective brightness robustness enhancement\nstrategy for DNNCC models, termed BRE. The core of BRE is built upon the\nadaptive step-size adversarial brightness augmentation technique, which\nidentifies high-risk brightness variation and generates augmented images via\nexplicit brightness adjustment. Subsequently, BRE develops a\nbrightness-robustness-aware model optimization strategy that integrates\nadversarial brightness training and brightness contrastive loss, significantly\nbolstering the brightness robustness of DNNCC models. BRE is\nhyperparameter-free and can be integrated into existing DNNCC models, without\nincurring additional overhead during the testing phase. Experiments on two\npublic color constancy datasets-ColorChecker and Cube+-demonstrate that the\nproposed BRE consistently enhances the illuminant estimation performance of\nexisting DNNCC models, reducing the estimation error by an average of 5.04%\nacross six mainstream DNNCC models, underscoring the critical role of enhancing\nbrightness robustness in these models.'}","['Mengda Xie', 'Chengzhi Zhong', 'Yiling He', 'Zhan Qin', 'Meie Fang']",{'name': 'Meie Fang'},Meie Fang,,"[{'href': 'http://arxiv.org/abs/2502.12418v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12418v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12418v1,None,http://arxiv.org/abs/2502.12418v1,,,19,0
http://arxiv.org/abs/2502.12420v2,True,2025-02-19T12:34:46Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=12, tm_min=34, tm_sec=46, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-18T01:41:13Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=1, tm_min=41, tm_sec=13, tm_wday=1, tm_yday=49, tm_isdst=0)","Sens-Merging: Sensitivity-Guided Parameter Balancing for Merging Large
  Language Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Sens-Merging: Sensitivity-Guided Parameter Balancing for Merging Large\n  Language Models'}","Recent advances in large language models have led to numerous
task-specialized fine-tuned variants, creating a need for efficient model
merging techniques that preserve specialized capabilities while avoiding costly
retraining. While existing task vector-based merging methods show promise, they
typically apply uniform coefficients across all parameters, overlooking varying
parameter importance both within and across tasks. We present Sens-Merging, a
sensitivity-guided coefficient adjustment method that enhances existing model
merging techniques by operating at both task-specific and cross-task levels.
Our method analyzes parameter sensitivity within individual tasks and evaluates
cross-task transferability to determine optimal merging coefficients. Extensive
experiments on Mistral 7B and LLaMA2-7B/13B models demonstrate that
Sens-Merging significantly improves performance across general knowledge,
mathematical reasoning, and code generation tasks. Notably, when combined with
existing merging techniques, our method enables merged models to outperform
specialized fine-tuned models, particularly in code generation tasks. Our
findings reveal important trade-offs between task-specific and cross-task
scalings, providing insights for future model merging strategies.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Recent advances in large language models have led to numerous\ntask-specialized fine-tuned variants, creating a need for efficient model\nmerging techniques that preserve specialized capabilities while avoiding costly\nretraining. While existing task vector-based merging methods show promise, they\ntypically apply uniform coefficients across all parameters, overlooking varying\nparameter importance both within and across tasks. We present Sens-Merging, a\nsensitivity-guided coefficient adjustment method that enhances existing model\nmerging techniques by operating at both task-specific and cross-task levels.\nOur method analyzes parameter sensitivity within individual tasks and evaluates\ncross-task transferability to determine optimal merging coefficients. Extensive\nexperiments on Mistral 7B and LLaMA2-7B/13B models demonstrate that\nSens-Merging significantly improves performance across general knowledge,\nmathematical reasoning, and code generation tasks. Notably, when combined with\nexisting merging techniques, our method enables merged models to outperform\nspecialized fine-tuned models, particularly in code generation tasks. Our\nfindings reveal important trade-offs between task-specific and cross-task\nscalings, providing insights for future model merging strategies.'}","['Shuqi Liu', 'Han Wu', 'Bowei He', 'Xiongwei Han', 'Mingxuan Yuan', 'Linqi Song']",{'name': 'Linqi Song'},Linqi Song,,"[{'href': 'http://arxiv.org/abs/2502.12420v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12420v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12420v2,None,http://arxiv.org/abs/2502.12420v2,,,70,0
http://arxiv.org/abs/2502.12430v1,True,2025-02-18T02:03:03Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=2, tm_min=3, tm_sec=3, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T02:03:03Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=2, tm_min=3, tm_sec=3, tm_wday=1, tm_yday=49, tm_isdst=0)",Bridge the Gaps between Machine Unlearning and AI Regulation,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Bridge the Gaps between Machine Unlearning and AI Regulation'}","The ""right to be forgotten"" and the data privacy laws that encode it have
motivated machine unlearning since its earliest days. Now, an inbound wave of
artificial intelligence regulations - like the European Union's Artificial
Intelligence Act (AIA) - potentially offer important new use cases for machine
unlearning. However, this position paper argues, this opportunity will only be
realized if researchers, aided by policymakers, proactively bridge the
(sometimes sizable) gaps between machine unlearning's state of the art and its
potential applications to AI regulation. To demonstrate this point, we use the
AIA as an example. Specifically, we deliver a ""state of the union"" as regards
machine unlearning's current potential for aiding compliance with the AIA. This
starts with a precise cataloging of the potential applications of machine
unlearning to AIA compliance. For each, we flag any legal ambiguities clouding
the potential application and, moreover, flag the technical gaps that exist
between the potential application and the state of the art of machine
unlearning. Finally, we end with a call to action: for both machine learning
researchers and policymakers, to, respectively, solve the open technical and
legal questions that will unlock machine unlearning's potential to assist
compliance with the AIA - and other AI regulation like it.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The ""right to be forgotten"" and the data privacy laws that encode it have\nmotivated machine unlearning since its earliest days. Now, an inbound wave of\nartificial intelligence regulations - like the European Union\'s Artificial\nIntelligence Act (AIA) - potentially offer important new use cases for machine\nunlearning. However, this position paper argues, this opportunity will only be\nrealized if researchers, aided by policymakers, proactively bridge the\n(sometimes sizable) gaps between machine unlearning\'s state of the art and its\npotential applications to AI regulation. To demonstrate this point, we use the\nAIA as an example. Specifically, we deliver a ""state of the union"" as regards\nmachine unlearning\'s current potential for aiding compliance with the AIA. This\nstarts with a precise cataloging of the potential applications of machine\nunlearning to AIA compliance. For each, we flag any legal ambiguities clouding\nthe potential application and, moreover, flag the technical gaps that exist\nbetween the potential application and the state of the art of machine\nunlearning. Finally, we end with a call to action: for both machine learning\nresearchers and policymakers, to, respectively, solve the open technical and\nlegal questions that will unlock machine unlearning\'s potential to assist\ncompliance with the AIA - and other AI regulation like it.'}","['Bill Marino', 'Meghdad Kurmanji', 'Nicholas D. Lane']",{'name': 'Nicholas D. Lane'},Nicholas D. Lane,,"[{'href': 'http://arxiv.org/abs/2502.12430v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12430v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12430v1,None,http://arxiv.org/abs/2502.12430v1,,,225,0
http://arxiv.org/abs/2502.12435v1,True,2025-02-18T02:11:03Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=2, tm_min=11, tm_sec=3, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T02:11:03Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=2, tm_min=11, tm_sec=3, tm_wday=1, tm_yday=49, tm_isdst=0)",A Survey on Large Language Models for Automated Planning,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A Survey on Large Language Models for Automated Planning'}","The planning ability of Large Language Models (LLMs) has garnered increasing
attention in recent years due to their remarkable capacity for multi-step
reasoning and their ability to generalize across a wide range of domains. While
some researchers emphasize the potential of LLMs to perform complex planning
tasks, others highlight significant limitations in their performance,
particularly when these models are tasked with handling the intricacies of
long-horizon reasoning. In this survey, we critically investigate existing
research on the use of LLMs in automated planning, examining both their
successes and shortcomings in detail. We illustrate that although LLMs are not
well-suited to serve as standalone planners because of these limitations, they
nonetheless present an enormous opportunity to enhance planning applications
when combined with other approaches. Thus, we advocate for a balanced
methodology that leverages the inherent flexibility and generalized knowledge
of LLMs alongside the rigor and cost-effectiveness of traditional planning
methods.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The planning ability of Large Language Models (LLMs) has garnered increasing\nattention in recent years due to their remarkable capacity for multi-step\nreasoning and their ability to generalize across a wide range of domains. While\nsome researchers emphasize the potential of LLMs to perform complex planning\ntasks, others highlight significant limitations in their performance,\nparticularly when these models are tasked with handling the intricacies of\nlong-horizon reasoning. In this survey, we critically investigate existing\nresearch on the use of LLMs in automated planning, examining both their\nsuccesses and shortcomings in detail. We illustrate that although LLMs are not\nwell-suited to serve as standalone planners because of these limitations, they\nnonetheless present an enormous opportunity to enhance planning applications\nwhen combined with other approaches. Thus, we advocate for a balanced\nmethodology that leverages the inherent flexibility and generalized knowledge\nof LLMs alongside the rigor and cost-effectiveness of traditional planning\nmethods.'}","['Mohamed Aghzal', 'Erion Plaku', 'Gregory J. Stein', 'Ziyu Yao']",{'name': 'Ziyu Yao'},Ziyu Yao,,"[{'href': 'http://arxiv.org/abs/2502.12435v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12435v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12435v1,None,http://arxiv.org/abs/2502.12435v1,,,2487,0
http://arxiv.org/abs/2502.12456v1,True,2025-02-18T02:37:34Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=2, tm_min=37, tm_sec=34, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T02:37:34Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=2, tm_min=37, tm_sec=34, tm_wday=1, tm_yday=49, tm_isdst=0)",Not-So-Optimal Transport Flows for 3D Point Cloud Generation,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Not-So-Optimal Transport Flows for 3D Point Cloud Generation'}","Learning generative models of 3D point clouds is one of the fundamental
problems in 3D generative learning. One of the key properties of point clouds
is their permutation invariance, i.e., changing the order of points in a point
cloud does not change the shape they represent. In this paper, we analyze the
recently proposed equivariant OT flows that learn permutation invariant
generative models for point-based molecular data and we show that these models
scale poorly on large point clouds. Also, we observe learning (equivariant) OT
flows is generally challenging since straightening flow trajectories makes the
learned flow model complex at the beginning of the trajectory. To remedy these,
we propose not-so-optimal transport flow models that obtain an approximate OT
by an offline OT precomputation, enabling an efficient construction of OT pairs
for training. During training, we can additionally construct a hybrid coupling
by combining our approximate OT and independent coupling to make the target
flow models easier to learn. In an extensive empirical study, we show that our
proposed model outperforms prior diffusion- and flow-based approaches on a wide
range of unconditional generation and shape completion on the ShapeNet
benchmark.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Learning generative models of 3D point clouds is one of the fundamental\nproblems in 3D generative learning. One of the key properties of point clouds\nis their permutation invariance, i.e., changing the order of points in a point\ncloud does not change the shape they represent. In this paper, we analyze the\nrecently proposed equivariant OT flows that learn permutation invariant\ngenerative models for point-based molecular data and we show that these models\nscale poorly on large point clouds. Also, we observe learning (equivariant) OT\nflows is generally challenging since straightening flow trajectories makes the\nlearned flow model complex at the beginning of the trajectory. To remedy these,\nwe propose not-so-optimal transport flow models that obtain an approximate OT\nby an offline OT precomputation, enabling an efficient construction of OT pairs\nfor training. During training, we can additionally construct a hybrid coupling\nby combining our approximate OT and independent coupling to make the target\nflow models easier to learn. In an extensive empirical study, we show that our\nproposed model outperforms prior diffusion- and flow-based approaches on a wide\nrange of unconditional generation and shape completion on the ShapeNet\nbenchmark.'}","['Ka-Hei Hui', 'Chao Liu', 'Xiaohui Zeng', 'Chi-Wing Fu', 'Arash Vahdat']",{'name': 'Arash Vahdat'},Arash Vahdat,,"[{'href': 'http://arxiv.org/abs/2502.12456v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12456v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12456v1,None,http://arxiv.org/abs/2502.12456v1,,,3400,0
http://arxiv.org/abs/2502.12468v1,True,2025-02-18T02:55:48Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=2, tm_min=55, tm_sec=48, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T02:55:48Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=2, tm_min=55, tm_sec=48, tm_wday=1, tm_yday=49, tm_isdst=0)","MCTS-Judge: Test-Time Scaling in LLM-as-a-Judge for Code Correctness
  Evaluation","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'MCTS-Judge: Test-Time Scaling in LLM-as-a-Judge for Code Correctness\n  Evaluation'}","The LLM-as-a-Judge paradigm shows promise for evaluating generative content
but lacks reliability in reasoning-intensive scenarios, such as programming.
Inspired by recent advances in reasoning models and shifts in scaling laws, we
pioneer bringing test-time computation into LLM-as-a-Judge, proposing
MCTS-Judge, a resource-efficient, System-2 thinking framework for code
correctness evaluation. MCTS-Judge leverages Monte Carlo Tree Search (MCTS) to
decompose problems into simpler, multi-perspective evaluations. Through a
node-selection strategy that combines self-assessment based on historical
actions in the current trajectory and the Upper Confidence Bound for Trees
based on prior rollouts, MCTS-Judge balances global optimization and refinement
of the current trajectory. We further designed a high-precision,
unit-test-level reward mechanism to encourage the Large Language Model (LLM) to
perform line-by-line analysis. Extensive experiments on three benchmarks and
five LLMs demonstrate the effectiveness of MCTS-Judge, which improves the base
model's accuracy from 41% to 80%, surpassing the o1-series models with 3x fewer
tokens. Further evaluations validate the superiority of its reasoning
trajectory in logic, analytics, thoroughness, and overall quality, while
revealing the test-time scaling law of the LLM-as-a-Judge paradigm.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""The LLM-as-a-Judge paradigm shows promise for evaluating generative content\nbut lacks reliability in reasoning-intensive scenarios, such as programming.\nInspired by recent advances in reasoning models and shifts in scaling laws, we\npioneer bringing test-time computation into LLM-as-a-Judge, proposing\nMCTS-Judge, a resource-efficient, System-2 thinking framework for code\ncorrectness evaluation. MCTS-Judge leverages Monte Carlo Tree Search (MCTS) to\ndecompose problems into simpler, multi-perspective evaluations. Through a\nnode-selection strategy that combines self-assessment based on historical\nactions in the current trajectory and the Upper Confidence Bound for Trees\nbased on prior rollouts, MCTS-Judge balances global optimization and refinement\nof the current trajectory. We further designed a high-precision,\nunit-test-level reward mechanism to encourage the Large Language Model (LLM) to\nperform line-by-line analysis. Extensive experiments on three benchmarks and\nfive LLMs demonstrate the effectiveness of MCTS-Judge, which improves the base\nmodel's accuracy from 41% to 80%, surpassing the o1-series models with 3x fewer\ntokens. Further evaluations validate the superiority of its reasoning\ntrajectory in logic, analytics, thoroughness, and overall quality, while\nrevealing the test-time scaling law of the LLM-as-a-Judge paradigm.""}","['Yutong Wang', 'Pengliang Ji', 'Chaoqun Yang', 'Kaixin Li', 'Ming Hu', 'Jiaoyang Li', 'Guillaume Sartoretti']",{'name': 'Guillaume Sartoretti'},Guillaume Sartoretti,,"[{'href': 'http://arxiv.org/abs/2502.12468v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12468v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12468v1,None,http://arxiv.org/abs/2502.12468v1,,,13,0
http://arxiv.org/abs/2502.12484v1,True,2025-02-18T03:10:27Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=3, tm_min=10, tm_sec=27, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T03:10:27Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=3, tm_min=10, tm_sec=27, tm_wday=1, tm_yday=49, tm_isdst=0)","LocalEscaper: A Weakly-supervised Framework with Regional Reconstruction
  for Scalable Neural TSP Solvers","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'LocalEscaper: A Weakly-supervised Framework with Regional Reconstruction\n  for Scalable Neural TSP Solvers'}","Neural solvers have shown significant potential in solving the Traveling
Salesman Problem (TSP), yet current approaches face significant challenges.
Supervised learning (SL)-based solvers require large amounts of high-quality
labeled data, while reinforcement learning (RL)-based solvers, though less
dependent on such data, often suffer from inefficiencies. To address these
limitations, we propose LocalEscaper, a novel weakly-supervised learning
framework for large-scale TSP. LocalEscaper effectively combines the advantages
of both SL and RL, enabling effective training on datasets with low-quality
labels. To further enhance solution quality, we introduce a regional
reconstruction strategy, which mitigates the problem of local optima, a common
issue in existing local reconstruction methods. Additionally, we propose a
linear-complexity attention mechanism that reduces computational overhead,
enabling the efficient solution of large-scale TSPs without sacrificing
performance. Experimental results on both synthetic and real-world datasets
demonstrate that LocalEscaper outperforms existing neural solvers, achieving
state-of-the-art results. Notably, it sets a new benchmark for scalability and
efficiency, solving TSP instances with up to 50,000 cities.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Neural solvers have shown significant potential in solving the Traveling\nSalesman Problem (TSP), yet current approaches face significant challenges.\nSupervised learning (SL)-based solvers require large amounts of high-quality\nlabeled data, while reinforcement learning (RL)-based solvers, though less\ndependent on such data, often suffer from inefficiencies. To address these\nlimitations, we propose LocalEscaper, a novel weakly-supervised learning\nframework for large-scale TSP. LocalEscaper effectively combines the advantages\nof both SL and RL, enabling effective training on datasets with low-quality\nlabels. To further enhance solution quality, we introduce a regional\nreconstruction strategy, which mitigates the problem of local optima, a common\nissue in existing local reconstruction methods. Additionally, we propose a\nlinear-complexity attention mechanism that reduces computational overhead,\nenabling the efficient solution of large-scale TSPs without sacrificing\nperformance. Experimental results on both synthetic and real-world datasets\ndemonstrate that LocalEscaper outperforms existing neural solvers, achieving\nstate-of-the-art results. Notably, it sets a new benchmark for scalability and\nefficiency, solving TSP instances with up to 50,000 cities.'}","['Junrui Wen', 'Yifei Li', 'Bart Selman', 'Kun He']",{'name': 'Kun He'},Kun He,,"[{'href': 'http://arxiv.org/abs/2502.12484v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12484v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12484v1,None,http://arxiv.org/abs/2502.12484v1,,,0,0
http://arxiv.org/abs/2502.12485v1,True,2025-02-18T03:11:06Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=3, tm_min=11, tm_sec=6, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T03:11:06Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=3, tm_min=11, tm_sec=6, tm_wday=1, tm_yday=49, tm_isdst=0)","Safe at the Margins: A General Approach to Safety Alignment in
  Low-Resource English Languages -- A Singlish Case Study","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Safe at the Margins: A General Approach to Safety Alignment in\n  Low-Resource English Languages -- A Singlish Case Study'}","To ensure safe usage, Large Language Models (LLMs) typically undergo
alignment with human-defined values. However, this alignment often relies on
primarily English data and is biased towards Western-centric values, limiting
its effectiveness in low-resource language settings. In this paper, we describe
our approach for aligning SEA-Lion-v2.1-Instruct (a Llama3-8B variant) to
minimize toxicity in Singlish, an English creole specific to Singapore. We find
that supervised fine-tuning and Kahneman-Tversky Optimization (KTO) on paired
and unpaired preferences is more sample efficient and yields significantly
better results than Direct Preference Optimization (DPO). Our analysis reveals
that DPO implicitly enforces a weaker safety objective than KTO, and that SFT
complements KTO by improving training stability. Finally, we introduce a simple
but novel modification to KTO, KTO-S, which improves training stability through
better gradient exploitation. Overall, we present a general approach for safety
alignment conducive to low-resource English languages, successfully reducing
toxicity by 99\% on our Singlish benchmark, with gains generalizing to the
broader TOXIGEN dataset while maintaining strong performance across standard
LLM benchmarks.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'To ensure safe usage, Large Language Models (LLMs) typically undergo\nalignment with human-defined values. However, this alignment often relies on\nprimarily English data and is biased towards Western-centric values, limiting\nits effectiveness in low-resource language settings. In this paper, we describe\nour approach for aligning SEA-Lion-v2.1-Instruct (a Llama3-8B variant) to\nminimize toxicity in Singlish, an English creole specific to Singapore. We find\nthat supervised fine-tuning and Kahneman-Tversky Optimization (KTO) on paired\nand unpaired preferences is more sample efficient and yields significantly\nbetter results than Direct Preference Optimization (DPO). Our analysis reveals\nthat DPO implicitly enforces a weaker safety objective than KTO, and that SFT\ncomplements KTO by improving training stability. Finally, we introduce a simple\nbut novel modification to KTO, KTO-S, which improves training stability through\nbetter gradient exploitation. Overall, we present a general approach for safety\nalignment conducive to low-resource English languages, successfully reducing\ntoxicity by 99\\% on our Singlish benchmark, with gains generalizing to the\nbroader TOXIGEN dataset while maintaining strong performance across standard\nLLM benchmarks.'}","['Isaac Lim', 'Shaun Khoo', 'Watson Chua', 'Goh Jiayi', 'Jessica Foo']",{'name': 'Jessica Foo'},Jessica Foo,,"[{'href': 'http://arxiv.org/abs/2502.12485v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12485v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12485v1,None,http://arxiv.org/abs/2502.12485v1,,,77,0
http://arxiv.org/abs/2502.12494v1,True,2025-02-18T03:21:18Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=3, tm_min=21, tm_sec=18, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T03:21:18Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=3, tm_min=21, tm_sec=18, tm_wday=1, tm_yday=49, tm_isdst=0)","EDGE: Efficient Data Selection for LLM Agents via Guideline
  Effectiveness","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'EDGE: Efficient Data Selection for LLM Agents via Guideline\n  Effectiveness'}","Large Language Models (LLMs) have shown remarkable capabilities as AI agents.
However, existing methods for enhancing LLM-agent abilities often lack a focus
on data quality, leading to inefficiencies and suboptimal results in both
fine-tuning and prompt engineering. To address this issue, we introduce EDGE, a
novel approach for identifying informative samples without needing golden
answers. We propose the Guideline Effectiveness (GE) metric, which selects
challenging samples by measuring the impact of human-provided guidelines in
multi-turn interaction tasks. A low GE score indicates that the human expertise
required for a sample is missing from the guideline, making the sample more
informative. By selecting samples with low GE scores, we can improve the
efficiency and outcomes of both prompt engineering and fine-tuning processes
for LLMs. Extensive experiments validate the performance of our method. Our
method achieves competitive results on the HotpotQA and WebShop and datasets,
requiring 75\% and 50\% less data, respectively, while outperforming existing
methods. We also provide a fresh perspective on the data quality of LLM-agent
fine-tuning.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Language Models (LLMs) have shown remarkable capabilities as AI agents.\nHowever, existing methods for enhancing LLM-agent abilities often lack a focus\non data quality, leading to inefficiencies and suboptimal results in both\nfine-tuning and prompt engineering. To address this issue, we introduce EDGE, a\nnovel approach for identifying informative samples without needing golden\nanswers. We propose the Guideline Effectiveness (GE) metric, which selects\nchallenging samples by measuring the impact of human-provided guidelines in\nmulti-turn interaction tasks. A low GE score indicates that the human expertise\nrequired for a sample is missing from the guideline, making the sample more\ninformative. By selecting samples with low GE scores, we can improve the\nefficiency and outcomes of both prompt engineering and fine-tuning processes\nfor LLMs. Extensive experiments validate the performance of our method. Our\nmethod achieves competitive results on the HotpotQA and WebShop and datasets,\nrequiring 75\\% and 50\\% less data, respectively, while outperforming existing\nmethods. We also provide a fresh perspective on the data quality of LLM-agent\nfine-tuning.'}","['Yunxiao Zhang', 'Guanming Xiong', 'Haochen Li', 'Wen Zhao']",{'name': 'Wen Zhao'},Wen Zhao,,"[{'href': 'http://arxiv.org/abs/2502.12494v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12494v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12494v1,None,http://arxiv.org/abs/2502.12494v1,,,12,0
http://arxiv.org/abs/2502.12507v1,True,2025-02-18T03:43:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=3, tm_min=43, tm_sec=42, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T03:43:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=3, tm_min=43, tm_sec=42, tm_wday=1, tm_yday=49, tm_isdst=0)",Mixture of Attention Yields Accurate Results for Tabular Data,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Mixture of Attention Yields Accurate Results for Tabular Data'}","Tabular data inherently exhibits significant feature heterogeneity, but
existing transformer-based methods lack specialized mechanisms to handle this
property. To bridge the gap, we propose MAYA, an encoder-decoder
transformer-based framework. In the encoder, we design a Mixture of Attention
(MOA) that constructs multiple parallel attention branches and averages the
features at each branch, effectively fusing heterogeneous features while
limiting parameter growth. Additionally, we employ collaborative learning with
a dynamic consistency weight constraint to produce more robust representations.
In the decoder stage, cross-attention is utilized to seamlessly integrate
tabular data with corresponding label features. This dual-attention mechanism
effectively captures both intra-instance and inter-instance interactions. We
evaluate the proposed method on a wide range of datasets and compare it with
other state-of-the-art transformer-based methods. Extensive experiments
demonstrate that our model achieves superior performance among
transformer-based methods in both tabular classification and regression tasks.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Tabular data inherently exhibits significant feature heterogeneity, but\nexisting transformer-based methods lack specialized mechanisms to handle this\nproperty. To bridge the gap, we propose MAYA, an encoder-decoder\ntransformer-based framework. In the encoder, we design a Mixture of Attention\n(MOA) that constructs multiple parallel attention branches and averages the\nfeatures at each branch, effectively fusing heterogeneous features while\nlimiting parameter growth. Additionally, we employ collaborative learning with\na dynamic consistency weight constraint to produce more robust representations.\nIn the decoder stage, cross-attention is utilized to seamlessly integrate\ntabular data with corresponding label features. This dual-attention mechanism\neffectively captures both intra-instance and inter-instance interactions. We\nevaluate the proposed method on a wide range of datasets and compare it with\nother state-of-the-art transformer-based methods. Extensive experiments\ndemonstrate that our model achieves superior performance among\ntransformer-based methods in both tabular classification and regression tasks.'}","['Xuechen Li', 'Yupeng Li', 'Jian Liu', 'Xiaolin Jin', 'Tian Yang', 'Xin Hu']",{'name': 'Xin Hu'},Xin Hu,"15 pages, 4 figures","[{'href': 'http://arxiv.org/abs/2502.12507v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12507v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12507v1,None,http://arxiv.org/abs/2502.12507v1,,,0,0
http://arxiv.org/abs/2502.12509v1,True,2025-02-18T03:47:53Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=3, tm_min=47, tm_sec=53, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T03:47:53Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=3, tm_min=47, tm_sec=53, tm_wday=1, tm_yday=49, tm_isdst=0)",LegalCore: A Dataset for Legal Documents Event Coreference Resolution,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'LegalCore: A Dataset for Legal Documents Event Coreference Resolution'}","Recognizing events and their coreferential mentions in a document is
essential for understanding semantic meanings of text. The existing research on
event coreference resolution is mostly limited to news articles. In this paper,
we present the first dataset for the legal domain, LegalCore, which has been
annotated with comprehensive event and event coreference information. The legal
contract documents we annotated in this dataset are several times longer than
news articles, with an average length of around 25k tokens per document. The
annotations show that legal documents have dense event mentions and feature
both short-distance and super long-distance coreference links between event
mentions. We further benchmark mainstream Large Language Models (LLMs) on this
dataset for both event detection and event coreference resolution tasks, and
find that this dataset poses significant challenges for state-of-the-art
open-source and proprietary LLMs, which perform significantly worse than a
supervised baseline. We will publish the dataset as well as the code.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Recognizing events and their coreferential mentions in a document is\nessential for understanding semantic meanings of text. The existing research on\nevent coreference resolution is mostly limited to news articles. In this paper,\nwe present the first dataset for the legal domain, LegalCore, which has been\nannotated with comprehensive event and event coreference information. The legal\ncontract documents we annotated in this dataset are several times longer than\nnews articles, with an average length of around 25k tokens per document. The\nannotations show that legal documents have dense event mentions and feature\nboth short-distance and super long-distance coreference links between event\nmentions. We further benchmark mainstream Large Language Models (LLMs) on this\ndataset for both event detection and event coreference resolution tasks, and\nfind that this dataset poses significant challenges for state-of-the-art\nopen-source and proprietary LLMs, which perform significantly worse than a\nsupervised baseline. We will publish the dataset as well as the code.'}","['Kangda Wei', 'Xi Shi', 'Jonathan Tong', 'Sai Ramana Reddy', 'Anandhavelu Natarajan', 'Rajiv Jain', 'Aparna Garimella', 'Ruihong Huang']",{'name': 'Ruihong Huang'},Ruihong Huang,,"[{'href': 'http://arxiv.org/abs/2502.12509v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12509v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12509v1,None,http://arxiv.org/abs/2502.12509v1,,,2966,0
http://arxiv.org/abs/2502.12521v1,True,2025-02-18T04:11:29Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=4, tm_min=11, tm_sec=29, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T04:11:29Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=4, tm_min=11, tm_sec=29, tm_wday=1, tm_yday=49, tm_isdst=0)","Inference-Time Computations for LLM Reasoning and Planning: A Benchmark
  and Insights","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Inference-Time Computations for LLM Reasoning and Planning: A Benchmark\n  and Insights'}","We examine the reasoning and planning capabilities of large language models
(LLMs) in solving complex tasks. Recent advances in inference-time techniques
demonstrate the potential to enhance LLM reasoning without additional training
by exploring intermediate steps during inference. Notably, OpenAI's o1 model
shows promising performance through its novel use of multi-step reasoning and
verification. Here, we explore how scaling inference-time techniques can
improve reasoning and planning, focusing on understanding the tradeoff between
computational cost and performance. To this end, we construct a comprehensive
benchmark, known as Sys2Bench, and perform extensive experiments evaluating
existing inference-time techniques on eleven diverse tasks across five
categories, including arithmetic reasoning, logical reasoning, common sense
reasoning, algorithmic reasoning, and planning. Our findings indicate that
simply scaling inference-time computation has limitations, as no single
inference-time technique consistently performs well across all reasoning and
planning tasks.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""We examine the reasoning and planning capabilities of large language models\n(LLMs) in solving complex tasks. Recent advances in inference-time techniques\ndemonstrate the potential to enhance LLM reasoning without additional training\nby exploring intermediate steps during inference. Notably, OpenAI's o1 model\nshows promising performance through its novel use of multi-step reasoning and\nverification. Here, we explore how scaling inference-time techniques can\nimprove reasoning and planning, focusing on understanding the tradeoff between\ncomputational cost and performance. To this end, we construct a comprehensive\nbenchmark, known as Sys2Bench, and perform extensive experiments evaluating\nexisting inference-time techniques on eleven diverse tasks across five\ncategories, including arithmetic reasoning, logical reasoning, common sense\nreasoning, algorithmic reasoning, and planning. Our findings indicate that\nsimply scaling inference-time computation has limitations, as no single\ninference-time technique consistently performs well across all reasoning and\nplanning tasks.""}","['Shubham Parashar', 'Blake Olson', 'Sambhav Khurana', 'Eric Li', 'Hongyi Ling', 'James Caverlee', 'Shuiwang Ji']",{'name': 'Shuiwang Ji'},Shuiwang Ji,,"[{'href': 'http://arxiv.org/abs/2502.12521v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12521v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12521v1,None,http://arxiv.org/abs/2502.12521v1,,,188,0
http://arxiv.org/abs/2502.12524v1,True,2025-02-18T04:20:14Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=4, tm_min=20, tm_sec=14, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T04:20:14Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=4, tm_min=20, tm_sec=14, tm_wday=1, tm_yday=49, tm_isdst=0)",YOLOv12: Attention-Centric Real-Time Object Detectors,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'YOLOv12: Attention-Centric Real-Time Object Detectors'}","Enhancing the network architecture of the YOLO framework has been crucial for
a long time, but has focused on CNN-based improvements despite the proven
superiority of attention mechanisms in modeling capabilities. This is because
attention-based models cannot match the speed of CNN-based models. This paper
proposes an attention-centric YOLO framework, namely YOLOv12, that matches the
speed of previous CNN-based ones while harnessing the performance benefits of
attention mechanisms. YOLOv12 surpasses all popular real-time object detectors
in accuracy with competitive speed. For example, YOLOv12-N achieves 40.6% mAP
with an inference latency of 1.64 ms on a T4 GPU, outperforming advanced
YOLOv10-N / YOLOv11-N by 2.1%/1.2% mAP with a comparable speed. This advantage
extends to other model scales. YOLOv12 also surpasses end-to-end real-time
detectors that improve DETR, such as RT-DETR / RT-DETRv2: YOLOv12-S beats
RT-DETR-R18 / RT-DETRv2-R18 while running 42% faster, using only 36% of the
computation and 45% of the parameters. More comparisons are shown in Figure 1.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Enhancing the network architecture of the YOLO framework has been crucial for\na long time, but has focused on CNN-based improvements despite the proven\nsuperiority of attention mechanisms in modeling capabilities. This is because\nattention-based models cannot match the speed of CNN-based models. This paper\nproposes an attention-centric YOLO framework, namely YOLOv12, that matches the\nspeed of previous CNN-based ones while harnessing the performance benefits of\nattention mechanisms. YOLOv12 surpasses all popular real-time object detectors\nin accuracy with competitive speed. For example, YOLOv12-N achieves 40.6% mAP\nwith an inference latency of 1.64 ms on a T4 GPU, outperforming advanced\nYOLOv10-N / YOLOv11-N by 2.1%/1.2% mAP with a comparable speed. This advantage\nextends to other model scales. YOLOv12 also surpasses end-to-end real-time\ndetectors that improve DETR, such as RT-DETR / RT-DETRv2: YOLOv12-S beats\nRT-DETR-R18 / RT-DETRv2-R18 while running 42% faster, using only 36% of the\ncomputation and 45% of the parameters. More comparisons are shown in Figure 1.'}","['Yunjie Tian', 'Qixiang Ye', 'David Doermann']",{'name': 'David Doermann'},David Doermann,https://github.com/sunsmarterjie/yolov12,"[{'href': 'http://arxiv.org/abs/2502.12524v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12524v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12524v1,None,http://arxiv.org/abs/2502.12524v1,,,445,0
http://arxiv.org/abs/2502.12525v1,True,2025-02-18T04:20:18Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=4, tm_min=20, tm_sec=18, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T04:20:18Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=4, tm_min=20, tm_sec=18, tm_wday=1, tm_yday=49, tm_isdst=0)",From Abstract to Actionable: Pairwise Shapley Values for Explainable AI,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'From Abstract to Actionable: Pairwise Shapley Values for Explainable AI'}","Explainable AI (XAI) is critical for ensuring transparency, accountability,
and trust in machine learning systems as black-box models are increasingly
deployed within high-stakes domains. Among XAI methods, Shapley values are
widely used for their fairness and consistency axioms. However, prevalent
Shapley value approximation methods commonly rely on abstract baselines or
computationally intensive calculations, which can limit their interpretability
and scalability. To address such challenges, we propose Pairwise Shapley
Values, a novel framework that grounds feature attributions in explicit,
human-relatable comparisons between pairs of data instances proximal in feature
space. Our method introduces pairwise reference selection combined with
single-value imputation to deliver intuitive, model-agnostic explanations while
significantly reducing computational overhead. Here, we demonstrate that
Pairwise Shapley Values enhance interpretability across diverse regression and
classification scenarios--including real estate pricing, polymer property
prediction, and drug discovery datasets. We conclude that the proposed methods
enable more transparent AI systems and advance the real-world applicability of
XAI.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Explainable AI (XAI) is critical for ensuring transparency, accountability,\nand trust in machine learning systems as black-box models are increasingly\ndeployed within high-stakes domains. Among XAI methods, Shapley values are\nwidely used for their fairness and consistency axioms. However, prevalent\nShapley value approximation methods commonly rely on abstract baselines or\ncomputationally intensive calculations, which can limit their interpretability\nand scalability. To address such challenges, we propose Pairwise Shapley\nValues, a novel framework that grounds feature attributions in explicit,\nhuman-relatable comparisons between pairs of data instances proximal in feature\nspace. Our method introduces pairwise reference selection combined with\nsingle-value imputation to deliver intuitive, model-agnostic explanations while\nsignificantly reducing computational overhead. Here, we demonstrate that\nPairwise Shapley Values enhance interpretability across diverse regression and\nclassification scenarios--including real estate pricing, polymer property\nprediction, and drug discovery datasets. We conclude that the proposed methods\nenable more transparent AI systems and advance the real-world applicability of\nXAI.'}","['Jiaxin Xu', 'Hung Chau', 'Angela Burden']",{'name': 'Angela Burden'},Angela Burden,,"[{'href': 'http://arxiv.org/abs/2502.12525v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12525v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12525v1,None,http://arxiv.org/abs/2502.12525v1,,,0,0
http://arxiv.org/abs/2502.12531v1,True,2025-02-18T04:35:17Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=4, tm_min=35, tm_sec=17, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T04:35:17Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=4, tm_min=35, tm_sec=17, tm_wday=1, tm_yday=49, tm_isdst=0)","GSCE: A Prompt Framework with Enhanced Reasoning for Reliable LLM-driven
  Drone Control","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'GSCE: A Prompt Framework with Enhanced Reasoning for Reliable LLM-driven\n  Drone Control'}","The integration of Large Language Models (LLMs) into robotic control,
including drones, has the potential to revolutionize autonomous systems.
Research studies have demonstrated that LLMs can be leveraged to support
robotic operations. However, when facing tasks with complex reasoning, concerns
and challenges are raised about the reliability of solutions produced by LLMs.
In this paper, we propose a prompt framework with enhanced reasoning to enable
reliable LLM-driven control for drones. Our framework consists of novel
technical components designed using Guidelines, Skill APIs, Constraints, and
Examples, namely GSCE. GSCE is featured by its reliable and
constraint-compliant code generation. We performed thorough experiments using
GSCE for the control of drones with a wide level of task complexities. Our
experiment results demonstrate that GSCE can significantly improve task success
rates and completeness compared to baseline approaches, highlighting its
potential for reliable LLM-driven autonomous drone systems.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The integration of Large Language Models (LLMs) into robotic control,\nincluding drones, has the potential to revolutionize autonomous systems.\nResearch studies have demonstrated that LLMs can be leveraged to support\nrobotic operations. However, when facing tasks with complex reasoning, concerns\nand challenges are raised about the reliability of solutions produced by LLMs.\nIn this paper, we propose a prompt framework with enhanced reasoning to enable\nreliable LLM-driven control for drones. Our framework consists of novel\ntechnical components designed using Guidelines, Skill APIs, Constraints, and\nExamples, namely GSCE. GSCE is featured by its reliable and\nconstraint-compliant code generation. We performed thorough experiments using\nGSCE for the control of drones with a wide level of task complexities. Our\nexperiment results demonstrate that GSCE can significantly improve task success\nrates and completeness compared to baseline approaches, highlighting its\npotential for reliable LLM-driven autonomous drone systems.'}","['Wenhao Wang', 'Yanyan Li', 'Long Jiao', 'Jiawei Yuan']",{'name': 'Jiawei Yuan'},Jiawei Yuan,8 pages,"[{'href': 'http://arxiv.org/abs/2502.12531v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12531v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12531v1,None,http://arxiv.org/abs/2502.12531v1,,,3,0
http://arxiv.org/abs/2502.12536v1,True,2025-02-18T04:39:35Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=4, tm_min=39, tm_sec=35, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T04:39:35Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=4, tm_min=39, tm_sec=35, tm_wday=1, tm_yday=49, tm_isdst=0)",An Algorithm Board in Neural Decoding,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'An Algorithm Board in Neural Decoding'}","Understanding the mechanisms of neural encoding and decoding has always been
a highly interesting research topic in fields such as neuroscience and
cognitive intelligence. In prior studies, some researchers identified a
symmetry in neural data decoded by unsupervised methods in motor scenarios and
constructed a cognitive learning system based on this pattern (i.e., symmetry).
Nevertheless, the distribution state of the data flow that significantly
influences neural decoding positions still remains a mystery within the system,
which further restricts the enhancement of the system's interpretability. Based
on this, this paper mainly explores changes in the distribution state within
the system from the machine learning and mathematical statistics perspectives.
In the experiment, we assessed the correctness of this symmetry using various
tools and indicators commonly utilized in mathematics and statistics. According
to the experimental results, the normal distribution (or Gaussian distribution)
plays a crucial role in the decoding of prediction positions within the system.
Eventually, an algorithm board similar to the Galton board was built to serve
as the mathematical foundation of the discovered symmetry.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Understanding the mechanisms of neural encoding and decoding has always been\na highly interesting research topic in fields such as neuroscience and\ncognitive intelligence. In prior studies, some researchers identified a\nsymmetry in neural data decoded by unsupervised methods in motor scenarios and\nconstructed a cognitive learning system based on this pattern (i.e., symmetry).\nNevertheless, the distribution state of the data flow that significantly\ninfluences neural decoding positions still remains a mystery within the system,\nwhich further restricts the enhancement of the system's interpretability. Based\non this, this paper mainly explores changes in the distribution state within\nthe system from the machine learning and mathematical statistics perspectives.\nIn the experiment, we assessed the correctness of this symmetry using various\ntools and indicators commonly utilized in mathematics and statistics. According\nto the experimental results, the normal distribution (or Gaussian distribution)\nplays a crucial role in the decoding of prediction positions within the system.\nEventually, an algorithm board similar to the Galton board was built to serve\nas the mathematical foundation of the discovered symmetry.""}","['Jingyi Feng', 'Kai Yang']",{'name': 'Kai Yang'},Kai Yang,"16 pages, 10 figures, 2 tables","[{'href': 'http://arxiv.org/abs/2502.12536v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12536v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12536v1,None,http://arxiv.org/abs/2502.12536v1,,,0,0
http://arxiv.org/abs/2502.12537v2,True,2025-02-19T10:24:59Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=10, tm_min=24, tm_sec=59, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-18T04:50:00Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=4, tm_min=50, tm_sec=0, tm_wday=1, tm_yday=49, tm_isdst=0)","Finding Optimal Trading History in Reinforcement Learning for Stock
  Market Trading","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Finding Optimal Trading History in Reinforcement Learning for Stock\n  Market Trading'}","This paper investigates the optimization of temporal windows in Financial
Deep Reinforcement Learning (DRL) models using 2D Convolutional Neural Networks
(CNNs). We introduce a novel approach to treating the temporal field as a
hyperparameter and examine its impact on model performance across various
datasets and feature arrangements. We introduce a new hyperparameter for the
CNN policy, proposing that this temporal field can and should be treated as a
hyperparameter for these models. We examine the significance of this temporal
field by iteratively expanding the window of observations presented to the CNN
policy during the deep reinforcement learning process. Our iterative process
involves progressively increasing the observation period from two weeks to
twelve weeks, allowing us to examine the effects of different temporal windows
on the model's performance. This window expansion is implemented in two
settings. In one setting, we rearrange the features in the dataset to group
them by company, allowing the model to have a full view of company data in its
observation window and CNN kernel. In the second setting, we do not group the
features by company, and features are arranged by category. Our study reveals
that shorter temporal windows are most effective when no feature rearrangement
to group per company is in effect. However, the model will utilize longer
temporal windows and yield better performance once we introduce the feature
rearrangement. To examine the consistency of our findings, we repeated our
experiment on two datasets containing the same thirty companies from the Dow
Jones Index but with different features in each dataset and consistently
observed the above-mentioned patterns. The result is a trading model
significantly outperforming global financial services firms such as the Global
X Guru by the established Mirae Asset.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""This paper investigates the optimization of temporal windows in Financial\nDeep Reinforcement Learning (DRL) models using 2D Convolutional Neural Networks\n(CNNs). We introduce a novel approach to treating the temporal field as a\nhyperparameter and examine its impact on model performance across various\ndatasets and feature arrangements. We introduce a new hyperparameter for the\nCNN policy, proposing that this temporal field can and should be treated as a\nhyperparameter for these models. We examine the significance of this temporal\nfield by iteratively expanding the window of observations presented to the CNN\npolicy during the deep reinforcement learning process. Our iterative process\ninvolves progressively increasing the observation period from two weeks to\ntwelve weeks, allowing us to examine the effects of different temporal windows\non the model's performance. This window expansion is implemented in two\nsettings. In one setting, we rearrange the features in the dataset to group\nthem by company, allowing the model to have a full view of company data in its\nobservation window and CNN kernel. In the second setting, we do not group the\nfeatures by company, and features are arranged by category. Our study reveals\nthat shorter temporal windows are most effective when no feature rearrangement\nto group per company is in effect. However, the model will utilize longer\ntemporal windows and yield better performance once we introduce the feature\nrearrangement. To examine the consistency of our findings, we repeated our\nexperiment on two datasets containing the same thirty companies from the Dow\nJones Index but with different features in each dataset and consistently\nobserved the above-mentioned patterns. The result is a trading model\nsignificantly outperforming global financial services firms such as the Global\nX Guru by the established Mirae Asset.""}","['Sina Montazeri', 'Haseebullah Jumakhanb', 'Amir Mirzaeinia']",{'name': 'Amir Mirzaeinia'},Amir Mirzaeinia,,"[{'href': 'http://arxiv.org/abs/2502.12537v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12537v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12537v2,None,http://arxiv.org/abs/2502.12537v2,,,12,0
http://arxiv.org/abs/2502.12542v1,True,2025-02-18T05:05:46Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=5, tm_min=5, tm_sec=46, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T05:05:46Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=5, tm_min=5, tm_sec=46, tm_wday=1, tm_yday=49, tm_isdst=0)",Computing Voting Rules with Improvement Feedback,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Computing Voting Rules with Improvement Feedback'}","Aggregating preferences under incomplete or constrained feedback is a
fundamental problem in social choice and related domains. While prior work has
established strong impossibility results for pairwise comparisons, this paper
extends the inquiry to improvement feedback, where voters express incremental
adjustments rather than complete preferences. We provide a complete
characterization of the positional scoring rules that can be computed given
improvement feedback. Interestingly, while plurality is learnable under
improvement feedback--unlike with pairwise feedback--strong impossibility
results persist for many other positional scoring rules. Furthermore, we show
that improvement feedback, unlike pairwise feedback, does not suffice for the
computation of any Condorcet-consistent rule. We complement our theoretical
findings with experimental results, providing further insights into the
practical implications of improvement feedback for preference aggregation.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Aggregating preferences under incomplete or constrained feedback is a\nfundamental problem in social choice and related domains. While prior work has\nestablished strong impossibility results for pairwise comparisons, this paper\nextends the inquiry to improvement feedback, where voters express incremental\nadjustments rather than complete preferences. We provide a complete\ncharacterization of the positional scoring rules that can be computed given\nimprovement feedback. Interestingly, while plurality is learnable under\nimprovement feedback--unlike with pairwise feedback--strong impossibility\nresults persist for many other positional scoring rules. Furthermore, we show\nthat improvement feedback, unlike pairwise feedback, does not suffice for the\ncomputation of any Condorcet-consistent rule. We complement our theoretical\nfindings with experimental results, providing further insights into the\npractical implications of improvement feedback for preference aggregation.'}","['Evi Micha', 'Vasilis Varsamis']",{'name': 'Vasilis Varsamis'},Vasilis Varsamis,,"[{'href': 'http://arxiv.org/abs/2502.12542v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12542v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12542v1,None,http://arxiv.org/abs/2502.12542v1,,,0,0
http://arxiv.org/abs/2502.12548v1,True,2025-02-18T05:18:22Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=5, tm_min=18, tm_sec=22, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T05:18:22Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=5, tm_min=18, tm_sec=22, tm_wday=1, tm_yday=49, tm_isdst=0)","Improving the Stability of GNN Force Field Models by Reducing Feature
  Correlation","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Improving the Stability of GNN Force Field Models by Reducing Feature\n  Correlation'}","Recently, Graph Neural Network based Force Field (GNNFF) models are widely
used in Molecular Dynamics (MD) simulation, which is one of the most
cost-effective means in semiconductor material research. However, even such
models provide high accuracy in energy and force Mean Absolute Error (MAE) over
trained (in-distribution) datasets, they often become unstable during long-time
MD simulation when used for out-of-distribution datasets. In this paper, we
propose a feature correlation based method for GNNFF models to enhance the
stability of MD simulation. We reveal the negative relationship between feature
correlation and the stability of GNNFF models, and design a loss function with
a dynamic loss coefficient scheduler to reduce edge feature correlation that
can be applied in general GNNFF training. We also propose an empirical metric
to evaluate the stability in MD simulation. Experiments show our method can
significantly improve stability for GNNFF models especially in
out-of-distribution data with less than 3% computational overhead. For example,
we can ensure the stable MD simulation time from 0.03ps to 10ps for Allegro
model.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Recently, Graph Neural Network based Force Field (GNNFF) models are widely\nused in Molecular Dynamics (MD) simulation, which is one of the most\ncost-effective means in semiconductor material research. However, even such\nmodels provide high accuracy in energy and force Mean Absolute Error (MAE) over\ntrained (in-distribution) datasets, they often become unstable during long-time\nMD simulation when used for out-of-distribution datasets. In this paper, we\npropose a feature correlation based method for GNNFF models to enhance the\nstability of MD simulation. We reveal the negative relationship between feature\ncorrelation and the stability of GNNFF models, and design a loss function with\na dynamic loss coefficient scheduler to reduce edge feature correlation that\ncan be applied in general GNNFF training. We also propose an empirical metric\nto evaluate the stability in MD simulation. Experiments show our method can\nsignificantly improve stability for GNNFF models especially in\nout-of-distribution data with less than 3% computational overhead. For example,\nwe can ensure the stable MD simulation time from 0.03ps to 10ps for Allegro\nmodel.'}","['Yujie Zeng', 'Wenlong He', 'Ihor Vasyltsov', 'Jiaxin Wei', 'Ying Zhang', 'Lin Chen', 'Yuehua Dai']",{'name': 'Yuehua Dai'},Yuehua Dai,,"[{'href': 'http://arxiv.org/abs/2502.12548v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12548v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12548v1,None,http://arxiv.org/abs/2502.12548v1,,,192,0
http://arxiv.org/abs/2502.12552v1,True,2025-02-18T05:26:27Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=5, tm_min=26, tm_sec=27, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T05:26:27Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=5, tm_min=26, tm_sec=27, tm_wday=1, tm_yday=49, tm_isdst=0)",LLM Safety for Children,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'LLM Safety for Children'}","This paper analyzes the safety of Large Language Models (LLMs) in
interactions with children below age of 18 years. Despite the transformative
applications of LLMs in various aspects of children's lives such as education
and therapy, there remains a significant gap in understanding and mitigating
potential content harms specific to this demographic. The study acknowledges
the diverse nature of children often overlooked by standard safety evaluations
and proposes a comprehensive approach to evaluating LLM safety specifically for
children. We list down potential risks that children may encounter when using
LLM powered applications. Additionally we develop Child User Models that
reflect the varied personalities and interests of children informed by
literature in child care and psychology. These user models aim to bridge the
existing gap in child safety literature across various fields. We utilize Child
User Models to evaluate the safety of six state of the art LLMs. Our
observations reveal significant safety gaps in LLMs particularly in categories
harmful to children but not adults","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""This paper analyzes the safety of Large Language Models (LLMs) in\ninteractions with children below age of 18 years. Despite the transformative\napplications of LLMs in various aspects of children's lives such as education\nand therapy, there remains a significant gap in understanding and mitigating\npotential content harms specific to this demographic. The study acknowledges\nthe diverse nature of children often overlooked by standard safety evaluations\nand proposes a comprehensive approach to evaluating LLM safety specifically for\nchildren. We list down potential risks that children may encounter when using\nLLM powered applications. Additionally we develop Child User Models that\nreflect the varied personalities and interests of children informed by\nliterature in child care and psychology. These user models aim to bridge the\nexisting gap in child safety literature across various fields. We utilize Child\nUser Models to evaluate the safety of six state of the art LLMs. Our\nobservations reveal significant safety gaps in LLMs particularly in categories\nharmful to children but not adults""}","['Prasanjit Rath', 'Hari Shrawgi', 'Parag Agrawal', 'Sandipan Dandapat']",{'name': 'Sandipan Dandapat'},Sandipan Dandapat,,"[{'href': 'http://arxiv.org/abs/2502.12552v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12552v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12552v1,None,http://arxiv.org/abs/2502.12552v1,,,1365,0
http://arxiv.org/abs/2502.12558v1,True,2025-02-18T05:50:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=5, tm_min=50, tm_sec=23, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T05:50:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=5, tm_min=50, tm_sec=23, tm_wday=1, tm_yday=49, tm_isdst=0)","MomentSeeker: A Comprehensive Benchmark and A Strong Baseline For Moment
  Retrieval Within Long Videos","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'MomentSeeker: A Comprehensive Benchmark and A Strong Baseline For Moment\n  Retrieval Within Long Videos'}","Retrieval augmented generation (RAG) holds great promise in addressing
challenges associated with long video understanding. These methods retrieve
useful moments from long videos for their presented tasks, thereby enabling
multimodal large language models (MLLMs) to generate high-quality answers in a
cost-effective way. In this work, we present MomentSeeker, a comprehensive
benchmark to evaluate retrieval models' performance in handling general
long-video moment retrieval (LVMR) tasks. MomentSeeker offers three key
advantages. First, it incorporates long videos of over 500 seconds on average,
making it the first benchmark specialized for long-video moment retrieval.
Second, it covers a wide range of task categories (including Moment Search,
Caption Alignment, Image-conditioned Moment Search, and Video-conditioned
Moment Search) and diverse application scenarios (e.g., sports, movies,
cartoons, and ego), making it a comprehensive tool for assessing retrieval
models' general LVMR performance. Additionally, the evaluation tasks are
carefully curated through human annotation, ensuring the reliability of
assessment. We further fine-tune an MLLM-based LVMR retriever on synthetic
data, which demonstrates strong performance on our benchmark. We perform
extensive experiments with various popular multimodal retrievers based on our
benchmark, whose results highlight the challenges of LVMR and limitations for
existing methods. Our created resources will be shared with community to
advance future research in this field.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Retrieval augmented generation (RAG) holds great promise in addressing\nchallenges associated with long video understanding. These methods retrieve\nuseful moments from long videos for their presented tasks, thereby enabling\nmultimodal large language models (MLLMs) to generate high-quality answers in a\ncost-effective way. In this work, we present MomentSeeker, a comprehensive\nbenchmark to evaluate retrieval models' performance in handling general\nlong-video moment retrieval (LVMR) tasks. MomentSeeker offers three key\nadvantages. First, it incorporates long videos of over 500 seconds on average,\nmaking it the first benchmark specialized for long-video moment retrieval.\nSecond, it covers a wide range of task categories (including Moment Search,\nCaption Alignment, Image-conditioned Moment Search, and Video-conditioned\nMoment Search) and diverse application scenarios (e.g., sports, movies,\ncartoons, and ego), making it a comprehensive tool for assessing retrieval\nmodels' general LVMR performance. Additionally, the evaluation tasks are\ncarefully curated through human annotation, ensuring the reliability of\nassessment. We further fine-tune an MLLM-based LVMR retriever on synthetic\ndata, which demonstrates strong performance on our benchmark. We perform\nextensive experiments with various popular multimodal retrievers based on our\nbenchmark, whose results highlight the challenges of LVMR and limitations for\nexisting methods. Our created resources will be shared with community to\nadvance future research in this field.""}","['Huaying Yuan', 'Jian Ni', 'Yueze Wang', 'Junjie Zhou', 'Zhengyang Liang', 'Zheng Liu', 'Zhao Cao', 'Zhicheng Dou', 'Ji-Rong Wen']",{'name': 'Ji-Rong Wen'},Ji-Rong Wen,,"[{'href': 'http://arxiv.org/abs/2502.12558v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12558v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12558v1,None,http://arxiv.org/abs/2502.12558v1,,,5079,0
http://arxiv.org/abs/2502.12568v2,True,2025-02-19T08:58:13Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=8, tm_min=58, tm_sec=13, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-18T06:12:14Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=6, tm_min=12, tm_sec=14, tm_wday=1, tm_yday=49, tm_isdst=0)","A Cognitive Writing Perspective for Constrained Long-Form Text
  Generation","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A Cognitive Writing Perspective for Constrained Long-Form Text\n  Generation'}","Like humans, Large Language Models (LLMs) struggle to generate high-quality
long-form text that adheres to strict requirements in a single pass. This
challenge is unsurprising, as successful human writing, according to the
Cognitive Writing Theory, is a complex cognitive process involving iterative
planning, translating, reviewing, and monitoring. Motivated by these cognitive
principles, we aim to equip LLMs with human-like cognitive writing capabilities
through CogWriter, a novel training-free framework that transforms LLM
constrained long-form text generation into a systematic cognitive writing
paradigm. Our framework consists of two key modules: (1) a Planning Agent that
performs hierarchical planning to decompose the task, and (2) multiple
Generation Agents that execute these plans in parallel. The system maintains
quality via continuous monitoring and reviewing mechanisms, which evaluate
outputs against specified requirements and trigger necessary revisions.
CogWriter demonstrates exceptional performance on LongGenBench, a benchmark for
complex constrained long-form text generation. Even when using Qwen-2.5-14B as
its backbone, CogWriter surpasses GPT-4o by 22% in complex instruction
completion accuracy while reliably generating texts exceeding 10,000 words. We
hope this cognitive science-inspired approach provides a paradigm for LLM
writing advancements:
\href{https://github.com/KaiyangWan/CogWriter}{CogWriter}.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Like humans, Large Language Models (LLMs) struggle to generate high-quality\nlong-form text that adheres to strict requirements in a single pass. This\nchallenge is unsurprising, as successful human writing, according to the\nCognitive Writing Theory, is a complex cognitive process involving iterative\nplanning, translating, reviewing, and monitoring. Motivated by these cognitive\nprinciples, we aim to equip LLMs with human-like cognitive writing capabilities\nthrough CogWriter, a novel training-free framework that transforms LLM\nconstrained long-form text generation into a systematic cognitive writing\nparadigm. Our framework consists of two key modules: (1) a Planning Agent that\nperforms hierarchical planning to decompose the task, and (2) multiple\nGeneration Agents that execute these plans in parallel. The system maintains\nquality via continuous monitoring and reviewing mechanisms, which evaluate\noutputs against specified requirements and trigger necessary revisions.\nCogWriter demonstrates exceptional performance on LongGenBench, a benchmark for\ncomplex constrained long-form text generation. Even when using Qwen-2.5-14B as\nits backbone, CogWriter surpasses GPT-4o by 22% in complex instruction\ncompletion accuracy while reliably generating texts exceeding 10,000 words. We\nhope this cognitive science-inspired approach provides a paradigm for LLM\nwriting advancements:\n\\href{https://github.com/KaiyangWan/CogWriter}{CogWriter}.'}","['Kaiyang Wan', 'Honglin Mu', 'Rui Hao', 'Haoran Luo', 'Tianle Gu', 'Xiuying Chen']",{'name': 'Xiuying Chen'},Xiuying Chen,"13 pages, 6 figures","[{'href': 'http://arxiv.org/abs/2502.12568v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12568v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12568v2,None,http://arxiv.org/abs/2502.12568v2,,,24,0
http://arxiv.org/abs/2502.12574v1,True,2025-02-18T06:26:05Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=6, tm_min=26, tm_sec=5, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T06:26:05Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=6, tm_min=26, tm_sec=5, tm_wday=1, tm_yday=49, tm_isdst=0)",HeadInfer: Memory-Efficient LLM Inference by Head-wise Offloading,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'HeadInfer: Memory-Efficient LLM Inference by Head-wise Offloading'}","Transformer-based large language models (LLMs) demonstrate impressive
performance in long context generation. Extending the context length has
disproportionately shifted the memory footprint of LLMs during inference to the
key-value cache (KV cache). In this paper, we propose HEADINFER, which offloads
the KV cache to CPU RAM while avoiding the need to fully store the KV cache for
any transformer layer on the GPU. HEADINFER employs a fine-grained, head-wise
offloading strategy, maintaining only selective attention heads KV cache on the
GPU while computing attention output dynamically. Through roofline analysis, we
demonstrate that HEADINFER maintains computational efficiency while
significantly reducing memory footprint. We evaluate HEADINFER on the
Llama-3-8B model with a 1-million-token sequence, reducing the GPU memory
footprint of the KV cache from 128 GB to 1 GB and the total GPU memory usage
from 207 GB to 17 GB, achieving a 92% reduction compared to BF16 baseline
inference. Notably, HEADINFER enables 4-million-token inference with an 8B
model on a single consumer GPU with 24GB memory (e.g., NVIDIA RTX 4090) without
approximation methods.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Transformer-based large language models (LLMs) demonstrate impressive\nperformance in long context generation. Extending the context length has\ndisproportionately shifted the memory footprint of LLMs during inference to the\nkey-value cache (KV cache). In this paper, we propose HEADINFER, which offloads\nthe KV cache to CPU RAM while avoiding the need to fully store the KV cache for\nany transformer layer on the GPU. HEADINFER employs a fine-grained, head-wise\noffloading strategy, maintaining only selective attention heads KV cache on the\nGPU while computing attention output dynamically. Through roofline analysis, we\ndemonstrate that HEADINFER maintains computational efficiency while\nsignificantly reducing memory footprint. We evaluate HEADINFER on the\nLlama-3-8B model with a 1-million-token sequence, reducing the GPU memory\nfootprint of the KV cache from 128 GB to 1 GB and the total GPU memory usage\nfrom 207 GB to 17 GB, achieving a 92% reduction compared to BF16 baseline\ninference. Notably, HEADINFER enables 4-million-token inference with an 8B\nmodel on a single consumer GPU with 24GB memory (e.g., NVIDIA RTX 4090) without\napproximation methods.'}","['Cheng Luo', 'Zefan Cai', 'Hanshi Sun', 'Jinqi Xiao', 'Bo Yuan', 'Wen Xiao', 'Junjie Hu', 'Jiawei Zhao', 'Beidi Chen', 'Anima Anandkumar']",{'name': 'Anima Anandkumar'},Anima Anandkumar,,"[{'href': 'http://arxiv.org/abs/2502.12574v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12574v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12574v1,None,http://arxiv.org/abs/2502.12574v1,,,1054,0
http://arxiv.org/abs/2502.12575v1,True,2025-02-18T06:26:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=6, tm_min=26, tm_sec=15, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T06:26:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=6, tm_min=26, tm_sec=15, tm_wday=1, tm_yday=49, tm_isdst=0)","DemonAgent: Dynamically Encrypted Multi-Backdoor Implantation Attack on
  LLM-based Agent","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'DemonAgent: Dynamically Encrypted Multi-Backdoor Implantation Attack on\n  LLM-based Agent'}","As LLM-based agents become increasingly prevalent, backdoors can be implanted
into agents through user queries or environment feedback, raising critical
concerns regarding safety vulnerabilities. However, backdoor attacks are
typically detectable by safety audits that analyze the reasoning process of
agents. To this end, we propose a novel backdoor implantation strategy called
\textbf{Dynamically Encrypted Multi-Backdoor Implantation Attack}.
Specifically, we introduce dynamic encryption, which maps the backdoor into
benign content, effectively circumventing safety audits. To enhance
stealthiness, we further decompose the backdoor into multiple sub-backdoor
fragments. Based on these advancements, backdoors are allowed to bypass safety
audits significantly. Additionally, we present AgentBackdoorEval, a dataset
designed for the comprehensive evaluation of agent backdoor attacks.
Experimental results across multiple datasets demonstrate that our method
achieves an attack success rate nearing 100\% while maintaining a detection
rate of 0\%, illustrating its effectiveness in evading safety audits. Our
findings highlight the limitations of existing safety mechanisms in detecting
advanced attacks, underscoring the urgent need for more robust defenses against
backdoor threats. Code and data are available at
https://github.com/whfeLingYu/DemonAgent.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'As LLM-based agents become increasingly prevalent, backdoors can be implanted\ninto agents through user queries or environment feedback, raising critical\nconcerns regarding safety vulnerabilities. However, backdoor attacks are\ntypically detectable by safety audits that analyze the reasoning process of\nagents. To this end, we propose a novel backdoor implantation strategy called\n\\textbf{Dynamically Encrypted Multi-Backdoor Implantation Attack}.\nSpecifically, we introduce dynamic encryption, which maps the backdoor into\nbenign content, effectively circumventing safety audits. To enhance\nstealthiness, we further decompose the backdoor into multiple sub-backdoor\nfragments. Based on these advancements, backdoors are allowed to bypass safety\naudits significantly. Additionally, we present AgentBackdoorEval, a dataset\ndesigned for the comprehensive evaluation of agent backdoor attacks.\nExperimental results across multiple datasets demonstrate that our method\nachieves an attack success rate nearing 100\\% while maintaining a detection\nrate of 0\\%, illustrating its effectiveness in evading safety audits. Our\nfindings highlight the limitations of existing safety mechanisms in detecting\nadvanced attacks, underscoring the urgent need for more robust defenses against\nbackdoor threats. Code and data are available at\nhttps://github.com/whfeLingYu/DemonAgent.'}","['Pengyu Zhu', 'Zhenhong Zhou', 'Yuanhe Zhang', 'Shilinlu Yan', 'Kun Wang', 'Sen Su']",{'name': 'Sen Su'},Sen Su,,"[{'href': 'http://arxiv.org/abs/2502.12575v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12575v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12575v1,None,http://arxiv.org/abs/2502.12575v1,,,0,0
http://arxiv.org/abs/2502.12584v1,True,2025-02-18T06:41:53Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=6, tm_min=41, tm_sec=53, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T06:41:53Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=6, tm_min=41, tm_sec=53, tm_wday=1, tm_yday=49, tm_isdst=0)",Enhancing Semi-supervised Learning with Noisy Zero-shot Pseudolabels,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Enhancing Semi-supervised Learning with Noisy Zero-shot Pseudolabels'}","Semi-supervised learning (SSL) leverages limited labeled data alongside
abundant unlabeled data to address labeling costs in machine learning. While
recent foundation models enable zero-shot inference, attempts to integrate
these capabilities into SSL through pseudo-labeling have shown mixed results
due to unreliable zero-shot predictions. We present ZMT (Zero-Shot Multi-Task
Learning), a framework that jointly optimizes zero-shot pseudo-labels and
unsupervised representation learning objectives from contemporary SSL
approaches. Our method introduces a multi-task learning-based mechanism that
incorporates pseudo-labels while ensuring robustness to varying pseudo-label
quality. Experiments across 8 datasets in vision, language, and audio domains
demonstrate that ZMT reduces error by up to 56% compared to traditional SSL
methods, with particularly compelling results when pseudo-labels are noisy and
unreliable. ZMT represents a significant step toward making semi-supervised
learning more effective and accessible in resource-constrained environments.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Semi-supervised learning (SSL) leverages limited labeled data alongside\nabundant unlabeled data to address labeling costs in machine learning. While\nrecent foundation models enable zero-shot inference, attempts to integrate\nthese capabilities into SSL through pseudo-labeling have shown mixed results\ndue to unreliable zero-shot predictions. We present ZMT (Zero-Shot Multi-Task\nLearning), a framework that jointly optimizes zero-shot pseudo-labels and\nunsupervised representation learning objectives from contemporary SSL\napproaches. Our method introduces a multi-task learning-based mechanism that\nincorporates pseudo-labels while ensuring robustness to varying pseudo-label\nquality. Experiments across 8 datasets in vision, language, and audio domains\ndemonstrate that ZMT reduces error by up to 56% compared to traditional SSL\nmethods, with particularly compelling results when pseudo-labels are noisy and\nunreliable. ZMT represents a significant step toward making semi-supervised\nlearning more effective and accessible in resource-constrained environments.'}","['Jichan Chung', 'Irene Y. Chen']",{'name': 'Irene Y. Chen'},Irene Y. Chen,Under review for ICML 2025,"[{'href': 'http://arxiv.org/abs/2502.12584v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12584v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12584v1,None,http://arxiv.org/abs/2502.12584v1,,,0,0
http://arxiv.org/abs/2502.12587v1,True,2025-02-18T06:45:21Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=6, tm_min=45, tm_sec=21, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T06:45:21Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=6, tm_min=45, tm_sec=21, tm_wday=1, tm_yday=49, tm_isdst=0)",RSMLP: A light Sampled MLP Structure for Incomplete Utterance Rewrite,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'RSMLP: A light Sampled MLP Structure for Incomplete Utterance Rewrite'}","The Incomplete Utterance Rewriting (IUR) task has garnered significant
attention in recent years. Its goal is to reconstruct conversational utterances
to better align with the current context, thereby enhancing comprehension. In
this paper, we introduce a novel and versatile lightweight method,
Rewritten-Sampled MLP (RSMLP). By employing an MLP based architecture with a
carefully designed down-sampling strategy, RSMLP effectively extracts latent
semantic information between utterances and makes appropriate edits to restore
incomplete utterances. Due to its simple yet efficient structure, our method
achieves competitive performance on public IUR datasets and in real-world
applications.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The Incomplete Utterance Rewriting (IUR) task has garnered significant\nattention in recent years. Its goal is to reconstruct conversational utterances\nto better align with the current context, thereby enhancing comprehension. In\nthis paper, we introduce a novel and versatile lightweight method,\nRewritten-Sampled MLP (RSMLP). By employing an MLP based architecture with a\ncarefully designed down-sampling strategy, RSMLP effectively extracts latent\nsemantic information between utterances and makes appropriate edits to restore\nincomplete utterances. Due to its simple yet efficient structure, our method\nachieves competitive performance on public IUR datasets and in real-world\napplications.'}","['Lunjun Liu', 'Weilai Jiang', 'Yaonan Wang']",{'name': 'Yaonan Wang'},Yaonan Wang,,"[{'href': 'http://arxiv.org/abs/2502.12587v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12587v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12587v1,None,http://arxiv.org/abs/2502.12587v1,,,198,0
http://arxiv.org/abs/2502.12603v1,True,2025-02-18T07:31:04Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=7, tm_min=31, tm_sec=4, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T07:31:04Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=7, tm_min=31, tm_sec=4, tm_wday=1, tm_yday=49, tm_isdst=0)","Disentangling Long-Short Term State Under Unknown Interventions for
  Online Time Series Forecasting","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Disentangling Long-Short Term State Under Unknown Interventions for\n  Online Time Series Forecasting'}","Current methods for time series forecasting struggle in the online scenario,
since it is difficult to preserve long-term dependency while adapting
short-term changes when data are arriving sequentially. Although some recent
methods solve this problem by controlling the updates of latent states, they
cannot disentangle the long/short-term states, leading to the inability to
effectively adapt to nonstationary. To tackle this challenge, we propose a
general framework to disentangle long/short-term states for online time series
forecasting. Our idea is inspired by the observations where short-term changes
can be led by unknown interventions like abrupt policies in the stock market.
Based on this insight, we formalize a data generation process with unknown
interventions on short-term states. Under mild assumptions, we further leverage
the independence of short-term states led by unknown interventions to establish
the identification theory to achieve the disentanglement of long/short-term
states. Built on this theory, we develop a long short-term disentanglement
model (LSTD) to extract the long/short-term states with long/short-term
encoders, respectively. Furthermore, the LSTD model incorporates a smooth
constraint to preserve the long-term dependencies and an interrupted dependency
constraint to enforce the forgetting of short-term dependencies, together
boosting the disentanglement of long/short-term states. Experimental results on
several benchmark datasets show that our \textbf{LSTD} model outperforms
existing methods for online time series forecasting, validating its efficacy in
real-world applications.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Current methods for time series forecasting struggle in the online scenario,\nsince it is difficult to preserve long-term dependency while adapting\nshort-term changes when data are arriving sequentially. Although some recent\nmethods solve this problem by controlling the updates of latent states, they\ncannot disentangle the long/short-term states, leading to the inability to\neffectively adapt to nonstationary. To tackle this challenge, we propose a\ngeneral framework to disentangle long/short-term states for online time series\nforecasting. Our idea is inspired by the observations where short-term changes\ncan be led by unknown interventions like abrupt policies in the stock market.\nBased on this insight, we formalize a data generation process with unknown\ninterventions on short-term states. Under mild assumptions, we further leverage\nthe independence of short-term states led by unknown interventions to establish\nthe identification theory to achieve the disentanglement of long/short-term\nstates. Built on this theory, we develop a long short-term disentanglement\nmodel (LSTD) to extract the long/short-term states with long/short-term\nencoders, respectively. Furthermore, the LSTD model incorporates a smooth\nconstraint to preserve the long-term dependencies and an interrupted dependency\nconstraint to enforce the forgetting of short-term dependencies, together\nboosting the disentanglement of long/short-term states. Experimental results on\nseveral benchmark datasets show that our \\textbf{LSTD} model outperforms\nexisting methods for online time series forecasting, validating its efficacy in\nreal-world applications.'}","['Ruichu Cai', 'Haiqin Huang', 'Zhifang Jiang', 'Zijian Li', 'Changze Zhou', 'Yuequn Liu', 'Yuming Liu', 'Zhifeng Hao']",{'name': 'Zhifeng Hao'},Zhifeng Hao,,"[{'href': 'http://arxiv.org/abs/2502.12603v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12603v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12603v1,None,http://arxiv.org/abs/2502.12603v1,AAAI2025,,1516,0
http://arxiv.org/abs/2502.12608v1,True,2025-02-18T07:46:10Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=7, tm_min=46, tm_sec=10, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T07:46:10Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=7, tm_min=46, tm_sec=10, tm_wday=1, tm_yday=49, tm_isdst=0)",Unveiling Mode Connectivity in Graph Neural Networks,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Unveiling Mode Connectivity in Graph Neural Networks'}","A fundamental challenge in understanding graph neural networks (GNNs) lies in
characterizing their optimization dynamics and loss landscape geometry,
critical for improving interpretability and robustness. While mode
connectivity, a lens for analyzing geometric properties of loss landscapes has
proven insightful for other deep learning architectures, its implications for
GNNs remain unexplored. This work presents the first investigation of mode
connectivity in GNNs. We uncover that GNNs exhibit distinct non-linear mode
connectivity, diverging from patterns observed in fully-connected networks or
CNNs. Crucially, we demonstrate that graph structure, rather than model
architecture, dominates this behavior, with graph properties like homophily
correlating with mode connectivity patterns. We further establish a link
between mode connectivity and generalization, proposing a generalization bound
based on loss barriers and revealing its utility as a diagnostic tool. Our
findings further bridge theoretical insights with practical implications: they
rationalize domain alignment strategies in graph learning and provide a
foundation for refining GNN training paradigms.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A fundamental challenge in understanding graph neural networks (GNNs) lies in\ncharacterizing their optimization dynamics and loss landscape geometry,\ncritical for improving interpretability and robustness. While mode\nconnectivity, a lens for analyzing geometric properties of loss landscapes has\nproven insightful for other deep learning architectures, its implications for\nGNNs remain unexplored. This work presents the first investigation of mode\nconnectivity in GNNs. We uncover that GNNs exhibit distinct non-linear mode\nconnectivity, diverging from patterns observed in fully-connected networks or\nCNNs. Crucially, we demonstrate that graph structure, rather than model\narchitecture, dominates this behavior, with graph properties like homophily\ncorrelating with mode connectivity patterns. We further establish a link\nbetween mode connectivity and generalization, proposing a generalization bound\nbased on loss barriers and revealing its utility as a diagnostic tool. Our\nfindings further bridge theoretical insights with practical implications: they\nrationalize domain alignment strategies in graph learning and provide a\nfoundation for refining GNN training paradigms.'}","['Bingheng Li', 'Zhikai Chen', 'Haoyu Han', 'Shenglai Zeng', 'Jingzhe Liu', 'Jiliang Tang']",{'name': 'Jiliang Tang'},Jiliang Tang,,"[{'href': 'http://arxiv.org/abs/2502.12608v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12608v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12608v1,None,http://arxiv.org/abs/2502.12608v1,,,196,0
http://arxiv.org/abs/2502.12614v1,True,2025-02-18T07:53:26Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=7, tm_min=53, tm_sec=26, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T07:53:26Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=7, tm_min=53, tm_sec=26, tm_wday=1, tm_yday=49, tm_isdst=0)","Label Drop for Multi-Aspect Relation Modeling in Universal Information
  Extraction","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Label Drop for Multi-Aspect Relation Modeling in Universal Information\n  Extraction'}","Universal Information Extraction (UIE) has garnered significant attention due
to its ability to address model explosion problems effectively. Extractive UIE
can achieve strong performance using a relatively small model, making it widely
adopted. Extractive UIEs generally rely on task instructions for different
tasks, including single-target instructions and multiple-target instructions.
Single-target instruction UIE enables the extraction of only one type of
relation at a time, limiting its ability to model correlations between
relations and thus restricting its capability to extract complex relations.
While multiple-target instruction UIE allows for the extraction of multiple
relations simultaneously, the inclusion of irrelevant relations introduces
decision complexity and impacts extraction accuracy. Therefore, for
multi-relation extraction, we propose LDNet, which incorporates multi-aspect
relation modeling and a label drop mechanism. By assigning different relations
to different levels for understanding and decision-making, we reduce decision
confusion. Additionally, the label drop mechanism effectively mitigates the
impact of irrelevant relations. Experiments show that LDNet outperforms or
achieves competitive performance with state-of-the-art systems on 9 tasks, 33
datasets, in both single-modal and multi-modal, few-shot and zero-shot
settings.\footnote{https://github.com/Lu-Yang666/LDNet}","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Universal Information Extraction (UIE) has garnered significant attention due\nto its ability to address model explosion problems effectively. Extractive UIE\ncan achieve strong performance using a relatively small model, making it widely\nadopted. Extractive UIEs generally rely on task instructions for different\ntasks, including single-target instructions and multiple-target instructions.\nSingle-target instruction UIE enables the extraction of only one type of\nrelation at a time, limiting its ability to model correlations between\nrelations and thus restricting its capability to extract complex relations.\nWhile multiple-target instruction UIE allows for the extraction of multiple\nrelations simultaneously, the inclusion of irrelevant relations introduces\ndecision complexity and impacts extraction accuracy. Therefore, for\nmulti-relation extraction, we propose LDNet, which incorporates multi-aspect\nrelation modeling and a label drop mechanism. By assigning different relations\nto different levels for understanding and decision-making, we reduce decision\nconfusion. Additionally, the label drop mechanism effectively mitigates the\nimpact of irrelevant relations. Experiments show that LDNet outperforms or\nachieves competitive performance with state-of-the-art systems on 9 tasks, 33\ndatasets, in both single-modal and multi-modal, few-shot and zero-shot\nsettings.\\footnote{https://github.com/Lu-Yang666/LDNet}'}","['Lu Yang', 'Jiajia Li', 'En Ci', 'Lefei Zhang', 'Zuchao Li', 'Ping Wang']",{'name': 'Ping Wang'},Ping Wang,Accepted to NAACL-main 2025,"[{'href': 'http://arxiv.org/abs/2502.12614v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12614v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12614v1,None,http://arxiv.org/abs/2502.12614v1,,,70,0
http://arxiv.org/abs/2502.12630v1,True,2025-02-18T08:17:32Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=8, tm_min=17, tm_sec=32, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T08:17:32Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=8, tm_min=17, tm_sec=32, tm_wday=1, tm_yday=49, tm_isdst=0)","Automating Prompt Leakage Attacks on Large Language Models Using Agentic
  Approach","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Automating Prompt Leakage Attacks on Large Language Models Using Agentic\n  Approach'}","This paper presents a novel approach to evaluating the security of large
language models (LLMs) against prompt leakage-the exposure of system-level
prompts or proprietary configurations. We define prompt leakage as a critical
threat to secure LLM deployment and introduce a framework for testing the
robustness of LLMs using agentic teams. Leveraging AG2 (formerly AutoGen), we
implement a multi-agent system where cooperative agents are tasked with probing
and exploiting the target LLM to elicit its prompt.
  Guided by traditional definitions of security in cryptography, we further
define a prompt leakage-safe system as one in which an attacker cannot
distinguish between two agents: one initialized with an original prompt and the
other with a prompt stripped of all sensitive information. In a safe system,
the agents' outputs will be indistinguishable to the attacker, ensuring that
sensitive information remains secure. This cryptographically inspired framework
provides a rigorous standard for evaluating and designing secure LLMs.
  This work establishes a systematic methodology for adversarial testing of
prompt leakage, bridging the gap between automated threat modeling and
practical LLM security.
  You can find the implementation of our prompt leakage probing on GitHub.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""This paper presents a novel approach to evaluating the security of large\nlanguage models (LLMs) against prompt leakage-the exposure of system-level\nprompts or proprietary configurations. We define prompt leakage as a critical\nthreat to secure LLM deployment and introduce a framework for testing the\nrobustness of LLMs using agentic teams. Leveraging AG2 (formerly AutoGen), we\nimplement a multi-agent system where cooperative agents are tasked with probing\nand exploiting the target LLM to elicit its prompt.\n  Guided by traditional definitions of security in cryptography, we further\ndefine a prompt leakage-safe system as one in which an attacker cannot\ndistinguish between two agents: one initialized with an original prompt and the\nother with a prompt stripped of all sensitive information. In a safe system,\nthe agents' outputs will be indistinguishable to the attacker, ensuring that\nsensitive information remains secure. This cryptographically inspired framework\nprovides a rigorous standard for evaluating and designing secure LLMs.\n  This work establishes a systematic methodology for adversarial testing of\nprompt leakage, bridging the gap between automated threat modeling and\npractical LLM security.\n  You can find the implementation of our prompt leakage probing on GitHub.""}","['Tvrtko Sternak', 'Davor Runje', 'Dorian Granoa', 'Chi Wang']",{'name': 'Chi Wang'},Chi Wang,,"[{'href': 'http://arxiv.org/abs/2502.12630v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12630v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12630v1,None,http://arxiv.org/abs/2502.12630v1,,,0,0
http://arxiv.org/abs/2502.12631v1,True,2025-02-18T08:22:20Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=8, tm_min=22, tm_sec=20, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T08:22:20Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=8, tm_min=22, tm_sec=20, tm_wday=1, tm_yday=49, tm_isdst=0)","Score-Based Diffusion Policy Compatible with Reinforcement Learning via
  Optimal Transport","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Score-Based Diffusion Policy Compatible with Reinforcement Learning via\n  Optimal Transport'}","Diffusion policies have shown promise in learning complex behaviors from
demonstrations, particularly for tasks requiring precise control and long-term
planning. However, they face challenges in robustness when encountering
distribution shifts. This paper explores improving diffusion-based imitation
learning models through online interactions with the environment. We propose
OTPR (Optimal Transport-guided score-based diffusion Policy for Reinforcement
learning fine-tuning), a novel method that integrates diffusion policies with
RL using optimal transport theory. OTPR leverages the Q-function as a transport
cost and views the policy as an optimal transport map, enabling efficient and
stable fine-tuning. Moreover, we introduce masked optimal transport to guide
state-action matching using expert keypoints and a compatibility-based
resampling strategy to enhance training stability. Experiments on three
simulation tasks demonstrate OTPR's superior performance and robustness
compared to existing methods, especially in complex and sparse-reward
environments. In sum, OTPR provides an effective framework for combining IL and
RL, achieving versatile and reliable policy learning. The code will be released
at https://github.com/Sunmmyy/OTPR.git.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Diffusion policies have shown promise in learning complex behaviors from\ndemonstrations, particularly for tasks requiring precise control and long-term\nplanning. However, they face challenges in robustness when encountering\ndistribution shifts. This paper explores improving diffusion-based imitation\nlearning models through online interactions with the environment. We propose\nOTPR (Optimal Transport-guided score-based diffusion Policy for Reinforcement\nlearning fine-tuning), a novel method that integrates diffusion policies with\nRL using optimal transport theory. OTPR leverages the Q-function as a transport\ncost and views the policy as an optimal transport map, enabling efficient and\nstable fine-tuning. Moreover, we introduce masked optimal transport to guide\nstate-action matching using expert keypoints and a compatibility-based\nresampling strategy to enhance training stability. Experiments on three\nsimulation tasks demonstrate OTPR's superior performance and robustness\ncompared to existing methods, especially in complex and sparse-reward\nenvironments. In sum, OTPR provides an effective framework for combining IL and\nRL, achieving versatile and reliable policy learning. The code will be released\nat https://github.com/Sunmmyy/OTPR.git.""}","['Mingyang Sun', 'Pengxiang Ding', 'Weinan Zhang', 'Donglin Wang']",{'name': 'Donglin Wang'},Donglin Wang,,"[{'href': 'http://arxiv.org/abs/2502.12631v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12631v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12631v1,None,http://arxiv.org/abs/2502.12631v1,,,140,0
http://arxiv.org/abs/2502.12633v2,True,2025-02-19T16:45:48Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=16, tm_min=45, tm_sec=48, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-18T08:24:52Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=8, tm_min=24, tm_sec=52, tm_wday=1, tm_yday=49, tm_isdst=0)","One Size doesn't Fit All: A Personalized Conversational Tutoring Agent
  for Mathematics Instruction","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""One Size doesn't Fit All: A Personalized Conversational Tutoring Agent\n  for Mathematics Instruction""}","Large language models (LLMs) have been increasingly employed in various
intelligent educational systems, simulating human tutors to facilitate
effective human-machine interaction. However, previous studies often overlook
the significance of recognizing and adapting to individual learner
characteristics. Such adaptation is crucial for enhancing student engagement
and learning efficiency, particularly in mathematics instruction, where diverse
learning styles require personalized strategies to promote comprehension and
enthusiasm. In this paper, we propose a \textbf{P}erson\textbf{A}lized
\textbf{C}onversational tutoring ag\textbf{E}nt (PACE) for mathematics
instruction. PACE simulates students' learning styles based on the Felder and
Silverman learning style model, aligning with each student's persona. In this
way, our PACE can effectively assess the personality of students, allowing to
develop individualized teaching strategies that resonate with their unique
learning styles. To further enhance students' comprehension, PACE employs the
Socratic teaching method to provide instant feedback and encourage deep
thinking. By constructing personalized teaching data and training models, PACE
demonstrates the ability to identify and adapt to the unique needs of each
student, significantly improving the overall learning experience and outcomes.
Moreover, we establish multi-aspect evaluation criteria and conduct extensive
analysis to assess the performance of personalized teaching. Experimental
results demonstrate the superiority of our model in personalizing the
educational experience and motivating students compared to existing methods.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Large language models (LLMs) have been increasingly employed in various\nintelligent educational systems, simulating human tutors to facilitate\neffective human-machine interaction. However, previous studies often overlook\nthe significance of recognizing and adapting to individual learner\ncharacteristics. Such adaptation is crucial for enhancing student engagement\nand learning efficiency, particularly in mathematics instruction, where diverse\nlearning styles require personalized strategies to promote comprehension and\nenthusiasm. In this paper, we propose a \\textbf{P}erson\\textbf{A}lized\n\\textbf{C}onversational tutoring ag\\textbf{E}nt (PACE) for mathematics\ninstruction. PACE simulates students' learning styles based on the Felder and\nSilverman learning style model, aligning with each student's persona. In this\nway, our PACE can effectively assess the personality of students, allowing to\ndevelop individualized teaching strategies that resonate with their unique\nlearning styles. To further enhance students' comprehension, PACE employs the\nSocratic teaching method to provide instant feedback and encourage deep\nthinking. By constructing personalized teaching data and training models, PACE\ndemonstrates the ability to identify and adapt to the unique needs of each\nstudent, significantly improving the overall learning experience and outcomes.\nMoreover, we establish multi-aspect evaluation criteria and conduct extensive\nanalysis to assess the performance of personalized teaching. Experimental\nresults demonstrate the superiority of our model in personalizing the\neducational experience and motivating students compared to existing methods.""}","['Ben Liu', 'Jihan Zhang', 'Fangquan Lin', 'Xu Jia', 'Min Peng']",{'name': 'Min Peng'},Min Peng,,"[{'href': 'http://arxiv.org/abs/2502.12633v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12633v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12633v2,None,http://arxiv.org/abs/2502.12633v2,,,28,0
http://arxiv.org/abs/2502.12659v1,True,2025-02-18T09:06:07Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=9, tm_min=6, tm_sec=7, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T09:06:07Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=9, tm_min=6, tm_sec=7, tm_wday=1, tm_yday=49, tm_isdst=0)",The Hidden Risks of Large Reasoning Models: A Safety Assessment of R1,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The Hidden Risks of Large Reasoning Models: A Safety Assessment of R1'}","The rapid development of large reasoning models, such as OpenAI-o3 and
DeepSeek-R1, has led to significant improvements in complex reasoning over
non-reasoning large language models~(LLMs). However, their enhanced
capabilities, combined with the open-source access of models like DeepSeek-R1,
raise serious safety concerns, particularly regarding their potential for
misuse. In this work, we present a comprehensive safety assessment of these
reasoning models, leveraging established safety benchmarks to evaluate their
compliance with safety regulations. Furthermore, we investigate their
susceptibility to adversarial attacks, such as jailbreaking and prompt
injection, to assess their robustness in real-world applications. Through our
multi-faceted analysis, we uncover four key findings: (1) There is a
significant safety gap between the open-source R1 models and the o3-mini model,
on both safety benchmark and attack, suggesting more safety effort on R1 is
needed. (2) The distilled reasoning model shows poorer safety performance
compared to its safety-aligned base models. (3) The stronger the model's
reasoning ability, the greater the potential harm it may cause when answering
unsafe questions. (4) The thinking process in R1 models pose greater safety
concerns than their final answers. Our study provides insights into the
security implications of reasoning models and highlights the need for further
advancements in R1 models' safety to close the gap.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""The rapid development of large reasoning models, such as OpenAI-o3 and\nDeepSeek-R1, has led to significant improvements in complex reasoning over\nnon-reasoning large language models~(LLMs). However, their enhanced\ncapabilities, combined with the open-source access of models like DeepSeek-R1,\nraise serious safety concerns, particularly regarding their potential for\nmisuse. In this work, we present a comprehensive safety assessment of these\nreasoning models, leveraging established safety benchmarks to evaluate their\ncompliance with safety regulations. Furthermore, we investigate their\nsusceptibility to adversarial attacks, such as jailbreaking and prompt\ninjection, to assess their robustness in real-world applications. Through our\nmulti-faceted analysis, we uncover four key findings: (1) There is a\nsignificant safety gap between the open-source R1 models and the o3-mini model,\non both safety benchmark and attack, suggesting more safety effort on R1 is\nneeded. (2) The distilled reasoning model shows poorer safety performance\ncompared to its safety-aligned base models. (3) The stronger the model's\nreasoning ability, the greater the potential harm it may cause when answering\nunsafe questions. (4) The thinking process in R1 models pose greater safety\nconcerns than their final answers. Our study provides insights into the\nsecurity implications of reasoning models and highlights the need for further\nadvancements in R1 models' safety to close the gap.""}","['Kaiwen Zhou', 'Chengzhi Liu', 'Xuandong Zhao', 'Shreedhar Jangam', 'Jayanth Srinivasa', 'Gaowen Liu', 'Dawn Song', 'Xin Eric Wang']",{'name': 'Xin Eric Wang'},Xin Eric Wang,,"[{'href': 'http://arxiv.org/abs/2502.12659v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12659v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12659v1,None,http://arxiv.org/abs/2502.12659v1,,,170,0
http://arxiv.org/abs/2502.12672v1,True,2025-02-18T09:23:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=9, tm_min=23, tm_sec=42, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T09:23:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=9, tm_min=23, tm_sec=42, tm_wday=1, tm_yday=49, tm_isdst=0)","Speech-FT: A Fine-tuning Strategy for Enhancing Speech Representation
  Models Without Compromising Generalization Ability","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Speech-FT: A Fine-tuning Strategy for Enhancing Speech Representation\n  Models Without Compromising Generalization Ability'}","Speech representation models are highly effective at extracting general
features for various tasks. While fine-tuning can enhance these representations
for specific applications, it often compromises their generalization ability.
To address this challenge, we propose Speech-FT, a fine-tuning strategy for
speech representation models that leverages model merging to preserve
generalization ability while still benefiting from fine-tuning. Speech-FT is
effective across different fine-tuning scenarios and is compatible with various
types of speech representation models, providing a versatile solution.
Speech-FT offers an efficient and practical approach to further improving
general speech representations after pre-training.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Speech representation models are highly effective at extracting general\nfeatures for various tasks. While fine-tuning can enhance these representations\nfor specific applications, it often compromises their generalization ability.\nTo address this challenge, we propose Speech-FT, a fine-tuning strategy for\nspeech representation models that leverages model merging to preserve\ngeneralization ability while still benefiting from fine-tuning. Speech-FT is\neffective across different fine-tuning scenarios and is compatible with various\ntypes of speech representation models, providing a versatile solution.\nSpeech-FT offers an efficient and practical approach to further improving\ngeneral speech representations after pre-training.'}","['Tzu-Quan Lin', 'Wei-Ping Huang', 'Hao Tang', 'Hung-yi Lee']",{'name': 'Hung-yi Lee'},Hung-yi Lee,,"[{'href': 'http://arxiv.org/abs/2502.12672v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12672v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12672v1,None,http://arxiv.org/abs/2502.12672v1,,,129,0
http://arxiv.org/abs/2502.12677v1,True,2025-02-18T09:32:29Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=9, tm_min=32, tm_sec=29, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T09:32:29Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=9, tm_min=32, tm_sec=29, tm_wday=1, tm_yday=49, tm_isdst=0)",Spiking Vision Transformer with Saccadic Attention,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Spiking Vision Transformer with Saccadic Attention'}","The combination of Spiking Neural Networks (SNNs) and Vision Transformers
(ViTs) holds potential for achieving both energy efficiency and high
performance, particularly suitable for edge vision applications. However, a
significant performance gap still exists between SNN-based ViTs and their ANN
counterparts. Here, we first analyze why SNN-based ViTs suffer from limited
performance and identify a mismatch between the vanilla self-attention
mechanism and spatio-temporal spike trains. This mismatch results in degraded
spatial relevance and limited temporal interactions. To address these issues,
we draw inspiration from biological saccadic attention mechanisms and introduce
an innovative Saccadic Spike Self-Attention (SSSA) method. Specifically, in the
spatial domain, SSSA employs a novel spike distribution-based method to
effectively assess the relevance between Query and Key pairs in SNN-based ViTs.
Temporally, SSSA employs a saccadic interaction module that dynamically focuses
on selected visual areas at each timestep and significantly enhances whole
scene understanding through temporal interactions. Building on the SSSA
mechanism, we develop a SNN-based Vision Transformer (SNN-ViT). Extensive
experiments across various visual tasks demonstrate that SNN-ViT achieves
state-of-the-art performance with linear computational complexity. The
effectiveness and efficiency of the SNN-ViT highlight its potential for
power-critical edge vision applications.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The combination of Spiking Neural Networks (SNNs) and Vision Transformers\n(ViTs) holds potential for achieving both energy efficiency and high\nperformance, particularly suitable for edge vision applications. However, a\nsignificant performance gap still exists between SNN-based ViTs and their ANN\ncounterparts. Here, we first analyze why SNN-based ViTs suffer from limited\nperformance and identify a mismatch between the vanilla self-attention\nmechanism and spatio-temporal spike trains. This mismatch results in degraded\nspatial relevance and limited temporal interactions. To address these issues,\nwe draw inspiration from biological saccadic attention mechanisms and introduce\nan innovative Saccadic Spike Self-Attention (SSSA) method. Specifically, in the\nspatial domain, SSSA employs a novel spike distribution-based method to\neffectively assess the relevance between Query and Key pairs in SNN-based ViTs.\nTemporally, SSSA employs a saccadic interaction module that dynamically focuses\non selected visual areas at each timestep and significantly enhances whole\nscene understanding through temporal interactions. Building on the SSSA\nmechanism, we develop a SNN-based Vision Transformer (SNN-ViT). Extensive\nexperiments across various visual tasks demonstrate that SNN-ViT achieves\nstate-of-the-art performance with linear computational complexity. The\neffectiveness and efficiency of the SNN-ViT highlight its potential for\npower-critical edge vision applications.'}","['Shuai Wang', 'Malu Zhang', 'Dehao Zhang', 'Ammar Belatreche', 'Yichen Xiao', 'Yu Liang', 'Yimeng Shan', 'Qian Sun', 'Enqi Zhang', 'Yang Yang']",{'name': 'Yang Yang'},Yang Yang,Published as a conference paper at ICLR 2025,"[{'href': 'http://arxiv.org/abs/2502.12677v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12677v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12677v1,None,http://arxiv.org/abs/2502.12677v1,,,2766,0
http://arxiv.org/abs/2502.12737v2,True,2025-02-19T05:32:40Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=5, tm_min=32, tm_sec=40, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-18T10:53:41Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=10, tm_min=53, tm_sec=41, tm_wday=1, tm_yday=49, tm_isdst=0)","Beyond Seen Data: Improving KBQA Generalization Through Schema-Guided
  Logical Form Generation","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Beyond Seen Data: Improving KBQA Generalization Through Schema-Guided\n  Logical Form Generation'}","Knowledge base question answering (KBQA) aims to answer user questions in
natural language using rich human knowledge stored in large KBs. As current
KBQA methods struggle with unseen knowledge base elements at test time,we
introduce SG-KBQA: a novel model that injects schema contexts into entity
retrieval and logical form generation to tackle this issue. It uses the richer
semantics and awareness of the knowledge base structure provided by schema
contexts to enhance generalizability. We show that SG-KBQA achieves strong
generalizability, outperforming state-of-the-art models on two commonly used
benchmark datasets across a variety of test settings. Our source code is
available at https://github.com/gaosx2000/SG_KBQA.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Knowledge base question answering (KBQA) aims to answer user questions in\nnatural language using rich human knowledge stored in large KBs. As current\nKBQA methods struggle with unseen knowledge base elements at test time,we\nintroduce SG-KBQA: a novel model that injects schema contexts into entity\nretrieval and logical form generation to tackle this issue. It uses the richer\nsemantics and awareness of the knowledge base structure provided by schema\ncontexts to enhance generalizability. We show that SG-KBQA achieves strong\ngeneralizability, outperforming state-of-the-art models on two commonly used\nbenchmark datasets across a variety of test settings. Our source code is\navailable at https://github.com/gaosx2000/SG_KBQA.'}","['Shengxiang Gao', 'Jey Han Lau', 'Jianzhong Qi']",{'name': 'Jianzhong Qi'},Jianzhong Qi,17 pages,"[{'href': 'http://arxiv.org/abs/2502.12737v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12737v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12737v2,None,http://arxiv.org/abs/2502.12737v2,,,5409,0
http://arxiv.org/abs/2502.12743v1,True,2025-02-18T11:00:28Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=11, tm_min=0, tm_sec=28, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T11:00:28Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=11, tm_min=0, tm_sec=28, tm_wday=1, tm_yday=49, tm_isdst=0)","""I know myself better, but not really greatly"": Using LLMs to Detect and
  Explain LLM-Generated Texts","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': '""I know myself better, but not really greatly"": Using LLMs to Detect and\n  Explain LLM-Generated Texts'}","Large language models (LLMs) have demonstrated impressive capabilities in
generating human-like texts, but the potential misuse of such LLM-generated
texts raises the need to distinguish between human-generated and LLM-generated
content. This paper explores the detection and explanation capabilities of
LLM-based detectors of LLM-generated texts, in the context of a binary
classification task (human-generated texts vs LLM-generated texts) and a
ternary classification task (human-generated texts, LLM-generated texts, and
undecided). By evaluating on six close/open-source LLMs with different sizes,
our findings reveal that while self-detection consistently outperforms
cross-detection, i.e., LLMs can detect texts generated by themselves more
accurately than those generated by other LLMs, the performance of
self-detection is still far from ideal, indicating that further improvements
are needed. We also show that extending the binary to the ternary
classification task with a new class ""Undecided"" can enhance both detection
accuracy and explanation quality, with improvements being statistically
significant and consistent across all LLMs. We finally conducted comprehensive
qualitative and quantitative analyses on the explanation errors, which are
categorized into three types: reliance on inaccurate features (the most
frequent error), hallucinations, and incorrect reasoning. These findings with
our human-annotated dataset emphasize the need for further research into
improving both self-detection and self-explanation, particularly to address
overfitting issues that may hinder generalization.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large language models (LLMs) have demonstrated impressive capabilities in\ngenerating human-like texts, but the potential misuse of such LLM-generated\ntexts raises the need to distinguish between human-generated and LLM-generated\ncontent. This paper explores the detection and explanation capabilities of\nLLM-based detectors of LLM-generated texts, in the context of a binary\nclassification task (human-generated texts vs LLM-generated texts) and a\nternary classification task (human-generated texts, LLM-generated texts, and\nundecided). By evaluating on six close/open-source LLMs with different sizes,\nour findings reveal that while self-detection consistently outperforms\ncross-detection, i.e., LLMs can detect texts generated by themselves more\naccurately than those generated by other LLMs, the performance of\nself-detection is still far from ideal, indicating that further improvements\nare needed. We also show that extending the binary to the ternary\nclassification task with a new class ""Undecided"" can enhance both detection\naccuracy and explanation quality, with improvements being statistically\nsignificant and consistent across all LLMs. We finally conducted comprehensive\nqualitative and quantitative analyses on the explanation errors, which are\ncategorized into three types: reliance on inaccurate features (the most\nfrequent error), hallucinations, and incorrect reasoning. These findings with\nour human-annotated dataset emphasize the need for further research into\nimproving both self-detection and self-explanation, particularly to address\noverfitting issues that may hinder generalization.'}","['Jiazhou Ji', 'Jie Guo', 'Weidong Qiu', 'Zheng Huang', 'Yang Xu', 'Xinru Lu', 'Xiaoyu Jiang', 'Ruizhe Li', 'Shujun Li']",{'name': 'Shujun Li'},Shujun Li,Under review,"[{'href': 'http://arxiv.org/abs/2502.12743v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12743v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12743v1,None,http://arxiv.org/abs/2502.12743v1,,,288,0
http://arxiv.org/abs/2502.12767v1,True,2025-02-18T11:31:52Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=11, tm_min=31, tm_sec=52, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T11:31:52Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=11, tm_min=31, tm_sec=52, tm_wday=1, tm_yday=49, tm_isdst=0)","R2-KG: General-Purpose Dual-Agent Framework for Reliable Reasoning on
  Knowledge Graphs","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'R2-KG: General-Purpose Dual-Agent Framework for Reliable Reasoning on\n  Knowledge Graphs'}","Recent studies have combined Large Language Models (LLMs) with Knowledge
Graphs (KGs) to enhance reasoning, improving inference accuracy without
additional training while mitigating hallucination. However, existing
frameworks are often rigid, struggling to adapt to KG or task changes. They
also rely heavily on powerful LLMs for reliable (i.e., trustworthy) reasoning.
To address this, We introduce R2-KG, a plug-and-play, dual-agent framework that
separates reasoning into two roles: an Operator (a low-capacity LLM) that
gathers evidence and a Supervisor (a high-capacity LLM) that makes final
judgments. This design is cost-efficient for LLM inference while still
maintaining strong reasoning accuracy. Additionally, R2-KG employs an
Abstention mechanism, generating answers only when sufficient evidence is
collected from KG, which significantly enhances reliability. Experiments across
multiple KG-based reasoning tasks show that R2-KG consistently outperforms
baselines in both accuracy and reliability, regardless of the inherent
capability of LLMs used as the Operator. Further experiments reveal that the
single-agent version of R2-KG, equipped with a strict self-consistency
strategy, achieves significantly higher-than-baseline reliability while
reducing inference cost. However, it also leads to a higher abstention rate in
complex KGs. Our findings establish R2-KG as a flexible and cost-effective
solution for KG-based reasoning. It reduces reliance on high-capacity LLMs
while ensuring trustworthy inference.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Recent studies have combined Large Language Models (LLMs) with Knowledge\nGraphs (KGs) to enhance reasoning, improving inference accuracy without\nadditional training while mitigating hallucination. However, existing\nframeworks are often rigid, struggling to adapt to KG or task changes. They\nalso rely heavily on powerful LLMs for reliable (i.e., trustworthy) reasoning.\nTo address this, We introduce R2-KG, a plug-and-play, dual-agent framework that\nseparates reasoning into two roles: an Operator (a low-capacity LLM) that\ngathers evidence and a Supervisor (a high-capacity LLM) that makes final\njudgments. This design is cost-efficient for LLM inference while still\nmaintaining strong reasoning accuracy. Additionally, R2-KG employs an\nAbstention mechanism, generating answers only when sufficient evidence is\ncollected from KG, which significantly enhances reliability. Experiments across\nmultiple KG-based reasoning tasks show that R2-KG consistently outperforms\nbaselines in both accuracy and reliability, regardless of the inherent\ncapability of LLMs used as the Operator. Further experiments reveal that the\nsingle-agent version of R2-KG, equipped with a strict self-consistency\nstrategy, achieves significantly higher-than-baseline reliability while\nreducing inference cost. However, it also leads to a higher abstention rate in\ncomplex KGs. Our findings establish R2-KG as a flexible and cost-effective\nsolution for KG-based reasoning. It reduces reliance on high-capacity LLMs\nwhile ensuring trustworthy inference.'}","['Sumin Jo', 'Junseong Choi', 'Jiho Kim', 'Edward Choi']",{'name': 'Edward Choi'},Edward Choi,,"[{'href': 'http://arxiv.org/abs/2502.12767v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12767v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12767v1,None,http://arxiv.org/abs/2502.12767v1,,,104,0
http://arxiv.org/abs/2502.12769v2,True,2025-02-20T10:50:09Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=10, tm_min=50, tm_sec=9, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-18T11:32:43Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=11, tm_min=32, tm_sec=43, tm_wday=1, tm_yday=49, tm_isdst=0)","How Much Do LLMs Hallucinate across Languages? On Multilingual
  Estimation of LLM Hallucination in the Wild","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'How Much Do LLMs Hallucinate across Languages? On Multilingual\n  Estimation of LLM Hallucination in the Wild'}","In the age of misinformation, hallucination -- the tendency of Large Language
Models (LLMs) to generate non-factual or unfaithful responses -- represents the
main risk for their global utility. Despite LLMs becoming increasingly
multilingual, the vast majority of research on detecting and quantifying LLM
hallucination are (a) English-centric and (b) focus on machine translation (MT)
and summarization, tasks that are less common ``in the wild'' than open
information seeking. In contrast, we aim to quantify the extent of LLM
hallucination across languages in knowledge-intensive long-form question
answering. To this end, we train a multilingual hallucination detection model
and conduct a large-scale study across 30 languages and 6 open-source LLM
families. We start from an English hallucination detection dataset and rely on
MT to generate (noisy) training data in other languages. We also manually
annotate gold data for five high-resource languages; we then demonstrate, for
these languages, that the estimates of hallucination rates are similar between
silver (LLM-generated) and gold test sets, validating the use of silver data
for estimating hallucination rates for other languages. For the final rates
estimation, we build a knowledge-intensive QA dataset for 30 languages with
LLM-generated prompts and Wikipedia articles as references. We find that, while
LLMs generate longer responses with more hallucinated tokens for
higher-resource languages, there is no correlation between length-normalized
hallucination rates of languages and their digital representation. Further, we
find that smaller LLMs exhibit larger hallucination rates than larger models.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""In the age of misinformation, hallucination -- the tendency of Large Language\nModels (LLMs) to generate non-factual or unfaithful responses -- represents the\nmain risk for their global utility. Despite LLMs becoming increasingly\nmultilingual, the vast majority of research on detecting and quantifying LLM\nhallucination are (a) English-centric and (b) focus on machine translation (MT)\nand summarization, tasks that are less common ``in the wild'' than open\ninformation seeking. In contrast, we aim to quantify the extent of LLM\nhallucination across languages in knowledge-intensive long-form question\nanswering. To this end, we train a multilingual hallucination detection model\nand conduct a large-scale study across 30 languages and 6 open-source LLM\nfamilies. We start from an English hallucination detection dataset and rely on\nMT to generate (noisy) training data in other languages. We also manually\nannotate gold data for five high-resource languages; we then demonstrate, for\nthese languages, that the estimates of hallucination rates are similar between\nsilver (LLM-generated) and gold test sets, validating the use of silver data\nfor estimating hallucination rates for other languages. For the final rates\nestimation, we build a knowledge-intensive QA dataset for 30 languages with\nLLM-generated prompts and Wikipedia articles as references. We find that, while\nLLMs generate longer responses with more hallucinated tokens for\nhigher-resource languages, there is no correlation between length-normalized\nhallucination rates of languages and their digital representation. Further, we\nfind that smaller LLMs exhibit larger hallucination rates than larger models.""}","['Saad Obaid ul Islam', 'Anne Lauscher', 'Goran Glava']",{'name': 'Goran Glava'},Goran Glava,,"[{'href': 'http://arxiv.org/abs/2502.12769v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12769v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12769v2,None,http://arxiv.org/abs/2502.12769v2,,,2966,0
http://arxiv.org/abs/2502.12777v1,True,2025-02-18T11:36:59Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=11, tm_min=36, tm_sec=59, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T11:36:59Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=11, tm_min=36, tm_sec=59, tm_wday=1, tm_yday=49, tm_isdst=0)",Evaluating link prediction: New perspectives and recommendations,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Evaluating link prediction: New perspectives and recommendations'}","Link prediction (LP) is an important problem in network science and machine
learning research. The state-of-the-art LP methods are usually evaluated in a
uniform setup, ignoring several factors associated with the data and
application specific needs. We identify a number of such factors, such as,
network-type, problem-type, geodesic distance between the end nodes and its
distribution over the classes, nature and applicability of LP methods, class
imbalance and its impact on early retrieval, evaluation metric, etc., and
present an experimental setup which allows us to evaluate LP methods in a
rigorous and controlled manner. We perform extensive experiments with a variety
of LP methods over real network datasets in this controlled setup, and gather
valuable insights on the interactions of these factors with the performance of
LP through an array of carefully designed hypotheses. Following the insights,
we provide recommendations to be followed as best practice for evaluating LP
methods.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Link prediction (LP) is an important problem in network science and machine\nlearning research. The state-of-the-art LP methods are usually evaluated in a\nuniform setup, ignoring several factors associated with the data and\napplication specific needs. We identify a number of such factors, such as,\nnetwork-type, problem-type, geodesic distance between the end nodes and its\ndistribution over the classes, nature and applicability of LP methods, class\nimbalance and its impact on early retrieval, evaluation metric, etc., and\npresent an experimental setup which allows us to evaluate LP methods in a\nrigorous and controlled manner. We perform extensive experiments with a variety\nof LP methods over real network datasets in this controlled setup, and gather\nvaluable insights on the interactions of these factors with the performance of\nLP through an array of carefully designed hypotheses. Following the insights,\nwe provide recommendations to be followed as best practice for evaluating LP\nmethods.'}","['Bhargavi Kalyani I', 'A Rama Prasad Mathi', 'Niladri Sett']",{'name': 'Niladri Sett'},Niladri Sett,,"[{'href': 'http://arxiv.org/abs/2502.12777v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12777v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12777v1,None,http://arxiv.org/abs/2502.12777v1,,,89,0
http://arxiv.org/abs/2502.12825v2,True,2025-02-19T11:57:19Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=11, tm_min=57, tm_sec=19, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-18T12:46:18Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=12, tm_min=46, tm_sec=18, tm_wday=1, tm_yday=49, tm_isdst=0)","Reasoning and the Trusting Behavior of DeepSeek and GPT: An Experiment
  Revealing Hidden Fault Lines in Large Language Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Reasoning and the Trusting Behavior of DeepSeek and GPT: An Experiment\n  Revealing Hidden Fault Lines in Large Language Models'}","When encountering increasingly frequent performance improvements or cost
reductions from a new large language model (LLM), developers of applications
leveraging LLMs must decide whether to take advantage of these improvements or
stay with older tried-and-tested models. Low perceived switching frictions can
lead to choices that do not consider more subtle behavior changes that the
transition may induce. Our experiments use a popular game-theoretic behavioral
economics model of trust to show stark differences in the trusting behavior of
OpenAI's and DeepSeek's models. We highlight a collapse in the economic trust
behavior of the o1-mini and o3-mini models as they reconcile profit-maximizing
and risk-seeking with future returns from trust, and contrast it with
DeepSeek's more sophisticated and profitable trusting behavior that stems from
an ability to incorporate deeper concepts like forward planning and
theory-of-mind. As LLMs form the basis for high-stakes commercial systems, our
results highlight the perils of relying on LLM performance benchmarks that are
too narrowly defined and suggest that careful analysis of their hidden fault
lines should be part of any organization's AI strategy.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""When encountering increasingly frequent performance improvements or cost\nreductions from a new large language model (LLM), developers of applications\nleveraging LLMs must decide whether to take advantage of these improvements or\nstay with older tried-and-tested models. Low perceived switching frictions can\nlead to choices that do not consider more subtle behavior changes that the\ntransition may induce. Our experiments use a popular game-theoretic behavioral\neconomics model of trust to show stark differences in the trusting behavior of\nOpenAI's and DeepSeek's models. We highlight a collapse in the economic trust\nbehavior of the o1-mini and o3-mini models as they reconcile profit-maximizing\nand risk-seeking with future returns from trust, and contrast it with\nDeepSeek's more sophisticated and profitable trusting behavior that stems from\nan ability to incorporate deeper concepts like forward planning and\ntheory-of-mind. As LLMs form the basis for high-stakes commercial systems, our\nresults highlight the perils of relying on LLM performance benchmarks that are\ntoo narrowly defined and suggest that careful analysis of their hidden fault\nlines should be part of any organization's AI strategy.""}","['Rubing Li', 'Joo Sedoc', 'Arun Sundararajan']",{'name': 'Arun Sundararajan'},Arun Sundararajan,,"[{'href': 'http://arxiv.org/abs/2502.12825v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12825v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12825v2,None,http://arxiv.org/abs/2502.12825v2,,,3,0
http://arxiv.org/abs/2502.12842v1,True,2025-02-18T13:22:14Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=13, tm_min=22, tm_sec=14, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T13:22:14Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=13, tm_min=22, tm_sec=14, tm_wday=1, tm_yday=49, tm_isdst=0)","Towards Adaptive Feedback with AI: Comparing the Feedback Quality of
  LLMs and Teachers on Experimentation Protocols","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Towards Adaptive Feedback with AI: Comparing the Feedback Quality of\n  LLMs and Teachers on Experimentation Protocols'}","Effective feedback is essential for fostering students' success in scientific
inquiry. With advancements in artificial intelligence, large language models
(LLMs) offer new possibilities for delivering instant and adaptive feedback.
However, this feedback often lacks the pedagogical validation provided by
real-world practitioners. To address this limitation, our study evaluates and
compares the feedback quality of LLM agents with that of human teachers and
science education experts on student-written experimentation protocols. Four
blinded raters, all professionals in scientific inquiry and science education,
evaluated the feedback texts generated by 1) the LLM agent, 2) the teachers and
3) the science education experts using a five-point Likert scale based on six
criteria of effective feedback: Feed Up, Feed Back, Feed Forward, Constructive
Tone, Linguistic Clarity, and Technical Terminology. Our results indicate that
LLM-generated feedback shows no significant difference to that of teachers and
experts in overall quality. However, the LLM agent's performance lags in the
Feed Back dimension, which involves identifying and explaining errors within
the student's work context. Qualitative analysis highlighted the LLM agent's
limitations in contextual understanding and in the clear communication of
specific errors. Our findings suggest that combining LLM-generated feedback
with human expertise can enhance educational practices by leveraging the
efficiency of LLMs and the nuanced understanding of educators.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Effective feedback is essential for fostering students' success in scientific\ninquiry. With advancements in artificial intelligence, large language models\n(LLMs) offer new possibilities for delivering instant and adaptive feedback.\nHowever, this feedback often lacks the pedagogical validation provided by\nreal-world practitioners. To address this limitation, our study evaluates and\ncompares the feedback quality of LLM agents with that of human teachers and\nscience education experts on student-written experimentation protocols. Four\nblinded raters, all professionals in scientific inquiry and science education,\nevaluated the feedback texts generated by 1) the LLM agent, 2) the teachers and\n3) the science education experts using a five-point Likert scale based on six\ncriteria of effective feedback: Feed Up, Feed Back, Feed Forward, Constructive\nTone, Linguistic Clarity, and Technical Terminology. Our results indicate that\nLLM-generated feedback shows no significant difference to that of teachers and\nexperts in overall quality. However, the LLM agent's performance lags in the\nFeed Back dimension, which involves identifying and explaining errors within\nthe student's work context. Qualitative analysis highlighted the LLM agent's\nlimitations in contextual understanding and in the clear communication of\nspecific errors. Our findings suggest that combining LLM-generated feedback\nwith human expertise can enhance educational practices by leveraging the\nefficiency of LLMs and the nuanced understanding of educators.""}","['Kathrin Seler', 'Arne Bewersdorff', 'Claudia Nerdel', 'Enkelejda Kasneci']",{'name': 'Enkelejda Kasneci'},Enkelejda Kasneci,This work has been submitted to the IJAIED for possible publication,"[{'href': 'http://arxiv.org/abs/2502.12842v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12842v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12842v1,None,http://arxiv.org/abs/2502.12842v1,,,13375,0
http://arxiv.org/abs/2502.12851v1,True,2025-02-18T13:39:22Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=13, tm_min=39, tm_sec=22, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T13:39:22Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=13, tm_min=39, tm_sec=22, tm_wday=1, tm_yday=49, tm_isdst=0)",MeMo: Towards Language Models with Associative Memory Mechanisms,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'MeMo: Towards Language Models with Associative Memory Mechanisms'}","Memorization is a fundamental ability of Transformer-based Large Language
Models, achieved through learning. In this paper, we propose a paradigm shift
by designing an architecture to memorize text directly, bearing in mind the
principle that memorization precedes learning. We introduce MeMo, a novel
architecture for language modeling that explicitly memorizes sequences of
tokens in layered associative memories. By design, MeMo offers transparency and
the possibility of model editing, including forgetting texts. We experimented
with the MeMo architecture, showing the memorization power of the one-layer and
the multi-layer configurations.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Memorization is a fundamental ability of Transformer-based Large Language\nModels, achieved through learning. In this paper, we propose a paradigm shift\nby designing an architecture to memorize text directly, bearing in mind the\nprinciple that memorization precedes learning. We introduce MeMo, a novel\narchitecture for language modeling that explicitly memorizes sequences of\ntokens in layered associative memories. By design, MeMo offers transparency and\nthe possibility of model editing, including forgetting texts. We experimented\nwith the MeMo architecture, showing the memorization power of the one-layer and\nthe multi-layer configurations.'}","['Fabio Massimo Zanzotto', 'Elena Sofia Ruzzetti', 'Giancarlo A. Xompero', 'Leonardo Ranaldi', 'Davide Venditti', 'Federico Ranaldi', 'Cristina Giannone', 'Andrea Favalli', 'Raniero Romagnoli']",{'name': 'Raniero Romagnoli'},Raniero Romagnoli,,"[{'href': 'http://arxiv.org/abs/2502.12851v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12851v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7; I.2.6; I.2.4', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12851v1,None,http://arxiv.org/abs/2502.12851v1,,,1126,0
http://arxiv.org/abs/2502.12859v1,True,2025-02-18T13:46:47Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=13, tm_min=46, tm_sec=47, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T13:46:47Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=13, tm_min=46, tm_sec=47, tm_wday=1, tm_yday=49, tm_isdst=0)",PAFT: Prompt-Agnostic Fine-Tuning,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'PAFT: Prompt-Agnostic Fine-Tuning'}","While Large Language Models (LLMs) adapt well to downstream tasks after
fine-tuning, this adaptability often compromises prompt robustness, as even
minor prompt variations can significantly degrade performance. To address this,
we propose Prompt-Agnostic Fine-Tuning(PAFT), a simple yet effective approach
that dynamically adjusts prompts during fine-tuning. This encourages the model
to learn underlying task principles rather than overfitting to specific prompt
formulations. PAFT operates in two stages: First, a diverse set of meaningful,
synthetic candidate prompts is constructed. Second, during fine-tuning, prompts
are randomly sampled from this set to create dynamic training inputs. Extensive
experiments across diverse datasets and LLMs demonstrate that models trained
with PAFT exhibit strong robustness and generalization across a wide range of
prompts, including unseen ones. This enhanced robustness improves both model
performance and inference speed while maintaining training efficiency. Ablation
studies further confirm the effectiveness of PAFT.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'While Large Language Models (LLMs) adapt well to downstream tasks after\nfine-tuning, this adaptability often compromises prompt robustness, as even\nminor prompt variations can significantly degrade performance. To address this,\nwe propose Prompt-Agnostic Fine-Tuning(PAFT), a simple yet effective approach\nthat dynamically adjusts prompts during fine-tuning. This encourages the model\nto learn underlying task principles rather than overfitting to specific prompt\nformulations. PAFT operates in two stages: First, a diverse set of meaningful,\nsynthetic candidate prompts is constructed. Second, during fine-tuning, prompts\nare randomly sampled from this set to create dynamic training inputs. Extensive\nexperiments across diverse datasets and LLMs demonstrate that models trained\nwith PAFT exhibit strong robustness and generalization across a wide range of\nprompts, including unseen ones. This enhanced robustness improves both model\nperformance and inference speed while maintaining training efficiency. Ablation\nstudies further confirm the effectiveness of PAFT.'}","['Chenxing Wei', 'Yao Shu', 'Mingwen Ou', 'Ying Tiffany He', 'Fei Richard Yu']",{'name': 'Fei Richard Yu'},Fei Richard Yu,"20 pages, 6 figures","[{'href': 'http://arxiv.org/abs/2502.12859v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12859v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12859v1,None,http://arxiv.org/abs/2502.12859v1,,,6,0
http://arxiv.org/abs/2502.12908v2,True,2025-02-19T05:09:09Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=5, tm_min=9, tm_sec=9, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-18T14:51:50Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=14, tm_min=51, tm_sec=50, tm_wday=1, tm_yday=49, tm_isdst=0)",Graph Neural Networks for Databases: A Survey,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Graph Neural Networks for Databases: A Survey'}","Graph neural networks (GNNs) are powerful deep learning models for
graph-structured data, demonstrating remarkable success across diverse domains.
Recently, the database (DB) community has increasingly recognized the
potentiality of GNNs, prompting a surge of researches focusing on improving
database systems through GNN-based approaches. However, despite notable
advances, There is a lack of a comprehensive review and understanding of how
GNNs could improve DB systems. Therefore, this survey aims to bridge this gap
by providing a structured and in-depth overview of GNNs for DB systems.
Specifically, we propose a new taxonomy that classifies existing methods into
two key categories: (1) Relational Databases, which includes tasks like
performance prediction, query optimization, and text-to-SQL, and (2) Graph
Databases, addressing challenges like efficient graph query processing and
graph similarity computation. We systematically review key methods in each
category, highlighting their contributions and practical implications. Finally,
we suggest promising avenues for integrating GNNs into Database systems.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Graph neural networks (GNNs) are powerful deep learning models for\ngraph-structured data, demonstrating remarkable success across diverse domains.\nRecently, the database (DB) community has increasingly recognized the\npotentiality of GNNs, prompting a surge of researches focusing on improving\ndatabase systems through GNN-based approaches. However, despite notable\nadvances, There is a lack of a comprehensive review and understanding of how\nGNNs could improve DB systems. Therefore, this survey aims to bridge this gap\nby providing a structured and in-depth overview of GNNs for DB systems.\nSpecifically, we propose a new taxonomy that classifies existing methods into\ntwo key categories: (1) Relational Databases, which includes tasks like\nperformance prediction, query optimization, and text-to-SQL, and (2) Graph\nDatabases, addressing challenges like efficient graph query processing and\ngraph similarity computation. We systematically review key methods in each\ncategory, highlighting their contributions and practical implications. Finally,\nwe suggest promising avenues for integrating GNNs into Database systems.'}","['Ziming Li', 'Youhuan Li', 'Yuyu Luo', 'Guoliang Li', 'Chuxu Zhang']",{'name': 'Chuxu Zhang'},Chuxu Zhang,"A survey focus on GNNs and databases. 9 pages, 4 figures","[{'href': 'http://arxiv.org/abs/2502.12908v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12908v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.DB', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.DB', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12908v2,None,http://arxiv.org/abs/2502.12908v2,,,86,0
http://arxiv.org/abs/2502.12924v1,True,2025-02-18T15:04:13Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=15, tm_min=4, tm_sec=13, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T15:04:13Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=15, tm_min=4, tm_sec=13, tm_wday=1, tm_yday=49, tm_isdst=0)","Conditioning LLMs to Generate Code-Switched Text: A Methodology Grounded
  in Naturally Occurring Data","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Conditioning LLMs to Generate Code-Switched Text: A Methodology Grounded\n  in Naturally Occurring Data'}","Code-switching (CS) is still a critical challenge in Natural Language
Processing (NLP). Current Large Language Models (LLMs) struggle to interpret
and generate code-switched text, primarily due to the scarcity of large-scale
CS datasets for training. This paper presents a novel methodology to generate
CS data using LLMs, and test it on the English-Spanish language pair. We
propose back-translating natural CS sentences into monolingual English, and
using the resulting parallel corpus to fine-tune LLMs to turn monolingual
sentences into CS. Unlike previous approaches to CS generation, our methodology
uses natural CS data as a starting point, allowing models to learn its natural
distribution beyond grammatical patterns. We thoroughly analyse the models'
performance through a study on human preferences, a qualitative error analysis
and an evaluation with popular automatic metrics. Results show that our
methodology generates fluent code-switched text, expanding research
opportunities in CS communication, and that traditional metrics do not
correlate with human judgement when assessing the quality of the generated CS
data. We release our code and generated dataset under a CC-BY-NC-SA license.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Code-switching (CS) is still a critical challenge in Natural Language\nProcessing (NLP). Current Large Language Models (LLMs) struggle to interpret\nand generate code-switched text, primarily due to the scarcity of large-scale\nCS datasets for training. This paper presents a novel methodology to generate\nCS data using LLMs, and test it on the English-Spanish language pair. We\npropose back-translating natural CS sentences into monolingual English, and\nusing the resulting parallel corpus to fine-tune LLMs to turn monolingual\nsentences into CS. Unlike previous approaches to CS generation, our methodology\nuses natural CS data as a starting point, allowing models to learn its natural\ndistribution beyond grammatical patterns. We thoroughly analyse the models'\nperformance through a study on human preferences, a qualitative error analysis\nand an evaluation with popular automatic metrics. Results show that our\nmethodology generates fluent code-switched text, expanding research\nopportunities in CS communication, and that traditional metrics do not\ncorrelate with human judgement when assessing the quality of the generated CS\ndata. We release our code and generated dataset under a CC-BY-NC-SA license.""}","['Maite Heredia', 'Gorka Labaka', 'Jeremy Barnes', 'Aitor Soroa']",{'name': 'Aitor Soroa'},Aitor Soroa,,"[{'href': 'http://arxiv.org/abs/2502.12924v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12924v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12924v1,None,http://arxiv.org/abs/2502.12924v1,,,213,0
http://arxiv.org/abs/2502.12925v1,True,2025-02-18T15:04:33Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=15, tm_min=4, tm_sec=33, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T15:04:33Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=15, tm_min=4, tm_sec=33, tm_wday=1, tm_yday=49, tm_isdst=0)","Keep what you need : extracting efficient subnetworks from large audio
  representation models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Keep what you need : extracting efficient subnetworks from large audio\n  representation models'}","Recently, research on audio foundation models has witnessed notable advances,
as illustrated by the ever improving results on complex downstream tasks.
Subsequently, those pretrained networks have quickly been used for various
audio applications. These improvements have however resulted in a considerable
increase both in size and complexity of these models. Along the environmental
concerns this issue raises, this prevents the deployment of such networks on
consumer-level devices, and precludes their use for real-time applications.
Moreover, this appears contradictory with the specificity of the tasks for
which these models are used, which are often simpler compared to extracting a
rich, multi-purpose representation from any type of audio data. In this paper,
we address this issue with a simple, yet effective method to extract
lightweight specialist subnetworks from large foundation models. Specifically,
we introduce learnable binary masks in-between the layers of a pretrained
representation model. When training the end-to-end model on a downstream task,
we add a sparsity-inducing loss to the overall objective, hence learning a
compact subnetwork specialized on a single task. Importantly, the weights of
the foundation model are kept frozen, resulting into low additional training
costs. Once trained, the masked computational units can then be removed from
the network, implying significant performance gains. We assess our method on
three widespread audio foundation models, each based on a different backbone
architecture, and illustrate its effectiveness on common audio representation
evaluation tasks, as well as its versatility on both speech, music, and general
audio. Code for reproducing the results and supporting webpage are available at
https://github.com/gnvIRCAM/Audio-representation-trimming","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Recently, research on audio foundation models has witnessed notable advances,\nas illustrated by the ever improving results on complex downstream tasks.\nSubsequently, those pretrained networks have quickly been used for various\naudio applications. These improvements have however resulted in a considerable\nincrease both in size and complexity of these models. Along the environmental\nconcerns this issue raises, this prevents the deployment of such networks on\nconsumer-level devices, and precludes their use for real-time applications.\nMoreover, this appears contradictory with the specificity of the tasks for\nwhich these models are used, which are often simpler compared to extracting a\nrich, multi-purpose representation from any type of audio data. In this paper,\nwe address this issue with a simple, yet effective method to extract\nlightweight specialist subnetworks from large foundation models. Specifically,\nwe introduce learnable binary masks in-between the layers of a pretrained\nrepresentation model. When training the end-to-end model on a downstream task,\nwe add a sparsity-inducing loss to the overall objective, hence learning a\ncompact subnetwork specialized on a single task. Importantly, the weights of\nthe foundation model are kept frozen, resulting into low additional training\ncosts. Once trained, the masked computational units can then be removed from\nthe network, implying significant performance gains. We assess our method on\nthree widespread audio foundation models, each based on a different backbone\narchitecture, and illustrate its effectiveness on common audio representation\nevaluation tasks, as well as its versatility on both speech, music, and general\naudio. Code for reproducing the results and supporting webpage are available at\nhttps://github.com/gnvIRCAM/Audio-representation-trimming'}","['David Genova', 'Philippe Esling', 'Tom Hurlin']",{'name': 'Tom Hurlin'},Tom Hurlin,,"[{'href': 'http://arxiv.org/abs/2502.12925v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12925v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.SD', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.SD', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12925v1,None,http://arxiv.org/abs/2502.12925v1,,,3340,0
http://arxiv.org/abs/2502.12948v1,True,2025-02-18T15:30:48Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=15, tm_min=30, tm_sec=48, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T15:30:48Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=15, tm_min=30, tm_sec=48, tm_wday=1, tm_yday=49, tm_isdst=0)","Fake It Till You Make It: Using Synthetic Data and Domain Knowledge for
  Improved Text-Based Learning for LGE Detection","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Fake It Till You Make It: Using Synthetic Data and Domain Knowledge for\n  Improved Text-Based Learning for LGE Detection'}","Detection of hyperenhancement from cardiac LGE MRI images is a complex task
requiring significant clinical expertise. Although deep learning-based models
have shown promising results for the task, they require large amounts of data
with fine-grained annotations. Clinical reports generated for cardiac MR
studies contain rich, clinically relevant information, including the location,
extent and etiology of any scars present. Although recently developed
CLIP-based training enables pretraining models with image-text pairs, it
requires large amounts of data and further finetuning strategies on downstream
tasks. In this study, we use various strategies rooted in domain knowledge to
train a model for LGE detection solely using text from clinical reports, on a
relatively small clinical cohort of 965 patients. We improve performance
through the use of synthetic data augmentation, by systematically creating scar
images and associated text. In addition, we standardize the orientation of the
images in an anatomy-informed way to enable better alignment of spatial and
text features. We also use a captioning loss to enable fine-grained supervision
and explore the effect of pretraining of the vision encoder on performance.
Finally, ablation studies are carried out to elucidate the contributions of
each design component to the overall performance of the model.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Detection of hyperenhancement from cardiac LGE MRI images is a complex task\nrequiring significant clinical expertise. Although deep learning-based models\nhave shown promising results for the task, they require large amounts of data\nwith fine-grained annotations. Clinical reports generated for cardiac MR\nstudies contain rich, clinically relevant information, including the location,\nextent and etiology of any scars present. Although recently developed\nCLIP-based training enables pretraining models with image-text pairs, it\nrequires large amounts of data and further finetuning strategies on downstream\ntasks. In this study, we use various strategies rooted in domain knowledge to\ntrain a model for LGE detection solely using text from clinical reports, on a\nrelatively small clinical cohort of 965 patients. We improve performance\nthrough the use of synthetic data augmentation, by systematically creating scar\nimages and associated text. In addition, we standardize the orientation of the\nimages in an anatomy-informed way to enable better alignment of spatial and\ntext features. We also use a captioning loss to enable fine-grained supervision\nand explore the effect of pretraining of the vision encoder on performance.\nFinally, ablation studies are carried out to elucidate the contributions of\neach design component to the overall performance of the model.'}","['Athira J Jacob', 'Puneet Sharma', 'Daniel Rueckert']",{'name': 'Daniel Rueckert'},Daniel Rueckert,"Poster at Workshop on Large Language Models and Generative AI for
  Health at AAAI 2025","[{'href': 'http://arxiv.org/abs/2502.12948v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12948v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12948v1,None,http://arxiv.org/abs/2502.12948v1,,,283,0
http://arxiv.org/abs/2502.12959v1,True,2025-02-18T15:43:27Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=15, tm_min=43, tm_sec=27, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T15:43:27Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=15, tm_min=43, tm_sec=27, tm_wday=1, tm_yday=49, tm_isdst=0)","AlignFreeze: Navigating the Impact of Realignment on the Layers of
  Multilingual Models Across Diverse Languages","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'AlignFreeze: Navigating the Impact of Realignment on the Layers of\n  Multilingual Models Across Diverse Languages'}","Realignment techniques are often employed to enhance cross-lingual transfer
in multilingual language models, still, they can sometimes degrade performance
in languages that differ significantly from the fine-tuned source language.
This paper introduces AlignFreeze, a method that freezes either the layers'
lower half or upper half during realignment. Through controlled experiments on
4 tasks, 3 models, and in 35 languages, we find that realignment affects all
the layers but can be the most detrimental to the lower ones. Freezing the
lower layers can prevent performance degradation. Particularly, AlignFreeze
improves Part-of-Speech (PoS) tagging performances in languages where full
realignment fails: with XLM-R, it provides improvements of more than one
standard deviation in accuracy in seven more languages than full realignment.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Realignment techniques are often employed to enhance cross-lingual transfer\nin multilingual language models, still, they can sometimes degrade performance\nin languages that differ significantly from the fine-tuned source language.\nThis paper introduces AlignFreeze, a method that freezes either the layers'\nlower half or upper half during realignment. Through controlled experiments on\n4 tasks, 3 models, and in 35 languages, we find that realignment affects all\nthe layers but can be the most detrimental to the lower ones. Freezing the\nlower layers can prevent performance degradation. Particularly, AlignFreeze\nimproves Part-of-Speech (PoS) tagging performances in languages where full\nrealignment fails: with XLM-R, it provides improvements of more than one\nstandard deviation in accuracy in seven more languages than full realignment.""}","['Steve Bakos', 'Flix Gaschi', 'David Guzmn', 'Riddhi More', 'Kelly Chutong Li', 'En-Shiun Annie Lee']",{'name': 'En-Shiun Annie Lee'},En-Shiun Annie Lee,"24 pages, 2 figures, to be published in Proceedings of NAACL 2025","[{'href': 'http://arxiv.org/abs/2502.12959v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12959v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12959v1,None,http://arxiv.org/abs/2502.12959v1,,,21,0
http://arxiv.org/abs/2502.12961v1,True,2025-02-18T15:45:01Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=15, tm_min=45, tm_sec=1, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T15:45:01Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=15, tm_min=45, tm_sec=1, tm_wday=1, tm_yday=49, tm_isdst=0)",Adaptive Tool Use in Large Language Models with Meta-Cognition Trigger,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Adaptive Tool Use in Large Language Models with Meta-Cognition Trigger'}","Large language models (LLMs) have shown remarkable emergent capabilities,
transforming the execution of functional tasks by leveraging external tools for
complex problems that require specialized processing or real-time data. While
existing research expands LLMs access to diverse tools (e.g., program
interpreters, search engines, weather/map apps), the necessity of using these
tools is often overlooked, leading to indiscriminate tool invocation. This
naive approach raises two key issues:(1) increased delays due to unnecessary
tool calls, and (2) potential errors resulting from faulty interactions with
external tools. In this paper, we introduce meta-cognition as a proxy for LLMs
self-assessment of their capabilities, representing the model's awareness of
its own limitations. Based on this, we propose MeCo, an adaptive
decision-making strategy for external tool use. MeCo quantifies metacognitive
scores by capturing high-level cognitive signals in the representation space,
guiding when to invoke tools. Notably, MeCo is fine-tuning-free and incurs
minimal cost. Our experiments show that MeCo accurately detects LLMs' internal
cognitive signals and significantly improves tool-use decision-making across
multiple base models and benchmarks.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Large language models (LLMs) have shown remarkable emergent capabilities,\ntransforming the execution of functional tasks by leveraging external tools for\ncomplex problems that require specialized processing or real-time data. While\nexisting research expands LLMs access to diverse tools (e.g., program\ninterpreters, search engines, weather/map apps), the necessity of using these\ntools is often overlooked, leading to indiscriminate tool invocation. This\nnaive approach raises two key issues:(1) increased delays due to unnecessary\ntool calls, and (2) potential errors resulting from faulty interactions with\nexternal tools. In this paper, we introduce meta-cognition as a proxy for LLMs\nself-assessment of their capabilities, representing the model's awareness of\nits own limitations. Based on this, we propose MeCo, an adaptive\ndecision-making strategy for external tool use. MeCo quantifies metacognitive\nscores by capturing high-level cognitive signals in the representation space,\nguiding when to invoke tools. Notably, MeCo is fine-tuning-free and incurs\nminimal cost. Our experiments show that MeCo accurately detects LLMs' internal\ncognitive signals and significantly improves tool-use decision-making across\nmultiple base models and benchmarks.""}","['Wenjun Li', 'Dexun Li', 'Kuicai Dong', 'Cong Zhang', 'Hao Zhang', 'Weiwen Liu', 'Yasheng Wang', 'Ruiming Tang', 'Yong Liu']",{'name': 'Yong Liu'},Yong Liu,,"[{'href': 'http://arxiv.org/abs/2502.12961v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12961v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12961v1,None,http://arxiv.org/abs/2502.12961v1,,,268,0
http://arxiv.org/abs/2502.12985v1,True,2025-02-18T16:08:47Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=16, tm_min=8, tm_sec=47, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T16:08:47Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=16, tm_min=8, tm_sec=47, tm_wday=1, tm_yday=49, tm_isdst=0)","PartSDF: Part-Based Implicit Neural Representation for Composite 3D
  Shape Parametrization and Optimization","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'PartSDF: Part-Based Implicit Neural Representation for Composite 3D\n  Shape Parametrization and Optimization'}","Accurate 3D shape representation is essential in engineering applications
such as design, optimization, and simulation. In practice, engineering
workflows require structured, part-aware representations, as objects are
inherently designed as assemblies of distinct components. However, most
existing methods either model shapes holistically or decompose them without
predefined part structures, limiting their applicability in real-world design
tasks. We propose PartSDF, a supervised implicit representation framework that
explicitly models composite shapes with independent, controllable parts while
maintaining shape consistency. Despite its simple single-decoder architecture,
PartSDF outperforms both supervised and unsupervised baselines in
reconstruction and generation tasks. We further demonstrate its effectiveness
as a structured shape prior for engineering applications, enabling precise
control over individual components while preserving overall coherence. Code
available at https://github.com/cvlab-epfl/PartSDF.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Accurate 3D shape representation is essential in engineering applications\nsuch as design, optimization, and simulation. In practice, engineering\nworkflows require structured, part-aware representations, as objects are\ninherently designed as assemblies of distinct components. However, most\nexisting methods either model shapes holistically or decompose them without\npredefined part structures, limiting their applicability in real-world design\ntasks. We propose PartSDF, a supervised implicit representation framework that\nexplicitly models composite shapes with independent, controllable parts while\nmaintaining shape consistency. Despite its simple single-decoder architecture,\nPartSDF outperforms both supervised and unsupervised baselines in\nreconstruction and generation tasks. We further demonstrate its effectiveness\nas a structured shape prior for engineering applications, enabling precise\ncontrol over individual components while preserving overall coherence. Code\navailable at https://github.com/cvlab-epfl/PartSDF.'}","['Nicolas Talabot', 'Olivier Clerc', 'Arda Cinar Demirtas', 'Doruk Oner', 'Pascal Fua']",{'name': 'Pascal Fua'},Pascal Fua,"22 pages, 14 figures","[{'href': 'http://arxiv.org/abs/2502.12985v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12985v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12985v1,None,http://arxiv.org/abs/2502.12985v1,,,83,0
http://arxiv.org/abs/2502.12992v1,True,2025-02-18T16:13:08Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=16, tm_min=13, tm_sec=8, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T16:13:08Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=16, tm_min=13, tm_sec=8, tm_wday=1, tm_yday=49, tm_isdst=0)","B-cos LM: Efficiently Transforming Pre-trained Language Models for
  Improved Explainability","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'B-cos LM: Efficiently Transforming Pre-trained Language Models for\n  Improved Explainability'}","Post-hoc explanation methods for black-box models often struggle with
faithfulness and human interpretability due to the lack of explainability in
current neural models. Meanwhile, B-cos networks have been introduced to
improve model explainability through architectural and computational
adaptations, but their application has so far been limited to computer vision
models and their associated training pipelines. In this work, we introduce
B-cos LMs, i.e., B-cos networks empowered for NLP tasks. Our approach directly
transforms pre-trained language models into B-cos LMs by combining B-cos
conversion and task fine-tuning, improving efficiency compared to previous
B-cos methods. Our automatic and human evaluation results demonstrate that
B-cos LMs produce more faithful and human interpretable explanations than post
hoc methods, while maintaining task performance comparable to conventional
fine-tuning. Our in-depth analysis explores how B-cos LMs differ from
conventionally fine-tuned models in their learning processes and explanation
patterns. Finally, we provide practical guidelines for effectively building
B-cos LMs based on our findings. Our code is available at
https://anonymous.4open.science/r/bcos_lm.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Post-hoc explanation methods for black-box models often struggle with\nfaithfulness and human interpretability due to the lack of explainability in\ncurrent neural models. Meanwhile, B-cos networks have been introduced to\nimprove model explainability through architectural and computational\nadaptations, but their application has so far been limited to computer vision\nmodels and their associated training pipelines. In this work, we introduce\nB-cos LMs, i.e., B-cos networks empowered for NLP tasks. Our approach directly\ntransforms pre-trained language models into B-cos LMs by combining B-cos\nconversion and task fine-tuning, improving efficiency compared to previous\nB-cos methods. Our automatic and human evaluation results demonstrate that\nB-cos LMs produce more faithful and human interpretable explanations than post\nhoc methods, while maintaining task performance comparable to conventional\nfine-tuning. Our in-depth analysis explores how B-cos LMs differ from\nconventionally fine-tuned models in their learning processes and explanation\npatterns. Finally, we provide practical guidelines for effectively building\nB-cos LMs based on our findings. Our code is available at\nhttps://anonymous.4open.science/r/bcos_lm.'}","['Yifan Wang', 'Sukrut Rao', 'Ji-Ung Lee', 'Mayank Jobanputra', 'Vera Demberg']",{'name': 'Vera Demberg'},Vera Demberg,"20 pages, 15 figures","[{'href': 'http://arxiv.org/abs/2502.12992v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12992v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12992v1,None,http://arxiv.org/abs/2502.12992v1,,,295,0
http://arxiv.org/abs/2502.13001v1,True,2025-02-18T16:21:22Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=16, tm_min=21, tm_sec=22, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T16:21:22Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=16, tm_min=21, tm_sec=22, tm_wday=1, tm_yday=49, tm_isdst=0)","You need to MIMIC to get FAME: Solving Meeting Transcript Scarcity with
  a Multi-Agent Conversations","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'You need to MIMIC to get FAME: Solving Meeting Transcript Scarcity with\n  a Multi-Agent Conversations'}","Meeting summarization suffers from limited high-quality data, mainly due to
privacy restrictions and expensive collection processes. We address this gap
with FAME, a dataset of 500 meetings in English and 300 in German produced by
MIMIC, our new multi-agent meeting synthesis framework that generates meeting
transcripts on a given knowledge source by defining psychologically grounded
participant profiles, outlining the conversation, and orchestrating a large
language model (LLM) debate. A modular post-processing step refines these
outputs, mitigating potential repetitiveness and overly formal tones, ensuring
coherent, credible dialogues at scale. We also propose a psychologically
grounded evaluation framework assessing naturalness, social behavior
authenticity, and transcript difficulties. Human assessments show that FAME
approximates real-meeting spontaneity (4.5/5 in naturalness), preserves
speaker-centric challenges (3/5 in spoken language), and introduces richer
information-oriented difficulty (4/5 in difficulty). These findings highlight
that FAME is a good and scalable proxy for real-world meeting conditions. It
enables new test scenarios for meeting summarization research and other
conversation-centric applications in tasks requiring conversation data or
simulating social scenarios under behavioral constraints.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Meeting summarization suffers from limited high-quality data, mainly due to\nprivacy restrictions and expensive collection processes. We address this gap\nwith FAME, a dataset of 500 meetings in English and 300 in German produced by\nMIMIC, our new multi-agent meeting synthesis framework that generates meeting\ntranscripts on a given knowledge source by defining psychologically grounded\nparticipant profiles, outlining the conversation, and orchestrating a large\nlanguage model (LLM) debate. A modular post-processing step refines these\noutputs, mitigating potential repetitiveness and overly formal tones, ensuring\ncoherent, credible dialogues at scale. We also propose a psychologically\ngrounded evaluation framework assessing naturalness, social behavior\nauthenticity, and transcript difficulties. Human assessments show that FAME\napproximates real-meeting spontaneity (4.5/5 in naturalness), preserves\nspeaker-centric challenges (3/5 in spoken language), and introduces richer\ninformation-oriented difficulty (4/5 in difficulty). These findings highlight\nthat FAME is a good and scalable proxy for real-world meeting conditions. It\nenables new test scenarios for meeting summarization research and other\nconversation-centric applications in tasks requiring conversation data or\nsimulating social scenarios under behavioral constraints.'}","['Frederic Kirstein', 'Muneeb Khan', 'Jan Philip Wahle', 'Terry Ruas', 'Bela Gipp']",{'name': 'Bela Gipp'},Bela Gipp,,"[{'href': 'http://arxiv.org/abs/2502.13001v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13001v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13001v1,None,http://arxiv.org/abs/2502.13001v1,,,370,0
http://arxiv.org/abs/2502.13016v1,True,2025-02-18T16:34:45Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=16, tm_min=34, tm_sec=45, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T16:34:45Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=16, tm_min=34, tm_sec=45, tm_wday=1, tm_yday=49, tm_isdst=0)",LLM-Powered Proactive Data Systems,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'LLM-Powered Proactive Data Systems'}","With the power of LLMs, we now have the ability to query data that was
previously impossible to query, including text, images, and video. However,
despite this enormous potential, most present-day data systems that leverage
LLMs are reactive, reflecting our community's desire to map LLMs to known
abstractions. Most data systems treat LLMs as an opaque black box that operates
on user inputs and data as is, optimizing them much like any other approximate,
expensive UDFs, in conjunction with other relational operators. Such data
systems do as they are told, but fail to understand and leverage what the LLM
is being asked to do (i.e. the underlying operations, which may be
error-prone), the data the LLM is operating on (e.g., long, complex documents),
or what the user really needs. They don't take advantage of the characteristics
of the operations and/or the data at hand, or ensure correctness of results
when there are imprecisions and ambiguities. We argue that data systems instead
need to be proactive: they need to be given more agency -- armed with the power
of LLMs -- to understand and rework the user inputs and the data and to make
decisions on how the operations and the data should be represented and
processed. By allowing the data system to parse, rewrite, and decompose user
inputs and data, or to interact with the user in ways that go beyond the
standard single-shot query-result paradigm, the data system is able to address
user needs more efficiently and effectively. These new capabilities lead to a
rich design space where the data system takes more initiative: they are
empowered to perform optimization based on the transformation operations, data
characteristics, and user intent. We discuss various successful examples of how
this framework has been and can be applied in real-world tasks, and present
future directions for this ambitious research agenda.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""With the power of LLMs, we now have the ability to query data that was\npreviously impossible to query, including text, images, and video. However,\ndespite this enormous potential, most present-day data systems that leverage\nLLMs are reactive, reflecting our community's desire to map LLMs to known\nabstractions. Most data systems treat LLMs as an opaque black box that operates\non user inputs and data as is, optimizing them much like any other approximate,\nexpensive UDFs, in conjunction with other relational operators. Such data\nsystems do as they are told, but fail to understand and leverage what the LLM\nis being asked to do (i.e. the underlying operations, which may be\nerror-prone), the data the LLM is operating on (e.g., long, complex documents),\nor what the user really needs. They don't take advantage of the characteristics\nof the operations and/or the data at hand, or ensure correctness of results\nwhen there are imprecisions and ambiguities. We argue that data systems instead\nneed to be proactive: they need to be given more agency -- armed with the power\nof LLMs -- to understand and rework the user inputs and the data and to make\ndecisions on how the operations and the data should be represented and\nprocessed. By allowing the data system to parse, rewrite, and decompose user\ninputs and data, or to interact with the user in ways that go beyond the\nstandard single-shot query-result paradigm, the data system is able to address\nuser needs more efficiently and effectively. These new capabilities lead to a\nrich design space where the data system takes more initiative: they are\nempowered to perform optimization based on the transformation operations, data\ncharacteristics, and user intent. We discuss various successful examples of how\nthis framework has been and can be applied in real-world tasks, and present\nfuture directions for this ambitious research agenda.""}","['Sepanta Zeighami', 'Yiming Lin', 'Shreya Shankar', 'Aditya Parameswaran']",{'name': 'Aditya Parameswaran'},Aditya Parameswaran,,"[{'href': 'http://arxiv.org/abs/2502.13016v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13016v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.DB', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.DB', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13016v1,None,http://arxiv.org/abs/2502.13016v1,IEEE Data Engineering Bulletin March 2025,,755,0
http://arxiv.org/abs/2502.13080v1,True,2025-02-18T17:33:41Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=17, tm_min=33, tm_sec=41, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T17:33:41Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=17, tm_min=33, tm_sec=41, tm_wday=1, tm_yday=49, tm_isdst=0)","BOLIMES: Boruta and LIME optiMized fEature Selection for Gene Expression
  Classification","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'BOLIMES: Boruta and LIME optiMized fEature Selection for Gene Expression\n  Classification'}","Gene expression classification is a pivotal yet challenging task in
bioinformatics, primarily due to the high dimensionality of genomic data and
the risk of overfitting. To bridge this gap, we propose BOLIMES, a novel
feature selection algorithm designed to enhance gene expression classification
by systematically refining the feature subset. Unlike conventional methods that
rely solely on statistical ranking or classifier-specific selection, we
integrate the robustness of Boruta with the interpretability of LIME, ensuring
that only the most relevant and influential genes are retained. BOLIMES first
employs Boruta to filter out non-informative genes by comparing each feature
against its randomized counterpart, thus preserving valuable information. It
then uses LIME to rank the remaining genes based on their local importance to
the classifier. Finally, an iterative classification evaluation determines the
optimal feature subset by selecting the number of genes that maximizes
predictive accuracy. By combining exhaustive feature selection with
interpretability-driven refinement, our solution effectively balances
dimensionality reduction with high classification performance, offering a
powerful solution for high-dimensional gene expression analysis.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Gene expression classification is a pivotal yet challenging task in\nbioinformatics, primarily due to the high dimensionality of genomic data and\nthe risk of overfitting. To bridge this gap, we propose BOLIMES, a novel\nfeature selection algorithm designed to enhance gene expression classification\nby systematically refining the feature subset. Unlike conventional methods that\nrely solely on statistical ranking or classifier-specific selection, we\nintegrate the robustness of Boruta with the interpretability of LIME, ensuring\nthat only the most relevant and influential genes are retained. BOLIMES first\nemploys Boruta to filter out non-informative genes by comparing each feature\nagainst its randomized counterpart, thus preserving valuable information. It\nthen uses LIME to rank the remaining genes based on their local importance to\nthe classifier. Finally, an iterative classification evaluation determines the\noptimal feature subset by selecting the number of genes that maximizes\npredictive accuracy. By combining exhaustive feature selection with\ninterpretability-driven refinement, our solution effectively balances\ndimensionality reduction with high classification performance, offering a\npowerful solution for high-dimensional gene expression analysis.'}","['Bich-Chung Phan', 'Thanh Ma', 'Huu-Hoa Nguyen', 'and Thanh-Nghi Do']",{'name': 'and Thanh-Nghi Do'},and Thanh-Nghi Do,,"[{'href': 'http://arxiv.org/abs/2502.13080v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13080v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13080v1,None,http://arxiv.org/abs/2502.13080v1,,,0,0
http://arxiv.org/abs/2502.13092v1,True,2025-02-18T17:59:48Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=17, tm_min=59, tm_sec=48, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T17:59:48Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=17, tm_min=59, tm_sec=48, tm_wday=1, tm_yday=49, tm_isdst=0)","Text2World: Benchmarking Large Language Models for Symbolic World Model
  Generation","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Text2World: Benchmarking Large Language Models for Symbolic World Model\n  Generation'}","Recently, there has been growing interest in leveraging large language models
(LLMs) to generate symbolic world models from textual descriptions. Although
LLMs have been extensively explored in the context of world modeling, prior
studies encountered several challenges, including evaluation randomness,
dependence on indirect metrics, and a limited domain scope. To address these
limitations, we introduce a novel benchmark, Text2World, based on planning
domain definition language (PDDL), featuring hundreds of diverse domains and
employing multi-criteria, execution-based metrics for a more robust evaluation.
We benchmark current LLMs using Text2World and find that reasoning models
trained with large-scale reinforcement learning outperform others. However,
even the best-performing model still demonstrates limited capabilities in world
modeling. Building on these insights, we examine several promising strategies
to enhance the world modeling capabilities of LLMs, including test-time
scaling, agent training, and more. We hope that Text2World can serve as a
crucial resource, laying the groundwork for future research in leveraging LLMs
as world models. The project page is available at
https://text-to-world.github.io/.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Recently, there has been growing interest in leveraging large language models\n(LLMs) to generate symbolic world models from textual descriptions. Although\nLLMs have been extensively explored in the context of world modeling, prior\nstudies encountered several challenges, including evaluation randomness,\ndependence on indirect metrics, and a limited domain scope. To address these\nlimitations, we introduce a novel benchmark, Text2World, based on planning\ndomain definition language (PDDL), featuring hundreds of diverse domains and\nemploying multi-criteria, execution-based metrics for a more robust evaluation.\nWe benchmark current LLMs using Text2World and find that reasoning models\ntrained with large-scale reinforcement learning outperform others. However,\neven the best-performing model still demonstrates limited capabilities in world\nmodeling. Building on these insights, we examine several promising strategies\nto enhance the world modeling capabilities of LLMs, including test-time\nscaling, agent training, and more. We hope that Text2World can serve as a\ncrucial resource, laying the groundwork for future research in leveraging LLMs\nas world models. The project page is available at\nhttps://text-to-world.github.io/.'}","['Mengkang Hu', 'Tianxing Chen', 'Yude Zou', 'Yuheng Lei', 'Qiguang Chen', 'Ming Li', 'Hongyuan Zhang', 'Wenqi Shao', 'Ping Luo']",{'name': 'Ping Luo'},Ping Luo,Project page: https://text-to-world.github.io/,"[{'href': 'http://arxiv.org/abs/2502.13092v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13092v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13092v1,None,http://arxiv.org/abs/2502.13092v1,,,20,0
http://arxiv.org/abs/2502.13107v1,True,2025-02-18T18:19:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=19, tm_sec=36, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T18:19:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=19, tm_sec=36, tm_wday=1, tm_yday=49, tm_isdst=0)",MatterChat: A Multi-Modal LLM for Material Science,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'MatterChat: A Multi-Modal LLM for Material Science'}","Understanding and predicting the properties of inorganic materials is crucial
for accelerating advancements in materials science and driving applications in
energy, electronics, and beyond. Integrating material structure data with
language-based information through multi-modal large language models (LLMs)
offers great potential to support these efforts by enhancing human-AI
interaction. However, a key challenge lies in integrating atomic structures at
full resolution into LLMs. In this work, we introduce MatterChat, a versatile
structure-aware multi-modal LLM that unifies material structural data and
textual inputs into a single cohesive model. MatterChat employs a bridging
module to effectively align a pretrained machine learning interatomic potential
with a pretrained LLM, reducing training costs and enhancing flexibility. Our
results demonstrate that MatterChat significantly improves performance in
material property prediction and human-AI interaction, surpassing
general-purpose LLMs such as GPT-4. We also demonstrate its usefulness in
applications such as more advanced scientific reasoning and step-by-step
material synthesis.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Understanding and predicting the properties of inorganic materials is crucial\nfor accelerating advancements in materials science and driving applications in\nenergy, electronics, and beyond. Integrating material structure data with\nlanguage-based information through multi-modal large language models (LLMs)\noffers great potential to support these efforts by enhancing human-AI\ninteraction. However, a key challenge lies in integrating atomic structures at\nfull resolution into LLMs. In this work, we introduce MatterChat, a versatile\nstructure-aware multi-modal LLM that unifies material structural data and\ntextual inputs into a single cohesive model. MatterChat employs a bridging\nmodule to effectively align a pretrained machine learning interatomic potential\nwith a pretrained LLM, reducing training costs and enhancing flexibility. Our\nresults demonstrate that MatterChat significantly improves performance in\nmaterial property prediction and human-AI interaction, surpassing\ngeneral-purpose LLMs such as GPT-4. We also demonstrate its usefulness in\napplications such as more advanced scientific reasoning and step-by-step\nmaterial synthesis.'}","['Yingheng Tang', 'Wenbin Xu', 'Jie Cao', 'Jianzhu Ma', 'Weilu Gao', 'Steve Farrell', 'Benjamin Erichson', 'Michael W. Mahoney', 'Andy Nonaka', 'Zhi Yao']",{'name': 'Zhi Yao'},Zhi Yao,,"[{'href': 'http://arxiv.org/abs/2502.13107v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13107v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13107v1,None,http://arxiv.org/abs/2502.13107v1,,,0,0
http://arxiv.org/abs/2502.13117v1,True,2025-02-18T18:37:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=37, tm_sec=15, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T18:37:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=37, tm_sec=15, tm_wday=1, tm_yday=49, tm_isdst=0)","Performance Evaluation of Large Language Models in Statistical
  Programming","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Performance Evaluation of Large Language Models in Statistical\n  Programming'}","The programming capabilities of large language models (LLMs) have
revolutionized automatic code generation and opened new avenues for automatic
statistical analysis. However, the validity and quality of these generated
codes need to be systematically evaluated before they can be widely adopted.
Despite their growing prominence, a comprehensive evaluation of statistical
code generated by LLMs remains scarce in the literature. In this paper, we
assess the performance of LLMs, including two versions of ChatGPT and one
version of Llama, in the domain of SAS programming for statistical analysis.
Our study utilizes a set of statistical analysis tasks encompassing diverse
statistical topics and datasets. Each task includes a problem description,
dataset information, and human-verified SAS code. We conduct a comprehensive
assessment of the quality of SAS code generated by LLMs through human expert
evaluation based on correctness, effectiveness, readability, executability, and
the accuracy of output results. The analysis of rating scores reveals that
while LLMs demonstrate usefulness in generating syntactically correct code,
they struggle with tasks requiring deep domain understanding and may produce
redundant or incorrect results. This study offers valuable insights into the
capabilities and limitations of LLMs in statistical programming, providing
guidance for future advancements in AI-assisted coding systems for statistical
analysis.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The programming capabilities of large language models (LLMs) have\nrevolutionized automatic code generation and opened new avenues for automatic\nstatistical analysis. However, the validity and quality of these generated\ncodes need to be systematically evaluated before they can be widely adopted.\nDespite their growing prominence, a comprehensive evaluation of statistical\ncode generated by LLMs remains scarce in the literature. In this paper, we\nassess the performance of LLMs, including two versions of ChatGPT and one\nversion of Llama, in the domain of SAS programming for statistical analysis.\nOur study utilizes a set of statistical analysis tasks encompassing diverse\nstatistical topics and datasets. Each task includes a problem description,\ndataset information, and human-verified SAS code. We conduct a comprehensive\nassessment of the quality of SAS code generated by LLMs through human expert\nevaluation based on correctness, effectiveness, readability, executability, and\nthe accuracy of output results. The analysis of rating scores reveals that\nwhile LLMs demonstrate usefulness in generating syntactically correct code,\nthey struggle with tasks requiring deep domain understanding and may produce\nredundant or incorrect results. This study offers valuable insights into the\ncapabilities and limitations of LLMs in statistical programming, providing\nguidance for future advancements in AI-assisted coding systems for statistical\nanalysis.'}","['Xinyi Song', 'Kexin Xie', 'Lina Lee', 'Ruizhe Chen', 'Jared M. Clark', 'Hao He', 'Haoran He', 'Jie Min', 'Xinlei Zhang', 'Simin Zheng', 'Zhiyang Zhang', 'Xinwei Deng', 'Yili Hong']",{'name': 'Yili Hong'},Yili Hong,"27 pages, 8 figures","[{'href': 'http://arxiv.org/abs/2502.13117v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13117v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'stat.AP', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'stat.AP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13117v1,None,http://arxiv.org/abs/2502.13117v1,,,41,0
http://arxiv.org/abs/2502.13120v1,True,2025-02-18T18:42:11Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=42, tm_sec=11, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T18:42:11Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=42, tm_sec=11, tm_wday=1, tm_yday=49, tm_isdst=0)","Adapting Psycholinguistic Research for LLMs: Gender-inclusive Language
  in a Coreference Context","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Adapting Psycholinguistic Research for LLMs: Gender-inclusive Language\n  in a Coreference Context'}","Gender-inclusive language is often used with the aim of ensuring that all
individuals, regardless of gender, can be associated with certain concepts.
While psycholinguistic studies have examined its effects in relation to human
cognition, it remains unclear how Large Language Models (LLMs) process
gender-inclusive language. Given that commercial LLMs are gaining an
increasingly strong foothold in everyday applications, it is crucial to examine
whether LLMs in fact interpret gender-inclusive language neutrally, because the
language they generate has the potential to influence the language of their
users. This study examines whether LLM-generated coreferent terms align with a
given gender expression or reflect model biases. Adapting psycholinguistic
methods from French to English and German, we find that in English, LLMs
generally maintain the antecedent's gender but exhibit underlying masculine
bias. In German, this bias is much stronger, overriding all tested
gender-neutralization strategies.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Gender-inclusive language is often used with the aim of ensuring that all\nindividuals, regardless of gender, can be associated with certain concepts.\nWhile psycholinguistic studies have examined its effects in relation to human\ncognition, it remains unclear how Large Language Models (LLMs) process\ngender-inclusive language. Given that commercial LLMs are gaining an\nincreasingly strong foothold in everyday applications, it is crucial to examine\nwhether LLMs in fact interpret gender-inclusive language neutrally, because the\nlanguage they generate has the potential to influence the language of their\nusers. This study examines whether LLM-generated coreferent terms align with a\ngiven gender expression or reflect model biases. Adapting psycholinguistic\nmethods from French to English and German, we find that in English, LLMs\ngenerally maintain the antecedent's gender but exhibit underlying masculine\nbias. In German, this bias is much stronger, overriding all tested\ngender-neutralization strategies.""}","['Marion Bartl', 'Thomas Brendan Murphy', 'Susan Leavy']",{'name': 'Susan Leavy'},Susan Leavy,"9 pages, 7 figures, submitted to ACL 2025 (ARR February 2025 cycle)","[{'href': 'http://arxiv.org/abs/2502.13120v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13120v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13120v1,None,http://arxiv.org/abs/2502.13120v1,,,541,0
http://arxiv.org/abs/2502.13128v1,True,2025-02-18T18:52:21Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=52, tm_sec=21, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T18:52:21Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=52, tm_sec=21, tm_wday=1, tm_yday=49, tm_isdst=0)","SongGen: A Single Stage Auto-regressive Transformer for Text-to-Song
  Generation","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'SongGen: A Single Stage Auto-regressive Transformer for Text-to-Song\n  Generation'}","Text-to-song generation, the task of creating vocals and accompaniment from
textual inputs, poses significant challenges due to domain complexity and data
scarcity. Existing approaches often employ multi-stage generation procedures,
resulting in cumbersome training and inference pipelines. In this paper, we
propose SongGen, a fully open-source, single-stage auto-regressive transformer
designed for controllable song generation. The proposed model facilitates
fine-grained control over diverse musical attributes, including lyrics and
textual descriptions of instrumentation, genre, mood, and timbre, while also
offering an optional three-second reference clip for voice cloning. Within a
unified auto-regressive framework, SongGen supports two output modes: mixed
mode, which generates a mixture of vocals and accompaniment directly, and
dual-track mode, which synthesizes them separately for greater flexibility in
downstream applications. We explore diverse token pattern strategies for each
mode, leading to notable improvements and valuable insights. Furthermore, we
design an automated data preprocessing pipeline with effective quality control.
To foster community engagement and future research, we will release our model
weights, training code, annotated data, and preprocessing pipeline. The
generated samples are showcased on our project page at
https://liuzh-19.github.io/SongGen/ , and the code will be available at
https://github.com/LiuZH-19/SongGen .","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Text-to-song generation, the task of creating vocals and accompaniment from\ntextual inputs, poses significant challenges due to domain complexity and data\nscarcity. Existing approaches often employ multi-stage generation procedures,\nresulting in cumbersome training and inference pipelines. In this paper, we\npropose SongGen, a fully open-source, single-stage auto-regressive transformer\ndesigned for controllable song generation. The proposed model facilitates\nfine-grained control over diverse musical attributes, including lyrics and\ntextual descriptions of instrumentation, genre, mood, and timbre, while also\noffering an optional three-second reference clip for voice cloning. Within a\nunified auto-regressive framework, SongGen supports two output modes: mixed\nmode, which generates a mixture of vocals and accompaniment directly, and\ndual-track mode, which synthesizes them separately for greater flexibility in\ndownstream applications. We explore diverse token pattern strategies for each\nmode, leading to notable improvements and valuable insights. Furthermore, we\ndesign an automated data preprocessing pipeline with effective quality control.\nTo foster community engagement and future research, we will release our model\nweights, training code, annotated data, and preprocessing pipeline. The\ngenerated samples are showcased on our project page at\nhttps://liuzh-19.github.io/SongGen/ , and the code will be available at\nhttps://github.com/LiuZH-19/SongGen .'}","['Zihan Liu', 'Shuangrui Ding', 'Zhixiong Zhang', 'Xiaoyi Dong', 'Pan Zhang', 'Yuhang Zang', 'Yuhang Cao', 'Dahua Lin', 'Jiaqi Wang']",{'name': 'Jiaqi Wang'},Jiaqi Wang,,"[{'href': 'http://arxiv.org/abs/2502.13128v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13128v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.SD', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.SD', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13128v1,None,http://arxiv.org/abs/2502.13128v1,,,8394,0
http://arxiv.org/abs/2502.13131v1,True,2025-02-18T18:55:26Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=55, tm_sec=26, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T18:55:26Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=55, tm_sec=26, tm_wday=1, tm_yday=49, tm_isdst=0)","Rethinking Diverse Human Preference Learning through Principal Component
  Analysis","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Rethinking Diverse Human Preference Learning through Principal Component\n  Analysis'}","Understanding human preferences is crucial for improving foundation models
and building personalized AI systems. However, preferences are inherently
diverse and complex, making it difficult for traditional reward models to
capture their full range. While fine-grained preference data can help,
collecting it is expensive and hard to scale. In this paper, we introduce
Decomposed Reward Models (DRMs), a novel approach that extracts diverse human
preferences from binary comparisons without requiring fine-grained annotations.
Our key insight is to represent human preferences as vectors and analyze them
using Principal Component Analysis (PCA). By constructing a dataset of
embedding differences between preferred and rejected responses, DRMs identify
orthogonal basis vectors that capture distinct aspects of preference. These
decomposed rewards can be flexibly combined to align with different user needs,
offering an interpretable and scalable alternative to traditional reward
models. We demonstrate that DRMs effectively extract meaningful preference
dimensions (e.g., helpfulness, safety, humor) and adapt to new users without
additional training. Our results highlight DRMs as a powerful framework for
personalized and interpretable LLM alignment.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Understanding human preferences is crucial for improving foundation models\nand building personalized AI systems. However, preferences are inherently\ndiverse and complex, making it difficult for traditional reward models to\ncapture their full range. While fine-grained preference data can help,\ncollecting it is expensive and hard to scale. In this paper, we introduce\nDecomposed Reward Models (DRMs), a novel approach that extracts diverse human\npreferences from binary comparisons without requiring fine-grained annotations.\nOur key insight is to represent human preferences as vectors and analyze them\nusing Principal Component Analysis (PCA). By constructing a dataset of\nembedding differences between preferred and rejected responses, DRMs identify\northogonal basis vectors that capture distinct aspects of preference. These\ndecomposed rewards can be flexibly combined to align with different user needs,\noffering an interpretable and scalable alternative to traditional reward\nmodels. We demonstrate that DRMs effectively extract meaningful preference\ndimensions (e.g., helpfulness, safety, humor) and adapt to new users without\nadditional training. Our results highlight DRMs as a powerful framework for\npersonalized and interpretable LLM alignment.'}","['Feng Luo', 'Rui Yang', 'Hao Sun', 'Chunyuan Deng', 'Jiarui Yao', 'Jingyan Shen', 'Huan Zhang', 'Hanjie Chen']",{'name': 'Hanjie Chen'},Hanjie Chen,14 pages,"[{'href': 'http://arxiv.org/abs/2502.13131v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13131v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13131v1,None,http://arxiv.org/abs/2502.13131v1,,,365,0
http://arxiv.org/abs/2502.13138v1,True,2025-02-18T18:57:21Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=57, tm_sec=21, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T18:57:21Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=57, tm_sec=21, tm_wday=1, tm_yday=49, tm_isdst=0)",AIDE: AI-Driven Exploration in the Space of Code,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'AIDE: AI-Driven Exploration in the Space of Code'}","Machine learning, the foundation of modern artificial intelligence, has
driven innovations that have fundamentally transformed the world. Yet, behind
advancements lies a complex and often tedious process requiring labor and
compute intensive iteration and experimentation. Engineers and scientists
developing machine learning models spend much of their time on trial-and-error
tasks instead of conceptualizing innovative solutions or research hypotheses.
To address this challenge, we introduce AI-Driven Exploration (AIDE), a machine
learning engineering agent powered by large language models (LLMs). AIDE frames
machine learning engineering as a code optimization problem, and formulates
trial-and-error as a tree search in the space of potential solutions. By
strategically reusing and refining promising solutions, AIDE effectively trades
computational resources for enhanced performance, achieving state-of-the-art
results on multiple machine learning engineering benchmarks, including our
Kaggle evaluations, OpenAI MLE-Bench and METRs RE-Bench.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Machine learning, the foundation of modern artificial intelligence, has\ndriven innovations that have fundamentally transformed the world. Yet, behind\nadvancements lies a complex and often tedious process requiring labor and\ncompute intensive iteration and experimentation. Engineers and scientists\ndeveloping machine learning models spend much of their time on trial-and-error\ntasks instead of conceptualizing innovative solutions or research hypotheses.\nTo address this challenge, we introduce AI-Driven Exploration (AIDE), a machine\nlearning engineering agent powered by large language models (LLMs). AIDE frames\nmachine learning engineering as a code optimization problem, and formulates\ntrial-and-error as a tree search in the space of potential solutions. By\nstrategically reusing and refining promising solutions, AIDE effectively trades\ncomputational resources for enhanced performance, achieving state-of-the-art\nresults on multiple machine learning engineering benchmarks, including our\nKaggle evaluations, OpenAI MLE-Bench and METRs RE-Bench.'}","['Zhengyao Jiang', 'Dominik Schmidt', 'Dhruv Srikanth', 'Dixing Xu', 'Ian Kaplan', 'Deniss Jacenko', 'Yuxiang Wu']",{'name': 'Yuxiang Wu'},Yuxiang Wu,,"[{'href': 'http://arxiv.org/abs/2502.13138v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13138v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13138v1,None,http://arxiv.org/abs/2502.13138v1,,,1,0
http://arxiv.org/abs/2502.13142v1,True,2025-02-18T18:59:01Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=59, tm_sec=1, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T18:59:01Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=59, tm_sec=1, tm_wday=1, tm_yday=49, tm_isdst=0)",Pre-training Auto-regressive Robotic Models with 4D Representations,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Pre-training Auto-regressive Robotic Models with 4D Representations'}","Foundation models pre-trained on massive unlabeled datasets have
revolutionized natural language and computer vision, exhibiting remarkable
generalization capabilities, thus highlighting the importance of pre-training.
Yet, efforts in robotics have struggled to achieve similar success, limited by
either the need for costly robotic annotations or the lack of representations
that effectively model the physical world. In this paper, we introduce ARM4R,
an Auto-regressive Robotic Model that leverages low-level 4D Representations
learned from human video data to yield a better pre-trained robotic model.
Specifically, we focus on utilizing 3D point tracking representations from
videos derived by lifting 2D representations into 3D space via monocular depth
estimation across time. These 4D representations maintain a shared geometric
structure between the points and robot state representations up to a linear
transformation, enabling efficient transfer learning from human video data to
low-level robotic control. Our experiments show that ARM4R can transfer
efficiently from human video data to robotics and consistently improves
performance on tasks across various robot environments and configurations.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Foundation models pre-trained on massive unlabeled datasets have\nrevolutionized natural language and computer vision, exhibiting remarkable\ngeneralization capabilities, thus highlighting the importance of pre-training.\nYet, efforts in robotics have struggled to achieve similar success, limited by\neither the need for costly robotic annotations or the lack of representations\nthat effectively model the physical world. In this paper, we introduce ARM4R,\nan Auto-regressive Robotic Model that leverages low-level 4D Representations\nlearned from human video data to yield a better pre-trained robotic model.\nSpecifically, we focus on utilizing 3D point tracking representations from\nvideos derived by lifting 2D representations into 3D space via monocular depth\nestimation across time. These 4D representations maintain a shared geometric\nstructure between the points and robot state representations up to a linear\ntransformation, enabling efficient transfer learning from human video data to\nlow-level robotic control. Our experiments show that ARM4R can transfer\nefficiently from human video data to robotics and consistently improves\nperformance on tasks across various robot environments and configurations.'}","['Dantong Niu', 'Yuvan Sharma', 'Haoru Xue', 'Giscard Biamby', 'Junyi Zhang', 'Ziteng Ji', 'Trevor Darrell', 'Roei Herzig']",{'name': 'Roei Herzig'},Roei Herzig,,"[{'href': 'http://arxiv.org/abs/2502.13142v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13142v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13142v1,None,http://arxiv.org/abs/2502.13142v1,,,1479,0
http://arxiv.org/abs/2502.13160v1,True,2025-02-16T03:02:48Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=3, tm_min=2, tm_sec=48, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T03:02:48Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=3, tm_min=2, tm_sec=48, tm_wday=6, tm_yday=47, tm_isdst=0)","Understanding Dynamic Diffusion Process of LLM-based Agents under
  Information Asymmetry","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Understanding Dynamic Diffusion Process of LLM-based Agents under\n  Information Asymmetry'}","Large language models have been used to simulate human society using
multi-agent systems. Most current social simulation research emphasizes
interactive behaviors in fixed environments, ignoring information opacity,
relationship variability and diffusion diversity. In this paper, we study the
dynamics of information diffusion in 12 asymmetric open environments defined by
information content and distribution mechanisms. We first present a general
framework to capture the features of information diffusion. Then, we designed a
dynamic attention mechanism to help agents allocate attention to different
information, addressing the limitations of LLM-based attention. Agents start by
responding to external information stimuli within a five-agent group,
increasing group size and forming information circles while developing
relationships and sharing information. Additionally, we observe the emergence
of information cocoons, the evolution of information gaps, and the accumulation
of social capital, which are closely linked to psychological, sociological, and
communication theories.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large language models have been used to simulate human society using\nmulti-agent systems. Most current social simulation research emphasizes\ninteractive behaviors in fixed environments, ignoring information opacity,\nrelationship variability and diffusion diversity. In this paper, we study the\ndynamics of information diffusion in 12 asymmetric open environments defined by\ninformation content and distribution mechanisms. We first present a general\nframework to capture the features of information diffusion. Then, we designed a\ndynamic attention mechanism to help agents allocate attention to different\ninformation, addressing the limitations of LLM-based attention. Agents start by\nresponding to external information stimuli within a five-agent group,\nincreasing group size and forming information circles while developing\nrelationships and sharing information. Additionally, we observe the emergence\nof information cocoons, the evolution of information gaps, and the accumulation\nof social capital, which are closely linked to psychological, sociological, and\ncommunication theories.'}","['Yiwen Zhang', 'Yifu Wu', 'Wenyue Hua', 'Xuming Hu']",{'name': 'Xuming Hu'},Xuming Hu,"8 pages, 4 figures","[{'href': 'http://arxiv.org/abs/2502.13160v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13160v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13160v1,None,http://arxiv.org/abs/2502.13160v1,,,0,0
http://arxiv.org/abs/2502.13161v1,True,2025-02-16T18:15:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=18, tm_min=15, tm_sec=37, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T18:15:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=18, tm_min=15, tm_sec=37, tm_wday=6, tm_yday=47, tm_isdst=0)",Noumenal Labs White Paper: How To Build A Brain,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Noumenal Labs White Paper: How To Build A Brain'}","This white paper describes some of the design principles for artificial or
machine intelligence that guide efforts at Noumenal Labs. These principles are
drawn from both nature and from the means by which we come to represent and
understand it. The end goal of research and development in this field should be
to design machine intelligences that augment our understanding of the world and
enhance our ability to act in it, without replacing us. In the first two
sections, we examine the core motivation for our approach: resolving the
grounding problem. We argue that the solution to the grounding problem rests in
the design of models grounded in the world that we inhabit, not mere word
models. A machine super intelligence that is capable of significantly enhancing
our understanding of the human world must represent the world as we do and be
capable of generating new knowledge, building on what we already know. In other
words, it must be properly grounded and explicitly designed for rational,
empirical inquiry, modeled after the scientific method. A primary implication
of this design principle is that agents must be capable of engaging
autonomously in causal physics discovery. We discuss the pragmatic implications
of this approach, and in particular, the use cases in realistic 3D world
modeling and multimodal, multidimensional time series analysis.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'This white paper describes some of the design principles for artificial or\nmachine intelligence that guide efforts at Noumenal Labs. These principles are\ndrawn from both nature and from the means by which we come to represent and\nunderstand it. The end goal of research and development in this field should be\nto design machine intelligences that augment our understanding of the world and\nenhance our ability to act in it, without replacing us. In the first two\nsections, we examine the core motivation for our approach: resolving the\ngrounding problem. We argue that the solution to the grounding problem rests in\nthe design of models grounded in the world that we inhabit, not mere word\nmodels. A machine super intelligence that is capable of significantly enhancing\nour understanding of the human world must represent the world as we do and be\ncapable of generating new knowledge, building on what we already know. In other\nwords, it must be properly grounded and explicitly designed for rational,\nempirical inquiry, modeled after the scientific method. A primary implication\nof this design principle is that agents must be capable of engaging\nautonomously in causal physics discovery. We discuss the pragmatic implications\nof this approach, and in particular, the use cases in realistic 3D world\nmodeling and multimodal, multidimensional time series analysis.'}","['Maxwell J. D. Ramstead', 'Candice Pattisapu', 'Jason Fox', 'Jeff Beck']",{'name': 'Jeff Beck'},Jeff Beck,,"[{'href': 'http://arxiv.org/abs/2502.13161v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13161v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'q-bio.NC', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'q-bio.NC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13161v1,None,http://arxiv.org/abs/2502.13161v1,,,2867,0
http://arxiv.org/abs/2502.13164v1,True,2025-02-17T04:03:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=4, tm_min=3, tm_sec=15, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T04:03:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=4, tm_min=3, tm_sec=15, tm_wday=0, tm_yday=48, tm_isdst=0)",Multi-Agent Actor-Critic Generative AI for Query Resolution and Analysis,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Multi-Agent Actor-Critic Generative AI for Query Resolution and Analysis'}","In this paper, we introduce MASQRAD (Multi-Agent Strategic Query Resolution
and Diagnostic tool), a transformative framework for query resolution based on
the actor-critic model, which utilizes multiple generative AI agents. MASQRAD
is excellent at translating imprecise or ambiguous user inquiries into precise
and actionable requests. This framework generates pertinent visualizations and
responses to these focused queries, as well as thorough analyses and insightful
interpretations for users. MASQRAD addresses the common shortcomings of
existing solutions in domains that demand fast and precise data interpretation,
such as their incapacity to successfully apply AI for generating actionable
insights and their challenges with the inherent ambiguity of user queries.
MASQRAD functions as a sophisticated multi-agent system but ""masquerades"" to
users as a single AI entity, which lowers errors and enhances data interaction.
This approach makes use of three primary AI agents: Actor Generative AI, Critic
Generative AI, and Expert Analysis Generative AI. Each is crucial for creating,
enhancing, and evaluating data interactions. The Actor AI generates Python
scripts to generate data visualizations from large datasets within operational
constraints, and the Critic AI rigorously refines these scripts through
multi-agent debate. Finally, the Expert Analysis AI contextualizes the outcomes
to aid in decision-making. With an accuracy rate of 87\% when handling tasks
related to natural language visualization, MASQRAD establishes new benchmarks
for automated data interpretation and showcases a noteworthy advancement that
has the potential to revolutionize AI-driven applications.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'In this paper, we introduce MASQRAD (Multi-Agent Strategic Query Resolution\nand Diagnostic tool), a transformative framework for query resolution based on\nthe actor-critic model, which utilizes multiple generative AI agents. MASQRAD\nis excellent at translating imprecise or ambiguous user inquiries into precise\nand actionable requests. This framework generates pertinent visualizations and\nresponses to these focused queries, as well as thorough analyses and insightful\ninterpretations for users. MASQRAD addresses the common shortcomings of\nexisting solutions in domains that demand fast and precise data interpretation,\nsuch as their incapacity to successfully apply AI for generating actionable\ninsights and their challenges with the inherent ambiguity of user queries.\nMASQRAD functions as a sophisticated multi-agent system but ""masquerades"" to\nusers as a single AI entity, which lowers errors and enhances data interaction.\nThis approach makes use of three primary AI agents: Actor Generative AI, Critic\nGenerative AI, and Expert Analysis Generative AI. Each is crucial for creating,\nenhancing, and evaluating data interactions. The Actor AI generates Python\nscripts to generate data visualizations from large datasets within operational\nconstraints, and the Critic AI rigorously refines these scripts through\nmulti-agent debate. Finally, the Expert Analysis AI contextualizes the outcomes\nto aid in decision-making. With an accuracy rate of 87\\% when handling tasks\nrelated to natural language visualization, MASQRAD establishes new benchmarks\nfor automated data interpretation and showcases a noteworthy advancement that\nhas the potential to revolutionize AI-driven applications.'}","['Mohammad Wali Ur Rahman', 'Ric Nevarez', 'Lamia Tasnim Mim', 'Salim Hariri']",{'name': 'Salim Hariri'},Salim Hariri,"Accepted for publication in IEEE Transactions on Artificial
  Intelligence","[{'href': 'http://arxiv.org/abs/2502.13164v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13164v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13164v1,None,http://arxiv.org/abs/2502.13164v1,,,12,0
http://arxiv.org/abs/2502.13167v1,True,2025-02-17T06:22:05Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=6, tm_min=22, tm_sec=5, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T06:22:05Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=6, tm_min=22, tm_sec=5, tm_wday=0, tm_yday=48, tm_isdst=0)",SmartLLM: Smart Contract Auditing using Custom Generative AI,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'SmartLLM: Smart Contract Auditing using Custom Generative AI'}","Smart contracts are essential to decentralized finance (DeFi) and blockchain
ecosystems but are increasingly vulnerable to exploits due to coding errors and
complex attack vectors. Traditional static analysis tools and existing
vulnerability detection methods often fail to address these challenges
comprehensively, leading to high false-positive rates and an inability to
detect dynamic vulnerabilities. This paper introduces SmartLLM, a novel
approach leveraging fine-tuned LLaMA 3.1 models with Retrieval-Augmented
Generation (RAG) to enhance the accuracy and efficiency of smart contract
auditing. By integrating domain-specific knowledge from ERC standards and
employing advanced techniques such as QLoRA for efficient fine-tuning, SmartLLM
achieves superior performance compared to static analysis tools like Mythril
and Slither, as well as zero-shot large language model (LLM) prompting methods
such as GPT-3.5 and GPT-4. Experimental results demonstrate a perfect recall of
100% and an accuracy score of 70%, highlighting the model's robustness in
identifying vulnerabilities, including reentrancy and access control issues.
This research advances smart contract security by offering a scalable and
effective auditing solution, supporting the secure adoption of decentralized
applications.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Smart contracts are essential to decentralized finance (DeFi) and blockchain\necosystems but are increasingly vulnerable to exploits due to coding errors and\ncomplex attack vectors. Traditional static analysis tools and existing\nvulnerability detection methods often fail to address these challenges\ncomprehensively, leading to high false-positive rates and an inability to\ndetect dynamic vulnerabilities. This paper introduces SmartLLM, a novel\napproach leveraging fine-tuned LLaMA 3.1 models with Retrieval-Augmented\nGeneration (RAG) to enhance the accuracy and efficiency of smart contract\nauditing. By integrating domain-specific knowledge from ERC standards and\nemploying advanced techniques such as QLoRA for efficient fine-tuning, SmartLLM\nachieves superior performance compared to static analysis tools like Mythril\nand Slither, as well as zero-shot large language model (LLM) prompting methods\nsuch as GPT-3.5 and GPT-4. Experimental results demonstrate a perfect recall of\n100% and an accuracy score of 70%, highlighting the model's robustness in\nidentifying vulnerabilities, including reentrancy and access control issues.\nThis research advances smart contract security by offering a scalable and\neffective auditing solution, supporting the secure adoption of decentralized\napplications.""}","['Jun Kevin', 'Pujianto Yugopuspito']",{'name': 'Pujianto Yugopuspito'},Pujianto Yugopuspito,,"[{'href': 'http://arxiv.org/abs/2502.13167v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13167v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13167v1,None,http://arxiv.org/abs/2502.13167v1,,,122,0
http://arxiv.org/abs/2502.13170v1,True,2025-02-17T10:39:58Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=10, tm_min=39, tm_sec=58, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T10:39:58Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=10, tm_min=39, tm_sec=58, tm_wday=0, tm_yday=48, tm_isdst=0)","Unveiling the Magic of Code Reasoning through Hypothesis Decomposition
  and Amendment","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Unveiling the Magic of Code Reasoning through Hypothesis Decomposition\n  and Amendment'}","The reasoning abilities are one of the most enigmatic and captivating aspects
of large language models (LLMs). Numerous studies are dedicated to exploring
and expanding the boundaries of this reasoning capability. However, tasks that
embody both reasoning and recall characteristics are often overlooked. In this
paper, we introduce such a novel task, code reasoning, to provide a new
perspective for the reasoning abilities of LLMs. We summarize three
meta-benchmarks based on established forms of logical reasoning, and
instantiate these into eight specific benchmark tasks. Our testing on these
benchmarks reveals that LLMs continue to struggle with identifying satisfactory
reasoning pathways. Additionally, we present a new pathway exploration pipeline
inspired by human intricate problem-solving methods. This Reflective Hypothesis
Decomposition and Amendment (RHDA) pipeline consists of the following iterative
steps: (1) Proposing potential hypotheses based on observations and decomposing
them; (2) Utilizing tools to validate hypotheses and reflection outcomes; (3)
Revising hypothesis in light of observations. Our approach effectively
mitigates logical chain collapses arising from forgetting or hallucination
issues in multi-step reasoning, resulting in performance gains of up to
$3\times$. Finally, we expanded this pipeline by applying it to simulate
complex household tasks in real-world scenarios, specifically in VirtualHome,
enhancing the handling of failure cases. We release our code and all of results
at https://github.com/TnTWoW/code_reasoning.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The reasoning abilities are one of the most enigmatic and captivating aspects\nof large language models (LLMs). Numerous studies are dedicated to exploring\nand expanding the boundaries of this reasoning capability. However, tasks that\nembody both reasoning and recall characteristics are often overlooked. In this\npaper, we introduce such a novel task, code reasoning, to provide a new\nperspective for the reasoning abilities of LLMs. We summarize three\nmeta-benchmarks based on established forms of logical reasoning, and\ninstantiate these into eight specific benchmark tasks. Our testing on these\nbenchmarks reveals that LLMs continue to struggle with identifying satisfactory\nreasoning pathways. Additionally, we present a new pathway exploration pipeline\ninspired by human intricate problem-solving methods. This Reflective Hypothesis\nDecomposition and Amendment (RHDA) pipeline consists of the following iterative\nsteps: (1) Proposing potential hypotheses based on observations and decomposing\nthem; (2) Utilizing tools to validate hypotheses and reflection outcomes; (3)\nRevising hypothesis in light of observations. Our approach effectively\nmitigates logical chain collapses arising from forgetting or hallucination\nissues in multi-step reasoning, resulting in performance gains of up to\n$3\\times$. Finally, we expanded this pipeline by applying it to simulate\ncomplex household tasks in real-world scenarios, specifically in VirtualHome,\nenhancing the handling of failure cases. We release our code and all of results\nat https://github.com/TnTWoW/code_reasoning.'}","['Yuze Zhao', 'Tianyun Ji', 'Wenjun Feng', 'Zhenya Huang', 'Qi Liu', 'Zhiding Liu', 'Yixiao Ma', 'Kai Zhang', 'Enhong Chen']",{'name': 'Enhong Chen'},Enhong Chen,"ICLR 2025 Poster;23 pages, 7 figures","[{'href': 'http://arxiv.org/abs/2502.13170v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13170v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13170v1,None,http://arxiv.org/abs/2502.13170v1,,,3755,0
http://arxiv.org/abs/2502.13172v1,True,2025-02-17T19:55:53Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=19, tm_min=55, tm_sec=53, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T19:55:53Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=19, tm_min=55, tm_sec=53, tm_wday=0, tm_yday=48, tm_isdst=0)",Unveiling Privacy Risks in LLM Agent Memory,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Unveiling Privacy Risks in LLM Agent Memory'}","Large Language Model (LLM) agents have become increasingly prevalent across
various real-world applications. They enhance decision-making by storing
private user-agent interactions in the memory module for demonstrations,
introducing new privacy risks for LLM agents. In this work, we systematically
investigate the vulnerability of LLM agents to our proposed Memory EXTRaction
Attack (MEXTRA) under a black-box setting. To extract private information from
memory, we propose an effective attacking prompt design and an automated prompt
generation method based on different levels of knowledge about the LLM agent.
Experiments on two representative agents demonstrate the effectiveness of
MEXTRA. Moreover, we explore key factors influencing memory leakage from both
the agent's and the attacker's perspectives. Our findings highlight the urgent
need for effective memory safeguards in LLM agent design and deployment.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Large Language Model (LLM) agents have become increasingly prevalent across\nvarious real-world applications. They enhance decision-making by storing\nprivate user-agent interactions in the memory module for demonstrations,\nintroducing new privacy risks for LLM agents. In this work, we systematically\ninvestigate the vulnerability of LLM agents to our proposed Memory EXTRaction\nAttack (MEXTRA) under a black-box setting. To extract private information from\nmemory, we propose an effective attacking prompt design and an automated prompt\ngeneration method based on different levels of knowledge about the LLM agent.\nExperiments on two representative agents demonstrate the effectiveness of\nMEXTRA. Moreover, we explore key factors influencing memory leakage from both\nthe agent's and the attacker's perspectives. Our findings highlight the urgent\nneed for effective memory safeguards in LLM agent design and deployment.""}","['Bo Wang', 'Weiyi He', 'Pengfei He', 'Shenglai Zeng', 'Zhen Xiang', 'Yue Xing', 'Jiliang Tang']",{'name': 'Jiliang Tang'},Jiliang Tang,Under review,"[{'href': 'http://arxiv.org/abs/2502.13172v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13172v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13172v1,None,http://arxiv.org/abs/2502.13172v1,,,15,0
http://arxiv.org/abs/2502.13173v1,True,2025-02-17T19:56:21Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=19, tm_min=56, tm_sec=21, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T19:56:21Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=19, tm_min=56, tm_sec=21, tm_wday=0, tm_yday=48, tm_isdst=0)",Thinking Preference Optimization,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Thinking Preference Optimization'}","Supervised Fine-Tuning (SFT) has been a go-to and effective method for
enhancing long chain-of-thought (CoT) reasoning in relatively small LLMs by
fine-tuning them with long CoT responses from larger LLMs. To continually
improve reasoning abilities, we can either collect new high-quality long CoT
reasoning SFT data or repeatedly train on existing SFT datasets. However,
acquiring new long CoT SFT data is costly and limited, while repeated training
often results in a performance plateau or decline. To further boost the
performance with the SFT data, we propose Thinking Preference Optimization
(ThinkPO), a simple yet effective post-SFT method that enhances long CoT
reasoning without requiring new long CoT responses. Instead, ThinkPO utilizes
readily available or easily obtainable short CoT reasoning responses as
rejected answers and long CoT responses as chosen answers for the same
question. It then applies direct preference optimization to encourage the model
to favor longer reasoning outputs. Experiments show that ThinkPO further
improves the reasoning performance of SFT-ed models, e.g. it increases math
reasoning accuracy of SFT-ed models by 8.6% and output length by 25.9%.
Notably, ThinkPO is capable of continually boosting the performance of the
publicly distilled SFT model, e.g., increasing the official
DeepSeek-R1-Distill-Qwen-7B's performance on MATH500 from 87.4% to 91.2%.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Supervised Fine-Tuning (SFT) has been a go-to and effective method for\nenhancing long chain-of-thought (CoT) reasoning in relatively small LLMs by\nfine-tuning them with long CoT responses from larger LLMs. To continually\nimprove reasoning abilities, we can either collect new high-quality long CoT\nreasoning SFT data or repeatedly train on existing SFT datasets. However,\nacquiring new long CoT SFT data is costly and limited, while repeated training\noften results in a performance plateau or decline. To further boost the\nperformance with the SFT data, we propose Thinking Preference Optimization\n(ThinkPO), a simple yet effective post-SFT method that enhances long CoT\nreasoning without requiring new long CoT responses. Instead, ThinkPO utilizes\nreadily available or easily obtainable short CoT reasoning responses as\nrejected answers and long CoT responses as chosen answers for the same\nquestion. It then applies direct preference optimization to encourage the model\nto favor longer reasoning outputs. Experiments show that ThinkPO further\nimproves the reasoning performance of SFT-ed models, e.g. it increases math\nreasoning accuracy of SFT-ed models by 8.6% and output length by 25.9%.\nNotably, ThinkPO is capable of continually boosting the performance of the\npublicly distilled SFT model, e.g., increasing the official\nDeepSeek-R1-Distill-Qwen-7B's performance on MATH500 from 87.4% to 91.2%.""}","['Wang Yang', 'Hongye Jin', 'Jingfeng Yang', 'Vipin Chaudhary', 'Xiaotian Han']",{'name': 'Xiaotian Han'},Xiaotian Han,,"[{'href': 'http://arxiv.org/abs/2502.13173v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13173v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13173v1,None,http://arxiv.org/abs/2502.13173v1,,,86,0
http://arxiv.org/abs/2502.13176v1,True,2025-02-18T04:08:29Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=4, tm_min=8, tm_sec=29, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T04:08:29Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=4, tm_min=8, tm_sec=29, tm_wday=1, tm_yday=49, tm_isdst=0)",BaKlaVa -- Budgeted Allocation of KV cache for Long-context Inference,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'BaKlaVa -- Budgeted Allocation of KV cache for Long-context Inference'}","In Large Language Model (LLM) inference, Key-Value (KV) caches (KV-caches)
are essential for reducing time complexity. However, they result in a linear
increase in GPU memory as the context length grows. While recent work explores
KV-cache eviction and compression policies to reduce memory usage, they often
consider uniform KV-caches across all attention heads, leading to suboptimal
performance. We introduce BaKlaVa, a method to allocate optimal memory for
individual KV-caches across the model by estimating the importance of each
KV-cache. Our empirical analysis demonstrates that not all KV-caches are
equally critical for LLM performance. Using a one-time profiling approach,
BaKlaVa assigns optimal memory budgets to each KV-cache. We evaluated our
method on LLaMA-3-8B, and Qwen2.5-7B models, achieving up to a 70\% compression
ratio while keeping baseline performance and delivering up to an
order-of-magnitude accuracy improvement at higher compression levels.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'In Large Language Model (LLM) inference, Key-Value (KV) caches (KV-caches)\nare essential for reducing time complexity. However, they result in a linear\nincrease in GPU memory as the context length grows. While recent work explores\nKV-cache eviction and compression policies to reduce memory usage, they often\nconsider uniform KV-caches across all attention heads, leading to suboptimal\nperformance. We introduce BaKlaVa, a method to allocate optimal memory for\nindividual KV-caches across the model by estimating the importance of each\nKV-cache. Our empirical analysis demonstrates that not all KV-caches are\nequally critical for LLM performance. Using a one-time profiling approach,\nBaKlaVa assigns optimal memory budgets to each KV-cache. We evaluated our\nmethod on LLaMA-3-8B, and Qwen2.5-7B models, achieving up to a 70\\% compression\nratio while keeping baseline performance and delivering up to an\norder-of-magnitude accuracy improvement at higher compression levels.'}","['Ahmed Burak Gulhan', 'Krishna Teja Chitty-Venkata', 'Murali Emani', 'Mahmut Kandemir', 'Venkatram Vishwanath']",{'name': 'Venkatram Vishwanath'},Venkatram Vishwanath,,"[{'href': 'http://arxiv.org/abs/2502.13176v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13176v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13176v1,None,http://arxiv.org/abs/2502.13176v1,,,946,0
http://arxiv.org/abs/2502.13177v1,True,2025-02-18T06:44:10Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=6, tm_min=44, tm_sec=10, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T06:44:10Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=6, tm_min=44, tm_sec=10, tm_wday=1, tm_yday=49, tm_isdst=0)",KL Penalty Control via Perturbation for Direct Preference Optimization,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'KL Penalty Control via Perturbation for Direct Preference Optimization'}","Direct Preference Optimization (DPO) demonstrates the advantage of aligning a
large language model with human preference using only an offline dataset.
However, DPO has the limitation that the KL penalty, which prevents excessive
deviation from the reference model, is static throughout the training process.
Several methods try to turn this static KL penalty into a dynamic one, but no
approach can adaptively assign different KL penalties for each preference pair.
In this paper, we propose $\varepsilon$-Direct Preference Optimization
($\varepsilon$-DPO), which allows adaptive control of the KL penalty strength
$\beta$ for each preference pair. Specifically, $\varepsilon$-DPO adaptively
controls $\beta$ for each preference pair based on the monotonicity of logits
as a preference model under the perturbation of $\beta$ during training by
simply reusing the logit of the current policy and the reference policy.
Experimental results show that $\varepsilon$-DPO outperforms existing direct
alignment algorithms and KL penalty relaxation methods on general chatbot
benchmarks, highlighting the significance of adaptive KL penalty relaxation at
the instance-level in DPO.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Direct Preference Optimization (DPO) demonstrates the advantage of aligning a\nlarge language model with human preference using only an offline dataset.\nHowever, DPO has the limitation that the KL penalty, which prevents excessive\ndeviation from the reference model, is static throughout the training process.\nSeveral methods try to turn this static KL penalty into a dynamic one, but no\napproach can adaptively assign different KL penalties for each preference pair.\nIn this paper, we propose $\\varepsilon$-Direct Preference Optimization\n($\\varepsilon$-DPO), which allows adaptive control of the KL penalty strength\n$\\beta$ for each preference pair. Specifically, $\\varepsilon$-DPO adaptively\ncontrols $\\beta$ for each preference pair based on the monotonicity of logits\nas a preference model under the perturbation of $\\beta$ during training by\nsimply reusing the logit of the current policy and the reference policy.\nExperimental results show that $\\varepsilon$-DPO outperforms existing direct\nalignment algorithms and KL penalty relaxation methods on general chatbot\nbenchmarks, highlighting the significance of adaptive KL penalty relaxation at\nthe instance-level in DPO.'}","['Sangkyu Lee', 'Janghoon Han', 'Hosung Song', 'Stanley Jungkyu Choi', 'Honglak Lee', 'Youngjae Yu']",{'name': 'Youngjae Yu'},Youngjae Yu,Preprint; Under review,"[{'href': 'http://arxiv.org/abs/2502.13177v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13177v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13177v1,None,http://arxiv.org/abs/2502.13177v1,,,504,0
http://arxiv.org/abs/2502.13178v1,True,2025-02-18T07:35:35Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=7, tm_min=35, tm_sec=35, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T07:35:35Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=7, tm_min=35, tm_sec=35, tm_wday=1, tm_yday=49, tm_isdst=0)","Benchmarking Post-Training Quantization in LLMs: Comprehensive Taxonomy,
  Unified Evaluation, and Comparative Analysis","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Benchmarking Post-Training Quantization in LLMs: Comprehensive Taxonomy,\n  Unified Evaluation, and Comparative Analysis'}","Post-training Quantization (PTQ) technique has been extensively adopted for
large language models (LLMs) compression owing to its efficiency and low
resource requirement. However, current research lacks a in-depth analysis of
the superior and applicable scenarios of each PTQ strategy. In addition,
existing algorithms focus primarily on performance, overlooking the trade-off
among model size, performance, and quantization bitwidth. To mitigate these
confusions, we provide a novel benchmark for LLMs PTQ in this paper. Firstly,
in order to support our benchmark, we propose a comprehensive taxonomy for
existing mainstream methods by scrutinizing their computational strategies
(e.g., optimization-based, compensation-based, etc.). Then, we conduct
extensive experiments with the baseline within each class, covering models with
various sizes (7B-70B), bitwidths, training levels (LLaMA1/2/3/3.1),
architectures (Mixtral, DeepSeekMoE and Mamba) and modality (LLaVA1.5 and
VILA1.5) on a wide range of evaluation metrics.Through comparative analysis on
the results, we summarize the superior of each PTQ strategy and
modelsize-bitwidth trade-off considering the performance. For example, our
benchmark reveals that compensation-based technique demonstrates outstanding
cross-architecture robustness and extremely low-bit PTQ for ultra large models
should be reexamined. Finally, we further accordingly claim that a practical
combination of compensation and other PTQ strategy can achieve SOTA various
robustness. We believe that our benchmark will provide valuable recommendations
for the deployment of LLMs and future research on PTQ approaches.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Post-training Quantization (PTQ) technique has been extensively adopted for\nlarge language models (LLMs) compression owing to its efficiency and low\nresource requirement. However, current research lacks a in-depth analysis of\nthe superior and applicable scenarios of each PTQ strategy. In addition,\nexisting algorithms focus primarily on performance, overlooking the trade-off\namong model size, performance, and quantization bitwidth. To mitigate these\nconfusions, we provide a novel benchmark for LLMs PTQ in this paper. Firstly,\nin order to support our benchmark, we propose a comprehensive taxonomy for\nexisting mainstream methods by scrutinizing their computational strategies\n(e.g., optimization-based, compensation-based, etc.). Then, we conduct\nextensive experiments with the baseline within each class, covering models with\nvarious sizes (7B-70B), bitwidths, training levels (LLaMA1/2/3/3.1),\narchitectures (Mixtral, DeepSeekMoE and Mamba) and modality (LLaVA1.5 and\nVILA1.5) on a wide range of evaluation metrics.Through comparative analysis on\nthe results, we summarize the superior of each PTQ strategy and\nmodelsize-bitwidth trade-off considering the performance. For example, our\nbenchmark reveals that compensation-based technique demonstrates outstanding\ncross-architecture robustness and extremely low-bit PTQ for ultra large models\nshould be reexamined. Finally, we further accordingly claim that a practical\ncombination of compensation and other PTQ strategy can achieve SOTA various\nrobustness. We believe that our benchmark will provide valuable recommendations\nfor the deployment of LLMs and future research on PTQ approaches.'}","['Jiaqi Zhao', 'Ming Wang', 'Miao Zhang', 'Yuzhang Shang', 'Xuebo Liu', 'Yaowei Wang', 'Min Zhang', 'Liqiang Nie']",{'name': 'Liqiang Nie'},Liqiang Nie,"17 pages, 3 fugures","[{'href': 'http://arxiv.org/abs/2502.13178v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13178v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13178v1,None,http://arxiv.org/abs/2502.13178v1,,,39,0
http://arxiv.org/abs/2502.13179v1,True,2025-02-18T08:04:58Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=8, tm_min=4, tm_sec=58, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T08:04:58Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=8, tm_min=4, tm_sec=58, tm_wday=1, tm_yday=49, tm_isdst=0)","PTQ1.61: Push the Real Limit of Extremely Low-Bit Post-Training
  Quantization Methods for Large Language Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'PTQ1.61: Push the Real Limit of Extremely Low-Bit Post-Training\n  Quantization Methods for Large Language Models'}","Large Language Models (LLMs) suffer severe performance degradation when
facing extremely low-bit (sub 2-bit) quantization. Several existing sub 2-bit
post-training quantization (PTQ) methods utilize a mix-precision scheme by
leveraging an unstructured fine-grained mask to explicitly distinguish salient
weights, while which introduces an extra 1-bit or more per weight. To explore
the real limit of PTQ, we propose an extremely low-bit PTQ method called
PTQ1.61, which enables weight quantization to 1.61-bit for the first time.
Specifically, we first introduce a one-dimensional structured mask with
negligibly additional 0.0002-bit per weight based on input activations from the
perspective of reducing the upper bound of quantization error to allocate
corresponding salient weight channels to 4-bit. For non-salient channels
binarization, an efficient block-wise scaling factors optimization framework is
then presented to take implicit row-wise correlations and angular biases into
account. Different from prior works that concentrate on adjusting quantization
methodologies, we further propose a novel paradigm called quantization
preprocessing, where we argue that transforming the weight distribution of the
pretrained model before quantization can alleviate the difficulty in
per-channel extremely low-bit PTQ. Extensive experiments indicate our PTQ1.61
achieves state-of-the-art performance in extremely low-bit quantization. Codes
are available at https://github.com/zjq0455/PTQ1.61.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Language Models (LLMs) suffer severe performance degradation when\nfacing extremely low-bit (sub 2-bit) quantization. Several existing sub 2-bit\npost-training quantization (PTQ) methods utilize a mix-precision scheme by\nleveraging an unstructured fine-grained mask to explicitly distinguish salient\nweights, while which introduces an extra 1-bit or more per weight. To explore\nthe real limit of PTQ, we propose an extremely low-bit PTQ method called\nPTQ1.61, which enables weight quantization to 1.61-bit for the first time.\nSpecifically, we first introduce a one-dimensional structured mask with\nnegligibly additional 0.0002-bit per weight based on input activations from the\nperspective of reducing the upper bound of quantization error to allocate\ncorresponding salient weight channels to 4-bit. For non-salient channels\nbinarization, an efficient block-wise scaling factors optimization framework is\nthen presented to take implicit row-wise correlations and angular biases into\naccount. Different from prior works that concentrate on adjusting quantization\nmethodologies, we further propose a novel paradigm called quantization\npreprocessing, where we argue that transforming the weight distribution of the\npretrained model before quantization can alleviate the difficulty in\nper-channel extremely low-bit PTQ. Extensive experiments indicate our PTQ1.61\nachieves state-of-the-art performance in extremely low-bit quantization. Codes\nare available at https://github.com/zjq0455/PTQ1.61.'}","['Jiaqi Zhao', 'Miao Zhang', 'Ming Wang', 'Yuzhang Shang', 'Kaihao Zhang', 'Weili Guan', 'Yaowei Wang', 'Min Zhang']",{'name': 'Min Zhang'},Min Zhang,"20 pages, 11 figures","[{'href': 'http://arxiv.org/abs/2502.13179v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13179v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13179v1,None,http://arxiv.org/abs/2502.13179v1,,,1,0
http://arxiv.org/abs/2502.13180v1,True,2025-02-18T08:10:09Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=8, tm_min=10, tm_sec=9, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T08:10:09Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=8, tm_min=10, tm_sec=9, tm_wday=1, tm_yday=49, tm_isdst=0)","Uncertain Multi-Objective Recommendation via Orthogonal Meta-Learning
  Enhanced Bayesian Optimization","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Uncertain Multi-Objective Recommendation via Orthogonal Meta-Learning\n  Enhanced Bayesian Optimization'}","Recommender systems (RSs) play a crucial role in shaping our digital
interactions, influencing how we access and engage with information across
various domains. Traditional research has predominantly centered on maximizing
recommendation accuracy, often leading to unintended side effects such as echo
chambers and constrained user experiences. Drawing inspiration from autonomous
driving, we introduce a novel framework that categorizes RS autonomy into five
distinct levels, ranging from basic rule-based accuracy-driven systems to
behavior-aware, uncertain multi-objective RSs - where users may have varying
needs, such as accuracy, diversity, and fairness. In response, we propose an
approach that dynamically identifies and optimizes multiple objectives based on
individual user preferences, fostering more ethical and intelligent
user-centric recommendations. To navigate the uncertainty inherent in
multi-objective RSs, we develop a Bayesian optimization (BO) framework that
captures personalized trade-offs between different objectives while accounting
for their uncertain interdependencies. Furthermore, we introduce an orthogonal
meta-learning paradigm to enhance BO efficiency and effectiveness by leveraging
shared knowledge across similar tasks and mitigating conflicts among objectives
through the discovery of orthogonal information. Finally, extensive empirical
evaluations demonstrate the effectiveness of our method in optimizing uncertain
multi-objectives for individual users, paving the way for more adaptive and
user-focused RSs.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Recommender systems (RSs) play a crucial role in shaping our digital\ninteractions, influencing how we access and engage with information across\nvarious domains. Traditional research has predominantly centered on maximizing\nrecommendation accuracy, often leading to unintended side effects such as echo\nchambers and constrained user experiences. Drawing inspiration from autonomous\ndriving, we introduce a novel framework that categorizes RS autonomy into five\ndistinct levels, ranging from basic rule-based accuracy-driven systems to\nbehavior-aware, uncertain multi-objective RSs - where users may have varying\nneeds, such as accuracy, diversity, and fairness. In response, we propose an\napproach that dynamically identifies and optimizes multiple objectives based on\nindividual user preferences, fostering more ethical and intelligent\nuser-centric recommendations. To navigate the uncertainty inherent in\nmulti-objective RSs, we develop a Bayesian optimization (BO) framework that\ncaptures personalized trade-offs between different objectives while accounting\nfor their uncertain interdependencies. Furthermore, we introduce an orthogonal\nmeta-learning paradigm to enhance BO efficiency and effectiveness by leveraging\nshared knowledge across similar tasks and mitigating conflicts among objectives\nthrough the discovery of orthogonal information. Finally, extensive empirical\nevaluations demonstrate the effectiveness of our method in optimizing uncertain\nmulti-objectives for individual users, paving the way for more adaptive and\nuser-focused RSs.'}","['Hongxu Wang', 'Zhu Sun', 'Yingpeng Du', 'Lu Zhang', 'Tiantian He', 'Yew-Soon Ong']",{'name': 'Yew-Soon Ong'},Yew-Soon Ong,,"[{'href': 'http://arxiv.org/abs/2502.13180v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13180v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13180v1,None,http://arxiv.org/abs/2502.13180v1,,,71,0
http://arxiv.org/abs/2502.13181v1,True,2025-02-18T09:34:31Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=9, tm_min=34, tm_sec=31, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T09:34:31Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=9, tm_min=34, tm_sec=31, tm_wday=1, tm_yday=49, tm_isdst=0)",RingFormer: Rethinking Recurrent Transformer with Adaptive Level Signals,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'RingFormer: Rethinking Recurrent Transformer with Adaptive Level Signals'}","Transformers have achieved great success in effectively processing sequential
data such as text. Their architecture consisting of several attention and
feedforward blocks can model relations between elements of a sequence in
parallel manner, which makes them very efficient to train and effective in
sequence modeling. Even though they have shown strong performance in processing
sequential data, the size of their parameters is considerably larger when
compared to other architectures such as RNN and CNN based models. Therefore,
several approaches have explored parameter sharing and recurrence in
Transformer models to address their computational demands. However, such
methods struggle to maintain high performance compared to the original
transformer model. To address this challenge, we propose our novel approach,
RingFormer, which employs one Transformer layer that processes input repeatedly
in a circular, ring-like manner, while utilizing low-rank matrices to generate
input-dependent level signals. This allows us to reduce the model parameters
substantially while maintaining high performance in a variety of tasks such as
translation and image classification, as validated in the experiments.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Transformers have achieved great success in effectively processing sequential\ndata such as text. Their architecture consisting of several attention and\nfeedforward blocks can model relations between elements of a sequence in\nparallel manner, which makes them very efficient to train and effective in\nsequence modeling. Even though they have shown strong performance in processing\nsequential data, the size of their parameters is considerably larger when\ncompared to other architectures such as RNN and CNN based models. Therefore,\nseveral approaches have explored parameter sharing and recurrence in\nTransformer models to address their computational demands. However, such\nmethods struggle to maintain high performance compared to the original\ntransformer model. To address this challenge, we propose our novel approach,\nRingFormer, which employs one Transformer layer that processes input repeatedly\nin a circular, ring-like manner, while utilizing low-rank matrices to generate\ninput-dependent level signals. This allows us to reduce the model parameters\nsubstantially while maintaining high performance in a variety of tasks such as\ntranslation and image classification, as validated in the experiments.'}","['Jaemu Heo', 'Eldor Fozilov', 'Hyunmin Song', 'Taehwan Kim']",{'name': 'Taehwan Kim'},Taehwan Kim,,"[{'href': 'http://arxiv.org/abs/2502.13181v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13181v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13181v1,None,http://arxiv.org/abs/2502.13181v1,,,0,0
http://arxiv.org/abs/2502.13191v1,True,2025-02-18T15:19:20Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=15, tm_min=19, tm_sec=20, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T15:19:20Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=15, tm_min=19, tm_sec=20, tm_wday=1, tm_yday=49, tm_isdst=0)","On the Privacy Risks of Spiking Neural Networks: A Membership Inference
  Analysis","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'On the Privacy Risks of Spiking Neural Networks: A Membership Inference\n  Analysis'}","Spiking Neural Networks (SNNs) are increasingly explored for their energy
efficiency and robustness in real-world applications, yet their privacy risks
remain largely unexamined. In this work, we investigate the susceptibility of
SNNs to Membership Inference Attacks (MIAs) -- a major privacy threat where an
adversary attempts to determine whether a given sample was part of the training
dataset. While prior work suggests that SNNs may offer inherent robustness due
to their discrete, event-driven nature, we find that its resilience diminishes
as latency (T) increases. Furthermore, we introduce an input dropout strategy
under black box setting, that significantly enhances membership inference in
SNNs. Our findings challenge the assumption that SNNs are inherently more
secure, and even though they are expected to be better, our results reveal that
SNNs exhibit privacy vulnerabilities that are equally comparable to Artificial
Neural Networks (ANNs). Our code is available at
https://anonymous.4open.science/r/MIA_SNN-3610.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Spiking Neural Networks (SNNs) are increasingly explored for their energy\nefficiency and robustness in real-world applications, yet their privacy risks\nremain largely unexamined. In this work, we investigate the susceptibility of\nSNNs to Membership Inference Attacks (MIAs) -- a major privacy threat where an\nadversary attempts to determine whether a given sample was part of the training\ndataset. While prior work suggests that SNNs may offer inherent robustness due\nto their discrete, event-driven nature, we find that its resilience diminishes\nas latency (T) increases. Furthermore, we introduce an input dropout strategy\nunder black box setting, that significantly enhances membership inference in\nSNNs. Our findings challenge the assumption that SNNs are inherently more\nsecure, and even though they are expected to be better, our results reveal that\nSNNs exhibit privacy vulnerabilities that are equally comparable to Artificial\nNeural Networks (ANNs). Our code is available at\nhttps://anonymous.4open.science/r/MIA_SNN-3610.'}","['Junyi Guan', 'Abhijith Sharma', 'Chong Tian', 'Salem Lahlou']",{'name': 'Salem Lahlou'},Salem Lahlou,"13 pages, 6 figures","[{'href': 'http://arxiv.org/abs/2502.13191v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13191v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13191v1,None,http://arxiv.org/abs/2502.13191v1,,,927,0
http://arxiv.org/abs/2502.13194v1,True,2025-02-18T17:16:27Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=17, tm_min=16, tm_sec=27, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T17:16:27Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=17, tm_min=16, tm_sec=27, tm_wday=1, tm_yday=49, tm_isdst=0)",Conditional Max-Sum for Asynchronous Multiagent Decision Making,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Conditional Max-Sum for Asynchronous Multiagent Decision Making'}","In this paper we present a novel approach for multiagent decision making in
dynamic environments based on Factor Graphs and the Max-Sum algorithm,
considering asynchronous variable reassignments and distributed message-passing
among agents. Motivated by the challenging domain of lane-free traffic where
automated vehicles can communicate and coordinate as agents, we propose a more
realistic communication framework for Factor Graph formulations that satisfies
the above-mentioned restrictions, along with Conditional Max-Sum: an extension
of Max-Sum with a revised message-passing process that is better suited for
asynchronous settings. The overall application in lane-free traffic can be
viewed as a hybrid system where the Factor Graph formulation undertakes the
strategic decision making of vehicles, that of desired lateral alignment in a
coordinated manner; and acts on top of a rule-based method we devise that
provides a structured representation of the lane-free environment for the
factors, while also handling the underlying control of vehicles regarding core
operations and safety. Our experimental evaluation showcases the capabilities
of the proposed framework in problems with intense coordination needs when
compared to a domain-specific baseline without communication, and an increased
adeptness of Conditional Max-Sum with respect to the standard algorithm.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'In this paper we present a novel approach for multiagent decision making in\ndynamic environments based on Factor Graphs and the Max-Sum algorithm,\nconsidering asynchronous variable reassignments and distributed message-passing\namong agents. Motivated by the challenging domain of lane-free traffic where\nautomated vehicles can communicate and coordinate as agents, we propose a more\nrealistic communication framework for Factor Graph formulations that satisfies\nthe above-mentioned restrictions, along with Conditional Max-Sum: an extension\nof Max-Sum with a revised message-passing process that is better suited for\nasynchronous settings. The overall application in lane-free traffic can be\nviewed as a hybrid system where the Factor Graph formulation undertakes the\nstrategic decision making of vehicles, that of desired lateral alignment in a\ncoordinated manner; and acts on top of a rule-based method we devise that\nprovides a structured representation of the lane-free environment for the\nfactors, while also handling the underlying control of vehicles regarding core\noperations and safety. Our experimental evaluation showcases the capabilities\nof the proposed framework in problems with intense coordination needs when\ncompared to a domain-specific baseline without communication, and an increased\nadeptness of Conditional Max-Sum with respect to the standard algorithm.'}","['Dimitrios Troullinos', 'Georgios Chalkiadakis', 'Ioannis Papamichail', 'Markos Papageorgiou']",{'name': 'Markos Papageorgiou'},Markos Papageorgiou,"Accepted Full Paper (Main Technical Track) - 24th International
  Conference on Autonomous Agents and Multiagent Systems (AAMAS 2025). This
  extended version includes the Appendix at the end","[{'href': 'http://arxiv.org/abs/2502.13194v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13194v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13194v1,None,http://arxiv.org/abs/2502.13194v1,,,28994,0
http://arxiv.org/abs/2502.13199v1,True,2025-02-18T18:08:20Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=8, tm_sec=20, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T18:08:20Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=8, tm_sec=20, tm_wday=1, tm_yday=49, tm_isdst=0)","The Role of GitHub Copilot on Software Development: A Perspec-tive on
  Productivity, Security, Best Practices and Future Directions","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The Role of GitHub Copilot on Software Development: A Perspec-tive on\n  Productivity, Security, Best Practices and Future Directions'}","GitHub Copilot is transforming software development by automating tasks and
boosting productivity through AI-driven code generation. In this paper, we
con-duct a literature survey to synthesize insights on Copilot's impact on
productivity and security. We review academic journal databases, industry
reports, and official docu-mentation to highlight key findings and challenges.
While Copilot accelerates coding and prototyping, concerns over security
vulnerabilities and intellectual property risks persist. Drawing from the
literature, we provide a perspective on best practices and future directions
for responsible AI adoption in software engineering, offering action-able
insights for developers and organizations to integrate Copilot effectively
while maintaining high standards of quality and security.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""GitHub Copilot is transforming software development by automating tasks and\nboosting productivity through AI-driven code generation. In this paper, we\ncon-duct a literature survey to synthesize insights on Copilot's impact on\nproductivity and security. We review academic journal databases, industry\nreports, and official docu-mentation to highlight key findings and challenges.\nWhile Copilot accelerates coding and prototyping, concerns over security\nvulnerabilities and intellectual property risks persist. Drawing from the\nliterature, we provide a perspective on best practices and future directions\nfor responsible AI adoption in software engineering, offering action-able\ninsights for developers and organizations to integrate Copilot effectively\nwhile maintaining high standards of quality and security.""}","['Suresh Babu Nettur', 'Shanthi Karpurapu', 'Unnati Nettur', 'Likhit Sagar Gajja', 'Sravanthy Myneni', 'Akhil Dusi']",{'name': 'Akhil Dusi'},Akhil Dusi,"Correspondence and co-first authors: nettursuresh@gmail.com,
  shanthi.karpurapu@gmail.com","[{'href': 'http://arxiv.org/abs/2502.13199v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13199v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.SE', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.SE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13199v1,None,http://arxiv.org/abs/2502.13199v1,,,0,0
http://arxiv.org/abs/2502.13200v1,True,2025-02-18T18:39:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=39, tm_sec=23, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T18:39:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=39, tm_sec=23, tm_wday=1, tm_yday=49, tm_isdst=0)","Learning To Explore With Predictive World Model Via Self-Supervised
  Learning","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Learning To Explore With Predictive World Model Via Self-Supervised\n  Learning'}","Autonomous artificial agents must be able to learn behaviors in complex
environments without humans to design tasks and rewards. Designing these
functions for each environment is not feasible, thus, motivating the
development of intrinsic reward functions. In this paper, we propose using
several cognitive elements that have been neglected for a long time to build an
internal world model for an intrinsically motivated agent. Our agent performs
satisfactory iterations with the environment, learning complex behaviors
without needing previously designed reward functions. We used 18 Atari games to
evaluate what cognitive skills emerge in games that require reactive and
deliberative behaviors. Our results show superior performance compared to the
state-of-the-art in many test cases with dense and sparse rewards.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Autonomous artificial agents must be able to learn behaviors in complex\nenvironments without humans to design tasks and rewards. Designing these\nfunctions for each environment is not feasible, thus, motivating the\ndevelopment of intrinsic reward functions. In this paper, we propose using\nseveral cognitive elements that have been neglected for a long time to build an\ninternal world model for an intrinsically motivated agent. Our agent performs\nsatisfactory iterations with the environment, learning complex behaviors\nwithout needing previously designed reward functions. We used 18 Atari games to\nevaluate what cognitive skills emerge in games that require reactive and\ndeliberative behaviors. Our results show superior performance compared to the\nstate-of-the-art in many test cases with dense and sparse rewards.'}","['Alana Santana', 'Paula P. Costa', 'Esther L. Colombini']",{'name': 'Esther L. Colombini'},Esther L. Colombini,,"[{'href': 'http://arxiv.org/abs/2502.13200v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13200v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13200v1,None,http://arxiv.org/abs/2502.13200v1,,,313,0
http://arxiv.org/abs/2502.13251v2,True,2025-02-20T09:03:05Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=9, tm_min=3, tm_sec=5, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-18T19:22:44Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=19, tm_min=22, tm_sec=44, tm_wday=1, tm_yday=49, tm_isdst=0)",Neural Attention Search,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Neural Attention Search'}","We present Neural Attention Search (NAtS), a framework that automatically
evaluates the importance of each token within a sequence and determines if the
corresponding token can be dropped after several steps. This approach can
efficiently reduce the KV cache sizes required by transformer-based models
during inference and thus reduce inference costs. In this paper, we design a
search space that contains three token types: (i) Global Tokens will be
preserved and queried by all the following tokens. (ii) Local Tokens survive
until the next global token appears. (iii) Sliding Window Tokens have an impact
on the inference of a fixed size of the next following tokens. Similar to the
One-Shot Neural Architecture Search approach, this token-type information can
be learned jointly with the architecture weights via a learnable attention
mask. Experiments on both training a new transformer from scratch and
fine-tuning existing large language models show that NAtS can efficiently
reduce the KV cache size required for the models while maintaining the models'
performance.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""We present Neural Attention Search (NAtS), a framework that automatically\nevaluates the importance of each token within a sequence and determines if the\ncorresponding token can be dropped after several steps. This approach can\nefficiently reduce the KV cache sizes required by transformer-based models\nduring inference and thus reduce inference costs. In this paper, we design a\nsearch space that contains three token types: (i) Global Tokens will be\npreserved and queried by all the following tokens. (ii) Local Tokens survive\nuntil the next global token appears. (iii) Sliding Window Tokens have an impact\non the inference of a fixed size of the next following tokens. Similar to the\nOne-Shot Neural Architecture Search approach, this token-type information can\nbe learned jointly with the architecture weights via a learnable attention\nmask. Experiments on both training a new transformer from scratch and\nfine-tuning existing large language models show that NAtS can efficiently\nreduce the KV cache size required for the models while maintaining the models'\nperformance.""}","['Difan Deng', 'Marius Lindauer']",{'name': 'Marius Lindauer'},Marius Lindauer,"18 pages, 8 figures","[{'href': 'http://arxiv.org/abs/2502.13251v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13251v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13251v2,None,http://arxiv.org/abs/2502.13251v2,,,731,0
http://arxiv.org/abs/2502.13256v1,True,2025-02-18T19:38:18Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=19, tm_min=38, tm_sec=18, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T19:38:18Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=19, tm_min=38, tm_sec=18, tm_wday=1, tm_yday=49, tm_isdst=0)",A Survey of Anomaly Detection in Cyber-Physical Systems,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A Survey of Anomaly Detection in Cyber-Physical Systems'}","In our increasingly interconnected world, Cyber-Physical Systems (CPS) play a
crucial role in industries like healthcare, transportation, and manufacturing
by combining physical processes with computing power. These systems, however,
face many challenges, especially regarding security and system faults.
Anomalies in CPS may indicate unexpected problems, from sensor malfunctions to
cyber-attacks, and must be detected to prevent failures that can cause harm or
disrupt services. This paper provides an overview of the different ways
researchers have approached anomaly detection in CPS. We categorize and compare
methods like machine learning, deep learning, mathematical models, invariant,
and hybrid techniques. Our goal is to help readers understand the strengths and
weaknesses of these methods and how they can be used to create safer, more
reliable CPS. By identifying the gaps in current solutions, we aim to encourage
future research that will make CPS more secure and adaptive in our increasingly
automated world.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'In our increasingly interconnected world, Cyber-Physical Systems (CPS) play a\ncrucial role in industries like healthcare, transportation, and manufacturing\nby combining physical processes with computing power. These systems, however,\nface many challenges, especially regarding security and system faults.\nAnomalies in CPS may indicate unexpected problems, from sensor malfunctions to\ncyber-attacks, and must be detected to prevent failures that can cause harm or\ndisrupt services. This paper provides an overview of the different ways\nresearchers have approached anomaly detection in CPS. We categorize and compare\nmethods like machine learning, deep learning, mathematical models, invariant,\nand hybrid techniques. Our goal is to help readers understand the strengths and\nweaknesses of these methods and how they can be used to create safer, more\nreliable CPS. By identifying the gaps in current solutions, we aim to encourage\nfuture research that will make CPS more secure and adaptive in our increasingly\nautomated world.'}","['Danial Abshari', 'Meera Sridhar']",{'name': 'Meera Sridhar'},Meera Sridhar,,"[{'href': 'http://arxiv.org/abs/2502.13256v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13256v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13256v1,None,http://arxiv.org/abs/2502.13256v1,,,6,0
http://arxiv.org/abs/2502.13277v1,True,2025-02-18T20:57:56Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=20, tm_min=57, tm_sec=56, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T20:57:56Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=20, tm_min=57, tm_sec=56, tm_wday=1, tm_yday=49, tm_isdst=0)","HyperGCL: Multi-Modal Graph Contrastive Learning via Learnable
  Hypergraph Views","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'HyperGCL: Multi-Modal Graph Contrastive Learning via Learnable\n  Hypergraph Views'}","Recent advancements in Graph Contrastive Learning (GCL) have demonstrated
remarkable effectiveness in improving graph representations. However, relying
on predefined augmentations (e.g., node dropping, edge perturbation, attribute
masking) may result in the loss of task-relevant information and a lack of
adaptability to diverse input data. Furthermore, the selection of negative
samples remains rarely explored. In this paper, we introduce HyperGCL, a novel
multimodal GCL framework from a hypergraph perspective. HyperGCL constructs
three distinct hypergraph views by jointly utilizing the input graph's
structure and attributes, enabling a comprehensive integration of multiple
modalities in contrastive learning. A learnable adaptive topology augmentation
technique enhances these views by preserving important relations and filtering
out noise. View-specific encoders capture essential characteristics from each
view, while a network-aware contrastive loss leverages the underlying topology
to define positive and negative samples effectively. Extensive experiments on
benchmark datasets demonstrate that HyperGCL achieves state-of-the-art node
classification performance.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Recent advancements in Graph Contrastive Learning (GCL) have demonstrated\nremarkable effectiveness in improving graph representations. However, relying\non predefined augmentations (e.g., node dropping, edge perturbation, attribute\nmasking) may result in the loss of task-relevant information and a lack of\nadaptability to diverse input data. Furthermore, the selection of negative\nsamples remains rarely explored. In this paper, we introduce HyperGCL, a novel\nmultimodal GCL framework from a hypergraph perspective. HyperGCL constructs\nthree distinct hypergraph views by jointly utilizing the input graph's\nstructure and attributes, enabling a comprehensive integration of multiple\nmodalities in contrastive learning. A learnable adaptive topology augmentation\ntechnique enhances these views by preserving important relations and filtering\nout noise. View-specific encoders capture essential characteristics from each\nview, while a network-aware contrastive loss leverages the underlying topology\nto define positive and negative samples effectively. Extensive experiments on\nbenchmark datasets demonstrate that HyperGCL achieves state-of-the-art node\nclassification performance.""}","['Khaled Mohammed Saifuddin', 'Jonathan Shihao Ji', 'Esra Akbas']",{'name': 'Esra Akbas'},Esra Akbas,"9 pages, 2 figures","[{'href': 'http://arxiv.org/abs/2502.13277v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13277v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13277v1,None,http://arxiv.org/abs/2502.13277v1,,,670,0
http://arxiv.org/abs/2502.13278v1,True,2025-02-18T20:58:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=20, tm_min=58, tm_sec=37, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T20:58:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=20, tm_min=58, tm_sec=37, tm_wday=1, tm_yday=49, tm_isdst=0)","Performance Evaluation of Sentiment Analysis on Text and Emoji Data
  Using End-to-End, Transfer Learning, Distributed and Explainable AI Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Performance Evaluation of Sentiment Analysis on Text and Emoji Data\n  Using End-to-End, Transfer Learning, Distributed and Explainable AI Models'}","Emojis are being frequently used in todays digital world to express from
simple to complex thoughts more than ever before. Hence, they are also being
used in sentiment analysis and targeted marketing campaigns. In this work, we
performed sentiment analysis of Tweets as well as on emoji dataset from the
Kaggle. Since tweets are sentences we have used Universal Sentence Encoder
(USE) and Sentence Bidirectional Encoder Representations from Transformers
(SBERT) end-to-end sentence embedding models to generate the embeddings which
are used to train the Standard fully connected Neural Networks (NN), and LSTM
NN models. We observe the text classification accuracy was almost the same for
both the models around 98 percent. On the contrary, when the validation set was
built using emojis that were not present in the training set then the accuracy
of both the models reduced drastically to 70 percent. In addition, the models
were also trained using the distributed training approach instead of a
traditional singlethreaded model for better scalability. Using the distributed
training approach, we were able to reduce the run-time by roughly 15% without
compromising on accuracy. Finally, as part of explainable AI the Shap algorithm
was used to explain the model behaviour and check for model biases for the
given feature set.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Emojis are being frequently used in todays digital world to express from\nsimple to complex thoughts more than ever before. Hence, they are also being\nused in sentiment analysis and targeted marketing campaigns. In this work, we\nperformed sentiment analysis of Tweets as well as on emoji dataset from the\nKaggle. Since tweets are sentences we have used Universal Sentence Encoder\n(USE) and Sentence Bidirectional Encoder Representations from Transformers\n(SBERT) end-to-end sentence embedding models to generate the embeddings which\nare used to train the Standard fully connected Neural Networks (NN), and LSTM\nNN models. We observe the text classification accuracy was almost the same for\nboth the models around 98 percent. On the contrary, when the validation set was\nbuilt using emojis that were not present in the training set then the accuracy\nof both the models reduced drastically to 70 percent. In addition, the models\nwere also trained using the distributed training approach instead of a\ntraditional singlethreaded model for better scalability. Using the distributed\ntraining approach, we were able to reduce the run-time by roughly 15% without\ncompromising on accuracy. Finally, as part of explainable AI the Shap algorithm\nwas used to explain the model behaviour and check for model biases for the\ngiven feature set.'}","['Sirisha Velampalli', 'Chandrashekar Muniyappa', 'Ashutosh Saxena']",{'name': 'Ashutosh Saxena'},Ashutosh Saxena,,"[{'title': 'doi', 'href': 'http://dx.doi.org/10.12720/jait.13.2.167-172', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2502.13278v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13278v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7; I.2.11', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13278v1,None,http://arxiv.org/abs/2502.13278v1,"Journal of Advances in Information Technology Vol. 13, No. 2,
  April 2022",10.12720/jait.13.2.167-172,157,0
http://arxiv.org/abs/2502.13290v1,True,2025-02-18T21:18:19Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=21, tm_min=18, tm_sec=19, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T21:18:19Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=21, tm_min=18, tm_sec=19, tm_wday=1, tm_yday=49, tm_isdst=0)",Prediction of Clinical Complication Onset using Neural Point Processes,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Prediction of Clinical Complication Onset using Neural Point Processes'}","Predicting medical events in advance within critical care settings is
paramount for patient outcomes and resource management. Utilizing predictive
models, healthcare providers can anticipate issues such as cardiac arrest,
sepsis, or respiratory failure before they manifest. Recently, there has been a
surge in research focusing on forecasting adverse medical event onsets prior to
clinical manifestation using machine learning. However, while these models
provide temporal prognostic predictions for the occurrence of a specific
adverse event of interest within defined time intervals, their interpretability
often remains a challenge. In this work, we explore the applicability of neural
temporal point processes in the context of adverse event onset prediction, with
the aim of explaining clinical pathways and providing interpretable insights.
Our experiments span six state-of-the-art neural point processes and six
critical care datasets, each focusing on the onset of distinct adverse events.
This work represents a novel application class of neural temporal point
processes in event prediction.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Predicting medical events in advance within critical care settings is\nparamount for patient outcomes and resource management. Utilizing predictive\nmodels, healthcare providers can anticipate issues such as cardiac arrest,\nsepsis, or respiratory failure before they manifest. Recently, there has been a\nsurge in research focusing on forecasting adverse medical event onsets prior to\nclinical manifestation using machine learning. However, while these models\nprovide temporal prognostic predictions for the occurrence of a specific\nadverse event of interest within defined time intervals, their interpretability\noften remains a challenge. In this work, we explore the applicability of neural\ntemporal point processes in the context of adverse event onset prediction, with\nthe aim of explaining clinical pathways and providing interpretable insights.\nOur experiments span six state-of-the-art neural point processes and six\ncritical care datasets, each focusing on the onset of distinct adverse events.\nThis work represents a novel application class of neural temporal point\nprocesses in event prediction.'}","['Sachini Weerasekara', 'Sagar Kamarthi', 'Jacqueline Isaacs']",{'name': 'Jacqueline Isaacs'},Jacqueline Isaacs,,"[{'href': 'http://arxiv.org/abs/2502.13290v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13290v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13290v1,None,http://arxiv.org/abs/2502.13290v1,,,2898,0
http://arxiv.org/abs/2502.13297v1,True,2025-02-18T21:35:46Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=21, tm_min=35, tm_sec=46, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T21:35:46Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=21, tm_min=35, tm_sec=46, tm_wday=1, tm_yday=49, tm_isdst=0)","Understanding and Tackling Label Errors in Individual-Level Nature
  Language Understanding","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Understanding and Tackling Label Errors in Individual-Level Nature\n  Language Understanding'}","Natural language understanding (NLU) is a task that enables machines to
understand human language. Some tasks, such as stance detection and sentiment
analysis, are closely related to individual subjective perspectives, thus
termed individual-level NLU. Previously, these tasks are often simplified to
text-level NLU tasks, ignoring individual factors. This not only makes
inference difficult and unexplainable but often results in a large number of
label errors when creating datasets. To address the above limitations, we
propose a new NLU annotation guideline based on individual-level factors.
Specifically, we incorporate other posts by the same individual and then
annotate individual subjective perspectives after considering all individual
posts. We use this guideline to expand and re-annotate the stance detection and
topic-based sentiment analysis datasets. We find that error rates in the
samples were as high as 31.7\% and 23.3\%. We further use large language models
to conduct experiments on the re-annotation datasets and find that the large
language models perform well on both datasets after adding individual factors.
Both GPT-4o and Llama3-70B can achieve an accuracy greater than 87\% on the
re-annotation datasets. We also verify the effectiveness of individual factors
through ablation studies. We call on future researchers to add individual
factors when creating such datasets. Our re-annotation dataset can be found at
https://github.com/24yearsoldstudent/Individual-NLU","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Natural language understanding (NLU) is a task that enables machines to\nunderstand human language. Some tasks, such as stance detection and sentiment\nanalysis, are closely related to individual subjective perspectives, thus\ntermed individual-level NLU. Previously, these tasks are often simplified to\ntext-level NLU tasks, ignoring individual factors. This not only makes\ninference difficult and unexplainable but often results in a large number of\nlabel errors when creating datasets. To address the above limitations, we\npropose a new NLU annotation guideline based on individual-level factors.\nSpecifically, we incorporate other posts by the same individual and then\nannotate individual subjective perspectives after considering all individual\nposts. We use this guideline to expand and re-annotate the stance detection and\ntopic-based sentiment analysis datasets. We find that error rates in the\nsamples were as high as 31.7\\% and 23.3\\%. We further use large language models\nto conduct experiments on the re-annotation datasets and find that the large\nlanguage models perform well on both datasets after adding individual factors.\nBoth GPT-4o and Llama3-70B can achieve an accuracy greater than 87\\% on the\nre-annotation datasets. We also verify the effectiveness of individual factors\nthrough ablation studies. We call on future researchers to add individual\nfactors when creating such datasets. Our re-annotation dataset can be found at\nhttps://github.com/24yearsoldstudent/Individual-NLU'}","['Yunpeng Xiao', 'Youpeng Zhao', 'Kai Shu']",{'name': 'Kai Shu'},Kai Shu,12 pages,"[{'href': 'http://arxiv.org/abs/2502.13297v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13297v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13297v1,None,http://arxiv.org/abs/2502.13297v1,,,13,0
http://arxiv.org/abs/2502.13311v1,True,2025-02-18T22:13:00Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=22, tm_min=13, tm_sec=0, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T22:13:00Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=22, tm_min=13, tm_sec=0, tm_wday=1, tm_yday=49, tm_isdst=0)","Training Turn-by-Turn Verifiers for Dialogue Tutoring Agents: The
  Curious Case of LLMs as Your Coding Tutors","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Training Turn-by-Turn Verifiers for Dialogue Tutoring Agents: The\n  Curious Case of LLMs as Your Coding Tutors'}","Intelligent tutoring agents powered by large language models (LLMs) have been
increasingly explored to deliver personalized guidance in areas such as
language learning and science education. However, their capabilities in guiding
users to solve complex real-world tasks remain underexplored. To address this
limitation, in this work, we focus on coding tutoring, a challenging problem
that requires tutors to proactively guide students toward completing predefined
coding tasks. We propose a novel agent workflow, Trace-and-Verify (TRAVER),
which combines knowledge tracing to estimate a student's knowledge state and
turn-by-turn verification to ensure effective guidance toward task completion.
We introduce DICT, an automatic evaluation protocol that assesses tutor agents
holistically using controlled student simulation and code generation tests.
Extensive experiments reveal the challenges of coding tutoring and demonstrate
that TRAVER achieves a significantly higher success rate. Although we use code
tutoring as an example in this paper, our results and findings can be extended
beyond coding, providing valuable insights into advancing tutoring agents for a
variety of tasks.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Intelligent tutoring agents powered by large language models (LLMs) have been\nincreasingly explored to deliver personalized guidance in areas such as\nlanguage learning and science education. However, their capabilities in guiding\nusers to solve complex real-world tasks remain underexplored. To address this\nlimitation, in this work, we focus on coding tutoring, a challenging problem\nthat requires tutors to proactively guide students toward completing predefined\ncoding tasks. We propose a novel agent workflow, Trace-and-Verify (TRAVER),\nwhich combines knowledge tracing to estimate a student's knowledge state and\nturn-by-turn verification to ensure effective guidance toward task completion.\nWe introduce DICT, an automatic evaluation protocol that assesses tutor agents\nholistically using controlled student simulation and code generation tests.\nExtensive experiments reveal the challenges of coding tutoring and demonstrate\nthat TRAVER achieves a significantly higher success rate. Although we use code\ntutoring as an example in this paper, our results and findings can be extended\nbeyond coding, providing valuable insights into advancing tutoring agents for a\nvariety of tasks.""}","['Jian Wang', 'Yinpei Dai', 'Yichi Zhang', 'Ziqiao Ma', 'Wenjie Li', 'Joyce Chai']",{'name': 'Joyce Chai'},Joyce Chai,,"[{'href': 'http://arxiv.org/abs/2502.13311v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13311v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13311v1,None,http://arxiv.org/abs/2502.13311v1,,,254,0
http://arxiv.org/abs/2502.13313v1,True,2025-02-18T22:16:03Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=22, tm_min=16, tm_sec=3, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T22:16:03Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=22, tm_min=16, tm_sec=3, tm_wday=1, tm_yday=49, tm_isdst=0)","Revisiting Privacy, Utility, and Efficiency Trade-offs when Fine-Tuning
  Large Language Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Revisiting Privacy, Utility, and Efficiency Trade-offs when Fine-Tuning\n  Large Language Models'}","We study the inherent trade-offs in minimizing privacy risks and maximizing
utility, while maintaining high computational efficiency, when fine-tuning
large language models (LLMs). A number of recent works in privacy research have
attempted to mitigate privacy risks posed by memorizing fine-tuning data by
using differentially private training methods (e.g., DP), albeit at a
significantly higher computational cost (inefficiency). In parallel, several
works in systems research have focussed on developing (parameter) efficient
fine-tuning methods (e.g., LoRA), but few works, if any, investigated whether
such efficient methods enhance or diminish privacy risks. In this paper, we
investigate this gap and arrive at a surprising conclusion: efficient
fine-tuning methods like LoRA mitigate privacy risks similar to private
fine-tuning methods like DP. Our empirical finding directly contradicts
prevailing wisdom that privacy and efficiency objectives are at odds during
fine-tuning. Our finding is established by (a) carefully defining measures of
privacy and utility that distinguish between memorizing sensitive and
non-sensitive tokens in training and test datasets used in fine-tuning and (b)
extensive evaluations using multiple open-source language models from Pythia,
Gemma, and Llama families and different domain-specific datasets.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'We study the inherent trade-offs in minimizing privacy risks and maximizing\nutility, while maintaining high computational efficiency, when fine-tuning\nlarge language models (LLMs). A number of recent works in privacy research have\nattempted to mitigate privacy risks posed by memorizing fine-tuning data by\nusing differentially private training methods (e.g., DP), albeit at a\nsignificantly higher computational cost (inefficiency). In parallel, several\nworks in systems research have focussed on developing (parameter) efficient\nfine-tuning methods (e.g., LoRA), but few works, if any, investigated whether\nsuch efficient methods enhance or diminish privacy risks. In this paper, we\ninvestigate this gap and arrive at a surprising conclusion: efficient\nfine-tuning methods like LoRA mitigate privacy risks similar to private\nfine-tuning methods like DP. Our empirical finding directly contradicts\nprevailing wisdom that privacy and efficiency objectives are at odds during\nfine-tuning. Our finding is established by (a) carefully defining measures of\nprivacy and utility that distinguish between memorizing sensitive and\nnon-sensitive tokens in training and test datasets used in fine-tuning and (b)\nextensive evaluations using multiple open-source language models from Pythia,\nGemma, and Llama families and different domain-specific datasets.'}","['Soumi Das', 'Camila Kolling', 'Mohammad Aflah Khan', 'Mahsa Amani', 'Bishwamittra Ghosh', 'Qinyuan Wu', 'Till Speicher', 'Krishna P. Gummadi']",{'name': 'Krishna P. Gummadi'},Krishna P. Gummadi,This is a work in progress. The draft may change in future,"[{'href': 'http://arxiv.org/abs/2502.13313v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13313v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13313v1,None,http://arxiv.org/abs/2502.13313v1,,,603,0
http://arxiv.org/abs/2502.13337v1,True,2025-02-18T23:38:21Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=23, tm_min=38, tm_sec=21, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T23:38:21Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=23, tm_min=38, tm_sec=21, tm_wday=1, tm_yday=49, tm_isdst=0)",Language Models are Few-Shot Graders,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Language Models are Few-Shot Graders'}","Providing evaluations to student work is a critical component of effective
student learning, and automating its process can significantly reduce the
workload on human graders. Automatic Short Answer Grading (ASAG) systems,
enabled by advancements in Large Language Models (LLMs), offer a promising
solution for assessing and providing instant feedback for open-ended student
responses. In this paper, we present an ASAG pipeline leveraging
state-of-the-art LLMs. Our new LLM-based ASAG pipeline achieves better
performances than existing custom-built models on the same datasets. We also
compare the grading performance of three OpenAI models: GPT-4, GPT-4o, and
o1-preview. Our results demonstrate that GPT-4o achieves the best balance
between accuracy and cost-effectiveness. On the other hand, o1-preview, despite
higher accuracy, exhibits a larger variance in error that makes it less
practical for classroom use. We investigate the effects of incorporating
instructor-graded examples into prompts using no examples, random selection,
and Retrieval-Augmented Generation (RAG)-based selection strategies. Our
findings indicate that providing graded examples enhances grading accuracy,
with RAG-based selection outperforming random selection. Additionally,
integrating grading rubrics improves accuracy by offering a structured standard
for evaluation.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Providing evaluations to student work is a critical component of effective\nstudent learning, and automating its process can significantly reduce the\nworkload on human graders. Automatic Short Answer Grading (ASAG) systems,\nenabled by advancements in Large Language Models (LLMs), offer a promising\nsolution for assessing and providing instant feedback for open-ended student\nresponses. In this paper, we present an ASAG pipeline leveraging\nstate-of-the-art LLMs. Our new LLM-based ASAG pipeline achieves better\nperformances than existing custom-built models on the same datasets. We also\ncompare the grading performance of three OpenAI models: GPT-4, GPT-4o, and\no1-preview. Our results demonstrate that GPT-4o achieves the best balance\nbetween accuracy and cost-effectiveness. On the other hand, o1-preview, despite\nhigher accuracy, exhibits a larger variance in error that makes it less\npractical for classroom use. We investigate the effects of incorporating\ninstructor-graded examples into prompts using no examples, random selection,\nand Retrieval-Augmented Generation (RAG)-based selection strategies. Our\nfindings indicate that providing graded examples enhances grading accuracy,\nwith RAG-based selection outperforming random selection. Additionally,\nintegrating grading rubrics improves accuracy by offering a structured standard\nfor evaluation.'}","['Chenyan Zhao', 'Mariana Silva', 'Seth Poulsen']",{'name': 'Seth Poulsen'},Seth Poulsen,,"[{'href': 'http://arxiv.org/abs/2502.13337v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13337v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13337v1,None,http://arxiv.org/abs/2502.13337v1,,,0,0
http://arxiv.org/abs/2502.13339v1,True,2025-02-18T23:38:39Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=23, tm_min=38, tm_sec=39, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T23:38:39Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=23, tm_min=38, tm_sec=39, tm_wday=1, tm_yday=49, tm_isdst=0)",How Expressive are Knowledge Graph Foundation Models?,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'How Expressive are Knowledge Graph Foundation Models?'}","Knowledge Graph Foundation Models (KGFMs) are at the frontier for deep
learning on knowledge graphs (KGs), as they can generalize to completely novel
knowledge graphs with different relational vocabularies. Despite their
empirical success, our theoretical understanding of KGFMs remains very limited.
In this paper, we conduct a rigorous study of the expressive power of KGFMs.
Specifically, we show that the expressive power of KGFMs directly depends on
the motifs that are used to learn the relation representations. We then observe
that the most typical motifs used in the existing literature are binary, as the
representations are learned based on how pairs of relations interact, which
limits the model's expressiveness. As part of our study, we design more
expressive KGFMs using richer motifs, which necessitate learning relation
representations based on, e.g., how triples of relations interact with each
other. Finally, we empirically validate our theoretical findings, showing that
the use of richer motifs results in better performance on a wide range of
datasets drawn from different domains.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Knowledge Graph Foundation Models (KGFMs) are at the frontier for deep\nlearning on knowledge graphs (KGs), as they can generalize to completely novel\nknowledge graphs with different relational vocabularies. Despite their\nempirical success, our theoretical understanding of KGFMs remains very limited.\nIn this paper, we conduct a rigorous study of the expressive power of KGFMs.\nSpecifically, we show that the expressive power of KGFMs directly depends on\nthe motifs that are used to learn the relation representations. We then observe\nthat the most typical motifs used in the existing literature are binary, as the\nrepresentations are learned based on how pairs of relations interact, which\nlimits the model's expressiveness. As part of our study, we design more\nexpressive KGFMs using richer motifs, which necessitate learning relation\nrepresentations based on, e.g., how triples of relations interact with each\nother. Finally, we empirically validate our theoretical findings, showing that\nthe use of richer motifs results in better performance on a wide range of\ndatasets drawn from different domains.""}","['Xingyue Huang', 'Pablo Barcel', 'Michael M. Bronstein', 'smail lkan Ceylan', 'Mikhail Galkin', 'Juan L Reutter', 'Miguel Romero Orth']",{'name': 'Miguel Romero Orth'},Miguel Romero Orth,,"[{'href': 'http://arxiv.org/abs/2502.13339v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13339v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13339v1,None,http://arxiv.org/abs/2502.13339v1,,,659,0
http://arxiv.org/abs/2502.13345v1,True,2025-02-18T23:55:33Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=23, tm_min=55, tm_sec=33, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T23:55:33Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=23, tm_min=55, tm_sec=33, tm_wday=1, tm_yday=49, tm_isdst=0)","Secure and Efficient Watermarking for Latent Diffusion Models in Model
  Distribution Scenarios","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Secure and Efficient Watermarking for Latent Diffusion Models in Model\n  Distribution Scenarios'}","Latent diffusion models have exhibited considerable potential in generative
tasks. Watermarking is considered to be an alternative to safeguard the
copyright of generative models and prevent their misuse. However, in the
context of model distribution scenarios, the accessibility of models to large
scale of model users brings new challenges to the security, efficiency and
robustness of existing watermark solutions. To address these issues, we propose
a secure and efficient watermarking solution. A new security mechanism is
designed to prevent watermark leakage and watermark escape, which considers
watermark randomness and watermark-model association as two constraints for
mandatory watermark injection. To reduce the time cost of training the security
module, watermark injection and the security mechanism are decoupled, ensuring
that fine-tuning VAE only accomplishes the security mechanism without the
burden of learning watermark patterns. A watermark distribution-based
verification strategy is proposed to enhance the robustness against diverse
attacks in the model distribution scenarios. Experimental results prove that
our watermarking consistently outperforms existing six baselines on
effectiveness and robustness against ten image processing attacks and
adversarial attacks, while enhancing security in the distribution scenarios.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Latent diffusion models have exhibited considerable potential in generative\ntasks. Watermarking is considered to be an alternative to safeguard the\ncopyright of generative models and prevent their misuse. However, in the\ncontext of model distribution scenarios, the accessibility of models to large\nscale of model users brings new challenges to the security, efficiency and\nrobustness of existing watermark solutions. To address these issues, we propose\na secure and efficient watermarking solution. A new security mechanism is\ndesigned to prevent watermark leakage and watermark escape, which considers\nwatermark randomness and watermark-model association as two constraints for\nmandatory watermark injection. To reduce the time cost of training the security\nmodule, watermark injection and the security mechanism are decoupled, ensuring\nthat fine-tuning VAE only accomplishes the security mechanism without the\nburden of learning watermark patterns. A watermark distribution-based\nverification strategy is proposed to enhance the robustness against diverse\nattacks in the model distribution scenarios. Experimental results prove that\nour watermarking consistently outperforms existing six baselines on\neffectiveness and robustness against ten image processing attacks and\nadversarial attacks, while enhancing security in the distribution scenarios.'}","['Liangqi Lei', 'Keke Gai', 'Jing Yu', 'Liehuang Zhu', 'Qi Wu']",{'name': 'Qi Wu'},Qi Wu,,"[{'href': 'http://arxiv.org/abs/2502.13345v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13345v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13345v1,None,http://arxiv.org/abs/2502.13345v1,,,92,0
http://arxiv.org/abs/2502.13361v1,True,2025-02-19T01:50:10Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=1, tm_min=50, tm_sec=10, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T01:50:10Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=1, tm_min=50, tm_sec=10, tm_wday=2, tm_yday=50, tm_isdst=0)","RGAR: Recurrence Generation-augmented Retrieval for Factual-aware
  Medical Question Answering","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'RGAR: Recurrence Generation-augmented Retrieval for Factual-aware\n  Medical Question Answering'}","Medical question answering requires extensive access to specialized
conceptual knowledge. The current paradigm, Retrieval-Augmented Generation
(RAG), acquires expertise medical knowledge through large-scale corpus
retrieval and uses this knowledge to guide a general-purpose large language
model (LLM) for generating answers. However, existing retrieval approaches
often overlook the importance of factual knowledge, which limits the relevance
of retrieved conceptual knowledge and restricts its applicability in real-world
scenarios, such as clinical decision-making based on Electronic Health Records
(EHRs). This paper introduces RGAR, a recurrence generation-augmented retrieval
framework that retrieves both relevant factual and conceptual knowledge from
dual sources (i.e., EHRs and the corpus), allowing them to interact and refine
each another. Through extensive evaluation across three factual-aware medical
question answering benchmarks, RGAR establishes a new state-of-the-art
performance among medical RAG systems. Notably, the Llama-3.1-8B-Instruct model
with RGAR surpasses the considerably larger, RAG-enhanced GPT-3.5. Our findings
demonstrate the benefit of extracting factual knowledge for retrieval, which
consistently yields improved generation quality.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Medical question answering requires extensive access to specialized\nconceptual knowledge. The current paradigm, Retrieval-Augmented Generation\n(RAG), acquires expertise medical knowledge through large-scale corpus\nretrieval and uses this knowledge to guide a general-purpose large language\nmodel (LLM) for generating answers. However, existing retrieval approaches\noften overlook the importance of factual knowledge, which limits the relevance\nof retrieved conceptual knowledge and restricts its applicability in real-world\nscenarios, such as clinical decision-making based on Electronic Health Records\n(EHRs). This paper introduces RGAR, a recurrence generation-augmented retrieval\nframework that retrieves both relevant factual and conceptual knowledge from\ndual sources (i.e., EHRs and the corpus), allowing them to interact and refine\neach another. Through extensive evaluation across three factual-aware medical\nquestion answering benchmarks, RGAR establishes a new state-of-the-art\nperformance among medical RAG systems. Notably, the Llama-3.1-8B-Instruct model\nwith RGAR surpasses the considerably larger, RAG-enhanced GPT-3.5. Our findings\ndemonstrate the benefit of extracting factual knowledge for retrieval, which\nconsistently yields improved generation quality.'}","['Sichu Liang', 'Linhai Zhang', 'Hongyu Zhu', 'Wenwen Wang', 'Yulan He', 'Deyu Zhou']",{'name': 'Deyu Zhou'},Deyu Zhou,,"[{'href': 'http://arxiv.org/abs/2502.13361v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13361v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13361v1,None,http://arxiv.org/abs/2502.13361v1,,,148,0
http://arxiv.org/abs/2502.13407v1,True,2025-02-19T03:33:54Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=3, tm_min=33, tm_sec=54, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T03:33:54Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=3, tm_min=33, tm_sec=54, tm_wday=2, tm_yday=50, tm_isdst=0)","JL1-CD: A New Benchmark for Remote Sensing Change Detection and a Robust
  Multi-Teacher Knowledge Distillation Framework","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'JL1-CD: A New Benchmark for Remote Sensing Change Detection and a Robust\n  Multi-Teacher Knowledge Distillation Framework'}","Deep learning has achieved significant success in the field of remote sensing
image change detection (CD), yet two major challenges remain: the scarcity of
sub-meter, all-inclusive open-source CD datasets, and the difficulty of
achieving consistent and satisfactory detection results across images with
varying change areas. To address these issues, we introduce the JL1-CD dataset,
which contains 5,000 pairs of 512 x 512 pixel images with a resolution of 0.5
to 0.75 meters. Additionally, we propose a multi-teacher knowledge distillation
(MTKD) framework for CD. Experimental results on the JL1-CD and SYSU-CD
datasets demonstrate that the MTKD framework significantly improves the
performance of CD models with various network architectures and parameter
sizes, achieving new state-of-the-art results. The code is available at
https://github.com/circleLZY/MTKD-CD.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Deep learning has achieved significant success in the field of remote sensing\nimage change detection (CD), yet two major challenges remain: the scarcity of\nsub-meter, all-inclusive open-source CD datasets, and the difficulty of\nachieving consistent and satisfactory detection results across images with\nvarying change areas. To address these issues, we introduce the JL1-CD dataset,\nwhich contains 5,000 pairs of 512 x 512 pixel images with a resolution of 0.5\nto 0.75 meters. Additionally, we propose a multi-teacher knowledge distillation\n(MTKD) framework for CD. Experimental results on the JL1-CD and SYSU-CD\ndatasets demonstrate that the MTKD framework significantly improves the\nperformance of CD models with various network architectures and parameter\nsizes, achieving new state-of-the-art results. The code is available at\nhttps://github.com/circleLZY/MTKD-CD.'}","['Ziyuan Liu', 'Ruifei Zhu', 'Long Gao', 'Yuanxiu Zhou', 'Jingyu Ma', 'Yuantao Gu']",{'name': 'Yuantao Gu'},Yuantao Gu,"14 pages, 9 figures. Submitted to IEEE Transactions on Geoscience and
  Remote Sensing (TGRS)","[{'href': 'http://arxiv.org/abs/2502.13407v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13407v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13407v1,None,http://arxiv.org/abs/2502.13407v1,,,3,0
http://arxiv.org/abs/2502.13412v1,True,2025-02-19T03:51:31Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=3, tm_min=51, tm_sec=31, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T03:51:31Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=3, tm_min=51, tm_sec=31, tm_wday=2, tm_yday=50, tm_isdst=0)","Explore-Construct-Filter: An Automated Framework for Rich and Reliable
  API Knowledge Graph Construction","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Explore-Construct-Filter: An Automated Framework for Rich and Reliable\n  API Knowledge Graph Construction'}","The API Knowledge Graph (API KG) is a structured network that models API
entities and their relations, providing essential semantic insights for tasks
such as API recommendation, code generation, and API misuse detection. However,
constructing a knowledge-rich and reliable API KG presents several challenges.
Existing schema-based methods rely heavily on manual annotations to design KG
schemas, leading to excessive manual overhead. On the other hand, schema-free
methods, due to the lack of schema guidance, are prone to introducing noise,
reducing the KG's reliability. To address these issues, we propose the
Explore-Construct-Filter framework, an automated approach for API KG
construction based on large language models (LLMs). This framework consists of
three key modules: 1) KG exploration: LLMs simulate the workflow of annotators
to automatically design a schema with comprehensive type triples, minimizing
human intervention; 2) KG construction: Guided by the schema, LLMs extract
instance triples to construct a rich yet unreliable API KG; 3) KG filtering:
Removing invalid type triples and suspicious instance triples to construct a
rich and reliable API KG. Experimental results demonstrate that our method
surpasses the state-of-the-art method, achieving a 25.2% improvement in F1
score. Moreover, the Explore-Construct-Filter framework proves effective, with
the KG exploration module increasing KG richness by 133.6% and the KG filtering
module improving reliability by 26.6%. Finally, cross-model experiments confirm
the generalizability of our framework.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""The API Knowledge Graph (API KG) is a structured network that models API\nentities and their relations, providing essential semantic insights for tasks\nsuch as API recommendation, code generation, and API misuse detection. However,\nconstructing a knowledge-rich and reliable API KG presents several challenges.\nExisting schema-based methods rely heavily on manual annotations to design KG\nschemas, leading to excessive manual overhead. On the other hand, schema-free\nmethods, due to the lack of schema guidance, are prone to introducing noise,\nreducing the KG's reliability. To address these issues, we propose the\nExplore-Construct-Filter framework, an automated approach for API KG\nconstruction based on large language models (LLMs). This framework consists of\nthree key modules: 1) KG exploration: LLMs simulate the workflow of annotators\nto automatically design a schema with comprehensive type triples, minimizing\nhuman intervention; 2) KG construction: Guided by the schema, LLMs extract\ninstance triples to construct a rich yet unreliable API KG; 3) KG filtering:\nRemoving invalid type triples and suspicious instance triples to construct a\nrich and reliable API KG. Experimental results demonstrate that our method\nsurpasses the state-of-the-art method, achieving a 25.2% improvement in F1\nscore. Moreover, the Explore-Construct-Filter framework proves effective, with\nthe KG exploration module increasing KG richness by 133.6% and the KG filtering\nmodule improving reliability by 26.6%. Finally, cross-model experiments confirm\nthe generalizability of our framework.""}","['Yanbang Sun', 'Qing Huang', 'Xiaoxue Ren', 'Zhenchang Xing', 'Xiaohong Li', 'Junjie Wang']",{'name': 'Junjie Wang'},Junjie Wang,,"[{'href': 'http://arxiv.org/abs/2502.13412v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13412v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.SE', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.SE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13412v1,None,http://arxiv.org/abs/2502.13412v1,,,10,0
http://arxiv.org/abs/2502.13428v1,True,2025-02-19T04:58:39Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=4, tm_min=58, tm_sec=39, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T04:58:39Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=4, tm_min=58, tm_sec=39, tm_wday=2, tm_yday=50, tm_isdst=0)",MCTS-KBQA: Monte Carlo Tree Search for Knowledge Base Question Answering,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'MCTS-KBQA: Monte Carlo Tree Search for Knowledge Base Question Answering'}","This study explores how to enhance the reasoning capabilities of large
language models (LLMs) in knowledge base question answering (KBQA) by
leveraging Monte Carlo Tree Search (MCTS). Semantic parsing-based KBQA methods
are particularly challenging as these approaches require locating elements from
knowledge bases and generating logical forms, demanding not only extensive
annotated data but also strong reasoning capabilities. Although recent
approaches leveraging LLMs as agents have demonstrated considerable potential,
these studies are inherently constrained by their linear decision-making
processes. To address this limitation, we propose a MCTS-based framework that
enhances LLMs' reasoning capabilities through tree search methodology. We
design a carefully designed step-wise reward mechanism that requires only
direct prompting of open-source instruction LLMs without additional
fine-tuning. Experimental results demonstrate that our approach significantly
outperforms linear decision-making methods, particularly in low-resource
scenarios. Additionally, we contribute new data resources to the KBQA community
by annotating intermediate reasoning processes for existing question-SPARQL
datasets using distant supervision. Experimental results on the extended
dataset demonstrate that our method achieves comparable performance to fully
supervised models while using significantly less training data.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""This study explores how to enhance the reasoning capabilities of large\nlanguage models (LLMs) in knowledge base question answering (KBQA) by\nleveraging Monte Carlo Tree Search (MCTS). Semantic parsing-based KBQA methods\nare particularly challenging as these approaches require locating elements from\nknowledge bases and generating logical forms, demanding not only extensive\nannotated data but also strong reasoning capabilities. Although recent\napproaches leveraging LLMs as agents have demonstrated considerable potential,\nthese studies are inherently constrained by their linear decision-making\nprocesses. To address this limitation, we propose a MCTS-based framework that\nenhances LLMs' reasoning capabilities through tree search methodology. We\ndesign a carefully designed step-wise reward mechanism that requires only\ndirect prompting of open-source instruction LLMs without additional\nfine-tuning. Experimental results demonstrate that our approach significantly\noutperforms linear decision-making methods, particularly in low-resource\nscenarios. Additionally, we contribute new data resources to the KBQA community\nby annotating intermediate reasoning processes for existing question-SPARQL\ndatasets using distant supervision. Experimental results on the extended\ndataset demonstrate that our method achieves comparable performance to fully\nsupervised models while using significantly less training data.""}","['Guanming Xiong', 'Haochen Li', 'Wen Zhao']",{'name': 'Wen Zhao'},Wen Zhao,,"[{'href': 'http://arxiv.org/abs/2502.13428v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13428v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13428v1,None,http://arxiv.org/abs/2502.13428v1,,,12,0
http://arxiv.org/abs/2502.13430v1,True,2025-02-19T05:04:10Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=5, tm_min=4, tm_sec=10, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T05:04:10Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=5, tm_min=4, tm_sec=10, tm_wday=2, tm_yday=50, tm_isdst=0)","Vision-Based Generic Potential Function for Policy Alignment in
  Multi-Agent Reinforcement Learning","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Vision-Based Generic Potential Function for Policy Alignment in\n  Multi-Agent Reinforcement Learning'}","Guiding the policy of multi-agent reinforcement learning to align with human
common sense is a difficult problem, largely due to the complexity of modeling
common sense as a reward, especially in complex and long-horizon multi-agent
tasks. Recent works have shown the effectiveness of reward shaping, such as
potential-based rewards, to enhance policy alignment. The existing works,
however, primarily rely on experts to design rule-based rewards, which are
often labor-intensive and lack a high-level semantic understanding of common
sense. To solve this problem, we propose a hierarchical vision-based reward
shaping method. At the bottom layer, a visual-language model (VLM) serves as a
generic potential function, guiding the policy to align with human common sense
through its intrinsic semantic understanding. To help the policy adapts to
uncertainty and changes in long-horizon tasks, the top layer features an
adaptive skill selection module based on a visual large language model (vLLM).
The module uses instructions, video replays, and training records to
dynamically select suitable potential function from a pre-designed pool.
Besides, our method is theoretically proven to preserve the optimal policy.
Extensive experiments conducted in the Google Research Football environment
demonstrate that our method not only achieves a higher win rate but also
effectively aligns the policy with human common sense.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Guiding the policy of multi-agent reinforcement learning to align with human\ncommon sense is a difficult problem, largely due to the complexity of modeling\ncommon sense as a reward, especially in complex and long-horizon multi-agent\ntasks. Recent works have shown the effectiveness of reward shaping, such as\npotential-based rewards, to enhance policy alignment. The existing works,\nhowever, primarily rely on experts to design rule-based rewards, which are\noften labor-intensive and lack a high-level semantic understanding of common\nsense. To solve this problem, we propose a hierarchical vision-based reward\nshaping method. At the bottom layer, a visual-language model (VLM) serves as a\ngeneric potential function, guiding the policy to align with human common sense\nthrough its intrinsic semantic understanding. To help the policy adapts to\nuncertainty and changes in long-horizon tasks, the top layer features an\nadaptive skill selection module based on a visual large language model (vLLM).\nThe module uses instructions, video replays, and training records to\ndynamically select suitable potential function from a pre-designed pool.\nBesides, our method is theoretically proven to preserve the optimal policy.\nExtensive experiments conducted in the Google Research Football environment\ndemonstrate that our method not only achieves a higher win rate but also\neffectively aligns the policy with human common sense.'}","['Hao Ma', 'Shijie Wang', 'Zhiqiang Pu', 'Siyao Zhao', 'Xiaolin Ai']",{'name': 'Xiaolin Ai'},Xiaolin Ai,,"[{'href': 'http://arxiv.org/abs/2502.13430v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13430v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13430v1,None,http://arxiv.org/abs/2502.13430v1,,,63,0
http://arxiv.org/abs/2502.13441v1,True,2025-02-19T05:37:08Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=5, tm_min=37, tm_sec=8, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T05:37:08Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=5, tm_min=37, tm_sec=8, tm_wday=2, tm_yday=50, tm_isdst=0)","The Self-Improvement Paradox: Can Language Models Bootstrap Reasoning
  Capabilities without External Scaffolding?","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The Self-Improvement Paradox: Can Language Models Bootstrap Reasoning\n  Capabilities without External Scaffolding?'}","Self-improving large language models (LLMs) -- i.e., to improve the
performance of an LLM by fine-tuning it with synthetic data generated by itself
-- is a promising way to advance the capabilities of LLMs while avoiding
extensive supervision. Existing approaches to self-improvement often rely on
external supervision signals in the form of seed data and/or assistance from
third-party models. This paper presents Crescent -- a simple yet effective
framework for generating high-quality synthetic question-answer data in a fully
autonomous manner. Crescent first elicits the LLM to generate raw questions via
a bait prompt, then diversifies these questions leveraging a rejection
sampling-based self-deduplication, and finally feeds the questions to the LLM
and collects the corresponding answers by means of majority voting. We show
that Crescent sheds light on the potential of true self-improvement with zero
external supervision signals for math reasoning; in particular,
Crescent-generated question-answer pairs suffice to (i) improve the reasoning
capabilities of an LLM while preserving its general performance (especially in
the 0-shot setting); and (ii) distil LLM knowledge to weaker models more
effectively than existing methods based on seed-dataset augmentation.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Self-improving large language models (LLMs) -- i.e., to improve the\nperformance of an LLM by fine-tuning it with synthetic data generated by itself\n-- is a promising way to advance the capabilities of LLMs while avoiding\nextensive supervision. Existing approaches to self-improvement often rely on\nexternal supervision signals in the form of seed data and/or assistance from\nthird-party models. This paper presents Crescent -- a simple yet effective\nframework for generating high-quality synthetic question-answer data in a fully\nautonomous manner. Crescent first elicits the LLM to generate raw questions via\na bait prompt, then diversifies these questions leveraging a rejection\nsampling-based self-deduplication, and finally feeds the questions to the LLM\nand collects the corresponding answers by means of majority voting. We show\nthat Crescent sheds light on the potential of true self-improvement with zero\nexternal supervision signals for math reasoning; in particular,\nCrescent-generated question-answer pairs suffice to (i) improve the reasoning\ncapabilities of an LLM while preserving its general performance (especially in\nthe 0-shot setting); and (ii) distil LLM knowledge to weaker models more\neffectively than existing methods based on seed-dataset augmentation.'}","['Yutao Sun', 'Mingshuai Chen', 'Tiancheng Zhao', 'Ruochen Xu', 'Zilun Zhang', 'Jianwei Yin']",{'name': 'Jianwei Yin'},Jianwei Yin,,"[{'href': 'http://arxiv.org/abs/2502.13441v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13441v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13441v1,None,http://arxiv.org/abs/2502.13441v1,,,22,0
http://arxiv.org/abs/2502.13450v1,True,2025-02-19T05:51:24Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=5, tm_min=51, tm_sec=24, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T05:51:24Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=5, tm_min=51, tm_sec=24, tm_wday=2, tm_yday=50, tm_isdst=0)",Interleaved Gibbs Diffusion for Constrained Generation,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Interleaved Gibbs Diffusion for Constrained Generation'}","We introduce Interleaved Gibbs Diffusion (IGD), a novel generative modeling
framework for mixed continuous-discrete data, focusing on constrained
generation problems. Prior works on discrete and continuous-discrete diffusion
models assume factorized denoising distribution for fast generation, which can
hinder the modeling of strong dependencies between random variables encountered
in constrained generation. IGD moves beyond this by interleaving continuous and
discrete denoising algorithms via a discrete time Gibbs sampling type Markov
chain. IGD provides flexibility in the choice of denoisers, allows conditional
generation via state-space doubling and inference time scaling via the
ReDeNoise method. Empirical evaluations on three challenging tasks-solving
3-SAT, generating molecule structures, and generating layouts-demonstrate
state-of-the-art performance. Notably, IGD achieves a 7% improvement on 3-SAT
out of the box and achieves state-of-the-art results in molecule generation
without relying on equivariant diffusion or domain-specific architectures. We
explore a wide range of modeling, and interleaving strategies along with
hyperparameters in each of these problems.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'We introduce Interleaved Gibbs Diffusion (IGD), a novel generative modeling\nframework for mixed continuous-discrete data, focusing on constrained\ngeneration problems. Prior works on discrete and continuous-discrete diffusion\nmodels assume factorized denoising distribution for fast generation, which can\nhinder the modeling of strong dependencies between random variables encountered\nin constrained generation. IGD moves beyond this by interleaving continuous and\ndiscrete denoising algorithms via a discrete time Gibbs sampling type Markov\nchain. IGD provides flexibility in the choice of denoisers, allows conditional\ngeneration via state-space doubling and inference time scaling via the\nReDeNoise method. Empirical evaluations on three challenging tasks-solving\n3-SAT, generating molecule structures, and generating layouts-demonstrate\nstate-of-the-art performance. Notably, IGD achieves a 7% improvement on 3-SAT\nout of the box and achieves state-of-the-art results in molecule generation\nwithout relying on equivariant diffusion or domain-specific architectures. We\nexplore a wide range of modeling, and interleaving strategies along with\nhyperparameters in each of these problems.'}","['Gautham Govind Anil', 'Sachin Yadav', 'Dheeraj Nagaraj', 'Karthikeyan Shanmugam', 'Prateek Jain']",{'name': 'Prateek Jain'},Prateek Jain,,"[{'href': 'http://arxiv.org/abs/2502.13450v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13450v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13450v1,None,http://arxiv.org/abs/2502.13450v1,,,586,0
http://arxiv.org/abs/2502.13464v1,True,2025-02-19T06:31:06Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=6, tm_min=31, tm_sec=6, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T06:31:06Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=6, tm_min=31, tm_sec=6, tm_wday=2, tm_yday=50, tm_isdst=0)",Estimating Commonsense Plausibility through Semantic Shifts,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Estimating Commonsense Plausibility through Semantic Shifts'}","Commonsense plausibility estimation is critical for evaluating language
models (LMs), yet existing generative approaches--reliant on likelihoods or
verbalized judgments--struggle with fine-grained discrimination. In this paper,
we propose ComPaSS, a novel discriminative framework that quantifies
commonsense plausibility by measuring semantic shifts when augmenting sentences
with commonsense-related information. Plausible augmentations induce minimal
shifts in semantics, while implausible ones result in substantial deviations.
Evaluations on two types of fine-grained commonsense plausibility estimation
tasks across different backbones, including LLMs and vision-language models
(VLMs), show that ComPaSS consistently outperforms baselines. It demonstrates
the advantage of discriminative approaches over generative methods in
fine-grained commonsense plausibility evaluation. Experiments also show that
(1) VLMs yield superior performance to LMs, when integrated with ComPaSS, on
vision-grounded commonsense tasks. (2) contrastive pre-training sharpens
backbone models' ability to capture semantic nuances, thereby further enhancing
ComPaSS.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Commonsense plausibility estimation is critical for evaluating language\nmodels (LMs), yet existing generative approaches--reliant on likelihoods or\nverbalized judgments--struggle with fine-grained discrimination. In this paper,\nwe propose ComPaSS, a novel discriminative framework that quantifies\ncommonsense plausibility by measuring semantic shifts when augmenting sentences\nwith commonsense-related information. Plausible augmentations induce minimal\nshifts in semantics, while implausible ones result in substantial deviations.\nEvaluations on two types of fine-grained commonsense plausibility estimation\ntasks across different backbones, including LLMs and vision-language models\n(VLMs), show that ComPaSS consistently outperforms baselines. It demonstrates\nthe advantage of discriminative approaches over generative methods in\nfine-grained commonsense plausibility evaluation. Experiments also show that\n(1) VLMs yield superior performance to LMs, when integrated with ComPaSS, on\nvision-grounded commonsense tasks. (2) contrastive pre-training sharpens\nbackbone models' ability to capture semantic nuances, thereby further enhancing\nComPaSS.""}","['Wanqing Cui', 'Keping Bi', 'Jiafeng Guo', 'Xueqi Cheng']",{'name': 'Xueqi Cheng'},Xueqi Cheng,,"[{'href': 'http://arxiv.org/abs/2502.13464v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13464v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13464v1,None,http://arxiv.org/abs/2502.13464v1,,,179,0
http://arxiv.org/abs/2502.13475v1,True,2025-02-19T06:58:34Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=6, tm_min=58, tm_sec=34, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T06:58:34Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=6, tm_min=58, tm_sec=34, tm_wday=2, tm_yday=50, tm_isdst=0)",LLM should think and action as a human,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'LLM should think and action as a human'}","It is popular lately to train large language models to be used as chat
assistants, but in the conversation between the user and the chat assistant,
there are prompts, require multi-turns between the chat assistant and the user.
However, there are a number of issues with the multi-turns conversation: The
response of the chat assistant is prone to errors and cannot help users achieve
their goals; It is difficult for chat assistant to generate responses with
different processes based on actual needs for the same command or request; Chat
assistant require the use of tools, but the current approach is not elegant and
efficient, and the number of tool calls that can be supported is limited. The
main reason for these issues is that large language models do not have the
thinking ability as a human, lack the reasoning ability and planning ability,
and lack the ability to execute plans. To solve these issues, we propose a
thinking method based on a built-in chain of thought: In the multi-turns
conversation, for each user prompt, the large language model thinks based on
elements such as chat history, thinking context, action calls, memory and
knowledge, makes detailed reasoning and planning, and actions according to the
plan. We also explored how the large language model enhances thinking ability
through this thinking method: Collect training datasets according to the
thinking method and fine tune the large language model through supervised
learning; Train a consistency reward model and use it as a reward function to
fine tune the large language model using reinforcement learning, and the
reinforced large language model outputs according to this way of thinking. Our
experimental results show that the reasoning ability and planning ability of
the large language model are enhanced, and the issues in the multi-turns
conversation are solved.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'It is popular lately to train large language models to be used as chat\nassistants, but in the conversation between the user and the chat assistant,\nthere are prompts, require multi-turns between the chat assistant and the user.\nHowever, there are a number of issues with the multi-turns conversation: The\nresponse of the chat assistant is prone to errors and cannot help users achieve\ntheir goals; It is difficult for chat assistant to generate responses with\ndifferent processes based on actual needs for the same command or request; Chat\nassistant require the use of tools, but the current approach is not elegant and\nefficient, and the number of tool calls that can be supported is limited. The\nmain reason for these issues is that large language models do not have the\nthinking ability as a human, lack the reasoning ability and planning ability,\nand lack the ability to execute plans. To solve these issues, we propose a\nthinking method based on a built-in chain of thought: In the multi-turns\nconversation, for each user prompt, the large language model thinks based on\nelements such as chat history, thinking context, action calls, memory and\nknowledge, makes detailed reasoning and planning, and actions according to the\nplan. We also explored how the large language model enhances thinking ability\nthrough this thinking method: Collect training datasets according to the\nthinking method and fine tune the large language model through supervised\nlearning; Train a consistency reward model and use it as a reward function to\nfine tune the large language model using reinforcement learning, and the\nreinforced large language model outputs according to this way of thinking. Our\nexperimental results show that the reasoning ability and planning ability of\nthe large language model are enhanced, and the issues in the multi-turns\nconversation are solved.'}","['Haun Leung', 'ZiNan Wang']",{'name': 'ZiNan Wang'},ZiNan Wang,"12 pages, 4 figures, 1 table","[{'href': 'http://arxiv.org/abs/2502.13475v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13475v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13475v1,None,http://arxiv.org/abs/2502.13475v1,,,0,0
http://arxiv.org/abs/2502.13476v1,True,2025-02-19T07:00:53Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=7, tm_min=0, tm_sec=53, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T07:00:53Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=7, tm_min=0, tm_sec=53, tm_wday=2, tm_yday=50, tm_isdst=0)","Integration of Agentic AI with 6G Networks for Mission-Critical
  Applications: Use-case and Challenges","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Integration of Agentic AI with 6G Networks for Mission-Critical\n  Applications: Use-case and Challenges'}","We are in a transformative era, and advances in Artificial Intelligence (AI),
especially the foundational models, are constantly in the news. AI has been an
integral part of many applications that rely on automation for service
delivery, and one of them is mission-critical public safety applications. The
problem with AI-oriented mission-critical applications is the humanin-the-loop
system and the lack of adaptability to dynamic conditions while maintaining
situational awareness. Agentic AI (AAI) has gained a lot of attention recently
due to its ability to analyze textual data through a contextual lens while
quickly adapting to conditions. In this context, this paper proposes an AAI
framework for mission-critical applications. We propose a novel framework with
a multi-layer architecture to realize the AAI. We also present a detailed
implementation of AAI layer that bridges the gap between network infrastructure
and missioncritical applications. Our preliminary analysis shows that the AAI
reduces initial response time by 5.6 minutes on average, while alert generation
time is reduced by 15.6 seconds on average and resource allocation is improved
by up to 13.4%. We also show that the AAI methods improve the number of
concurrent operations by 40, which reduces the recovery time by up to 5.2
minutes. Finally, we highlight some of the issues and challenges that need to
be considered when implementing AAI frameworks.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'We are in a transformative era, and advances in Artificial Intelligence (AI),\nespecially the foundational models, are constantly in the news. AI has been an\nintegral part of many applications that rely on automation for service\ndelivery, and one of them is mission-critical public safety applications. The\nproblem with AI-oriented mission-critical applications is the humanin-the-loop\nsystem and the lack of adaptability to dynamic conditions while maintaining\nsituational awareness. Agentic AI (AAI) has gained a lot of attention recently\ndue to its ability to analyze textual data through a contextual lens while\nquickly adapting to conditions. In this context, this paper proposes an AAI\nframework for mission-critical applications. We propose a novel framework with\na multi-layer architecture to realize the AAI. We also present a detailed\nimplementation of AAI layer that bridges the gap between network infrastructure\nand missioncritical applications. Our preliminary analysis shows that the AAI\nreduces initial response time by 5.6 minutes on average, while alert generation\ntime is reduced by 15.6 seconds on average and resource allocation is improved\nby up to 13.4%. We also show that the AAI methods improve the number of\nconcurrent operations by 40, which reduces the recovery time by up to 5.2\nminutes. Finally, we highlight some of the issues and challenges that need to\nbe considered when implementing AAI frameworks.'}","['Sunder Ali Khowaja', 'Kapal Dev', 'Muhammad Salman Pathan', 'Engin Zeydan', 'Merouane Debbah']",{'name': 'Merouane Debbah'},Merouane Debbah,"FEMA
  [https://www.fema.gov/openfema-data-page/disaster-declarations-summaries-v2]
  National Oceanic and Atmospheric Administration
  [https://www.ncdc.noaa.gov/stormevents/details.jsp] packages Pytorch
  [https://pytorch.org/] RLib [https://docs.ray.io/en/latest/rllib/index.html]
  Neo4j [https://neo4j.com/] Apache Kafka [https://kafka.apache.org/]","[{'href': 'http://arxiv.org/abs/2502.13476v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13476v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13476v1,None,http://arxiv.org/abs/2502.13476v1,,,6963,0
http://arxiv.org/abs/2502.13480v1,True,2025-02-19T07:08:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=7, tm_min=8, tm_sec=37, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T07:08:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=7, tm_min=8, tm_sec=37, tm_wday=2, tm_yday=50, tm_isdst=0)","Astra: Efficient and Money-saving Automatic Parallel Strategies Search
  on Heterogeneous GPUs","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Astra: Efficient and Money-saving Automatic Parallel Strategies Search\n  on Heterogeneous GPUs'}","In this paper, we introduce an efficient and money-saving automatic parallel
strategies search framework on heterogeneous GPUs: Astra. First, Astra searches
for the efficiency-optimal parallel strategy in both GPU configurations search
space (GPU types and GPU numbers) and parallel parameters search space. Then,
Astra also provides the solution on heterogeneous GPUs by mathematically
modeling the time consumption of heterogeneous training. At last, Astra is the
first to propose the automatic parallel strategy search on money-saving. The
experiment results demonstrate that Astra can achieve better throughput than
expert-designed strategies. The search time cost for Astra can also be limited
to 1.27 seconds in a single-GPU setting and less than 1.35 minutes in a
heterogeneous-GPU setting on average with an accuracy of over 95%.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'In this paper, we introduce an efficient and money-saving automatic parallel\nstrategies search framework on heterogeneous GPUs: Astra. First, Astra searches\nfor the efficiency-optimal parallel strategy in both GPU configurations search\nspace (GPU types and GPU numbers) and parallel parameters search space. Then,\nAstra also provides the solution on heterogeneous GPUs by mathematically\nmodeling the time consumption of heterogeneous training. At last, Astra is the\nfirst to propose the automatic parallel strategy search on money-saving. The\nexperiment results demonstrate that Astra can achieve better throughput than\nexpert-designed strategies. The search time cost for Astra can also be limited\nto 1.27 seconds in a single-GPU setting and less than 1.35 minutes in a\nheterogeneous-GPU setting on average with an accuracy of over 95%.'}","['Peiran Wang', 'Haibing Li', 'Fu Haohan', 'Shiyong Li', 'Yanpeng Wang', 'Dou Shen']",{'name': 'Dou Shen'},Dou Shen,,"[{'href': 'http://arxiv.org/abs/2502.13480v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13480v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.DC', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.DC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13480v1,None,http://arxiv.org/abs/2502.13480v1,,,0,0
http://arxiv.org/abs/2502.13490v1,True,2025-02-19T07:23:18Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=7, tm_min=23, tm_sec=18, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T07:23:18Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=7, tm_min=23, tm_sec=18, tm_wday=2, tm_yday=50, tm_isdst=0)","What are Models Thinking about? Understanding Large Language Model
  Hallucinations ""Psychology"" through Model Inner State Analysis","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'What are Models Thinking about? Understanding Large Language Model\n  Hallucinations ""Psychology"" through Model Inner State Analysis'}","Large language model (LLM) systems suffer from the models' unstable ability
to generate valid and factual content, resulting in hallucination generation.
Current hallucination detection methods heavily rely on out-of-model
information sources, such as RAG to assist the detection, thus bringing heavy
additional latency. Recently, internal states of LLMs' inference have been
widely used in numerous research works, such as prompt injection detection,
etc. Considering the interpretability of LLM internal states and the fact that
they do not require external information sources, we introduce such states into
LLM hallucination detection. In this paper, we systematically analyze different
internal states' revealing features during inference forward and
comprehensively evaluate their ability in hallucination detection.
Specifically, we cut the forward process of a large language model into three
stages: understanding, query, generation, and extracting the internal state
from these stages. By analyzing these states, we provide a deep understanding
of why the hallucinated content is generated and what happened in the internal
state of the models. Then, we introduce these internal states into
hallucination detection and conduct comprehensive experiments to discuss the
advantages and limitations.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Large language model (LLM) systems suffer from the models' unstable ability\nto generate valid and factual content, resulting in hallucination generation.\nCurrent hallucination detection methods heavily rely on out-of-model\ninformation sources, such as RAG to assist the detection, thus bringing heavy\nadditional latency. Recently, internal states of LLMs' inference have been\nwidely used in numerous research works, such as prompt injection detection,\netc. Considering the interpretability of LLM internal states and the fact that\nthey do not require external information sources, we introduce such states into\nLLM hallucination detection. In this paper, we systematically analyze different\ninternal states' revealing features during inference forward and\ncomprehensively evaluate their ability in hallucination detection.\nSpecifically, we cut the forward process of a large language model into three\nstages: understanding, query, generation, and extracting the internal state\nfrom these stages. By analyzing these states, we provide a deep understanding\nof why the hallucinated content is generated and what happened in the internal\nstate of the models. Then, we introduce these internal states into\nhallucination detection and conduct comprehensive experiments to discuss the\nadvantages and limitations.""}","['Peiran Wang', 'Yang Liu', 'Yunfei Lu', 'Jue Hong', 'Ye Wu']",{'name': 'Ye Wu'},Ye Wu,,"[{'href': 'http://arxiv.org/abs/2502.13490v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13490v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13490v1,None,http://arxiv.org/abs/2502.13490v1,,,24,0
http://arxiv.org/abs/2502.13497v2,True,2025-02-20T06:38:50Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=6, tm_min=38, tm_sec=50, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-19T07:29:58Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=7, tm_min=29, tm_sec=58, tm_wday=2, tm_yday=50, tm_isdst=0)",Towards Geo-Culturally Grounded LLM Generations,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Towards Geo-Culturally Grounded LLM Generations'}","Generative large language models (LLMs) have been demonstrated to have gaps
in diverse, cultural knowledge across the globe. We investigate the effect of
retrieval augmented generation and search-grounding techniques on the ability
of LLMs to display familiarity with a diverse range of national cultures.
Specifically, we compare the performance of standard LLMs, LLMs augmented with
retrievals from a bespoke knowledge base (i.e., KB grounding), and LLMs
augmented with retrievals from a web search (i.e., search grounding) on a
series of cultural familiarity benchmarks. We find that search grounding
significantly improves the LLM performance on multiple-choice benchmarks that
test propositional knowledge (e.g., the norms, artifacts, and institutions of
national cultures), while KB grounding's effectiveness is limited by inadequate
knowledge base coverage and a suboptimal retriever. However, search grounding
also increases the risk of stereotypical judgments by language models, while
failing to improve evaluators' judgments of cultural familiarity in a human
evaluation with adequate statistical power. These results highlight the
distinction between propositional knowledge about a culture and open-ended
cultural fluency when it comes to evaluating the cultural familiarity of
generative LLMs.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Generative large language models (LLMs) have been demonstrated to have gaps\nin diverse, cultural knowledge across the globe. We investigate the effect of\nretrieval augmented generation and search-grounding techniques on the ability\nof LLMs to display familiarity with a diverse range of national cultures.\nSpecifically, we compare the performance of standard LLMs, LLMs augmented with\nretrievals from a bespoke knowledge base (i.e., KB grounding), and LLMs\naugmented with retrievals from a web search (i.e., search grounding) on a\nseries of cultural familiarity benchmarks. We find that search grounding\nsignificantly improves the LLM performance on multiple-choice benchmarks that\ntest propositional knowledge (e.g., the norms, artifacts, and institutions of\nnational cultures), while KB grounding's effectiveness is limited by inadequate\nknowledge base coverage and a suboptimal retriever. However, search grounding\nalso increases the risk of stereotypical judgments by language models, while\nfailing to improve evaluators' judgments of cultural familiarity in a human\nevaluation with adequate statistical power. These results highlight the\ndistinction between propositional knowledge about a culture and open-ended\ncultural fluency when it comes to evaluating the cultural familiarity of\ngenerative LLMs.""}","['Piyawat Lertvittayakumjorn', 'David Kinney', 'Vinodkumar Prabhakaran', 'Donald Martin Jr.', 'Sunipa Dev']",{'name': 'Sunipa Dev'},Sunipa Dev,,"[{'href': 'http://arxiv.org/abs/2502.13497v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13497v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13497v2,None,http://arxiv.org/abs/2502.13497v2,,,8043,0
http://arxiv.org/abs/2502.13527v1,True,2025-02-19T08:29:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=8, tm_min=29, tm_sec=36, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T08:29:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=8, tm_min=29, tm_sec=36, tm_wday=2, tm_yday=50, tm_isdst=0)","Exploiting Prefix-Tree in Structured Output Interfaces for Enhancing
  Jailbreak Attacking","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Exploiting Prefix-Tree in Structured Output Interfaces for Enhancing\n  Jailbreak Attacking'}","The rise of Large Language Models (LLMs) has led to significant applications
but also introduced serious security threats, particularly from jailbreak
attacks that manipulate output generation. These attacks utilize prompt
engineering and logit manipulation to steer models toward harmful content,
prompting LLM providers to implement filtering and safety alignment strategies.
We investigate LLMs' safety mechanisms and their recent applications, revealing
a new threat model targeting structured output interfaces, which enable
attackers to manipulate the inner logit during LLM generation, requiring only
API access permissions. To demonstrate this threat model, we introduce a
black-box attack framework called AttackPrefixTree (APT). APT exploits
structured output interfaces to dynamically construct attack patterns. By
leveraging prefixes of models' safety refusal response and latent harmful
outputs, APT effectively bypasses safety measures. Experiments on benchmark
datasets indicate that this approach achieves higher attack success rate than
existing methods. This work highlights the urgent need for LLM providers to
enhance security protocols to address vulnerabilities arising from the
interaction between safety patterns and structured outputs.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""The rise of Large Language Models (LLMs) has led to significant applications\nbut also introduced serious security threats, particularly from jailbreak\nattacks that manipulate output generation. These attacks utilize prompt\nengineering and logit manipulation to steer models toward harmful content,\nprompting LLM providers to implement filtering and safety alignment strategies.\nWe investigate LLMs' safety mechanisms and their recent applications, revealing\na new threat model targeting structured output interfaces, which enable\nattackers to manipulate the inner logit during LLM generation, requiring only\nAPI access permissions. To demonstrate this threat model, we introduce a\nblack-box attack framework called AttackPrefixTree (APT). APT exploits\nstructured output interfaces to dynamically construct attack patterns. By\nleveraging prefixes of models' safety refusal response and latent harmful\noutputs, APT effectively bypasses safety measures. Experiments on benchmark\ndatasets indicate that this approach achieves higher attack success rate than\nexisting methods. This work highlights the urgent need for LLM providers to\nenhance security protocols to address vulnerabilities arising from the\ninteraction between safety patterns and structured outputs.""}","['Yanzeng Li', 'Yunfan Xiong', 'Jialun Zhong', 'Jinchao Zhang', 'Jie Zhou', 'Lei Zou']",{'name': 'Lei Zou'},Lei Zou,,"[{'href': 'http://arxiv.org/abs/2502.13527v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13527v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13527v1,None,http://arxiv.org/abs/2502.13527v1,,,3335,0
http://arxiv.org/abs/2502.13542v1,True,2025-02-19T08:50:44Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=8, tm_min=50, tm_sec=44, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T08:50:44Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=8, tm_min=50, tm_sec=44, tm_wday=2, tm_yday=50, tm_isdst=0)","Activation-aware Probe-Query: Effective Key-Value Retrieval for
  Long-Context LLMs Inference","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Activation-aware Probe-Query: Effective Key-Value Retrieval for\n  Long-Context LLMs Inference'}","Recent advances in large language models (LLMs) have showcased exceptional
performance in long-context tasks, while facing significant inference
efficiency challenges with limited GPU memory. Existing solutions first
proposed the sliding-window approach to accumulate a set of historical
\textbf{key-value} (KV) pairs for reuse, then further improvements selectively
retain its subsets at each step. However, due to the sparse attention
distribution across a long context, it is hard to identify and recall relevant
KV pairs, as the attention is distracted by massive candidate pairs.
Additionally, we found it promising to select representative tokens as
probe-Query in each sliding window to effectively represent the entire context,
which is an approach overlooked by existing methods. Thus, we propose
\textbf{ActQKV}, a training-free, \textbf{Act}ivation-aware approach that
dynamically determines probe-\textbf{Q}uery and leverages it to retrieve the
relevant \textbf{KV} pairs for inference. Specifically, ActQKV monitors a
token-level indicator, Activation Bias, within each context window, enabling
the proper construction of probe-Query for retrieval at pre-filling stage. To
accurately recall the relevant KV pairs and minimize the irrelevant ones, we
design a dynamic KV cut-off mechanism guided by information density across
layers at the decoding stage. Experiments on the Long-Bench and $\infty$
Benchmarks demonstrate its state-of-the-art performance with competitive
inference quality and resource efficiency.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Recent advances in large language models (LLMs) have showcased exceptional\nperformance in long-context tasks, while facing significant inference\nefficiency challenges with limited GPU memory. Existing solutions first\nproposed the sliding-window approach to accumulate a set of historical\n\\textbf{key-value} (KV) pairs for reuse, then further improvements selectively\nretain its subsets at each step. However, due to the sparse attention\ndistribution across a long context, it is hard to identify and recall relevant\nKV pairs, as the attention is distracted by massive candidate pairs.\nAdditionally, we found it promising to select representative tokens as\nprobe-Query in each sliding window to effectively represent the entire context,\nwhich is an approach overlooked by existing methods. Thus, we propose\n\\textbf{ActQKV}, a training-free, \\textbf{Act}ivation-aware approach that\ndynamically determines probe-\\textbf{Q}uery and leverages it to retrieve the\nrelevant \\textbf{KV} pairs for inference. Specifically, ActQKV monitors a\ntoken-level indicator, Activation Bias, within each context window, enabling\nthe proper construction of probe-Query for retrieval at pre-filling stage. To\naccurately recall the relevant KV pairs and minimize the irrelevant ones, we\ndesign a dynamic KV cut-off mechanism guided by information density across\nlayers at the decoding stage. Experiments on the Long-Bench and $\\infty$\nBenchmarks demonstrate its state-of-the-art performance with competitive\ninference quality and resource efficiency.'}","['Qingfa Xiao', 'Jiachuan Wang', 'Haoyang Li', 'Cheng Deng', 'Jiaqi Tang', 'Shuangyin Li', 'Yongqi Zhang', 'Jun Wang', 'Lei Chen']",{'name': 'Lei Chen'},Lei Chen,,"[{'href': 'http://arxiv.org/abs/2502.13542v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13542v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13542v1,None,http://arxiv.org/abs/2502.13542v1,,,203,0
http://arxiv.org/abs/2502.13544v1,True,2025-02-19T08:52:45Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=8, tm_min=52, tm_sec=45, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T08:52:45Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=8, tm_min=52, tm_sec=45, tm_wday=2, tm_yday=50, tm_isdst=0)","From Sub-Ability Diagnosis to Human-Aligned Generation: Bridging the Gap
  for Text Length Control via MARKERGEN","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'From Sub-Ability Diagnosis to Human-Aligned Generation: Bridging the Gap\n  for Text Length Control via MARKERGEN'}","Despite the rapid progress of large language models (LLMs), their
length-controllable text generation (LCTG) ability remains below expectations,
posing a major limitation for practical applications. Existing methods mainly
focus on end-to-end training to reinforce adherence to length constraints.
However, the lack of decomposition and targeted enhancement of LCTG
sub-abilities restricts further progress.To bridge this gap, we conduct a
bottom-up decomposition of LCTG sub-abilities with human patterns as reference
and perform a detailed error analysis.On this basis, we propose MarkerGen, a
simple-yet-effective plug-and-play approach that:(1) mitigates LLM fundamental
deficiencies via external tool integration;(2) conducts explicit length
modeling with dynamically inserted markers;(3) employs a three-stage generation
scheme to better align length constraints while maintaining content
quality.Comprehensive experiments demonstrate that MarkerGen significantly
improves LCTG across various settings, exhibiting outstanding effectiveness and
generalizability.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Despite the rapid progress of large language models (LLMs), their\nlength-controllable text generation (LCTG) ability remains below expectations,\nposing a major limitation for practical applications. Existing methods mainly\nfocus on end-to-end training to reinforce adherence to length constraints.\nHowever, the lack of decomposition and targeted enhancement of LCTG\nsub-abilities restricts further progress.To bridge this gap, we conduct a\nbottom-up decomposition of LCTG sub-abilities with human patterns as reference\nand perform a detailed error analysis.On this basis, we propose MarkerGen, a\nsimple-yet-effective plug-and-play approach that:(1) mitigates LLM fundamental\ndeficiencies via external tool integration;(2) conducts explicit length\nmodeling with dynamically inserted markers;(3) employs a three-stage generation\nscheme to better align length constraints while maintaining content\nquality.Comprehensive experiments demonstrate that MarkerGen significantly\nimproves LCTG across various settings, exhibiting outstanding effectiveness and\ngeneralizability.'}","['Peiwen Yuan', 'Chuyi Tan', 'Shaoxiong Feng', 'Yiwei Li', 'Xinglin Wang', 'Yueqi Zhang', 'Jiayi Shi', 'Boyuan Pan', 'Yao Hu', 'Kan Li']",{'name': 'Kan Li'},Kan Li,,"[{'href': 'http://arxiv.org/abs/2502.13544v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13544v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13544v1,None,http://arxiv.org/abs/2502.13544v1,,,288,0
http://arxiv.org/abs/2502.13555v1,True,2025-02-19T09:00:32Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=9, tm_min=0, tm_sec=32, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T09:00:32Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=9, tm_min=0, tm_sec=32, tm_wday=2, tm_yday=50, tm_isdst=0)","Democratizing Large Language Model-Based Graph Data Augmentation via
  Latent Knowledge Graphs","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Democratizing Large Language Model-Based Graph Data Augmentation via\n  Latent Knowledge Graphs'}","Data augmentation is necessary for graph representation learning due to the
scarcity and noise present in graph data. Most of the existing augmentation
methods overlook the context information inherited from the dataset as they
rely solely on the graph structure for augmentation. Despite the success of
some large language model-based (LLM) graph learning methods, they are mostly
white-box which require access to the weights or latent features from the
open-access LLMs, making them difficult to be democratized for everyone as
existing LLMs are mostly closed-source for commercial considerations. To
overcome these limitations, we propose a black-box context-driven graph data
augmentation approach, with the guidance of LLMs -- DemoGraph. Leveraging the
text prompt as context-related information, we task the LLM with generating
knowledge graphs (KGs), which allow us to capture the structural interactions
from the text outputs. We then design a dynamic merging schema to
stochastically integrate the LLM-generated KGs into the original graph during
training. To control the sparsity of the augmented graph, we further devise a
granularity-aware prompting strategy and an instruction fine-tuning module,
which seamlessly generates text prompts according to different granularity
levels of the dataset. Extensive experiments on various graph learning tasks
validate the effectiveness of our method over existing graph data augmentation
methods. Notably, our approach excels in scenarios involving electronic health
records (EHRs), which validates its maximal utilization of contextual
knowledge, leading to enhanced predictive performance and interpretability.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Data augmentation is necessary for graph representation learning due to the\nscarcity and noise present in graph data. Most of the existing augmentation\nmethods overlook the context information inherited from the dataset as they\nrely solely on the graph structure for augmentation. Despite the success of\nsome large language model-based (LLM) graph learning methods, they are mostly\nwhite-box which require access to the weights or latent features from the\nopen-access LLMs, making them difficult to be democratized for everyone as\nexisting LLMs are mostly closed-source for commercial considerations. To\novercome these limitations, we propose a black-box context-driven graph data\naugmentation approach, with the guidance of LLMs -- DemoGraph. Leveraging the\ntext prompt as context-related information, we task the LLM with generating\nknowledge graphs (KGs), which allow us to capture the structural interactions\nfrom the text outputs. We then design a dynamic merging schema to\nstochastically integrate the LLM-generated KGs into the original graph during\ntraining. To control the sparsity of the augmented graph, we further devise a\ngranularity-aware prompting strategy and an instruction fine-tuning module,\nwhich seamlessly generates text prompts according to different granularity\nlevels of the dataset. Extensive experiments on various graph learning tasks\nvalidate the effectiveness of our method over existing graph data augmentation\nmethods. Notably, our approach excels in scenarios involving electronic health\nrecords (EHRs), which validates its maximal utilization of contextual\nknowledge, leading to enhanced predictive performance and interpretability.'}","['Yushi Feng', 'Tsai Hor Chan', 'Guosheng Yin', 'Lequan Yu']",{'name': 'Lequan Yu'},Lequan Yu,,"[{'href': 'http://arxiv.org/abs/2502.13555v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13555v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13555v1,None,http://arxiv.org/abs/2502.13555v1,,,76,0
http://arxiv.org/abs/2502.13562v1,True,2025-02-19T09:14:19Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=9, tm_min=14, tm_sec=19, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T09:14:19Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=9, tm_min=14, tm_sec=19, tm_wday=2, tm_yday=50, tm_isdst=0)",Are Large Language Models In-Context Graph Learners?,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Are Large Language Models In-Context Graph Learners?'}","Large language models (LLMs) have demonstrated remarkable in-context
reasoning capabilities across a wide range of tasks, particularly with
unstructured inputs such as language or images. However, LLMs struggle to
handle structured data, such as graphs, due to their lack of understanding of
non-Euclidean structures. As a result, without additional fine-tuning, their
performance significantly lags behind that of graph neural networks (GNNs) in
graph learning tasks. In this paper, we show that learning on graph data can be
conceptualized as a retrieval-augmented generation (RAG) process, where
specific instances (e.g., nodes or edges) act as queries, and the graph itself
serves as the retrieved context. Building on this insight, we propose a series
of RAG frameworks to enhance the in-context learning capabilities of LLMs for
graph learning tasks. Comprehensive evaluations demonstrate that our proposed
RAG frameworks significantly improve LLM performance on graph-based tasks,
particularly in scenarios where a pretrained LLM must be used without
modification or accessed via an API.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large language models (LLMs) have demonstrated remarkable in-context\nreasoning capabilities across a wide range of tasks, particularly with\nunstructured inputs such as language or images. However, LLMs struggle to\nhandle structured data, such as graphs, due to their lack of understanding of\nnon-Euclidean structures. As a result, without additional fine-tuning, their\nperformance significantly lags behind that of graph neural networks (GNNs) in\ngraph learning tasks. In this paper, we show that learning on graph data can be\nconceptualized as a retrieval-augmented generation (RAG) process, where\nspecific instances (e.g., nodes or edges) act as queries, and the graph itself\nserves as the retrieved context. Building on this insight, we propose a series\nof RAG frameworks to enhance the in-context learning capabilities of LLMs for\ngraph learning tasks. Comprehensive evaluations demonstrate that our proposed\nRAG frameworks significantly improve LLM performance on graph-based tasks,\nparticularly in scenarios where a pretrained LLM must be used without\nmodification or accessed via an API.'}","['Jintang Li', 'Ruofan Wu', 'Yuchang Zhu', 'Huizhe Zhang', 'Liang Chen', 'Zibin Zheng']",{'name': 'Zibin Zheng'},Zibin Zheng,"Preprint, under review","[{'href': 'http://arxiv.org/abs/2502.13562v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13562v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13562v1,None,http://arxiv.org/abs/2502.13562v1,,,693,0
http://arxiv.org/abs/2502.13576v1,True,2025-02-19T09:31:50Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=9, tm_min=31, tm_sec=50, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T09:31:50Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=9, tm_min=31, tm_sec=50, tm_wday=2, tm_yday=50, tm_isdst=0)",Beyond One-Size-Fits-All: Tailored Benchmarks for Efficient Evaluation,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Beyond One-Size-Fits-All: Tailored Benchmarks for Efficient Evaluation'}","Evaluating models on large benchmarks is very resource-intensive, especially
during the period of rapid model evolution. Existing efficient evaluation
methods estimate the performance of target models by testing them only on a
small and static coreset of the benchmark, which is derived from the publicly
available evaluation results of source models. These methods rely on the
assumption that target models have high prediction consistency with source
models. However, we demonstrate that it doesn't generalize well in practice. To
alleviate the inconsistency issue, we present TailoredBench, a method that
conducts customized evaluation tailored to each target model. Specifically, a
Global-coreset is first constructed as a probe to identify the most consistent
source models for each target model with an adaptive source model selection
strategy. Afterwards, a scalable K-Medoids clustering algorithm is proposed to
extend the Global-coreset to a tailored Native-coreset for each target model.
According to the predictions on Native-coresets, we obtain the performance of
target models on the whole benchmark with a calibrated estimation strategy.
Comprehensive experiments on 5 benchmarks across over 300 models demonstrate
that compared to best performing baselines, TailoredBench achieves an average
reduction of 31.4% in MAE of accuracy estimates under the same inference
budgets, showcasing strong effectiveness and generalizability.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Evaluating models on large benchmarks is very resource-intensive, especially\nduring the period of rapid model evolution. Existing efficient evaluation\nmethods estimate the performance of target models by testing them only on a\nsmall and static coreset of the benchmark, which is derived from the publicly\navailable evaluation results of source models. These methods rely on the\nassumption that target models have high prediction consistency with source\nmodels. However, we demonstrate that it doesn't generalize well in practice. To\nalleviate the inconsistency issue, we present TailoredBench, a method that\nconducts customized evaluation tailored to each target model. Specifically, a\nGlobal-coreset is first constructed as a probe to identify the most consistent\nsource models for each target model with an adaptive source model selection\nstrategy. Afterwards, a scalable K-Medoids clustering algorithm is proposed to\nextend the Global-coreset to a tailored Native-coreset for each target model.\nAccording to the predictions on Native-coresets, we obtain the performance of\ntarget models on the whole benchmark with a calibrated estimation strategy.\nComprehensive experiments on 5 benchmarks across over 300 models demonstrate\nthat compared to best performing baselines, TailoredBench achieves an average\nreduction of 31.4% in MAE of accuracy estimates under the same inference\nbudgets, showcasing strong effectiveness and generalizability.""}","['Peiwen Yuan', 'Yueqi Zhang', 'Shaoxiong Feng', 'Yiwei Li', 'Xinglin Wang', 'Jiayi Shi', 'Chuyi Tan', 'Boyuan Pan', 'Yao Hu', 'Kan Li']",{'name': 'Kan Li'},Kan Li,,"[{'href': 'http://arxiv.org/abs/2502.13576v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13576v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13576v1,None,http://arxiv.org/abs/2502.13576v1,,,288,0
http://arxiv.org/abs/2502.13619v1,True,2025-02-19T10:56:27Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=10, tm_min=56, tm_sec=27, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T10:56:27Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=10, tm_min=56, tm_sec=27, tm_wday=2, tm_yday=50, tm_isdst=0)",Complex Ontology Matching with Large Language Model Embeddings,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Complex Ontology Matching with Large Language Model Embeddings'}","Ontology, and more broadly, Knowledge Graph Matching is a challenging task in
which expressiveness has not been fully addressed. Despite the increasing use
of embeddings and language models for this task, approaches for generating
expressive correspondences still do not take full advantage of these models, in
particular, large language models (LLMs). This paper proposes to integrate LLMs
into an approach for generating expressive correspondences based on alignment
need and ABox-based relation discovery. The generation of correspondences is
performed by matching similar surroundings of instance sub-graphs. The
integration of LLMs results in different architectural modifications, including
label similarity, sub-graph matching, and entity matching. The performance word
embeddings, sentence embeddings, and LLM-based embeddings, was compared. The
results demonstrate that integrating LLMs surpasses all other models, enhancing
the baseline version of the approach with a 45\% increase in F-measure.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Ontology, and more broadly, Knowledge Graph Matching is a challenging task in\nwhich expressiveness has not been fully addressed. Despite the increasing use\nof embeddings and language models for this task, approaches for generating\nexpressive correspondences still do not take full advantage of these models, in\nparticular, large language models (LLMs). This paper proposes to integrate LLMs\ninto an approach for generating expressive correspondences based on alignment\nneed and ABox-based relation discovery. The generation of correspondences is\nperformed by matching similar surroundings of instance sub-graphs. The\nintegration of LLMs results in different architectural modifications, including\nlabel similarity, sub-graph matching, and entity matching. The performance word\nembeddings, sentence embeddings, and LLM-based embeddings, was compared. The\nresults demonstrate that integrating LLMs surpasses all other models, enhancing\nthe baseline version of the approach with a 45\\% increase in F-measure.'}","['Guilherme Sousa', 'Rinaldo Lima', 'Cassia Trojahn']",{'name': 'Cassia Trojahn'},Cassia Trojahn,,"[{'href': 'http://arxiv.org/abs/2502.13619v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13619v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13619v1,None,http://arxiv.org/abs/2502.13619v1,,,624,0
http://arxiv.org/abs/2502.13621v1,True,2025-02-19T10:59:02Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=10, tm_min=59, tm_sec=2, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T10:59:02Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=10, tm_min=59, tm_sec=2, tm_wday=2, tm_yday=50, tm_isdst=0)",Decentralized Planning Using Probabilistic Hyperproperties,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Decentralized Planning Using Probabilistic Hyperproperties'}","Multi-agent planning under stochastic dynamics is usually formalised using
decentralized (partially observable) Markov decision processes ( MDPs) and
reachability or expected reward specifications. In this paper, we propose a
different approach: we use an MDP describing how a single agent operates in an
environment and probabilistic hyperproperties to capture desired temporal
objectives for a set of decentralized agents operating in the environment. We
extend existing approaches for model checking probabilistic hyperproperties to
handle temporal formulae relating paths of different agents, thus requiring the
self-composition between multiple MDPs. Using several case studies, we
demonstrate that our approach provides a flexible and expressive framework to
broaden the specification capabilities with respect to existing planning
techniques. Additionally, we establish a close connection between a subclass of
probabilistic hyperproperties and planning for a particular type of Dec-MDPs,
for both of which we show undecidability. This lays the ground for the use of
existing decentralized planning tools in the field of probabilistic
hyperproperty verification.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Multi-agent planning under stochastic dynamics is usually formalised using\ndecentralized (partially observable) Markov decision processes ( MDPs) and\nreachability or expected reward specifications. In this paper, we propose a\ndifferent approach: we use an MDP describing how a single agent operates in an\nenvironment and probabilistic hyperproperties to capture desired temporal\nobjectives for a set of decentralized agents operating in the environment. We\nextend existing approaches for model checking probabilistic hyperproperties to\nhandle temporal formulae relating paths of different agents, thus requiring the\nself-composition between multiple MDPs. Using several case studies, we\ndemonstrate that our approach provides a flexible and expressive framework to\nbroaden the specification capabilities with respect to existing planning\ntechniques. Additionally, we establish a close connection between a subclass of\nprobabilistic hyperproperties and planning for a particular type of Dec-MDPs,\nfor both of which we show undecidability. This lays the ground for the use of\nexisting decentralized planning tools in the field of probabilistic\nhyperproperty verification.'}","['Francesco Pontiggia', 'Filip Mack', 'Roman Andriushchenko', 'Michele Chiari', 'Milan eka']",{'name': 'Milan eka'},Milan eka,"11 pages, 1 figure, 2 tables. Accepted at AAMAS 2025: the 24th
  International Conference on Autonomous Agents and Multiagent Systems","[{'href': 'http://arxiv.org/abs/2502.13621v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13621v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LO', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13621v1,None,http://arxiv.org/abs/2502.13621v1,,,45,0
http://arxiv.org/abs/2502.13622v1,True,2025-02-19T10:59:05Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=10, tm_min=59, tm_sec=5, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T10:59:05Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=10, tm_min=59, tm_sec=5, tm_wday=2, tm_yday=50, tm_isdst=0)","REFIND: Retrieval-Augmented Factuality Hallucination Detection in Large
  Language Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'REFIND: Retrieval-Augmented Factuality Hallucination Detection in Large\n  Language Models'}","Hallucinations in large language model (LLM) outputs severely limit their
reliability in knowledge-intensive tasks such as question answering. To address
this challenge, we introduce REFIND (Retrieval-augmented Factuality
hallucINation Detection), a novel framework that detects hallucinated spans
within LLM outputs by directly leveraging retrieved documents. As part of the
REFIND, we propose the Context Sensitivity Ratio (CSR), a novel metric that
quantifies the sensitivity of LLM outputs to retrieved evidence. This
innovative approach enables REFIND to efficiently and accurately detect
hallucinations, setting it apart from existing methods. In the evaluation,
REFIND demonstrated robustness across nine languages, including low-resource
settings, and significantly outperformed baseline models, achieving superior
IoU scores in identifying hallucinated spans. This work highlights the
effectiveness of quantifying context sensitivity for hallucination detection,
thereby paving the way for more reliable and trustworthy LLM applications
across diverse languages.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Hallucinations in large language model (LLM) outputs severely limit their\nreliability in knowledge-intensive tasks such as question answering. To address\nthis challenge, we introduce REFIND (Retrieval-augmented Factuality\nhallucINation Detection), a novel framework that detects hallucinated spans\nwithin LLM outputs by directly leveraging retrieved documents. As part of the\nREFIND, we propose the Context Sensitivity Ratio (CSR), a novel metric that\nquantifies the sensitivity of LLM outputs to retrieved evidence. This\ninnovative approach enables REFIND to efficiently and accurately detect\nhallucinations, setting it apart from existing methods. In the evaluation,\nREFIND demonstrated robustness across nine languages, including low-resource\nsettings, and significantly outperformed baseline models, achieving superior\nIoU scores in identifying hallucinated spans. This work highlights the\neffectiveness of quantifying context sensitivity for hallucination detection,\nthereby paving the way for more reliable and trustworthy LLM applications\nacross diverse languages.'}","['DongGeon Lee', 'Hwanjo Yu']",{'name': 'Hwanjo Yu'},Hwanjo Yu,,"[{'href': 'http://arxiv.org/abs/2502.13622v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13622v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13622v1,None,http://arxiv.org/abs/2502.13622v1,,,0,0
http://arxiv.org/abs/2502.13638v1,True,2025-02-19T11:24:51Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=11, tm_min=24, tm_sec=51, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T11:24:51Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=11, tm_min=24, tm_sec=51, tm_wday=2, tm_yday=50, tm_isdst=0)","Integrating Inverse and Forward Modeling for Sparse Temporal Data from
  Sensor Networks","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Integrating Inverse and Forward Modeling for Sparse Temporal Data from\n  Sensor Networks'}","We present CavePerception, a framework for the analysis of sparse data from
sensor networks that incorporates elements of inverse modeling and forward
modeling. By integrating machine learning with physical modeling in a
hypotheses space, we aim to improve the interpretability of sparse, noisy, and
potentially incomplete sensor data. The framework assumes data from a
two-dimensional sensor network laid out in a graph structure that detects
certain objects, with certain motion patterns. Examples of such sensors are
magnetometers. Given knowledge about the objects and the way they act on the
sensors, one can develop a data generator that produces data from simulated
motions of the objects across the sensor field. The framework uses the
simulated data to infer object behaviors across the sensor network. The
approach is experimentally tested on real-world data, where magnetometers are
used on an airport to detect and identify aircraft motions. Experiments
demonstrate the value of integrating inverse and forward modeling, enabling
intelligent systems to better understand and predict complex, sensor-driven
events.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'We present CavePerception, a framework for the analysis of sparse data from\nsensor networks that incorporates elements of inverse modeling and forward\nmodeling. By integrating machine learning with physical modeling in a\nhypotheses space, we aim to improve the interpretability of sparse, noisy, and\npotentially incomplete sensor data. The framework assumes data from a\ntwo-dimensional sensor network laid out in a graph structure that detects\ncertain objects, with certain motion patterns. Examples of such sensors are\nmagnetometers. Given knowledge about the objects and the way they act on the\nsensors, one can develop a data generator that produces data from simulated\nmotions of the objects across the sensor field. The framework uses the\nsimulated data to infer object behaviors across the sensor network. The\napproach is experimentally tested on real-world data, where magnetometers are\nused on an airport to detect and identify aircraft motions. Experiments\ndemonstrate the value of integrating inverse and forward modeling, enabling\nintelligent systems to better understand and predict complex, sensor-driven\nevents.'}","['Julian Vexler', 'Bjrn Vieten', 'Martin Nelke', 'Stefan Kramer']",{'name': 'Stefan Kramer'},Stefan Kramer,,"[{'href': 'http://arxiv.org/abs/2502.13638v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13638v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13638v1,None,http://arxiv.org/abs/2502.13638v1,,,7,0
http://arxiv.org/abs/2502.13652v1,True,2025-02-19T11:57:02Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=11, tm_min=57, tm_sec=2, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T11:57:02Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=11, tm_min=57, tm_sec=2, tm_wday=2, tm_yday=50, tm_isdst=0)",C2T: A Classifier-Based Tree Construction Method in Speculative Decoding,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'C2T: A Classifier-Based Tree Construction Method in Speculative Decoding'}","The growing scale of Large Language Models (LLMs) has exacerbated inference
latency and computational costs. Speculative decoding methods, which aim to
mitigate these issues, often face inefficiencies in the construction of token
trees and the verification of candidate tokens. Existing strategies, including
chain mode, static tree, and dynamic tree approaches, have limitations in
accurately preparing candidate token trees for verification. We propose a novel
method named C2T that adopts a lightweight classifier to generate and prune
token trees dynamically. Our classifier considers additional feature variables
beyond the commonly used joint probability to predict the confidence score for
each draft token to determine whether it is the candidate token for
verification. This method outperforms state-of-the-art (SOTA) methods such as
EAGLE-2 on multiple benchmarks, by reducing the total number of candidate
tokens by 25% while maintaining or even improving the acceptance length.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The growing scale of Large Language Models (LLMs) has exacerbated inference\nlatency and computational costs. Speculative decoding methods, which aim to\nmitigate these issues, often face inefficiencies in the construction of token\ntrees and the verification of candidate tokens. Existing strategies, including\nchain mode, static tree, and dynamic tree approaches, have limitations in\naccurately preparing candidate token trees for verification. We propose a novel\nmethod named C2T that adopts a lightweight classifier to generate and prune\ntoken trees dynamically. Our classifier considers additional feature variables\nbeyond the commonly used joint probability to predict the confidence score for\neach draft token to determine whether it is the candidate token for\nverification. This method outperforms state-of-the-art (SOTA) methods such as\nEAGLE-2 on multiple benchmarks, by reducing the total number of candidate\ntokens by 25% while maintaining or even improving the acceptance length.'}","['Feiye Huo', 'Jianchao Tan', 'Kefeng Zhang', 'Xunliang Cai', 'Shengli Sun']",{'name': 'Shengli Sun'},Shengli Sun,,"[{'href': 'http://arxiv.org/abs/2502.13652v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13652v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13652v1,None,http://arxiv.org/abs/2502.13652v1,,,1,0
http://arxiv.org/abs/2502.13701v1,True,2025-02-19T13:18:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=13, tm_min=18, tm_sec=42, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T13:18:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=13, tm_min=18, tm_sec=42, tm_wday=2, tm_yday=50, tm_isdst=0)",Causes and Strategies in Multiagent Systems,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Causes and Strategies in Multiagent Systems'}","Causality plays an important role in daily processes, human reasoning, and
artificial intelligence. There has however not been much research on causality
in multi-agent strategic settings. In this work, we introduce a systematic way
to build a multi-agent system model, represented as a concurrent game
structure, for a given structural causal model. In the obtained so-called
causal concurrent game structure, transitions correspond to interventions on
agent variables of the given causal model. The Halpern and Pearl framework of
causality is used to determine the effects of a certain value for an agent
variable on other variables. The causal concurrent game structure allows us to
analyse and reason about causal effects of agents' strategic decisions. We
formally investigate the relation between causal concurrent game structures and
the original structural causal models.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Causality plays an important role in daily processes, human reasoning, and\nartificial intelligence. There has however not been much research on causality\nin multi-agent strategic settings. In this work, we introduce a systematic way\nto build a multi-agent system model, represented as a concurrent game\nstructure, for a given structural causal model. In the obtained so-called\ncausal concurrent game structure, transitions correspond to interventions on\nagent variables of the given causal model. The Halpern and Pearl framework of\ncausality is used to determine the effects of a certain value for an agent\nvariable on other variables. The causal concurrent game structure allows us to\nanalyse and reason about causal effects of agents' strategic decisions. We\nformally investigate the relation between causal concurrent game structures and\nthe original structural causal models.""}","['Sylvia S. Kerkhove', 'Natasha Alechina', 'Mehdi Dastani']",{'name': 'Mehdi Dastani'},Mehdi Dastani,Accepted at AAMAS 2025,"[{'href': 'http://arxiv.org/abs/2502.13701v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13701v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13701v1,None,http://arxiv.org/abs/2502.13701v1,,,1958,0
http://arxiv.org/abs/2502.13719v1,True,2025-02-19T13:45:27Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=13, tm_min=45, tm_sec=27, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T13:45:27Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=13, tm_min=45, tm_sec=27, tm_wday=2, tm_yday=50, tm_isdst=0)",TrustRAG: An Information Assistant with Retrieval Augmented Generation,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'TrustRAG: An Information Assistant with Retrieval Augmented Generation'}","\Ac{RAG} has emerged as a crucial technique for enhancing large models with
real-time and domain-specific knowledge. While numerous improvements and
open-source tools have been proposed to refine the \ac{RAG} framework for
accuracy, relatively little attention has been given to improving the
trustworthiness of generated results. To address this gap, we introduce
TrustRAG, a novel framework that enhances \ac{RAG} from three perspectives:
indexing, retrieval, and generation. Specifically, in the indexing stage, we
propose a semantic-enhanced chunking strategy that incorporates hierarchical
indexing to supplement each chunk with contextual information, ensuring
semantic completeness. In the retrieval stage, we introduce a utility-based
filtering mechanism to identify high-quality information, supporting answer
generation while reducing input length. In the generation stage, we propose
fine-grained citation enhancement, which detects opinion-bearing sentences in
responses and infers citation relationships at the sentence-level, thereby
improving citation accuracy. We open-source the TrustRAG framework and provide
a demonstration studio designed for excerpt-based question answering tasks
\footnote{https://huggingface.co/spaces/golaxy/TrustRAG}. Based on these, we
aim to help researchers: 1) systematically enhancing the trustworthiness of
\ac{RAG} systems and (2) developing their own \ac{RAG} systems with more
reliable outputs.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': '\\Ac{RAG} has emerged as a crucial technique for enhancing large models with\nreal-time and domain-specific knowledge. While numerous improvements and\nopen-source tools have been proposed to refine the \\ac{RAG} framework for\naccuracy, relatively little attention has been given to improving the\ntrustworthiness of generated results. To address this gap, we introduce\nTrustRAG, a novel framework that enhances \\ac{RAG} from three perspectives:\nindexing, retrieval, and generation. Specifically, in the indexing stage, we\npropose a semantic-enhanced chunking strategy that incorporates hierarchical\nindexing to supplement each chunk with contextual information, ensuring\nsemantic completeness. In the retrieval stage, we introduce a utility-based\nfiltering mechanism to identify high-quality information, supporting answer\ngeneration while reducing input length. In the generation stage, we propose\nfine-grained citation enhancement, which detects opinion-bearing sentences in\nresponses and infers citation relationships at the sentence-level, thereby\nimproving citation accuracy. We open-source the TrustRAG framework and provide\na demonstration studio designed for excerpt-based question answering tasks\n\\footnote{https://huggingface.co/spaces/golaxy/TrustRAG}. Based on these, we\naim to help researchers: 1) systematically enhancing the trustworthiness of\n\\ac{RAG} systems and (2) developing their own \\ac{RAG} systems with more\nreliable outputs.'}","['Yixing Fan', 'Qiang Yan', 'Wenshan Wang', 'Jiafeng Guo', 'Ruqing Zhang', 'Xueqi Cheng']",{'name': 'Xueqi Cheng'},Xueqi Cheng,,"[{'href': 'http://arxiv.org/abs/2502.13719v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13719v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13719v1,None,http://arxiv.org/abs/2502.13719v1,,,1351,0
http://arxiv.org/abs/2502.13723v1,True,2025-02-19T13:51:05Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=13, tm_min=51, tm_sec=5, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T13:51:05Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=13, tm_min=51, tm_sec=5, tm_wday=2, tm_yday=50, tm_isdst=0)","Direct Value Optimization: Improving Chain-of-Thought Reasoning in LLMs
  with Refined Values","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Direct Value Optimization: Improving Chain-of-Thought Reasoning in LLMs\n  with Refined Values'}","We introduce Direct Value Optimization (DVO), an innovative reinforcement
learning framework for enhancing large language models in complex reasoning
tasks. Unlike traditional methods relying on preference labels, DVO utilizes
value signals at individual reasoning steps, optimizing models via a mean
squared error loss. The key benefit of DVO lies in its fine-grained
supervision, circumventing the need for labor-intensive human annotations.
Target values within the DVO are estimated using either Monte Carlo Tree Search
or an outcome value model. Our empirical analysis on both mathematical and
commonsense reasoning tasks shows that DVO consistently outperforms existing
offline preference optimization techniques, even with fewer training steps.
These findings underscore the importance of value signals in advancing
reasoning capabilities and highlight DVO as a superior methodology under
scenarios lacking explicit human preference information.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'We introduce Direct Value Optimization (DVO), an innovative reinforcement\nlearning framework for enhancing large language models in complex reasoning\ntasks. Unlike traditional methods relying on preference labels, DVO utilizes\nvalue signals at individual reasoning steps, optimizing models via a mean\nsquared error loss. The key benefit of DVO lies in its fine-grained\nsupervision, circumventing the need for labor-intensive human annotations.\nTarget values within the DVO are estimated using either Monte Carlo Tree Search\nor an outcome value model. Our empirical analysis on both mathematical and\ncommonsense reasoning tasks shows that DVO consistently outperforms existing\noffline preference optimization techniques, even with fewer training steps.\nThese findings underscore the importance of value signals in advancing\nreasoning capabilities and highlight DVO as a superior methodology under\nscenarios lacking explicit human preference information.'}","['Hongbo Zhang', 'Han Cui', 'Guangsheng Bao', 'Linyi Yang', 'Jun Wang', 'Yue Zhang']",{'name': 'Yue Zhang'},Yue Zhang,preprint,"[{'href': 'http://arxiv.org/abs/2502.13723v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13723v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13723v1,None,http://arxiv.org/abs/2502.13723v1,,,2557,0
http://arxiv.org/abs/2502.13728v1,True,2025-02-19T13:54:44Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=13, tm_min=54, tm_sec=44, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T13:54:44Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=13, tm_min=54, tm_sec=44, tm_wday=2, tm_yday=50, tm_isdst=0)",Secure Federated Data Distillation,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Secure Federated Data Distillation'}","Dataset Distillation (DD) is a powerful technique for reducing large datasets
into compact, representative synthetic datasets, accelerating Machine Learning
training. However, traditional DD methods operate in a centralized manner,
which poses significant privacy threats and reduces its applicability. To
mitigate these risks, we propose a Secure Federated Data Distillation framework
(SFDD) to decentralize the distillation process while preserving privacy.Unlike
existing Federated Distillation techniques that focus on training global models
with distilled knowledge, our approach aims to produce a distilled dataset
without exposing local contributions. We leverage the gradient-matching-based
distillation method, adapting it for a distributed setting where clients
contribute to the distillation process without sharing raw data. The central
aggregator iteratively refines a synthetic dataset by integrating client-side
updates while ensuring data confidentiality. To make our approach resilient to
inference attacks perpetrated by the server that could exploit gradient updates
to reconstruct private data, we create an optimized Local Differential Privacy
approach, called LDPO-RLD (Label Differential Privacy Obfuscation via
Randomized Linear Dispersion). Furthermore, we assess the framework's
resilience against malicious clients executing backdoor attacks and demonstrate
robustness under the assumption of a sufficient number of participating
clients. Our experimental results demonstrate the effectiveness of SFDD and
that the proposed defense concretely mitigates the identified vulnerabilities,
with minimal impact on the performance of the distilled dataset. By addressing
the interplay between privacy and federation in dataset distillation, this work
advances the field of privacy-preserving Machine Learning making our SFDD
framework a viable solution for sensitive data-sharing applications.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Dataset Distillation (DD) is a powerful technique for reducing large datasets\ninto compact, representative synthetic datasets, accelerating Machine Learning\ntraining. However, traditional DD methods operate in a centralized manner,\nwhich poses significant privacy threats and reduces its applicability. To\nmitigate these risks, we propose a Secure Federated Data Distillation framework\n(SFDD) to decentralize the distillation process while preserving privacy.Unlike\nexisting Federated Distillation techniques that focus on training global models\nwith distilled knowledge, our approach aims to produce a distilled dataset\nwithout exposing local contributions. We leverage the gradient-matching-based\ndistillation method, adapting it for a distributed setting where clients\ncontribute to the distillation process without sharing raw data. The central\naggregator iteratively refines a synthetic dataset by integrating client-side\nupdates while ensuring data confidentiality. To make our approach resilient to\ninference attacks perpetrated by the server that could exploit gradient updates\nto reconstruct private data, we create an optimized Local Differential Privacy\napproach, called LDPO-RLD (Label Differential Privacy Obfuscation via\nRandomized Linear Dispersion). Furthermore, we assess the framework's\nresilience against malicious clients executing backdoor attacks and demonstrate\nrobustness under the assumption of a sufficient number of participating\nclients. Our experimental results demonstrate the effectiveness of SFDD and\nthat the proposed defense concretely mitigates the identified vulnerabilities,\nwith minimal impact on the performance of the distilled dataset. By addressing\nthe interplay between privacy and federation in dataset distillation, this work\nadvances the field of privacy-preserving Machine Learning making our SFDD\nframework a viable solution for sensitive data-sharing applications.""}","['Marco Arazzi', 'Mert Cihangiroglu', 'Serena Nicolazzo', 'Antonino Nocera']",{'name': 'Antonino Nocera'},Antonino Nocera,,"[{'href': 'http://arxiv.org/abs/2502.13728v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13728v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13728v1,None,http://arxiv.org/abs/2502.13728v1,,,1682,0
http://arxiv.org/abs/2502.13751v1,True,2025-02-19T14:12:01Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=14, tm_min=12, tm_sec=1, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T14:12:01Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=14, tm_min=12, tm_sec=1, tm_wday=2, tm_yday=50, tm_isdst=0)",RobustX: Robust Counterfactual Explanations Made Easy,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'RobustX: Robust Counterfactual Explanations Made Easy'}","The increasing use of Machine Learning (ML) models to aid decision-making in
high-stakes industries demands explainability to facilitate trust.
Counterfactual Explanations (CEs) are ideally suited for this, as they can
offer insights into the predictions of an ML model by illustrating how changes
in its input data may lead to different outcomes. However, for CEs to realise
their explanatory potential, significant challenges remain in ensuring their
robustness under slight changes in the scenario being explained. Despite the
widespread recognition of CEs' robustness as a fundamental requirement, a lack
of standardised tools and benchmarks hinders a comprehensive and effective
comparison of robust CE generation methods. In this paper, we introduce
RobustX, an open-source Python library implementing a collection of CE
generation and evaluation methods, with a focus on the robustness property.
RobustX provides interfaces to several existing methods from the literature,
enabling streamlined access to state-of-the-art techniques. The library is also
easily extensible, allowing fast prototyping of novel robust CE generation and
evaluation methods.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""The increasing use of Machine Learning (ML) models to aid decision-making in\nhigh-stakes industries demands explainability to facilitate trust.\nCounterfactual Explanations (CEs) are ideally suited for this, as they can\noffer insights into the predictions of an ML model by illustrating how changes\nin its input data may lead to different outcomes. However, for CEs to realise\ntheir explanatory potential, significant challenges remain in ensuring their\nrobustness under slight changes in the scenario being explained. Despite the\nwidespread recognition of CEs' robustness as a fundamental requirement, a lack\nof standardised tools and benchmarks hinders a comprehensive and effective\ncomparison of robust CE generation methods. In this paper, we introduce\nRobustX, an open-source Python library implementing a collection of CE\ngeneration and evaluation methods, with a focus on the robustness property.\nRobustX provides interfaces to several existing methods from the literature,\nenabling streamlined access to state-of-the-art techniques. The library is also\neasily extensible, allowing fast prototyping of novel robust CE generation and\nevaluation methods.""}","['Junqi Jiang', 'Luca Marzari', 'Aaryan Purohit', 'Francesco Leofante']",{'name': 'Francesco Leofante'},Francesco Leofante,,"[{'href': 'http://arxiv.org/abs/2502.13751v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13751v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13751v1,None,http://arxiv.org/abs/2502.13751v1,,,62,0
http://arxiv.org/abs/2502.13755v1,True,2025-02-19T14:20:07Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=14, tm_min=20, tm_sec=7, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T14:20:07Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=14, tm_min=20, tm_sec=7, tm_wday=2, tm_yday=50, tm_isdst=0)",GPA: Grover Policy Agent for Generating Optimal Quantum Sensor Circuits,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'GPA: Grover Policy Agent for Generating Optimal Quantum Sensor Circuits'}","This study proposes a GPA for designing optimal Quantum Sensor Circuits
(QSCs) to address complex quantum physics problems. The GPA consists of two
parts: the Quantum Policy Evaluation (QPE) and the Quantum Policy Improvement
(QPI). The QPE performs phase estimation to generate the search space, while
the QPI utilizes Grover search and amplitude amplification techniques to
efficiently identify an optimal policy that generates optimal QSCs. The GPA
generates QSCs by selecting sequences of gates that maximize the Quantum Fisher
Information (QFI) while minimizing the number of gates. The QSCs generated by
the GPA are capable of producing entangled quantum states, specifically the
squeezed states. High QFI indicates increased sensitivity to parameter changes,
making the circuit useful for quantum state estimation and control tasks.
Evaluation of the GPA on a QSC that consists of two qubits and a sequence of
R_x, R_y, and S gates demonstrates its efficiency in generating optimal QSCs
with a QFI of 1. Compared to existing quantum agents, the GPA achieves higher
QFI with fewer gates, demonstrating a more efficient and scalable approach to
the design of QSCs. This work illustrates the potential computational power of
quantum agents for solving quantum physics problems","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'This study proposes a GPA for designing optimal Quantum Sensor Circuits\n(QSCs) to address complex quantum physics problems. The GPA consists of two\nparts: the Quantum Policy Evaluation (QPE) and the Quantum Policy Improvement\n(QPI). The QPE performs phase estimation to generate the search space, while\nthe QPI utilizes Grover search and amplitude amplification techniques to\nefficiently identify an optimal policy that generates optimal QSCs. The GPA\ngenerates QSCs by selecting sequences of gates that maximize the Quantum Fisher\nInformation (QFI) while minimizing the number of gates. The QSCs generated by\nthe GPA are capable of producing entangled quantum states, specifically the\nsqueezed states. High QFI indicates increased sensitivity to parameter changes,\nmaking the circuit useful for quantum state estimation and control tasks.\nEvaluation of the GPA on a QSC that consists of two qubits and a sequence of\nR_x, R_y, and S gates demonstrates its efficiency in generating optimal QSCs\nwith a QFI of 1. Compared to existing quantum agents, the GPA achieves higher\nQFI with fewer gates, demonstrating a more efficient and scalable approach to\nthe design of QSCs. This work illustrates the potential computational power of\nquantum agents for solving quantum physics problems'}","['Ahmad Alomari', 'Sathish A. P. Kumar']",{'name': 'Sathish A. P. Kumar'},Sathish A. P. Kumar,10 pages,"[{'href': 'http://arxiv.org/abs/2502.13755v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13755v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'quant-ph', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'quant-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13755v1,None,http://arxiv.org/abs/2502.13755v1,,,14,0
http://arxiv.org/abs/2502.13764v1,True,2025-02-19T14:24:25Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=14, tm_min=24, tm_sec=25, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T14:24:25Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=14, tm_min=24, tm_sec=25, tm_wday=2, tm_yday=50, tm_isdst=0)","An Overall Real-Time Mechanism for Classification and Quality Evaluation
  of Rice","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'An Overall Real-Time Mechanism for Classification and Quality Evaluation\n  of Rice'}","Rice is one of the most widely cultivated crops globally and has been
developed into numerous varieties. The quality of rice during cultivation is
primarily determined by its cultivar and characteristics. Traditionally, rice
classification and quality assessment rely on manual visual inspection, a
process that is both time-consuming and prone to errors. However, with
advancements in machine vision technology, automating rice classification and
quality evaluation based on its cultivar and characteristics has become
increasingly feasible, enhancing both accuracy and efficiency. This study
proposes a real-time evaluation mechanism for comprehensive rice grain
assessment, integrating a one-stage object detection approach, a deep
convolutional neural network, and traditional machine learning techniques. The
proposed framework enables rice variety identification, grain completeness
grading, and grain chalkiness evaluation. The rice grain dataset used in this
study comprises approximately 20,000 images from six widely cultivated rice
varieties in China. Experimental results demonstrate that the proposed
mechanism achieves a mean average precision (mAP) of 99.14% in the object
detection task and an accuracy of 97.89% in the classification task.
Furthermore, the framework attains an average accuracy of 97.56% in grain
completeness grading within the same rice variety, contributing to an effective
quality evaluation system.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Rice is one of the most widely cultivated crops globally and has been\ndeveloped into numerous varieties. The quality of rice during cultivation is\nprimarily determined by its cultivar and characteristics. Traditionally, rice\nclassification and quality assessment rely on manual visual inspection, a\nprocess that is both time-consuming and prone to errors. However, with\nadvancements in machine vision technology, automating rice classification and\nquality evaluation based on its cultivar and characteristics has become\nincreasingly feasible, enhancing both accuracy and efficiency. This study\nproposes a real-time evaluation mechanism for comprehensive rice grain\nassessment, integrating a one-stage object detection approach, a deep\nconvolutional neural network, and traditional machine learning techniques. The\nproposed framework enables rice variety identification, grain completeness\ngrading, and grain chalkiness evaluation. The rice grain dataset used in this\nstudy comprises approximately 20,000 images from six widely cultivated rice\nvarieties in China. Experimental results demonstrate that the proposed\nmechanism achieves a mean average precision (mAP) of 99.14% in the object\ndetection task and an accuracy of 97.89% in the classification task.\nFurthermore, the framework attains an average accuracy of 97.56% in grain\ncompleteness grading within the same rice variety, contributing to an effective\nquality evaluation system.'}","['Wanke Xia', 'Ruxin Peng', 'Haoqi Chu', 'Xinlei Zhu', 'Zhiyu Yang', 'Yaojun Wang']",{'name': 'Yaojun Wang'},Yaojun Wang,,"[{'href': 'http://arxiv.org/abs/2502.13764v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13764v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13764v1,None,http://arxiv.org/abs/2502.13764v1,,,0,0
http://arxiv.org/abs/2502.13767v1,True,2025-02-19T14:28:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=14, tm_min=28, tm_sec=42, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T14:28:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=14, tm_min=28, tm_sec=42, tm_wday=2, tm_yday=50, tm_isdst=0)",AI Software Engineer: Programming with Trust,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'AI Software Engineer: Programming with Trust'}","Large Language Models (LLMs) have shown surprising proficiency in generating
code snippets, promising to automate large parts of software engineering via
artificial intelligence (AI). We argue that successfully deploying AI software
engineers requires a level of trust equal to or even greater than the trust
established by human-driven software engineering practices. The recent trend
toward LLM agents offers a path toward integrating the power of LLMs to create
new code with the power of analysis tools to increase trust in the code. This
opinion piece comments on whether LLM agents could dominate software
engineering workflows in the future and whether the focus of programming will
shift from programming at scale to programming with trust.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Language Models (LLMs) have shown surprising proficiency in generating\ncode snippets, promising to automate large parts of software engineering via\nartificial intelligence (AI). We argue that successfully deploying AI software\nengineers requires a level of trust equal to or even greater than the trust\nestablished by human-driven software engineering practices. The recent trend\ntoward LLM agents offers a path toward integrating the power of LLMs to create\nnew code with the power of analysis tools to increase trust in the code. This\nopinion piece comments on whether LLM agents could dominate software\nengineering workflows in the future and whether the focus of programming will\nshift from programming at scale to programming with trust.'}","['Abhik Roychoudhury', 'Corina Pasareanu', 'Michael Pradel', 'Baishakhi Ray']",{'name': 'Baishakhi Ray'},Baishakhi Ray,5 pages,"[{'href': 'http://arxiv.org/abs/2502.13767v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13767v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.SE', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.SE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13767v1,None,http://arxiv.org/abs/2502.13767v1,,,1078,0
http://arxiv.org/abs/2502.13778v1,True,2025-02-19T14:42:32Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=14, tm_min=42, tm_sec=32, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T14:42:32Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=14, tm_min=42, tm_sec=32, tm_wday=2, tm_yday=50, tm_isdst=0)","Poster: SpiderSim: Multi-Agent Driven Theoretical Cybersecurity
  Simulation for Industrial Digitalization","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Poster: SpiderSim: Multi-Agent Driven Theoretical Cybersecurity\n  Simulation for Industrial Digitalization'}","Rapid industrial digitalization has created intricate cybersecurity demands
that necessitate effective validation methods. While cyber ranges and
simulation platforms are widely deployed, they frequently face limitations in
scenario diversity and creation efficiency. In this paper, we present
SpiderSim, a theoretical cybersecurity simulation platform enabling rapid and
lightweight scenario generation for industrial digitalization security
research. At its core, our platform introduces three key innovations: a
structured framework for unified scenario modeling, a multi-agent collaboration
mechanism for automated generation, and modular atomic security capabilities
for flexible scenario composition. Extensive implementation trials across
multiple industrial digitalization contexts, including marine ranch monitoring
systems, validate our platform's capacity for broad scenario coverage with
efficient generation processes. Built on solid theoretical foundations and
released as open-source software, SpiderSim facilitates broader research and
development in automated security testing for industrial digitalization.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Rapid industrial digitalization has created intricate cybersecurity demands\nthat necessitate effective validation methods. While cyber ranges and\nsimulation platforms are widely deployed, they frequently face limitations in\nscenario diversity and creation efficiency. In this paper, we present\nSpiderSim, a theoretical cybersecurity simulation platform enabling rapid and\nlightweight scenario generation for industrial digitalization security\nresearch. At its core, our platform introduces three key innovations: a\nstructured framework for unified scenario modeling, a multi-agent collaboration\nmechanism for automated generation, and modular atomic security capabilities\nfor flexible scenario composition. Extensive implementation trials across\nmultiple industrial digitalization contexts, including marine ranch monitoring\nsystems, validate our platform's capacity for broad scenario coverage with\nefficient generation processes. Built on solid theoretical foundations and\nreleased as open-source software, SpiderSim facilitates broader research and\ndevelopment in automated security testing for industrial digitalization.""}","['Jiaqi Li', 'Xizhong Guo', 'Yang Zhao', 'Lvyang Zhang', 'Lidong Zhai']",{'name': 'Lidong Zhai'},Lidong Zhai,https://github.com/NRT2024/SpiderSim,"[{'href': 'http://arxiv.org/abs/2502.13778v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13778v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13778v1,None,http://arxiv.org/abs/2502.13778v1,,,25,0
http://arxiv.org/abs/2502.13785v1,True,2025-02-19T14:51:41Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=14, tm_min=51, tm_sec=41, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T14:51:41Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=14, tm_min=51, tm_sec=41, tm_wday=2, tm_yday=50, tm_isdst=0)","Helix-mRNA: A Hybrid Foundation Model For Full Sequence mRNA
  Therapeutics","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Helix-mRNA: A Hybrid Foundation Model For Full Sequence mRNA\n  Therapeutics'}","mRNA-based vaccines have become a major focus in the pharmaceutical industry.
The coding sequence as well as the Untranslated Regions (UTRs) of an mRNA can
strongly influence translation efficiency, stability, degradation, and other
factors that collectively determine a vaccine's effectiveness. However,
optimizing mRNA sequences for those properties remains a complex challenge.
Existing deep learning models often focus solely on coding region optimization,
overlooking the UTRs. We present Helix-mRNA, a structured state-space-based and
attention hybrid model to address these challenges. In addition to a first
pre-training, a second pre-training stage allows us to specialise the model
with high-quality data. We employ single nucleotide tokenization of mRNA
sequences with codon separation, ensuring prior biological and structural
information from the original mRNA sequence is not lost. Our model, Helix-mRNA,
outperforms existing methods in analysing both UTRs and coding region
properties. It can process sequences 6x longer than current approaches while
using only 10% of the parameters of existing foundation models. Its predictive
capabilities extend to all mRNA regions. We open-source the model
(https://github.com/helicalAI/helical) and model weights
(https://huggingface.co/helical-ai/helix-mRNA).","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""mRNA-based vaccines have become a major focus in the pharmaceutical industry.\nThe coding sequence as well as the Untranslated Regions (UTRs) of an mRNA can\nstrongly influence translation efficiency, stability, degradation, and other\nfactors that collectively determine a vaccine's effectiveness. However,\noptimizing mRNA sequences for those properties remains a complex challenge.\nExisting deep learning models often focus solely on coding region optimization,\noverlooking the UTRs. We present Helix-mRNA, a structured state-space-based and\nattention hybrid model to address these challenges. In addition to a first\npre-training, a second pre-training stage allows us to specialise the model\nwith high-quality data. We employ single nucleotide tokenization of mRNA\nsequences with codon separation, ensuring prior biological and structural\ninformation from the original mRNA sequence is not lost. Our model, Helix-mRNA,\noutperforms existing methods in analysing both UTRs and coding region\nproperties. It can process sequences 6x longer than current approaches while\nusing only 10% of the parameters of existing foundation models. Its predictive\ncapabilities extend to all mRNA regions. We open-source the model\n(https://github.com/helicalAI/helical) and model weights\n(https://huggingface.co/helical-ai/helix-mRNA).""}","['Matthew Wood', 'Mathieu Klop', 'Maxime Allard']",{'name': 'Maxime Allard'},Maxime Allard,"8 pages, 3 figures, 3 tables","[{'href': 'http://arxiv.org/abs/2502.13785v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13785v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'q-bio.GN', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'q-bio.GN', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13785v1,None,http://arxiv.org/abs/2502.13785v1,,,0,0
http://arxiv.org/abs/2502.13836v1,True,2025-02-19T15:58:09Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=15, tm_min=58, tm_sec=9, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T15:58:09Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=15, tm_min=58, tm_sec=9, tm_wday=2, tm_yday=50, tm_isdst=0)","Quantifying Memorization and Retriever Performance in
  Retrieval-Augmented Vision-Language Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Quantifying Memorization and Retriever Performance in\n  Retrieval-Augmented Vision-Language Models'}","Large Language Models (LLMs) demonstrate remarkable capabilities in question
answering (QA), but metrics for assessing their reliance on memorization versus
retrieval remain underdeveloped. Moreover, while finetuned models are
state-of-the-art on closed-domain tasks, general-purpose models like GPT-4o
exhibit strong zero-shot performance. This raises questions about the
trade-offs between memorization, generalization, and retrieval. In this work,
we analyze the extent to which multimodal retrieval-augmented VLMs memorize
training data compared to baseline VLMs. Using the WebQA benchmark, we contrast
finetuned models with baseline VLMs on multihop retrieval and question
answering, examining the impact of finetuning on data memorization. To quantify
memorization in end-to-end retrieval and QA systems, we propose several proxy
metrics by investigating instances where QA succeeds despite retrieval failing.
Our results reveal the extent to which finetuned models rely on memorization.
In contrast, retrieval-augmented VLMs have lower memorization scores, at the
cost of accuracy (72% vs 52% on WebQA test set). As such, our measures pose a
challenge for future work to reconcile memorization and generalization in both
Open-Domain QA and joint Retrieval-QA tasks.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Language Models (LLMs) demonstrate remarkable capabilities in question\nanswering (QA), but metrics for assessing their reliance on memorization versus\nretrieval remain underdeveloped. Moreover, while finetuned models are\nstate-of-the-art on closed-domain tasks, general-purpose models like GPT-4o\nexhibit strong zero-shot performance. This raises questions about the\ntrade-offs between memorization, generalization, and retrieval. In this work,\nwe analyze the extent to which multimodal retrieval-augmented VLMs memorize\ntraining data compared to baseline VLMs. Using the WebQA benchmark, we contrast\nfinetuned models with baseline VLMs on multihop retrieval and question\nanswering, examining the impact of finetuning on data memorization. To quantify\nmemorization in end-to-end retrieval and QA systems, we propose several proxy\nmetrics by investigating instances where QA succeeds despite retrieval failing.\nOur results reveal the extent to which finetuned models rely on memorization.\nIn contrast, retrieval-augmented VLMs have lower memorization scores, at the\ncost of accuracy (72% vs 52% on WebQA test set). As such, our measures pose a\nchallenge for future work to reconcile memorization and generalization in both\nOpen-Domain QA and joint Retrieval-QA tasks.'}","['Peter Carragher', 'Abhinand Jha', 'R Raghav', 'Kathleen M. Carley']",{'name': 'Kathleen M. Carley'},Kathleen M. Carley,,"[{'href': 'http://arxiv.org/abs/2502.13836v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13836v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13836v1,None,http://arxiv.org/abs/2502.13836v1,,,1201,0
http://arxiv.org/abs/2502.13840v1,True,2025-02-19T15:59:49Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=15, tm_min=59, tm_sec=49, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T15:59:49Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=15, tm_min=59, tm_sec=49, tm_wday=2, tm_yday=50, tm_isdst=0)","Mitigating Popularity Bias in Collaborative Filtering through Fair
  Sampling","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Mitigating Popularity Bias in Collaborative Filtering through Fair\n  Sampling'}","Recommender systems often suffer from popularity bias, where frequently
interacted items are overrepresented in recommendations. This bias stems from
propensity factors influencing training data, leading to imbalanced exposure.
In this paper, we introduce a Fair Sampling (FS) approach to address this issue
by ensuring that both users and items are selected with equal probability as
positive and negative instances. Unlike traditional inverse propensity score
(IPS) methods, FS does not require propensity estimation, eliminating errors
associated with inaccurate calculations. Our theoretical analysis demonstrates
that FS effectively neutralizes the influence of propensity factors, achieving
unbiased learning. Experimental results validate that FS outperforms
state-of-the-art methods in both point-wise and pair-wise recommendation tasks,
enhancing recommendation fairness without sacrificing accuracy. The
implementation is available at https://anonymous.4open.science/r/Fair-Sampling.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Recommender systems often suffer from popularity bias, where frequently\ninteracted items are overrepresented in recommendations. This bias stems from\npropensity factors influencing training data, leading to imbalanced exposure.\nIn this paper, we introduce a Fair Sampling (FS) approach to address this issue\nby ensuring that both users and items are selected with equal probability as\npositive and negative instances. Unlike traditional inverse propensity score\n(IPS) methods, FS does not require propensity estimation, eliminating errors\nassociated with inaccurate calculations. Our theoretical analysis demonstrates\nthat FS effectively neutralizes the influence of propensity factors, achieving\nunbiased learning. Experimental results validate that FS outperforms\nstate-of-the-art methods in both point-wise and pair-wise recommendation tasks,\nenhancing recommendation fairness without sacrificing accuracy. The\nimplementation is available at https://anonymous.4open.science/r/Fair-Sampling.'}","['Jiahao Liu', 'Dongsheng Li', 'Hansu Gu', 'Peng Zhang', 'Tun Lu', 'Li Shang', 'Ning Gu']",{'name': 'Ning Gu'},Ning Gu,"6 pages, under review","[{'href': 'http://arxiv.org/abs/2502.13840v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13840v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13840v1,None,http://arxiv.org/abs/2502.13840v1,,,589,0
http://arxiv.org/abs/2502.13843v1,True,2025-02-19T16:02:59Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=16, tm_min=2, tm_sec=59, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T16:02:59Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=16, tm_min=2, tm_sec=59, tm_wday=2, tm_yday=50, tm_isdst=0)","Enhancing Cross-Domain Recommendations with Memory-Optimized LLM-Based
  User Agents","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Enhancing Cross-Domain Recommendations with Memory-Optimized LLM-Based\n  User Agents'}","Large Language Model (LLM)-based user agents have emerged as a powerful tool
for improving recommender systems by simulating user interactions. However,
existing methods struggle with cross-domain scenarios due to inefficient memory
structures, leading to irrelevant information retention and failure to account
for social influence factors such as popularity. To address these limitations,
we introduce AgentCF++, a novel framework featuring a dual-layer memory
architecture and a two-step fusion mechanism to filter domain-specific
preferences effectively. Additionally, we propose interest groups with shared
memory, allowing the model to capture the impact of popularity trends on users
with similar interests. Through extensive experiments on multiple cross-domain
datasets, AgentCF++ demonstrates superior performance over baseline models,
highlighting its effectiveness in refining user behavior simulation for
recommender systems. Our code is available at
https://anonymous.4open.science/r/AgentCF-plus.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Language Model (LLM)-based user agents have emerged as a powerful tool\nfor improving recommender systems by simulating user interactions. However,\nexisting methods struggle with cross-domain scenarios due to inefficient memory\nstructures, leading to irrelevant information retention and failure to account\nfor social influence factors such as popularity. To address these limitations,\nwe introduce AgentCF++, a novel framework featuring a dual-layer memory\narchitecture and a two-step fusion mechanism to filter domain-specific\npreferences effectively. Additionally, we propose interest groups with shared\nmemory, allowing the model to capture the impact of popularity trends on users\nwith similar interests. Through extensive experiments on multiple cross-domain\ndatasets, AgentCF++ demonstrates superior performance over baseline models,\nhighlighting its effectiveness in refining user behavior simulation for\nrecommender systems. Our code is available at\nhttps://anonymous.4open.science/r/AgentCF-plus.'}","['Jiahao Liu', 'Shengkang Gu', 'Dongsheng Li', 'Guangping Zhang', 'Mingzhe Han', 'Hansu Gu', 'Peng Zhang', 'Tun Lu', 'Li Shang', 'Ning Gu']",{'name': 'Ning Gu'},Ning Gu,"6 pages, under review","[{'href': 'http://arxiv.org/abs/2502.13843v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13843v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13843v1,None,http://arxiv.org/abs/2502.13843v1,,,589,0
http://arxiv.org/abs/2502.13845v1,True,2025-02-19T16:08:17Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=16, tm_min=8, tm_sec=17, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T16:08:17Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=16, tm_min=8, tm_sec=17, tm_wday=2, tm_yday=50, tm_isdst=0)",Enhancing LLM-Based Recommendations Through Personalized Reasoning,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Enhancing LLM-Based Recommendations Through Personalized Reasoning'}","Current recommendation systems powered by large language models (LLMs) often
underutilize their reasoning capabilities due to a lack of explicit logical
structuring. To address this limitation, we introduce CoT-Rec, a framework that
integrates Chain-of-Thought (CoT) reasoning into LLM-driven recommendations by
incorporating two crucial processes: user preference analysis and item
perception evaluation. CoT-Rec operates in two key phases: (1) personalized
data extraction, where user preferences and item perceptions are identified,
and (2) personalized data application, where this information is leveraged to
refine recommendations. Our experimental analysis demonstrates that CoT-Rec
improves recommendation accuracy by making better use of LLMs' reasoning
potential. The implementation is publicly available at
https://anonymous.4open.science/r/CoT-Rec.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Current recommendation systems powered by large language models (LLMs) often\nunderutilize their reasoning capabilities due to a lack of explicit logical\nstructuring. To address this limitation, we introduce CoT-Rec, a framework that\nintegrates Chain-of-Thought (CoT) reasoning into LLM-driven recommendations by\nincorporating two crucial processes: user preference analysis and item\nperception evaluation. CoT-Rec operates in two key phases: (1) personalized\ndata extraction, where user preferences and item perceptions are identified,\nand (2) personalized data application, where this information is leveraged to\nrefine recommendations. Our experimental analysis demonstrates that CoT-Rec\nimproves recommendation accuracy by making better use of LLMs' reasoning\npotential. The implementation is publicly available at\nhttps://anonymous.4open.science/r/CoT-Rec.""}","['Jiahao Liu', 'Xueshuo Yan', 'Dongsheng Li', 'Guangping Zhang', 'Hansu Gu', 'Peng Zhang', 'Tun Lu', 'Li Shang', 'Ning Gu']",{'name': 'Ning Gu'},Ning Gu,"7 pages, under review","[{'href': 'http://arxiv.org/abs/2502.13845v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13845v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13845v1,None,http://arxiv.org/abs/2502.13845v1,,,589,0
http://arxiv.org/abs/2502.13873v1,True,2025-02-19T16:54:58Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=16, tm_min=54, tm_sec=58, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T16:54:58Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=16, tm_min=54, tm_sec=58, tm_wday=2, tm_yday=50, tm_isdst=0)",NVR: Vector Runahead on NPUs for Sparse Memory Access,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'NVR: Vector Runahead on NPUs for Sparse Memory Access'}","Deep Neural Networks are increasingly leveraging sparsity to reduce the
scaling up of model parameter size. However, reducing wall-clock time through
sparsity and pruning remains challenging due to irregular memory access
patterns, leading to frequent cache misses. In this paper, we present NPU
Vector Runahead (NVR), a prefetching mechanism tailored for NPUs to address
cache miss problems in sparse DNN workloads. Rather than optimising memory
patterns with high overhead and poor portability, NVR adapts runahead execution
to the unique architecture of NPUs. NVR provides a general micro-architectural
solution for sparse DNN workloads without requiring compiler or algorithmic
support, operating as a decoupled, speculative, lightweight hardware sub-thread
alongside the NPU, with minimal hardware overhead (under 5%). NVR achieves an
average 90% reduction in cache misses compared to SOTA prefetching in
general-purpose processors, delivering 4x average speedup on sparse workloads
versus NPUs without prefetching. Moreover, we investigate the advantages of
incorporating a small cache (16KB) into the NPU combined with NVR. Our
evaluation shows that expanding this modest cache delivers 5x higher
performance benefits than increasing the L2 cache size by the same amount.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Deep Neural Networks are increasingly leveraging sparsity to reduce the\nscaling up of model parameter size. However, reducing wall-clock time through\nsparsity and pruning remains challenging due to irregular memory access\npatterns, leading to frequent cache misses. In this paper, we present NPU\nVector Runahead (NVR), a prefetching mechanism tailored for NPUs to address\ncache miss problems in sparse DNN workloads. Rather than optimising memory\npatterns with high overhead and poor portability, NVR adapts runahead execution\nto the unique architecture of NPUs. NVR provides a general micro-architectural\nsolution for sparse DNN workloads without requiring compiler or algorithmic\nsupport, operating as a decoupled, speculative, lightweight hardware sub-thread\nalongside the NPU, with minimal hardware overhead (under 5%). NVR achieves an\naverage 90% reduction in cache misses compared to SOTA prefetching in\ngeneral-purpose processors, delivering 4x average speedup on sparse workloads\nversus NPUs without prefetching. Moreover, we investigate the advantages of\nincorporating a small cache (16KB) into the NPU combined with NVR. Our\nevaluation shows that expanding this modest cache delivers 5x higher\nperformance benefits than increasing the L2 cache size by the same amount.'}","['Hui Wang', 'Zhengpeng Zhao', 'Jing Wang', 'Yushu Du', 'Yuan Cheng', 'Bing Guo', 'He Xiao', 'Chenhao Ma', 'Xiaomeng Han', 'Dean You', 'Jiapeng Guan', 'Ran Wei', 'Dawei Yang', 'Zhe Jiang']",{'name': 'Zhe Jiang'},Zhe Jiang,,"[{'href': 'http://arxiv.org/abs/2502.13873v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13873v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13873v1,None,http://arxiv.org/abs/2502.13873v1,,,20,0
http://arxiv.org/abs/2502.13875v1,True,2025-02-19T16:58:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=16, tm_min=58, tm_sec=42, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T16:58:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=16, tm_min=58, tm_sec=42, tm_wday=2, tm_yday=50, tm_isdst=0)",MEX: Memory-efficient Approach to Referring Multi-Object Tracking,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'MEX: Memory-efficient Approach to Referring Multi-Object Tracking'}","Referring Multi-Object Tracking (RMOT) is a relatively new concept that has
rapidly gained traction as a promising research direction at the intersection
of computer vision and natural language processing. Unlike traditional
multi-object tracking, RMOT identifies and tracks objects and incorporates
textual descriptions for object class names, making the approach more
intuitive. Various techniques have been proposed to address this challenging
problem; however, most require the training of the entire network due to their
end-to-end nature. Among these methods, iKUN has emerged as a particularly
promising solution. Therefore, we further explore its pipeline and enhance its
performance. In this paper, we introduce a practical module dubbed
Memory-Efficient Cross-modality -- MEX. This memory-efficient technique can be
directly applied to off-the-shelf trackers like iKUN, resulting in significant
architectural improvements. Our method proves effective during inference on a
single GPU with 4 GB of memory. Among the various benchmarks, the Refer-KITTI
dataset, which offers diverse autonomous driving scenes with relevant language
expressions, is particularly useful for studying this problem. Empirically, our
method demonstrates effectiveness and efficiency regarding HOTA tracking
scores, substantially improving memory allocation and processing speed.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Referring Multi-Object Tracking (RMOT) is a relatively new concept that has\nrapidly gained traction as a promising research direction at the intersection\nof computer vision and natural language processing. Unlike traditional\nmulti-object tracking, RMOT identifies and tracks objects and incorporates\ntextual descriptions for object class names, making the approach more\nintuitive. Various techniques have been proposed to address this challenging\nproblem; however, most require the training of the entire network due to their\nend-to-end nature. Among these methods, iKUN has emerged as a particularly\npromising solution. Therefore, we further explore its pipeline and enhance its\nperformance. In this paper, we introduce a practical module dubbed\nMemory-Efficient Cross-modality -- MEX. This memory-efficient technique can be\ndirectly applied to off-the-shelf trackers like iKUN, resulting in significant\narchitectural improvements. Our method proves effective during inference on a\nsingle GPU with 4 GB of memory. Among the various benchmarks, the Refer-KITTI\ndataset, which offers diverse autonomous driving scenes with relevant language\nexpressions, is particularly useful for studying this problem. Empirically, our\nmethod demonstrates effectiveness and efficiency regarding HOTA tracking\nscores, substantially improving memory allocation and processing speed.'}","['Huu-Thien Tran', 'Phuoc-Sang Pham', 'Thai-Son Tran', 'Khoa Luu']",{'name': 'Khoa Luu'},Khoa Luu,"6 pages, 6 figures, 2024 International Conference on Advanced
  Technologies for Communications (ATC), Signal Processing Track","[{'href': 'http://arxiv.org/abs/2502.13875v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13875v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13875v1,None,http://arxiv.org/abs/2502.13875v1,,,0,0
http://arxiv.org/abs/2502.13905v1,True,2025-02-19T17:39:46Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=17, tm_min=39, tm_sec=46, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T17:39:46Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=17, tm_min=39, tm_sec=46, tm_wday=2, tm_yday=50, tm_isdst=0)","Partially Observable Gaussian Process Network and Doubly Stochastic
  Variational Inference","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Partially Observable Gaussian Process Network and Doubly Stochastic\n  Variational Inference'}","To reduce the curse of dimensionality for Gaussian processes (GP), they can
be decomposed into a Gaussian Process Network (GPN) of coupled subprocesses
with lower dimensionality. In some cases, intermediate observations are
available within the GPN. However, intermediate observations are often
indirect, noisy, and incomplete in most real-world systems. This work
introduces the Partially Observable Gaussian Process Network (POGPN) to model
real-world process networks. We model a joint distribution of latent functions
of subprocesses and make inferences using observations from all subprocesses.
POGPN incorporates observation lenses (observation likelihoods) into the
well-established inference method of deep Gaussian processes. We also introduce
two training methods for POPGN to make inferences on the whole network using
node observations. The application to benchmark problems demonstrates how
incorporating partial observations during training and inference can improve
the predictive performance of the overall network, offering a promising outlook
for its practical application.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'To reduce the curse of dimensionality for Gaussian processes (GP), they can\nbe decomposed into a Gaussian Process Network (GPN) of coupled subprocesses\nwith lower dimensionality. In some cases, intermediate observations are\navailable within the GPN. However, intermediate observations are often\nindirect, noisy, and incomplete in most real-world systems. This work\nintroduces the Partially Observable Gaussian Process Network (POGPN) to model\nreal-world process networks. We model a joint distribution of latent functions\nof subprocesses and make inferences using observations from all subprocesses.\nPOGPN incorporates observation lenses (observation likelihoods) into the\nwell-established inference method of deep Gaussian processes. We also introduce\ntwo training methods for POPGN to make inferences on the whole network using\nnode observations. The application to benchmark problems demonstrates how\nincorporating partial observations during training and inference can improve\nthe predictive performance of the overall network, offering a promising outlook\nfor its practical application.'}","['Saksham Kiroriwal', 'Julius Pfrommer', 'Jrgen Beyerer']",{'name': 'Jrgen Beyerer'},Jrgen Beyerer,"8 pages, 6 figures","[{'href': 'http://arxiv.org/abs/2502.13905v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13905v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13905v1,None,http://arxiv.org/abs/2502.13905v1,,,638,0
http://arxiv.org/abs/2502.13909v1,True,2025-02-19T17:41:09Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=17, tm_min=41, tm_sec=9, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T17:41:09Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=17, tm_min=41, tm_sec=9, tm_wday=2, tm_yday=50, tm_isdst=0)","Lost in Sequence: Do Large Language Models Understand Sequential
  Recommendation?","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Lost in Sequence: Do Large Language Models Understand Sequential\n  Recommendation?'}","Large Language Models (LLMs) have recently emerged as promising tools for
recommendation thanks to their advanced textual understanding ability and
context-awareness. Despite the current practice of training and evaluating
LLM-based recommendation (LLM4Rec) models under a sequential recommendation
scenario, we found that whether these models understand the sequential
information inherent in users' item interaction sequences has been largely
overlooked. In this paper, we first demonstrate through a series of experiments
that existing LLM4Rec models do not fully capture sequential information both
during training and inference. Then, we propose a simple yet effective
LLM-based sequential recommender, called LLM-SRec, a method that enhances the
integration of sequential information into LLMs by distilling the user
representations extracted from a pre-trained CF-SRec model into LLMs. Our
extensive experiments show that LLM-SRec enhances LLMs' ability to understand
users' item interaction sequences, ultimately leading to improved
recommendation performance. Furthermore, unlike existing LLM4Rec models that
require fine-tuning of LLMs, LLM-SRec achieves state-of-the-art performance by
training only a few lightweight MLPs, highlighting its practicality in
real-world applications. Our code is available at
https://github.com/Sein-Kim/LLM-SRec.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Large Language Models (LLMs) have recently emerged as promising tools for\nrecommendation thanks to their advanced textual understanding ability and\ncontext-awareness. Despite the current practice of training and evaluating\nLLM-based recommendation (LLM4Rec) models under a sequential recommendation\nscenario, we found that whether these models understand the sequential\ninformation inherent in users' item interaction sequences has been largely\noverlooked. In this paper, we first demonstrate through a series of experiments\nthat existing LLM4Rec models do not fully capture sequential information both\nduring training and inference. Then, we propose a simple yet effective\nLLM-based sequential recommender, called LLM-SRec, a method that enhances the\nintegration of sequential information into LLMs by distilling the user\nrepresentations extracted from a pre-trained CF-SRec model into LLMs. Our\nextensive experiments show that LLM-SRec enhances LLMs' ability to understand\nusers' item interaction sequences, ultimately leading to improved\nrecommendation performance. Furthermore, unlike existing LLM4Rec models that\nrequire fine-tuning of LLMs, LLM-SRec achieves state-of-the-art performance by\ntraining only a few lightweight MLPs, highlighting its practicality in\nreal-world applications. Our code is available at\nhttps://github.com/Sein-Kim/LLM-SRec.""}","['Sein Kim', 'Hongseok Kang', 'Kibum Kim', 'Jiwan Kim', 'Donghyun Kim', 'Minchul Yang', 'Kwangjin Oh', 'Julian McAuley', 'Chanyoung Park']",{'name': 'Chanyoung Park'},Chanyoung Park,Under Review,"[{'href': 'http://arxiv.org/abs/2502.13909v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13909v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13909v1,None,http://arxiv.org/abs/2502.13909v1,,,1542,0
http://arxiv.org/abs/2502.13913v1,True,2025-02-19T17:46:30Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=17, tm_min=46, tm_sec=30, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T17:46:30Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=17, tm_min=46, tm_sec=30, tm_wday=2, tm_yday=50, tm_isdst=0)",How Do LLMs Perform Two-Hop Reasoning in Context?,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'How Do LLMs Perform Two-Hop Reasoning in Context?'}","""Socrates is human. All humans are mortal. Therefore, Socrates is mortal.""
This classical example demonstrates two-hop reasoning, where a conclusion
logically follows from two connected premises. While transformer-based Large
Language Models (LLMs) can make two-hop reasoning, they tend to collapse to
random guessing when faced with distracting premises. To understand the
underlying mechanism, we train a three-layer transformer on synthetic two-hop
reasoning tasks. The training dynamics show two stages: a slow learning phase,
where the 3-layer transformer performs random guessing like LLMs, followed by
an abrupt phase transitions, where the 3-layer transformer suddenly reaches
$100%$ accuracy. Through reverse engineering, we explain the inner mechanisms
for how models learn to randomly guess between distractions initially, and how
they learn to ignore distractions eventually. We further propose a
three-parameter model that supports the causal claims for the mechanisms to the
training dynamics of the transformer. Finally, experiments on LLMs suggest that
the discovered mechanisms generalize across scales. Our methodologies provide
new perspectives for scientific understandings of LLMs and our findings provide
new insights into how reasoning emerges during training.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': '""Socrates is human. All humans are mortal. Therefore, Socrates is mortal.""\nThis classical example demonstrates two-hop reasoning, where a conclusion\nlogically follows from two connected premises. While transformer-based Large\nLanguage Models (LLMs) can make two-hop reasoning, they tend to collapse to\nrandom guessing when faced with distracting premises. To understand the\nunderlying mechanism, we train a three-layer transformer on synthetic two-hop\nreasoning tasks. The training dynamics show two stages: a slow learning phase,\nwhere the 3-layer transformer performs random guessing like LLMs, followed by\nan abrupt phase transitions, where the 3-layer transformer suddenly reaches\n$100%$ accuracy. Through reverse engineering, we explain the inner mechanisms\nfor how models learn to randomly guess between distractions initially, and how\nthey learn to ignore distractions eventually. We further propose a\nthree-parameter model that supports the causal claims for the mechanisms to the\ntraining dynamics of the transformer. Finally, experiments on LLMs suggest that\nthe discovered mechanisms generalize across scales. Our methodologies provide\nnew perspectives for scientific understandings of LLMs and our findings provide\nnew insights into how reasoning emerges during training.'}","['Tianyu Guo', 'Hanlin Zhu', 'Ruiqi Zhang', 'Jiantao Jiao', 'Song Mei', 'Michael I. Jordan', 'Stuart Russell']",{'name': 'Stuart Russell'},Stuart Russell,,"[{'href': 'http://arxiv.org/abs/2502.13913v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13913v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13913v1,None,http://arxiv.org/abs/2502.13913v1,,,306,0
http://arxiv.org/abs/2502.13957v1,True,2025-02-19T18:56:03Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=18, tm_min=56, tm_sec=3, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T18:56:03Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=18, tm_min=56, tm_sec=3, tm_wday=2, tm_yday=50, tm_isdst=0)",RAG-Gym: Optimizing Reasoning and Search Agents with Process Supervision,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'RAG-Gym: Optimizing Reasoning and Search Agents with Process Supervision'}","Retrieval-augmented generation (RAG) has shown great potential for
knowledge-intensive tasks, but its traditional architectures rely on static
retrieval, limiting their effectiveness for complex questions that require
sequential information-seeking. While agentic reasoning and search offer a more
adaptive approach, most existing methods depend heavily on prompt engineering.
In this work, we introduce RAG-Gym, a unified optimization framework that
enhances information-seeking agents through fine-grained process supervision at
each search step. We also propose ReSearch, a novel agent architecture that
synergizes answer reasoning and search query generation within the RAG-Gym
framework. Experiments on four challenging datasets show that RAG-Gym improves
performance by up to 25.6\% across various agent architectures, with ReSearch
consistently outperforming existing baselines. Further analysis highlights the
effectiveness of advanced LLMs as process reward judges and the transferability
of trained reward models as verifiers for different LLMs. Additionally, we
examine the scaling properties of training and inference in agentic RAG. The
project homepage is available at https://rag-gym.github.io/.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Retrieval-augmented generation (RAG) has shown great potential for\nknowledge-intensive tasks, but its traditional architectures rely on static\nretrieval, limiting their effectiveness for complex questions that require\nsequential information-seeking. While agentic reasoning and search offer a more\nadaptive approach, most existing methods depend heavily on prompt engineering.\nIn this work, we introduce RAG-Gym, a unified optimization framework that\nenhances information-seeking agents through fine-grained process supervision at\neach search step. We also propose ReSearch, a novel agent architecture that\nsynergizes answer reasoning and search query generation within the RAG-Gym\nframework. Experiments on four challenging datasets show that RAG-Gym improves\nperformance by up to 25.6\\% across various agent architectures, with ReSearch\nconsistently outperforming existing baselines. Further analysis highlights the\neffectiveness of advanced LLMs as process reward judges and the transferability\nof trained reward models as verifiers for different LLMs. Additionally, we\nexamine the scaling properties of training and inference in agentic RAG. The\nproject homepage is available at https://rag-gym.github.io/.'}","['Guangzhi Xiong', 'Qiao Jin', 'Xiao Wang', 'Yin Fang', 'Haolin Liu', 'Yifan Yang', 'Fangyuan Chen', 'Zhixing Song', 'Dengyu Wang', 'Minjia Zhang', 'Zhiyong Lu', 'Aidong Zhang']",{'name': 'Aidong Zhang'},Aidong Zhang,,"[{'href': 'http://arxiv.org/abs/2502.13957v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13957v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13957v1,None,http://arxiv.org/abs/2502.13957v1,,,499,0
http://arxiv.org/abs/2502.13983v1,True,2025-02-18T14:15:55Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=14, tm_min=15, tm_sec=55, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T14:15:55Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=14, tm_min=15, tm_sec=55, tm_wday=1, tm_yday=49, tm_isdst=0)","Gesture-Aware Zero-Shot Speech Recognition for Patients with Language
  Disorders","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Gesture-Aware Zero-Shot Speech Recognition for Patients with Language\n  Disorders'}","Individuals with language disorders often face significant communication
challenges due to their limited language processing and comprehension
abilities, which also affect their interactions with voice-assisted systems
that mostly rely on Automatic Speech Recognition (ASR). Despite advancements in
ASR that address disfluencies, there has been little attention on integrating
non-verbal communication methods, such as gestures, which individuals with
language disorders substantially rely on to supplement their communication.
Recognizing the need to interpret the latent meanings of visual information not
captured by speech alone, we propose a gesture-aware ASR system utilizing a
multimodal large language model with zero-shot learning for individuals with
speech impairments. Our experiment results and analyses show that including
gesture information significantly enhances semantic understanding. This study
can help develop effective communication technologies, specifically designed to
meet the unique needs of individuals with language impairments.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Individuals with language disorders often face significant communication\nchallenges due to their limited language processing and comprehension\nabilities, which also affect their interactions with voice-assisted systems\nthat mostly rely on Automatic Speech Recognition (ASR). Despite advancements in\nASR that address disfluencies, there has been little attention on integrating\nnon-verbal communication methods, such as gestures, which individuals with\nlanguage disorders substantially rely on to supplement their communication.\nRecognizing the need to interpret the latent meanings of visual information not\ncaptured by speech alone, we propose a gesture-aware ASR system utilizing a\nmultimodal large language model with zero-shot learning for individuals with\nspeech impairments. Our experiment results and analyses show that including\ngesture information significantly enhances semantic understanding. This study\ncan help develop effective communication technologies, specifically designed to\nmeet the unique needs of individuals with language impairments.'}","['Seungbae Kim', 'Daeun Lee', 'Brielle Stark', 'Jinyoung Han']",{'name': 'Jinyoung Han'},Jinyoung Han,,"[{'href': 'http://arxiv.org/abs/2502.13983v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13983v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'eess.AS', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'eess.AS', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13983v1,None,http://arxiv.org/abs/2502.13983v1,,,350,0
http://arxiv.org/abs/2502.13991v1,True,2025-02-19T03:25:49Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=3, tm_min=25, tm_sec=49, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T03:25:49Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=3, tm_min=25, tm_sec=49, tm_wday=2, tm_yday=50, tm_isdst=0)",Learning to Discover Regulatory Elements for Gene Expression Prediction,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Learning to Discover Regulatory Elements for Gene Expression Prediction'}","We consider the problem of predicting gene expressions from DNA sequences. A
key challenge of this task is to find the regulatory elements that control gene
expressions. Here, we introduce Seq2Exp, a Sequence to Expression network
explicitly designed to discover and extract regulatory elements that drive
target gene expression, enhancing the accuracy of the gene expression
prediction. Our approach captures the causal relationship between epigenomic
signals, DNA sequences and their associated regulatory elements. Specifically,
we propose to decompose the epigenomic signals and the DNA sequence conditioned
on the causal active regulatory elements, and apply an information bottleneck
with the Beta distribution to combine their effects while filtering out
non-causal components. Our experiments demonstrate that Seq2Exp outperforms
existing baselines in gene expression prediction tasks and discovers
influential regions compared to commonly used statistical methods for peak
detection such as MACS3. The source code is released as part of the AIRS
library (https://github.com/divelab/AIRS/).","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'We consider the problem of predicting gene expressions from DNA sequences. A\nkey challenge of this task is to find the regulatory elements that control gene\nexpressions. Here, we introduce Seq2Exp, a Sequence to Expression network\nexplicitly designed to discover and extract regulatory elements that drive\ntarget gene expression, enhancing the accuracy of the gene expression\nprediction. Our approach captures the causal relationship between epigenomic\nsignals, DNA sequences and their associated regulatory elements. Specifically,\nwe propose to decompose the epigenomic signals and the DNA sequence conditioned\non the causal active regulatory elements, and apply an information bottleneck\nwith the Beta distribution to combine their effects while filtering out\nnon-causal components. Our experiments demonstrate that Seq2Exp outperforms\nexisting baselines in gene expression prediction tasks and discovers\ninfluential regions compared to commonly used statistical methods for peak\ndetection such as MACS3. The source code is released as part of the AIRS\nlibrary (https://github.com/divelab/AIRS/).'}","['Xingyu Su', 'Haiyang Yu', 'Degui Zhi', 'Shuiwang Ji']",{'name': 'Shuiwang Ji'},Shuiwang Ji,,"[{'href': 'http://arxiv.org/abs/2502.13991v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13991v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'q-bio.GN', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'q-bio.GN', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13991v1,None,http://arxiv.org/abs/2502.13991v1,,,0,0
http://arxiv.org/abs/2502.13994v1,True,2025-02-19T06:39:51Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=6, tm_min=39, tm_sec=51, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T06:39:51Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=6, tm_min=39, tm_sec=51, tm_wday=2, tm_yday=50, tm_isdst=0)",Generative Detail Enhancement for Physically Based Materials,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Generative Detail Enhancement for Physically Based Materials'}","We present a tool for enhancing the detail of physically based materials
using an off-the-shelf diffusion model and inverse rendering. Our goal is to
enhance the visual fidelity of materials with detail that is often tedious to
author, by adding signs of wear, aging, weathering, etc. As these appearance
details are often rooted in real-world processes, we leverage a generative
image model trained on a large dataset of natural images with corresponding
visuals in context. Starting with a given geometry, UV mapping, and basic
appearance, we render multiple views of the object. We use these views,
together with an appearance-defining text prompt, to condition a diffusion
model. The details it generates are then backpropagated from the enhanced
images to the material parameters via inverse differentiable rendering. For
inverse rendering to be successful, the generated appearance has to be
consistent across all the images. We propose two priors to address the
multi-view consistency of the diffusion model. First, we ensure that the
initial noise that seeds the diffusion process is itself consistent across
views by integrating it from a view-independent UV space. Second, we enforce
geometric consistency by biasing the attention mechanism via a projective
constraint so that pixels attend strongly to their corresponding pixel
locations in other views. Our approach does not require any training or
finetuning of the diffusion model, is agnostic of the material model used, and
the enhanced material properties, i.e., 2D PBR textures, can be further edited
by artists.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'We present a tool for enhancing the detail of physically based materials\nusing an off-the-shelf diffusion model and inverse rendering. Our goal is to\nenhance the visual fidelity of materials with detail that is often tedious to\nauthor, by adding signs of wear, aging, weathering, etc. As these appearance\ndetails are often rooted in real-world processes, we leverage a generative\nimage model trained on a large dataset of natural images with corresponding\nvisuals in context. Starting with a given geometry, UV mapping, and basic\nappearance, we render multiple views of the object. We use these views,\ntogether with an appearance-defining text prompt, to condition a diffusion\nmodel. The details it generates are then backpropagated from the enhanced\nimages to the material parameters via inverse differentiable rendering. For\ninverse rendering to be successful, the generated appearance has to be\nconsistent across all the images. We propose two priors to address the\nmulti-view consistency of the diffusion model. First, we ensure that the\ninitial noise that seeds the diffusion process is itself consistent across\nviews by integrating it from a view-independent UV space. Second, we enforce\ngeometric consistency by biasing the attention mechanism via a projective\nconstraint so that pixels attend strongly to their corresponding pixel\nlocations in other views. Our approach does not require any training or\nfinetuning of the diffusion model, is agnostic of the material model used, and\nthe enhanced material properties, i.e., 2D PBR textures, can be further edited\nby artists.'}","['Saeed Hadadan', 'Benedikt Bitterli', 'Tizian Zeltner', 'Jan Novk', 'Fabrice Rousselle', 'Jacob Munkberg', 'Jon Hasselgren', 'Bartlomiej Wronski', 'Matthias Zwicker']",{'name': 'Matthias Zwicker'},Matthias Zwicker,,"[{'href': 'http://arxiv.org/abs/2502.13994v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13994v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.GR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.GR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13994v1,None,http://arxiv.org/abs/2502.13994v1,,,8850,0
http://arxiv.org/abs/2502.13998v1,True,2025-02-19T07:30:19Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=7, tm_min=30, tm_sec=19, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T07:30:19Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=7, tm_min=30, tm_sec=19, tm_wday=2, tm_yday=50, tm_isdst=0)","A Baseline Method for Removing Invisible Image Watermarks using Deep
  Image Prior","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A Baseline Method for Removing Invisible Image Watermarks using Deep\n  Image Prior'}","Image watermarks have been considered a promising technique to help detect
AI-generated content, which can be used to protect copyright or prevent fake
image abuse. In this work, we present a black-box method for removing invisible
image watermarks, without the need of any dataset of watermarked images or any
knowledge about the watermark system. Our approach is simple to implement:
given a single watermarked image, we regress it by deep image prior (DIP). We
show that from the intermediate steps of DIP one can reliably find an evasion
image that can remove invisible watermarks while preserving high image quality.
Due to its unique working mechanism and practical effectiveness, we advocate
including DIP as a baseline invasion method for benchmarking the robustness of
watermarking systems. Finally, by showing the limited ability of DIP and other
existing black-box methods in evading training-based visible watermarks, we
discuss the positive implications on the practical use of training-based
visible watermarks to prevent misinformation abuse.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Image watermarks have been considered a promising technique to help detect\nAI-generated content, which can be used to protect copyright or prevent fake\nimage abuse. In this work, we present a black-box method for removing invisible\nimage watermarks, without the need of any dataset of watermarked images or any\nknowledge about the watermark system. Our approach is simple to implement:\ngiven a single watermarked image, we regress it by deep image prior (DIP). We\nshow that from the intermediate steps of DIP one can reliably find an evasion\nimage that can remove invisible watermarks while preserving high image quality.\nDue to its unique working mechanism and practical effectiveness, we advocate\nincluding DIP as a baseline invasion method for benchmarking the robustness of\nwatermarking systems. Finally, by showing the limited ability of DIP and other\nexisting black-box methods in evading training-based visible watermarks, we\ndiscuss the positive implications on the practical use of training-based\nvisible watermarks to prevent misinformation abuse.'}","['Hengyue Liang', 'Taihui Li', 'Ju Sun']",{'name': 'Ju Sun'},Ju Sun,,"[{'href': 'http://arxiv.org/abs/2502.13998v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13998v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'eess.IV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'eess.IV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13998v1,None,http://arxiv.org/abs/2502.13998v1,,,0,0
http://arxiv.org/abs/2502.14003v1,True,2025-02-19T09:50:22Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=9, tm_min=50, tm_sec=22, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T09:50:22Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=9, tm_min=50, tm_sec=22, tm_wday=2, tm_yday=50, tm_isdst=0)","Rectified Lagrangian for Out-of-Distribution Detection in Modern
  Hopfield Networks","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Rectified Lagrangian for Out-of-Distribution Detection in Modern\n  Hopfield Networks'}","Modern Hopfield networks (MHNs) have recently gained significant attention in
the field of artificial intelligence because they can store and retrieve a
large set of patterns with an exponentially large memory capacity. A MHN is
generally a dynamical system defined with Lagrangians of memory and feature
neurons, where memories associated with in-distribution (ID) samples are
represented by attractors in the feature space. One major problem in existing
MHNs lies in managing out-of-distribution (OOD) samples because it was
originally assumed that all samples are ID samples. To address this, we propose
the rectified Lagrangian (RegLag), a new Lagrangian for memory neurons that
explicitly incorporates an attractor for OOD samples in the dynamical system of
MHNs. RecLag creates a trivial point attractor for any interaction matrix,
enabling OOD detection by identifying samples that fall into this attractor as
OOD. The interaction matrix is optimized so that the probability densities can
be estimated to identify ID/OOD. We demonstrate the effectiveness of
RecLag-based MHNs compared to energy-based OOD detection methods, including
those using state-of-the-art Hopfield energies, across nine image datasets.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Modern Hopfield networks (MHNs) have recently gained significant attention in\nthe field of artificial intelligence because they can store and retrieve a\nlarge set of patterns with an exponentially large memory capacity. A MHN is\ngenerally a dynamical system defined with Lagrangians of memory and feature\nneurons, where memories associated with in-distribution (ID) samples are\nrepresented by attractors in the feature space. One major problem in existing\nMHNs lies in managing out-of-distribution (OOD) samples because it was\noriginally assumed that all samples are ID samples. To address this, we propose\nthe rectified Lagrangian (RegLag), a new Lagrangian for memory neurons that\nexplicitly incorporates an attractor for OOD samples in the dynamical system of\nMHNs. RecLag creates a trivial point attractor for any interaction matrix,\nenabling OOD detection by identifying samples that fall into this attractor as\nOOD. The interaction matrix is optimized so that the probability densities can\nbe estimated to identify ID/OOD. We demonstrate the effectiveness of\nRecLag-based MHNs compared to energy-based OOD detection methods, including\nthose using state-of-the-art Hopfield energies, across nine image datasets.'}","['Ryo Moriai', 'Nakamasa Inoue', 'Masayuki Tanaka', 'Rei Kawakami', 'Satoshi Ikehata', 'Ikuro Sato']",{'name': 'Ikuro Sato'},Ikuro Sato,Accepted to AAAI 2025,"[{'href': 'http://arxiv.org/abs/2502.14003v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14003v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14003v1,None,http://arxiv.org/abs/2502.14003v1,,,75,0
http://arxiv.org/abs/2502.14043v1,True,2025-02-19T19:01:39Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=19, tm_min=1, tm_sec=39, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T19:01:39Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=19, tm_min=1, tm_sec=39, tm_wday=2, tm_yday=50, tm_isdst=0)","Asking for Help Enables Safety Guarantees Without Sacrificing
  Effectiveness","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Asking for Help Enables Safety Guarantees Without Sacrificing\n  Effectiveness'}","Most reinforcement learning algorithms with regret guarantees rely on a
critical assumption: that all errors are recoverable. Recent work by Plaut et
al. discarded this assumption and presented algorithms that avoid ""catastrophe""
(i.e., irreparable errors) by asking for help. However, they provided only
safety guarantees and did not consider reward maximization. We prove that any
algorithm that avoids catastrophe in their setting also guarantees high reward
(i.e., sublinear regret) in any Markov Decision Process (MDP), including MDPs
with irreversible costs. This constitutes the first no-regret guarantee for
general MDPs. More broadly, our result may be the first formal proof that it is
possible for an agent to obtain high reward while becoming self-sufficient in
an unknown, unbounded, and high-stakes environment without causing catastrophe
or requiring resets.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Most reinforcement learning algorithms with regret guarantees rely on a\ncritical assumption: that all errors are recoverable. Recent work by Plaut et\nal. discarded this assumption and presented algorithms that avoid ""catastrophe""\n(i.e., irreparable errors) by asking for help. However, they provided only\nsafety guarantees and did not consider reward maximization. We prove that any\nalgorithm that avoids catastrophe in their setting also guarantees high reward\n(i.e., sublinear regret) in any Markov Decision Process (MDP), including MDPs\nwith irreversible costs. This constitutes the first no-regret guarantee for\ngeneral MDPs. More broadly, our result may be the first formal proof that it is\npossible for an agent to obtain high reward while becoming self-sufficient in\nan unknown, unbounded, and high-stakes environment without causing catastrophe\nor requiring resets.'}","['Benjamin Plaut', 'Juan Livano-Karim', 'Stuart Russell']",{'name': 'Stuart Russell'},Stuart Russell,,"[{'href': 'http://arxiv.org/abs/2502.14043v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14043v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14043v1,None,http://arxiv.org/abs/2502.14043v1,,,0,0
http://arxiv.org/abs/2502.14045v1,True,2025-02-19T19:08:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=19, tm_min=8, tm_sec=37, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T19:08:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=19, tm_min=8, tm_sec=37, tm_wday=2, tm_yday=50, tm_isdst=0)",Position: There are no Champions in Long-Term Time Series Forecasting,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Position: There are no Champions in Long-Term Time Series Forecasting'}","Recent advances in long-term time series forecasting have introduced numerous
complex prediction models that consistently outperform previously published
architectures. However, this rapid progression raises concerns regarding
inconsistent benchmarking and reporting practices, which may undermine the
reliability of these comparisons. Our position emphasizes the need to shift
focus away from pursuing ever-more complex models and towards enhancing
benchmarking practices through rigorous and standardized evaluation methods. To
support our claim, we first perform a broad, thorough, and reproducible
evaluation of the top-performing models on the most popular benchmark by
training 3,500+ networks over 14 datasets. Then, through a comprehensive
analysis, we find that slight changes to experimental setups or current
evaluation metrics drastically shift the common belief that newly published
results are advancing the state of the art. Our findings suggest the need for
rigorous and standardized evaluation methods that enable more substantiated
claims, including reproducible hyperparameter setups and statistical testing.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Recent advances in long-term time series forecasting have introduced numerous\ncomplex prediction models that consistently outperform previously published\narchitectures. However, this rapid progression raises concerns regarding\ninconsistent benchmarking and reporting practices, which may undermine the\nreliability of these comparisons. Our position emphasizes the need to shift\nfocus away from pursuing ever-more complex models and towards enhancing\nbenchmarking practices through rigorous and standardized evaluation methods. To\nsupport our claim, we first perform a broad, thorough, and reproducible\nevaluation of the top-performing models on the most popular benchmark by\ntraining 3,500+ networks over 14 datasets. Then, through a comprehensive\nanalysis, we find that slight changes to experimental setups or current\nevaluation metrics drastically shift the common belief that newly published\nresults are advancing the state of the art. Our findings suggest the need for\nrigorous and standardized evaluation methods that enable more substantiated\nclaims, including reproducible hyperparameter setups and statistical testing.'}","['Lorenzo Brigato', 'Rafael Morand', 'Knut Strmmen', 'Maria Panagiotou', 'Markus Schmidt', 'Stavroula Mougiakakou']",{'name': 'Stavroula Mougiakakou'},Stavroula Mougiakakou,Pre-print,"[{'href': 'http://arxiv.org/abs/2502.14045v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14045v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14045v1,None,http://arxiv.org/abs/2502.14045v1,,,15,0
http://arxiv.org/abs/2502.14064v1,True,2025-02-19T19:31:52Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=19, tm_min=31, tm_sec=52, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T19:31:52Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=19, tm_min=31, tm_sec=52, tm_wday=2, tm_yday=50, tm_isdst=0)",Triad: Vision Foundation Model for 3D Magnetic Resonance Imaging,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Triad: Vision Foundation Model for 3D Magnetic Resonance Imaging'}","Vision foundation models (VFMs) are pre-trained on extensive image datasets
to learn general representations for diverse types of data. These models can
subsequently be fine-tuned for specific downstream tasks, significantly
boosting performance across a broad range of applications. However, existing
vision foundation models that claim to be applicable to various radiology tasks
are mostly pre-trained on 3D computed tomography (CT), which benefits from the
availability of extensive 3D CT databases. Significant differences between CT
and magnetic resonance imaging (MRI) in imaging principles, signal
characteristics, and data distribution may hinder their practical performance
and versatility in MRI-specific applications. Here, we propose Triad, a vision
foundation model for 3D MRI. Triad adopts a widely used autoencoder
architecture to learn robust representations from 131,170 3D MRI volumes and
uses organ-independent imaging descriptions to constrain the semantic
distribution of the visual modality. The above pre-training dataset is called
Triad-131K, which is currently the largest 3D MRI pre-training dataset. We
evaluate Triad across three tasks, namely, organ/tumor segmentation,
organ/cancer classification, and medical image registration, in two data
modalities (within-domain and out-of-domain) settings using 25 downstream
datasets. By initializing models with Triad's pre-trained weights, nnUNet-Triad
improves segmentation performance by 6.88% compared to nnUNet-Scratch across 17
datasets. Swin-B-Triad achieves a 3.97% improvement over Swin-B-Scratch in
classification tasks across five datasets. SwinUNETR-Triad improves by 4.00%
compared to SwinUNETR-Scratch in registration tasks across two datasets. Our
study demonstrates that pre-training can maximize performance when the data
modalities and organs of upstream and downstream tasks are consistent.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Vision foundation models (VFMs) are pre-trained on extensive image datasets\nto learn general representations for diverse types of data. These models can\nsubsequently be fine-tuned for specific downstream tasks, significantly\nboosting performance across a broad range of applications. However, existing\nvision foundation models that claim to be applicable to various radiology tasks\nare mostly pre-trained on 3D computed tomography (CT), which benefits from the\navailability of extensive 3D CT databases. Significant differences between CT\nand magnetic resonance imaging (MRI) in imaging principles, signal\ncharacteristics, and data distribution may hinder their practical performance\nand versatility in MRI-specific applications. Here, we propose Triad, a vision\nfoundation model for 3D MRI. Triad adopts a widely used autoencoder\narchitecture to learn robust representations from 131,170 3D MRI volumes and\nuses organ-independent imaging descriptions to constrain the semantic\ndistribution of the visual modality. The above pre-training dataset is called\nTriad-131K, which is currently the largest 3D MRI pre-training dataset. We\nevaluate Triad across three tasks, namely, organ/tumor segmentation,\norgan/cancer classification, and medical image registration, in two data\nmodalities (within-domain and out-of-domain) settings using 25 downstream\ndatasets. By initializing models with Triad's pre-trained weights, nnUNet-Triad\nimproves segmentation performance by 6.88% compared to nnUNet-Scratch across 17\ndatasets. Swin-B-Triad achieves a 3.97% improvement over Swin-B-Scratch in\nclassification tasks across five datasets. SwinUNETR-Triad improves by 4.00%\ncompared to SwinUNETR-Scratch in registration tasks across two datasets. Our\nstudy demonstrates that pre-training can maximize performance when the data\nmodalities and organs of upstream and downstream tasks are consistent.""}","['Shansong Wang', 'Mojtaba Safari', 'Qiang Li', 'Chih-Wei Chang', 'Richard LJ Qiu', 'Justin Roper', 'David S. Yu', 'Xiaofeng Yang']",{'name': 'Xiaofeng Yang'},Xiaofeng Yang,,"[{'href': 'http://arxiv.org/abs/2502.14064v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14064v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14064v1,None,http://arxiv.org/abs/2502.14064v1,,,55,0
http://arxiv.org/abs/2502.14070v1,True,2025-02-19T19:47:58Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=19, tm_min=47, tm_sec=58, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T19:47:58Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=19, tm_min=47, tm_sec=58, tm_wday=2, tm_yday=50, tm_isdst=0)","DiffExp: Efficient Exploration in Reward Fine-tuning for Text-to-Image
  Diffusion Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'DiffExp: Efficient Exploration in Reward Fine-tuning for Text-to-Image\n  Diffusion Models'}","Fine-tuning text-to-image diffusion models to maximize rewards has proven
effective for enhancing model performance. However, reward fine-tuning methods
often suffer from slow convergence due to online sample generation. Therefore,
obtaining diverse samples with strong reward signals is crucial for improving
sample efficiency and overall performance. In this work, we introduce DiffExp,
a simple yet effective exploration strategy for reward fine-tuning of
text-to-image models. Our approach employs two key strategies: (a) dynamically
adjusting the scale of classifier-free guidance to enhance sample diversity,
and (b) randomly weighting phrases of the text prompt to exploit high-quality
reward signals. We demonstrate that these strategies significantly enhance
exploration during online sample generation, improving the sample efficiency of
recent reward fine-tuning methods, such as DDPO and AlignProp.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Fine-tuning text-to-image diffusion models to maximize rewards has proven\neffective for enhancing model performance. However, reward fine-tuning methods\noften suffer from slow convergence due to online sample generation. Therefore,\nobtaining diverse samples with strong reward signals is crucial for improving\nsample efficiency and overall performance. In this work, we introduce DiffExp,\na simple yet effective exploration strategy for reward fine-tuning of\ntext-to-image models. Our approach employs two key strategies: (a) dynamically\nadjusting the scale of classifier-free guidance to enhance sample diversity,\nand (b) randomly weighting phrases of the text prompt to exploit high-quality\nreward signals. We demonstrate that these strategies significantly enhance\nexploration during online sample generation, improving the sample efficiency of\nrecent reward fine-tuning methods, such as DDPO and AlignProp.'}","['Daewon Chae', 'June Suk Choi', 'Jinkyu Kim', 'Kimin Lee']",{'name': 'Kimin Lee'},Kimin Lee,AAAI 2025,"[{'href': 'http://arxiv.org/abs/2502.14070v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14070v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14070v1,None,http://arxiv.org/abs/2502.14070v1,,,25,0
http://arxiv.org/abs/2502.14080v1,True,2025-02-19T20:11:19Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=20, tm_min=11, tm_sec=19, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T20:11:19Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=20, tm_min=11, tm_sec=19, tm_wday=2, tm_yday=50, tm_isdst=0)","Personalized Education with Generative AI and Digital Twins: VR, RAG,
  and Zero-Shot Sentiment Analysis for Industry 4.0 Workforce Development","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Personalized Education with Generative AI and Digital Twins: VR, RAG,\n  and Zero-Shot Sentiment Analysis for Industry 4.0 Workforce Development'}","The Fourth Industrial Revolution (4IR) technologies, such as cloud computing,
machine learning, and AI, have improved productivity but introduced challenges
in workforce training and reskilling. This is critical given existing workforce
shortages, especially in marginalized communities like Underrepresented
Minorities (URM), who often lack access to quality education. Addressing these
challenges, this research presents gAI-PT4I4, a Generative AI-based
Personalized Tutor for Industrial 4.0, designed to personalize 4IR experiential
learning. gAI-PT4I4 employs sentiment analysis to assess student comprehension,
leveraging generative AI and finite automaton to tailor learning experiences.
The framework integrates low-fidelity Digital Twins for VR-based training,
featuring an Interactive Tutor - a generative AI assistant providing real-time
guidance via audio and text. It uses zero-shot sentiment analysis with LLMs and
prompt engineering, achieving 86\% accuracy in classifying student-teacher
interactions as positive or negative. Additionally, retrieval-augmented
generation (RAG) enables personalized learning content grounded in
domain-specific knowledge. To adapt training dynamically, finite automaton
structures exercises into states of increasing difficulty, requiring 80\%
task-performance accuracy for progression. Experimental evaluation with 22
volunteers showed improved accuracy exceeding 80\%, reducing training time.
Finally, this paper introduces a Multi-Fidelity Digital Twin model, aligning
Digital Twin complexity with Bloom's Taxonomy and Kirkpatrick's model,
providing a scalable educational framework.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""The Fourth Industrial Revolution (4IR) technologies, such as cloud computing,\nmachine learning, and AI, have improved productivity but introduced challenges\nin workforce training and reskilling. This is critical given existing workforce\nshortages, especially in marginalized communities like Underrepresented\nMinorities (URM), who often lack access to quality education. Addressing these\nchallenges, this research presents gAI-PT4I4, a Generative AI-based\nPersonalized Tutor for Industrial 4.0, designed to personalize 4IR experiential\nlearning. gAI-PT4I4 employs sentiment analysis to assess student comprehension,\nleveraging generative AI and finite automaton to tailor learning experiences.\nThe framework integrates low-fidelity Digital Twins for VR-based training,\nfeaturing an Interactive Tutor - a generative AI assistant providing real-time\nguidance via audio and text. It uses zero-shot sentiment analysis with LLMs and\nprompt engineering, achieving 86\\% accuracy in classifying student-teacher\ninteractions as positive or negative. Additionally, retrieval-augmented\ngeneration (RAG) enables personalized learning content grounded in\ndomain-specific knowledge. To adapt training dynamically, finite automaton\nstructures exercises into states of increasing difficulty, requiring 80\\%\ntask-performance accuracy for progression. Experimental evaluation with 22\nvolunteers showed improved accuracy exceeding 80\\%, reducing training time.\nFinally, this paper introduces a Multi-Fidelity Digital Twin model, aligning\nDigital Twin complexity with Bloom's Taxonomy and Kirkpatrick's model,\nproviding a scalable educational framework.""}","['Yu-Zheng Lin', 'Karan Petal', 'Ahmed H Alhamadah', 'Sujan Ghimire', 'Matthew William Redondo', 'David Rafael Vidal Corona', 'Jesus Pacheco', 'Soheil Salehi', 'Pratik Satam']",{'name': 'Pratik Satam'},Pratik Satam,,"[{'href': 'http://arxiv.org/abs/2502.14080v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14080v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14080v1,None,http://arxiv.org/abs/2502.14080v1,,,466,0
http://arxiv.org/abs/2502.14086v1,True,2025-02-19T20:20:24Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=20, tm_min=20, tm_sec=24, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T20:20:24Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=20, tm_min=20, tm_sec=24, tm_wday=2, tm_yday=50, tm_isdst=0)","Navigating Semantic Relations: Challenges for Language Models in
  Abstract Common-Sense Reasoning","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Navigating Semantic Relations: Challenges for Language Models in\n  Abstract Common-Sense Reasoning'}","Large language models (LLMs) have achieved remarkable performance in
generating human-like text and solving reasoning tasks of moderate complexity,
such as question-answering and mathematical problem-solving. However, their
capabilities in tasks requiring deeper cognitive skills, such as common-sense
understanding and abstract reasoning, remain under-explored. In this paper, we
systematically evaluate abstract common-sense reasoning in LLMs using the
ConceptNet knowledge graph. We propose two prompting approaches: instruct
prompting, where models predict plausible semantic relationships based on
provided definitions, and few-shot prompting, where models identify relations
using examples as guidance. Our experiments with the gpt-4o-mini model show
that in instruct prompting, consistent performance is obtained when ranking
multiple relations but with substantial decline when the model is restricted to
predicting only one relation. In few-shot prompting, the model's accuracy
improves significantly when selecting from five relations rather than the full
set, although with notable bias toward certain relations. These results suggest
significant gaps still, even in commercially used LLMs' abstract common-sense
reasoning abilities, compared to human-level understanding. However, the
findings also highlight the promise of careful prompt engineering, based on
selective retrieval, for obtaining better performance.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Large language models (LLMs) have achieved remarkable performance in\ngenerating human-like text and solving reasoning tasks of moderate complexity,\nsuch as question-answering and mathematical problem-solving. However, their\ncapabilities in tasks requiring deeper cognitive skills, such as common-sense\nunderstanding and abstract reasoning, remain under-explored. In this paper, we\nsystematically evaluate abstract common-sense reasoning in LLMs using the\nConceptNet knowledge graph. We propose two prompting approaches: instruct\nprompting, where models predict plausible semantic relationships based on\nprovided definitions, and few-shot prompting, where models identify relations\nusing examples as guidance. Our experiments with the gpt-4o-mini model show\nthat in instruct prompting, consistent performance is obtained when ranking\nmultiple relations but with substantial decline when the model is restricted to\npredicting only one relation. In few-shot prompting, the model's accuracy\nimproves significantly when selecting from five relations rather than the full\nset, although with notable bias toward certain relations. These results suggest\nsignificant gaps still, even in commercially used LLMs' abstract common-sense\nreasoning abilities, compared to human-level understanding. However, the\nfindings also highlight the promise of careful prompt engineering, based on\nselective retrieval, for obtaining better performance.""}","['Cole Gawin', 'Yidan Sun', 'Mayank Kejriwal']",{'name': 'Mayank Kejriwal'},Mayank Kejriwal,"5 pages, 3 figures, ACM Web Conference 2025","[{'href': 'http://arxiv.org/abs/2502.14086v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14086v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14086v1,None,http://arxiv.org/abs/2502.14086v1,,,1206,0
http://arxiv.org/abs/2502.14113v1,True,2025-02-19T21:30:51Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=21, tm_min=30, tm_sec=51, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T21:30:51Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=21, tm_min=30, tm_sec=51, tm_wday=2, tm_yday=50, tm_isdst=0)",Object-centric Binding in Contrastive Language-Image Pretraining,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Object-centric Binding in Contrastive Language-Image Pretraining'}","Recent advances in vision language models (VLM) have been driven by
contrastive models such as CLIP, which learn to associate visual information
with their corresponding text descriptions. However, these models have
limitations in understanding complex compositional scenes involving multiple
objects and their spatial relationships. To address these challenges, we
propose a novel approach that diverges from commonly used strategies, which
rely on the design of hard-negative augmentations. Instead, our work focuses on
integrating inductive biases into pre-trained CLIP-like models to improve their
compositional understanding without using any additional hard-negatives. To
that end, we introduce a binding module that connects a scene graph, derived
from a text description, with a slot-structured image representation,
facilitating a structured similarity assessment between the two modalities. We
also leverage relationships as text-conditioned visual constraints, thereby
capturing the intricate interactions between objects and their contextual
relationships more effectively. Our resulting model not only enhances the
performance of CLIP-based models in multi-object compositional understanding
but also paves the way towards more accurate and sample-efficient image-text
matching of complex scenes.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Recent advances in vision language models (VLM) have been driven by\ncontrastive models such as CLIP, which learn to associate visual information\nwith their corresponding text descriptions. However, these models have\nlimitations in understanding complex compositional scenes involving multiple\nobjects and their spatial relationships. To address these challenges, we\npropose a novel approach that diverges from commonly used strategies, which\nrely on the design of hard-negative augmentations. Instead, our work focuses on\nintegrating inductive biases into pre-trained CLIP-like models to improve their\ncompositional understanding without using any additional hard-negatives. To\nthat end, we introduce a binding module that connects a scene graph, derived\nfrom a text description, with a slot-structured image representation,\nfacilitating a structured similarity assessment between the two modalities. We\nalso leverage relationships as text-conditioned visual constraints, thereby\ncapturing the intricate interactions between objects and their contextual\nrelationships more effectively. Our resulting model not only enhances the\nperformance of CLIP-based models in multi-object compositional understanding\nbut also paves the way towards more accurate and sample-efficient image-text\nmatching of complex scenes.'}","['Rim Assouel', 'Pietro Astolfi', 'Florian Bordes', 'Michal Drozdzal', 'Adriana Romero-Soriano']",{'name': 'Adriana Romero-Soriano'},Adriana Romero-Soriano,,"[{'href': 'http://arxiv.org/abs/2502.14113v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14113v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14113v1,None,http://arxiv.org/abs/2502.14113v1,,,7887,0
http://arxiv.org/abs/2502.14132v1,True,2025-02-19T22:26:39Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=22, tm_min=26, tm_sec=39, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T22:26:39Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=22, tm_min=26, tm_sec=39, tm_wday=2, tm_yday=50, tm_isdst=0)",Can Community Notes Replace Professional Fact-Checkers?,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Can Community Notes Replace Professional Fact-Checkers?'}","Two commonly-employed strategies to combat the rise of misinformation on
social media are (i) fact-checking by professional organisations and (ii)
community moderation by platform users. Policy changes by Twitter/X and, more
recently, Meta, signal a shift away from partnerships with fact-checking
organisations and towards an increased reliance on crowdsourced community
notes. However, the extent and nature of dependencies between fact-checking and
helpful community notes remain unclear. To address these questions, we use
language models to annotate a large corpus of Twitter/X community notes with
attributes such as topic, cited sources, and whether they refute claims tied to
broader misinformation narratives. Our analysis reveals that community notes
cite fact-checking sources up to five times more than previously reported.
Fact-checking is especially crucial for notes on posts linked to broader
narratives, which are twice as likely to reference fact-checking sources
compared to other sources. In conclusion, our results show that successful
community moderation heavily relies on professional fact-checking.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Two commonly-employed strategies to combat the rise of misinformation on\nsocial media are (i) fact-checking by professional organisations and (ii)\ncommunity moderation by platform users. Policy changes by Twitter/X and, more\nrecently, Meta, signal a shift away from partnerships with fact-checking\norganisations and towards an increased reliance on crowdsourced community\nnotes. However, the extent and nature of dependencies between fact-checking and\nhelpful community notes remain unclear. To address these questions, we use\nlanguage models to annotate a large corpus of Twitter/X community notes with\nattributes such as topic, cited sources, and whether they refute claims tied to\nbroader misinformation narratives. Our analysis reveals that community notes\ncite fact-checking sources up to five times more than previously reported.\nFact-checking is especially crucial for notes on posts linked to broader\nnarratives, which are twice as likely to reference fact-checking sources\ncompared to other sources. In conclusion, our results show that successful\ncommunity moderation heavily relies on professional fact-checking.'}","['Nadav Borenstein', 'Greta Warren', 'Desmond Elliott', 'Isabelle Augenstein']",{'name': 'Isabelle Augenstein'},Isabelle Augenstein,,"[{'href': 'http://arxiv.org/abs/2502.14132v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14132v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14132v1,None,http://arxiv.org/abs/2502.14132v1,,,46,0
http://arxiv.org/abs/2502.14149v1,True,2025-02-19T23:28:39Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=23, tm_min=28, tm_sec=39, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T23:28:39Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=23, tm_min=28, tm_sec=39, tm_wday=2, tm_yday=50, tm_isdst=0)","PitVQA++: Vector Matrix-Low-Rank Adaptation for Open-Ended Visual
  Question Answering in Pituitary Surgery","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'PitVQA++: Vector Matrix-Low-Rank Adaptation for Open-Ended Visual\n  Question Answering in Pituitary Surgery'}","Vision-Language Models (VLMs) in visual question answering (VQA) offer a
unique opportunity to enhance intra-operative decision-making, promote
intuitive interactions, and significantly advancing surgical education.
However, the development of VLMs for surgical VQA is challenging due to limited
datasets and the risk of overfitting and catastrophic forgetting during full
fine-tuning of pretrained weights. While parameter-efficient techniques like
Low-Rank Adaptation (LoRA) and Matrix of Rank Adaptation (MoRA) address
adaptation challenges, their uniform parameter distribution overlooks the
feature hierarchy in deep networks, where earlier layers, that learn general
features, require more parameters than later ones. This work introduces
PitVQA++ with an open-ended PitVQA dataset and vector matrix-low-rank
adaptation (Vector-MoLoRA), an innovative VLM fine-tuning approach for adapting
GPT-2 to pituitary surgery. Open-Ended PitVQA comprises around 101,803 frames
from 25 procedural videos with 745,972 question-answer sentence pairs, covering
key surgical elements such as phase and step recognition, context
understanding, tool detection, localization, and interactions recognition.
Vector-MoLoRA incorporates the principles of LoRA and MoRA to develop a
matrix-low-rank adaptation strategy that employs vector ranking to allocate
more parameters to earlier layers, gradually reducing them in the later layers.
Our approach, validated on the Open-Ended PitVQA and EndoVis18-VQA datasets,
effectively mitigates catastrophic forgetting while significantly enhancing
performance over recent baselines. Furthermore, our risk-coverage analysis
highlights its enhanced reliability and trustworthiness in handling uncertain
predictions. Our source code and dataset is available
at~\url{https://github.com/HRL-Mike/PitVQA-Plus}.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Vision-Language Models (VLMs) in visual question answering (VQA) offer a\nunique opportunity to enhance intra-operative decision-making, promote\nintuitive interactions, and significantly advancing surgical education.\nHowever, the development of VLMs for surgical VQA is challenging due to limited\ndatasets and the risk of overfitting and catastrophic forgetting during full\nfine-tuning of pretrained weights. While parameter-efficient techniques like\nLow-Rank Adaptation (LoRA) and Matrix of Rank Adaptation (MoRA) address\nadaptation challenges, their uniform parameter distribution overlooks the\nfeature hierarchy in deep networks, where earlier layers, that learn general\nfeatures, require more parameters than later ones. This work introduces\nPitVQA++ with an open-ended PitVQA dataset and vector matrix-low-rank\nadaptation (Vector-MoLoRA), an innovative VLM fine-tuning approach for adapting\nGPT-2 to pituitary surgery. Open-Ended PitVQA comprises around 101,803 frames\nfrom 25 procedural videos with 745,972 question-answer sentence pairs, covering\nkey surgical elements such as phase and step recognition, context\nunderstanding, tool detection, localization, and interactions recognition.\nVector-MoLoRA incorporates the principles of LoRA and MoRA to develop a\nmatrix-low-rank adaptation strategy that employs vector ranking to allocate\nmore parameters to earlier layers, gradually reducing them in the later layers.\nOur approach, validated on the Open-Ended PitVQA and EndoVis18-VQA datasets,\neffectively mitigates catastrophic forgetting while significantly enhancing\nperformance over recent baselines. Furthermore, our risk-coverage analysis\nhighlights its enhanced reliability and trustworthiness in handling uncertain\npredictions. Our source code and dataset is available\nat~\\url{https://github.com/HRL-Mike/PitVQA-Plus}.'}","['Runlong He', 'Danyal Z. Khan', 'Evangelos B. Mazomenos', 'Hani J. Marcus', 'Danail Stoyanov', 'Matthew J. Clarkson', 'Mobarakol Islam']",{'name': 'Mobarakol Islam'},Mobarakol Islam,9 pages,"[{'href': 'http://arxiv.org/abs/2502.14149v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14149v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14149v1,None,http://arxiv.org/abs/2502.14149v1,,,1840,0
http://arxiv.org/abs/2502.14176v1,True,2025-02-20T01:07:01Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=1, tm_min=7, tm_sec=1, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T01:07:01Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=1, tm_min=7, tm_sec=1, tm_wday=3, tm_yday=51, tm_isdst=0)",A modal logic translation of the AGM axioms for belief revision,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A modal logic translation of the AGM axioms for belief revision'}","Building on the analysis of Bonanno (Artificial Intelligence, 2025) we
introduce a simple modal logic containing three modal operators: a unimodal
belief operator, a bimodal conditional operator and the unimodal global
operator. For each AGM axiom for belief revision, we provide a corresponding
modal axiom. The correspondence is as follows: each AGM axiom is characterized
by a property of the Kripke-Lewis frames considered in Bonanno (Artificial
Intelligence, 2025) and, in turn, that property characterizes the proposed
modal axiom.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Building on the analysis of Bonanno (Artificial Intelligence, 2025) we\nintroduce a simple modal logic containing three modal operators: a unimodal\nbelief operator, a bimodal conditional operator and the unimodal global\noperator. For each AGM axiom for belief revision, we provide a corresponding\nmodal axiom. The correspondence is as follows: each AGM axiom is characterized\nby a property of the Kripke-Lewis frames considered in Bonanno (Artificial\nIntelligence, 2025) and, in turn, that property characterizes the proposed\nmodal axiom.'}",['Giacomo Bonanno'],{'name': 'Giacomo Bonanno'},Giacomo Bonanno,"19 pages, 3 figures","[{'href': 'http://arxiv.org/abs/2502.14176v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14176v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LO', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68, 03', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14176v1,None,http://arxiv.org/abs/2502.14176v1,,,0,0
http://arxiv.org/abs/2502.14183v1,True,2025-02-20T01:26:00Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=1, tm_min=26, tm_sec=0, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T01:26:00Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=1, tm_min=26, tm_sec=0, tm_wday=3, tm_yday=51, tm_isdst=0)","Type 1 Diabetes Management using GLIMMER: Glucose Level Indicator Model
  with Modified Error Rate","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Type 1 Diabetes Management using GLIMMER: Glucose Level Indicator Model\n  with Modified Error Rate'}","Managing Type 1 Diabetes (T1D) demands constant vigilance as individuals
strive to regulate their blood glucose levels to avert the dangers of
dysglycemia (hyperglycemia or hypoglycemia). Despite the advent of
sophisticated technologies such as automated insulin delivery (AID) systems,
achieving optimal glycemic control remains a formidable task. AID systems
integrate continuous subcutaneous insulin infusion (CSII) and continuous
glucose monitors (CGM) data, offering promise in reducing variability and
increasing glucose time-in-range. However, these systems often fail to prevent
dysglycemia, partly due to limitations in prediction algorithms that lack the
precision to avert abnormal glucose events. This gap highlights the need for
proactive behavioral adjustments. We address this need with GLIMMER, Glucose
Level Indicator Model with Modified Error Rate, a machine learning approach for
forecasting blood glucose levels. GLIMMER categorizes glucose values into
normal and abnormal ranges and devises a novel custom loss function to
prioritize accuracy in dysglycemic events where patient safety is critical. To
evaluate the potential of GLIMMER for T1D management, we both use a publicly
available dataset and collect new data involving 25 patients with T1D. In
predicting next-hour glucose values, GLIMMER achieved a root mean square error
(RMSE) of 23.97 (+/-3.77) and a mean absolute error (MAE) of 15.83 (+/-2.09)
mg/dL. These results reflect a 23% improvement in RMSE and a 31% improvement in
MAE compared to the best-reported error rates.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Managing Type 1 Diabetes (T1D) demands constant vigilance as individuals\nstrive to regulate their blood glucose levels to avert the dangers of\ndysglycemia (hyperglycemia or hypoglycemia). Despite the advent of\nsophisticated technologies such as automated insulin delivery (AID) systems,\nachieving optimal glycemic control remains a formidable task. AID systems\nintegrate continuous subcutaneous insulin infusion (CSII) and continuous\nglucose monitors (CGM) data, offering promise in reducing variability and\nincreasing glucose time-in-range. However, these systems often fail to prevent\ndysglycemia, partly due to limitations in prediction algorithms that lack the\nprecision to avert abnormal glucose events. This gap highlights the need for\nproactive behavioral adjustments. We address this need with GLIMMER, Glucose\nLevel Indicator Model with Modified Error Rate, a machine learning approach for\nforecasting blood glucose levels. GLIMMER categorizes glucose values into\nnormal and abnormal ranges and devises a novel custom loss function to\nprioritize accuracy in dysglycemic events where patient safety is critical. To\nevaluate the potential of GLIMMER for T1D management, we both use a publicly\navailable dataset and collect new data involving 25 patients with T1D. In\npredicting next-hour glucose values, GLIMMER achieved a root mean square error\n(RMSE) of 23.97 (+/-3.77) and a mean absolute error (MAE) of 15.83 (+/-2.09)\nmg/dL. These results reflect a 23% improvement in RMSE and a 31% improvement in\nMAE compared to the best-reported error rates.'}","['Saman Khamesian', 'Asiful Arefeen', 'Adela Grando', 'Bithika Thompson', 'Hassan Ghasemzadeh']",{'name': 'Hassan Ghasemzadeh'},Hassan Ghasemzadeh,,"[{'href': 'http://arxiv.org/abs/2502.14183v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14183v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14183v1,None,http://arxiv.org/abs/2502.14183v1,,,139,0
http://arxiv.org/abs/2502.14191v1,True,2025-02-20T01:48:13Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=1, tm_min=48, tm_sec=13, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T01:48:13Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=1, tm_min=48, tm_sec=13, tm_wday=3, tm_yday=51, tm_isdst=0)","Multimodal RewardBench: Holistic Evaluation of Reward Models for Vision
  Language Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Multimodal RewardBench: Holistic Evaluation of Reward Models for Vision\n  Language Models'}","Reward models play an essential role in training vision-language models
(VLMs) by assessing output quality to enable aligning with human preferences.
Despite their importance, the research community lacks comprehensive open
benchmarks for evaluating multimodal reward models in VLMs. To address this
gap, we introduce Multimodal RewardBench, an expert-annotated benchmark
covering six domains: general correctness, preference, knowledge, reasoning,
safety, and visual question-answering. Our dataset comprises 5,211 annotated
(prompt, chosen response, rejected response) triplets collected from various
VLMs. In evaluating a range of VLM judges, we find that even the top-performing
models, Gemini 1.5 Pro and Claude 3.5 Sonnet, achieve only 72% overall
accuracy. Notably, most models struggle in the reasoning and safety domains.
These findings suggest that Multimodal RewardBench offers a challenging testbed
for advancing reward model development across multiple domains. We release the
benchmark at https://github.com/facebookresearch/multimodal_rewardbench.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Reward models play an essential role in training vision-language models\n(VLMs) by assessing output quality to enable aligning with human preferences.\nDespite their importance, the research community lacks comprehensive open\nbenchmarks for evaluating multimodal reward models in VLMs. To address this\ngap, we introduce Multimodal RewardBench, an expert-annotated benchmark\ncovering six domains: general correctness, preference, knowledge, reasoning,\nsafety, and visual question-answering. Our dataset comprises 5,211 annotated\n(prompt, chosen response, rejected response) triplets collected from various\nVLMs. In evaluating a range of VLM judges, we find that even the top-performing\nmodels, Gemini 1.5 Pro and Claude 3.5 Sonnet, achieve only 72% overall\naccuracy. Notably, most models struggle in the reasoning and safety domains.\nThese findings suggest that Multimodal RewardBench offers a challenging testbed\nfor advancing reward model development across multiple domains. We release the\nbenchmark at https://github.com/facebookresearch/multimodal_rewardbench.'}","['Michihiro Yasunaga', 'Luke Zettlemoyer', 'Marjan Ghazvininejad']",{'name': 'Marjan Ghazvininejad'},Marjan Ghazvininejad,"Dataset available at
  https://github.com/facebookresearch/multimodal_rewardbench","[{'href': 'http://arxiv.org/abs/2502.14191v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14191v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14191v1,None,http://arxiv.org/abs/2502.14191v1,,,28588,0
http://arxiv.org/abs/2502.14197v1,True,2025-02-20T02:01:40Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=2, tm_min=1, tm_sec=40, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T02:01:40Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=2, tm_min=1, tm_sec=40, tm_wday=3, tm_yday=51, tm_isdst=0)","Adaptive Sparsified Graph Learning Framework for Vessel Behavior
  Anomalies","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Adaptive Sparsified Graph Learning Framework for Vessel Behavior\n  Anomalies'}","Graph neural networks have emerged as a powerful tool for learning
spatiotemporal interactions. However, conventional approaches often rely on
predefined graphs, which may obscure the precise relationships being modeled.
Additionally, existing methods typically define nodes based on fixed spatial
locations, a strategy that is ill-suited for dynamic environments like maritime
environments. Our method introduces an innovative graph representation where
timestamps are modeled as distinct nodes, allowing temporal dependencies to be
explicitly captured through graph edges. This setup is extended to construct a
multi-ship graph that effectively captures spatial interactions while
preserving graph sparsity. The graph is processed using Graph Convolutional
Network layers to capture spatiotemporal patterns, with a forecasting layer for
feature prediction and a Variational Graph Autoencoder for reconstruction,
enabling robust anomaly detection.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Graph neural networks have emerged as a powerful tool for learning\nspatiotemporal interactions. However, conventional approaches often rely on\npredefined graphs, which may obscure the precise relationships being modeled.\nAdditionally, existing methods typically define nodes based on fixed spatial\nlocations, a strategy that is ill-suited for dynamic environments like maritime\nenvironments. Our method introduces an innovative graph representation where\ntimestamps are modeled as distinct nodes, allowing temporal dependencies to be\nexplicitly captured through graph edges. This setup is extended to construct a\nmulti-ship graph that effectively captures spatial interactions while\npreserving graph sparsity. The graph is processed using Graph Convolutional\nNetwork layers to capture spatiotemporal patterns, with a forecasting layer for\nfeature prediction and a Variational Graph Autoencoder for reconstruction,\nenabling robust anomaly detection.'}","['Jeehong Kim', 'Minchan Kim', 'Jaeseong Ju', 'Youngseok Hwang', 'Wonhee Lee', 'Hyunwoo Park']",{'name': 'Hyunwoo Park'},Hyunwoo Park,Anomaly Detection in Scientific Domains AAAI Workshop,"[{'href': 'http://arxiv.org/abs/2502.14197v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14197v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14197v1,None,http://arxiv.org/abs/2502.14197v1,,,0,0
http://arxiv.org/abs/2502.14200v1,True,2025-02-20T02:15:58Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=2, tm_min=15, tm_sec=58, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T02:15:58Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=2, tm_min=15, tm_sec=58, tm_wday=3, tm_yday=51, tm_isdst=0)",Causal Mean Field Multi-Agent Reinforcement Learning,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Causal Mean Field Multi-Agent Reinforcement Learning'}","Scalability remains a challenge in multi-agent reinforcement learning and is
currently under active research. A framework named mean-field reinforcement
learning (MFRL) could alleviate the scalability problem by employing the Mean
Field Theory to turn a many-agent problem into a two-agent problem. However,
this framework lacks the ability to identify essential interactions under
nonstationary environments. Causality contains relatively invariant mechanisms
behind interactions, though environments are nonstationary. Therefore, we
propose an algorithm called causal mean-field Q-learning (CMFQ) to address the
scalability problem. CMFQ is ever more robust toward the change of the number
of agents though inheriting the compressed representation of MFRL's
action-state space. Firstly, we model the causality behind the decision-making
process of MFRL into a structural causal model (SCM). Then the essential degree
of each interaction is quantified via intervening on the SCM. Furthermore, we
design the causality-aware compact representation for behavioral information of
agents as the weighted sum of all behavioral information according to their
causal effects. We test CMFQ in a mixed cooperative-competitive game and a
cooperative game. The result shows that our method has excellent scalability
performance in both training in environments containing a large number of
agents and testing in environments containing much more agents.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Scalability remains a challenge in multi-agent reinforcement learning and is\ncurrently under active research. A framework named mean-field reinforcement\nlearning (MFRL) could alleviate the scalability problem by employing the Mean\nField Theory to turn a many-agent problem into a two-agent problem. However,\nthis framework lacks the ability to identify essential interactions under\nnonstationary environments. Causality contains relatively invariant mechanisms\nbehind interactions, though environments are nonstationary. Therefore, we\npropose an algorithm called causal mean-field Q-learning (CMFQ) to address the\nscalability problem. CMFQ is ever more robust toward the change of the number\nof agents though inheriting the compressed representation of MFRL's\naction-state space. Firstly, we model the causality behind the decision-making\nprocess of MFRL into a structural causal model (SCM). Then the essential degree\nof each interaction is quantified via intervening on the SCM. Furthermore, we\ndesign the causality-aware compact representation for behavioral information of\nagents as the weighted sum of all behavioral information according to their\ncausal effects. We test CMFQ in a mixed cooperative-competitive game and a\ncooperative game. The result shows that our method has excellent scalability\nperformance in both training in environments containing a large number of\nagents and testing in environments containing much more agents.""}","['Hao Ma', 'Zhiqiang Pu', 'Yi Pan', 'Boyin Liu', 'Junlong Gao', 'Zhenyu Guo']",{'name': 'Zhenyu Guo'},Zhenyu Guo,,"[{'title': 'doi', 'href': 'http://dx.doi.org/10.1109/IJCNN54540.2023.10191654', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2502.14200v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14200v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14200v1,None,http://arxiv.org/abs/2502.14200v1,"Proc. 2023 International Joint Conference on Neural Networks
  (IJCNN), 2023, pp. 1-8",10.1109/IJCNN54540.2023.10191654,16514,0
http://arxiv.org/abs/2502.14204v1,True,2025-02-20T02:23:09Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=2, tm_min=23, tm_sec=9, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T02:23:09Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=2, tm_min=23, tm_sec=9, tm_wday=3, tm_yday=51, tm_isdst=0)",On-the-fly Preference Alignment via Principle-Guided Decoding,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'On-the-fly Preference Alignment via Principle-Guided Decoding'}","With the rapidly expanding landscape of large language models, aligning model
generations with human values and preferences is becoming increasingly
important. Popular alignment methods, such as Reinforcement Learning from Human
Feedback, have shown significant success in guiding models with greater
control. However, these methods require considerable computational resources,
which is inefficient, and substantial collection of training data to
accommodate the diverse and pluralistic nature of human preferences, which is
impractical. These limitations significantly constrain the scope and efficacy
of both task-specific and general preference alignment methods. In this work,
we introduce On-the-fly Preference Alignment via Principle-Guided Decoding
(OPAD) to directly align model outputs with human preferences during inference,
eliminating the need for fine-tuning. Our approach involves first curating a
surrogate solution to an otherwise infeasible optimization problem and then
designing a principle-guided reward function based on this surrogate. The final
aligned policy is derived by maximizing this customized reward, which exploits
the discrepancy between the constrained policy and its unconstrained
counterpart. OPAD directly modifies the model's predictions during inference,
ensuring principle adherence without incurring the computational overhead of
retraining or fine-tuning. Experiments show that OPAD achieves competitive or
superior performance in both general and personalized alignment tasks,
demonstrating its efficiency and effectiveness compared to state-of-the-art
baselines.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""With the rapidly expanding landscape of large language models, aligning model\ngenerations with human values and preferences is becoming increasingly\nimportant. Popular alignment methods, such as Reinforcement Learning from Human\nFeedback, have shown significant success in guiding models with greater\ncontrol. However, these methods require considerable computational resources,\nwhich is inefficient, and substantial collection of training data to\naccommodate the diverse and pluralistic nature of human preferences, which is\nimpractical. These limitations significantly constrain the scope and efficacy\nof both task-specific and general preference alignment methods. In this work,\nwe introduce On-the-fly Preference Alignment via Principle-Guided Decoding\n(OPAD) to directly align model outputs with human preferences during inference,\neliminating the need for fine-tuning. Our approach involves first curating a\nsurrogate solution to an otherwise infeasible optimization problem and then\ndesigning a principle-guided reward function based on this surrogate. The final\naligned policy is derived by maximizing this customized reward, which exploits\nthe discrepancy between the constrained policy and its unconstrained\ncounterpart. OPAD directly modifies the model's predictions during inference,\nensuring principle adherence without incurring the computational overhead of\nretraining or fine-tuning. Experiments show that OPAD achieves competitive or\nsuperior performance in both general and personalized alignment tasks,\ndemonstrating its efficiency and effectiveness compared to state-of-the-art\nbaselines.""}","['Mingye Zhu', 'Yi Liu', 'Lei Zhang', 'Junbo Guo', 'Zhendong Mao']",{'name': 'Zhendong Mao'},Zhendong Mao,Accepted to ICLR 2025,"[{'href': 'http://arxiv.org/abs/2502.14204v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14204v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14204v1,None,http://arxiv.org/abs/2502.14204v1,,,53,0
http://arxiv.org/abs/2502.14205v1,True,2025-02-20T02:35:17Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=2, tm_min=35, tm_sec=17, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T02:35:17Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=2, tm_min=35, tm_sec=17, tm_wday=3, tm_yday=51, tm_isdst=0)",Accurate Forgetting for Heterogeneous Federated Continual Learning,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Accurate Forgetting for Heterogeneous Federated Continual Learning'}","Recent years have witnessed a burgeoning interest in federated learning (FL).
However, the contexts in which clients engage in sequential learning remain
under-explored. Bridging FL and continual learning (CL) gives rise to a
challenging practical problem: federated continual learning (FCL). Existing
research in FCL primarily focuses on mitigating the catastrophic forgetting
issue of continual learning while collaborating with other clients. We argue
that the forgetting phenomena are not invariably detrimental. In this paper, we
consider a more practical and challenging FCL setting characterized by
potentially unrelated or even antagonistic data/tasks across different clients.
In the FL scenario, statistical heterogeneity and data noise among clients may
exhibit spurious correlations which result in biased feature learning. While
existing CL strategies focus on a complete utilization of previous knowledge,
we found that forgetting biased information is beneficial in our study.
Therefore, we propose a new concept accurate forgetting (AF) and develop a
novel generative-replay method~\method~which selectively utilizes previous
knowledge in federated networks. We employ a probabilistic framework based on a
normalizing flow model to quantify the credibility of previous knowledge.
Comprehensive experiments affirm the superiority of our method over baselines.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Recent years have witnessed a burgeoning interest in federated learning (FL).\nHowever, the contexts in which clients engage in sequential learning remain\nunder-explored. Bridging FL and continual learning (CL) gives rise to a\nchallenging practical problem: federated continual learning (FCL). Existing\nresearch in FCL primarily focuses on mitigating the catastrophic forgetting\nissue of continual learning while collaborating with other clients. We argue\nthat the forgetting phenomena are not invariably detrimental. In this paper, we\nconsider a more practical and challenging FCL setting characterized by\npotentially unrelated or even antagonistic data/tasks across different clients.\nIn the FL scenario, statistical heterogeneity and data noise among clients may\nexhibit spurious correlations which result in biased feature learning. While\nexisting CL strategies focus on a complete utilization of previous knowledge,\nwe found that forgetting biased information is beneficial in our study.\nTherefore, we propose a new concept accurate forgetting (AF) and develop a\nnovel generative-replay method~\\method~which selectively utilizes previous\nknowledge in federated networks. We employ a probabilistic framework based on a\nnormalizing flow model to quantify the credibility of previous knowledge.\nComprehensive experiments affirm the superiority of our method over baselines.'}","['Abudukelimu Wuerkaixi', 'Sen Cui', 'Jingfeng Zhang', 'Kunda Yan', 'Bo Han', 'Gang Niu', 'Lei Fang', 'Changshui Zhang', 'Masashi Sugiyama']",{'name': 'Masashi Sugiyama'},Masashi Sugiyama,published in ICLR 2024,"[{'href': 'http://arxiv.org/abs/2502.14205v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14205v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14205v1,None,http://arxiv.org/abs/2502.14205v1,,,10794,0
http://arxiv.org/abs/2502.14215v1,True,2025-02-20T03:07:56Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=3, tm_min=7, tm_sec=56, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T03:07:56Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=3, tm_min=7, tm_sec=56, tm_wday=3, tm_yday=51, tm_isdst=0)","Towards Secure Program Partitioning for Smart Contracts with LLM's
  In-Context Learning","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Towards Secure Program Partitioning for Smart Contracts with LLM's\n  In-Context Learning""}","Smart contracts are highly susceptible to manipulation attacks due to the
leakage of sensitive information. Addressing manipulation vulnerabilities is
particularly challenging because they stem from inherent data confidentiality
issues rather than straightforward implementation bugs. To tackle this by
preventing sensitive information leakage, we present PartitionGPT, the first
LLM-driven approach that combines static analysis with the in-context learning
capabilities of large language models (LLMs) to partition smart contracts into
privileged and normal codebases, guided by a few annotated sensitive data
variables. We evaluated PartitionGPT on 18 annotated smart contracts containing
99 sensitive functions. The results demonstrate that PartitionGPT successfully
generates compilable, and verified partitions for 78% of the sensitive
functions while reducing approximately 30% code compared to function-level
partitioning approach. Furthermore, we evaluated PartitionGPT on nine
real-world manipulation attacks that lead to a total loss of 25 million
dollars, PartitionGPT effectively prevents eight cases, highlighting its
potential for broad applicability and the necessity for secure program
partitioning during smart contract development to diminish manipulation
vulnerabilities.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Smart contracts are highly susceptible to manipulation attacks due to the\nleakage of sensitive information. Addressing manipulation vulnerabilities is\nparticularly challenging because they stem from inherent data confidentiality\nissues rather than straightforward implementation bugs. To tackle this by\npreventing sensitive information leakage, we present PartitionGPT, the first\nLLM-driven approach that combines static analysis with the in-context learning\ncapabilities of large language models (LLMs) to partition smart contracts into\nprivileged and normal codebases, guided by a few annotated sensitive data\nvariables. We evaluated PartitionGPT on 18 annotated smart contracts containing\n99 sensitive functions. The results demonstrate that PartitionGPT successfully\ngenerates compilable, and verified partitions for 78% of the sensitive\nfunctions while reducing approximately 30% code compared to function-level\npartitioning approach. Furthermore, we evaluated PartitionGPT on nine\nreal-world manipulation attacks that lead to a total loss of 25 million\ndollars, PartitionGPT effectively prevents eight cases, highlighting its\npotential for broad applicability and the necessity for secure program\npartitioning during smart contract development to diminish manipulation\nvulnerabilities.'}","['Ye Liu', 'Yuqing Niu', 'Chengyan Ma', 'Ruidong Han', 'Wei Ma', 'Yi Li', 'Debin Gao', 'David Lo']",{'name': 'David Lo'},David Lo,,"[{'href': 'http://arxiv.org/abs/2502.14215v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14215v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.SE', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.SE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14215v1,None,http://arxiv.org/abs/2502.14215v1,,,0,0
http://arxiv.org/abs/2502.14218v1,True,2025-02-20T03:15:52Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=3, tm_min=15, tm_sec=52, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T03:15:52Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=3, tm_min=15, tm_sec=52, tm_wday=3, tm_yday=51, tm_isdst=0)",Rethinking Spiking Neural Networks from an Ensemble Learning Perspective,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Rethinking Spiking Neural Networks from an Ensemble Learning Perspective'}","Spiking neural networks (SNNs) exhibit superior energy efficiency but suffer
from limited performance. In this paper, we consider SNNs as ensembles of
temporal subnetworks that share architectures and weights, and highlight a
crucial issue that affects their performance: excessive differences in initial
states (neuronal membrane potentials) across timesteps lead to unstable
subnetwork outputs, resulting in degraded performance. To mitigate this, we
promote the consistency of the initial membrane potential distribution and
output through membrane potential smoothing and temporally adjacent subnetwork
guidance, respectively, to improve overall stability and performance. Moreover,
membrane potential smoothing facilitates forward propagation of information and
backward propagation of gradients, mitigating the notorious temporal gradient
vanishing problem. Our method requires only minimal modification of the spiking
neurons without adapting the network structure, making our method generalizable
and showing consistent performance gains in 1D speech, 2D object, and 3D point
cloud recognition tasks. In particular, on the challenging CIFAR10-DVS dataset,
we achieved 83.20\% accuracy with only four timesteps. This provides valuable
insights into unleashing the potential of SNNs.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Spiking neural networks (SNNs) exhibit superior energy efficiency but suffer\nfrom limited performance. In this paper, we consider SNNs as ensembles of\ntemporal subnetworks that share architectures and weights, and highlight a\ncrucial issue that affects their performance: excessive differences in initial\nstates (neuronal membrane potentials) across timesteps lead to unstable\nsubnetwork outputs, resulting in degraded performance. To mitigate this, we\npromote the consistency of the initial membrane potential distribution and\noutput through membrane potential smoothing and temporally adjacent subnetwork\nguidance, respectively, to improve overall stability and performance. Moreover,\nmembrane potential smoothing facilitates forward propagation of information and\nbackward propagation of gradients, mitigating the notorious temporal gradient\nvanishing problem. Our method requires only minimal modification of the spiking\nneurons without adapting the network structure, making our method generalizable\nand showing consistent performance gains in 1D speech, 2D object, and 3D point\ncloud recognition tasks. In particular, on the challenging CIFAR10-DVS dataset,\nwe achieved 83.20\\% accuracy with only four timesteps. This provides valuable\ninsights into unleashing the potential of SNNs.'}","['Yongqi Ding', 'Lin Zuo', 'Mengmeng Jing', 'Pei He', 'Hanpu Deng']",{'name': 'Hanpu Deng'},Hanpu Deng,Published as a conference paper at ICLR 2025,"[{'href': 'http://arxiv.org/abs/2502.14218v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14218v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14218v1,None,http://arxiv.org/abs/2502.14218v1,,,53,0
http://arxiv.org/abs/2502.14227v1,True,2025-02-20T03:42:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=3, tm_min=42, tm_sec=42, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T03:42:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=3, tm_min=42, tm_sec=42, tm_wday=3, tm_yday=51, tm_isdst=0)","SleepGMUformer: A gated multimodal temporal neural network for sleep
  staging","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'SleepGMUformer: A gated multimodal temporal neural network for sleep\n  staging'}","Sleep staging is a key method for assessing sleep quality and diagnosing
sleep disorders. However, current deep learning methods face challenges: 1)
postfusion techniques ignore the varying contributions of different modalities;
2) unprocessed sleep data can interfere with frequency-domain information. To
tackle these issues, this paper proposes a gated multimodal temporal neural
network for multidomain sleep data, including heart rate, motion, steps, EEG
(Fpz-Cz, Pz-Oz), and EOG from WristHR-Motion-Sleep and SleepEDF-78. The model
integrates: 1) a pre-processing module for feature alignment, missing value
handling, and EEG de-trending; 2) a feature extraction module for complex sleep
features in the time dimension; and 3) a dynamic fusion module for real-time
modality weighting.Experiments show classification accuracies of 85.03% on
SleepEDF-78 and 94.54% on WristHR-Motion-Sleep datasets. The model handles
heterogeneous datasets and outperforms state-of-the-art models by 1.00%-4.00%.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Sleep staging is a key method for assessing sleep quality and diagnosing\nsleep disorders. However, current deep learning methods face challenges: 1)\npostfusion techniques ignore the varying contributions of different modalities;\n2) unprocessed sleep data can interfere with frequency-domain information. To\ntackle these issues, this paper proposes a gated multimodal temporal neural\nnetwork for multidomain sleep data, including heart rate, motion, steps, EEG\n(Fpz-Cz, Pz-Oz), and EOG from WristHR-Motion-Sleep and SleepEDF-78. The model\nintegrates: 1) a pre-processing module for feature alignment, missing value\nhandling, and EEG de-trending; 2) a feature extraction module for complex sleep\nfeatures in the time dimension; and 3) a dynamic fusion module for real-time\nmodality weighting.Experiments show classification accuracies of 85.03% on\nSleepEDF-78 and 94.54% on WristHR-Motion-Sleep datasets. The model handles\nheterogeneous datasets and outperforms state-of-the-art models by 1.00%-4.00%.'}","['Chenjun Zhao', 'Xuesen Niu', 'Xinglin Yu', 'Long Chen', 'Na Lv', 'Huiyu Zhou', 'Aite Zhao']",{'name': 'Aite Zhao'},Aite Zhao,,"[{'href': 'http://arxiv.org/abs/2502.14227v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14227v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14227v1,None,http://arxiv.org/abs/2502.14227v1,,,711,0
http://arxiv.org/abs/2502.14235v1,True,2025-02-20T04:00:47Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=4, tm_min=0, tm_sec=47, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T04:00:47Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=4, tm_min=0, tm_sec=47, tm_wday=3, tm_yday=51, tm_isdst=0)",OG-Gaussian: Occupancy Based Street Gaussians for Autonomous Driving,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'OG-Gaussian: Occupancy Based Street Gaussians for Autonomous Driving'}","Accurate and realistic 3D scene reconstruction enables the lifelike creation
of autonomous driving simulation environments. With advancements in 3D Gaussian
Splatting (3DGS), previous studies have applied it to reconstruct complex
dynamic driving scenes. These methods typically require expensive LiDAR sensors
and pre-annotated datasets of dynamic objects. To address these challenges, we
propose OG-Gaussian, a novel approach that replaces LiDAR point clouds with
Occupancy Grids (OGs) generated from surround-view camera images using
Occupancy Prediction Network (ONet). Our method leverages the semantic
information in OGs to separate dynamic vehicles from static street background,
converting these grids into two distinct sets of initial point clouds for
reconstructing both static and dynamic objects. Additionally, we estimate the
trajectories and poses of dynamic objects through a learning-based approach,
eliminating the need for complex manual annotations. Experiments on Waymo Open
dataset demonstrate that OG-Gaussian is on par with the current
state-of-the-art in terms of reconstruction quality and rendering speed,
achieving an average PSNR of 35.13 and a rendering speed of 143 FPS, while
significantly reducing computational costs and economic overhead.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Accurate and realistic 3D scene reconstruction enables the lifelike creation\nof autonomous driving simulation environments. With advancements in 3D Gaussian\nSplatting (3DGS), previous studies have applied it to reconstruct complex\ndynamic driving scenes. These methods typically require expensive LiDAR sensors\nand pre-annotated datasets of dynamic objects. To address these challenges, we\npropose OG-Gaussian, a novel approach that replaces LiDAR point clouds with\nOccupancy Grids (OGs) generated from surround-view camera images using\nOccupancy Prediction Network (ONet). Our method leverages the semantic\ninformation in OGs to separate dynamic vehicles from static street background,\nconverting these grids into two distinct sets of initial point clouds for\nreconstructing both static and dynamic objects. Additionally, we estimate the\ntrajectories and poses of dynamic objects through a learning-based approach,\neliminating the need for complex manual annotations. Experiments on Waymo Open\ndataset demonstrate that OG-Gaussian is on par with the current\nstate-of-the-art in terms of reconstruction quality and rendering speed,\nachieving an average PSNR of 35.13 and a rendering speed of 143 FPS, while\nsignificantly reducing computational costs and economic overhead.'}","['Yedong Shen', 'Xinran Zhang', 'Yifan Duan', 'Shiqi Zhang', 'Heng Li', 'Yilong Wu', 'Jianmin Ji', 'Yanyong Zhang']",{'name': 'Yanyong Zhang'},Yanyong Zhang,,"[{'href': 'http://arxiv.org/abs/2502.14235v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14235v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14235v1,None,http://arxiv.org/abs/2502.14235v1,,,19,0
http://arxiv.org/abs/2502.14254v1,True,2025-02-20T04:41:40Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=4, tm_min=41, tm_sec=40, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T04:41:40Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=4, tm_min=41, tm_sec=40, tm_wday=3, tm_yday=51, tm_isdst=0)","Mem2Ego: Empowering Vision-Language Models with Global-to-Ego Memory for
  Long-Horizon Embodied Navigation","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Mem2Ego: Empowering Vision-Language Models with Global-to-Ego Memory for\n  Long-Horizon Embodied Navigation'}","Recent advancements in Large Language Models (LLMs) and Vision-Language
Models (VLMs) have made them powerful tools in embodied navigation, enabling
agents to leverage commonsense and spatial reasoning for efficient exploration
in unfamiliar environments. Existing LLM-based approaches convert global
memory, such as semantic or topological maps, into language descriptions to
guide navigation. While this improves efficiency and reduces redundant
exploration, the loss of geometric information in language-based
representations hinders spatial reasoning, especially in intricate
environments. To address this, VLM-based approaches directly process
ego-centric visual inputs to select optimal directions for exploration.
However, relying solely on a first-person perspective makes navigation a
partially observed decision-making problem, leading to suboptimal decisions in
complex environments. In this paper, we present a novel vision-language model
(VLM)-based navigation framework that addresses these challenges by adaptively
retrieving task-relevant cues from a global memory module and integrating them
with the agent's egocentric observations. By dynamically aligning global
contextual information with local perception, our approach enhances spatial
reasoning and decision-making in long-horizon tasks. Experimental results
demonstrate that the proposed method surpasses previous state-of-the-art
approaches in object navigation tasks, providing a more effective and scalable
solution for embodied navigation.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Recent advancements in Large Language Models (LLMs) and Vision-Language\nModels (VLMs) have made them powerful tools in embodied navigation, enabling\nagents to leverage commonsense and spatial reasoning for efficient exploration\nin unfamiliar environments. Existing LLM-based approaches convert global\nmemory, such as semantic or topological maps, into language descriptions to\nguide navigation. While this improves efficiency and reduces redundant\nexploration, the loss of geometric information in language-based\nrepresentations hinders spatial reasoning, especially in intricate\nenvironments. To address this, VLM-based approaches directly process\nego-centric visual inputs to select optimal directions for exploration.\nHowever, relying solely on a first-person perspective makes navigation a\npartially observed decision-making problem, leading to suboptimal decisions in\ncomplex environments. In this paper, we present a novel vision-language model\n(VLM)-based navigation framework that addresses these challenges by adaptively\nretrieving task-relevant cues from a global memory module and integrating them\nwith the agent's egocentric observations. By dynamically aligning global\ncontextual information with local perception, our approach enhances spatial\nreasoning and decision-making in long-horizon tasks. Experimental results\ndemonstrate that the proposed method surpasses previous state-of-the-art\napproaches in object navigation tasks, providing a more effective and scalable\nsolution for embodied navigation.""}","['Lingfeng Zhang', 'Yuecheng Liu', 'Zhanguang Zhang', 'Matin Aghaei', 'Yaochen Hu', 'Hongjian Gu', 'Mohammad Ali Alomrani', 'David Gamaliel Arcos Bravo', 'Raika Karimi', 'Atia Hamidizadeh', 'Haoping Xu', 'Guowei Huang', 'Zhanpeng Zhang', 'Tongtong Cao', 'Weichao Qiu', 'Xingyue Quan', 'Jianye Hao', 'Yuzheng Zhuang', 'Yingxue Zhang']",{'name': 'Yingxue Zhang'},Yingxue Zhang,,"[{'href': 'http://arxiv.org/abs/2502.14254v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14254v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14254v1,None,http://arxiv.org/abs/2502.14254v1,,,218,0
http://arxiv.org/abs/2502.14258v1,True,2025-02-20T04:52:05Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=4, tm_min=52, tm_sec=5, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T04:52:05Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=4, tm_min=52, tm_sec=5, tm_wday=3, tm_yday=51, tm_isdst=0)","Does Time Have Its Place? Temporal Heads: Where Language Models Recall
  Time-specific Information","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Does Time Have Its Place? Temporal Heads: Where Language Models Recall\n  Time-specific Information'}","While the ability of language models to elicit facts has been widely
investigated, how they handle temporally changing facts remains underexplored.
We discover Temporal Heads, specific attention heads primarily responsible for
processing temporal knowledge through circuit analysis. We confirm that these
heads are present across multiple models, though their specific locations may
vary, and their responses differ depending on the type of knowledge and its
corresponding years. Disabling these heads degrades the model's ability to
recall time-specific knowledge while maintaining its general capabilities
without compromising time-invariant and question-answering performances.
Moreover, the heads are activated not only numeric conditions (""In 2004"") but
also textual aliases (""In the year ...""), indicating that they encode a
temporal dimension beyond simple numerical representation. Furthermore, we
expand the potential of our findings by demonstrating how temporal knowledge
can be edited by adjusting the values of these heads.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'While the ability of language models to elicit facts has been widely\ninvestigated, how they handle temporally changing facts remains underexplored.\nWe discover Temporal Heads, specific attention heads primarily responsible for\nprocessing temporal knowledge through circuit analysis. We confirm that these\nheads are present across multiple models, though their specific locations may\nvary, and their responses differ depending on the type of knowledge and its\ncorresponding years. Disabling these heads degrades the model\'s ability to\nrecall time-specific knowledge while maintaining its general capabilities\nwithout compromising time-invariant and question-answering performances.\nMoreover, the heads are activated not only numeric conditions (""In 2004"") but\nalso textual aliases (""In the year ...""), indicating that they encode a\ntemporal dimension beyond simple numerical representation. Furthermore, we\nexpand the potential of our findings by demonstrating how temporal knowledge\ncan be edited by adjusting the values of these heads.'}","['Yein Park', 'Chanwoong Yoon', 'Jungwoo Park', 'Minbyul Jeong', 'Jaewoo Kang']",{'name': 'Jaewoo Kang'},Jaewoo Kang,,"[{'href': 'http://arxiv.org/abs/2502.14258v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14258v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14258v1,None,http://arxiv.org/abs/2502.14258v1,,,110,0
http://arxiv.org/abs/2502.14268v1,True,2025-02-20T05:09:29Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=5, tm_min=9, tm_sec=29, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T05:09:29Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=5, tm_min=9, tm_sec=29, tm_wday=3, tm_yday=51, tm_isdst=0)","MCQA-Eval: Efficient Confidence Evaluation in NLG with Gold-Standard
  Correctness Labels","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'MCQA-Eval: Efficient Confidence Evaluation in NLG with Gold-Standard\n  Correctness Labels'}","Large Language Models (LLMs) require robust confidence estimation,
particularly in critical domains like healthcare and law where unreliable
outputs can lead to significant consequences. Despite much recent work in
confidence estimation, current evaluation frameworks rely on correctness
functions -- various heuristics that are often noisy, expensive, and possibly
introduce systematic biases. These methodological weaknesses tend to distort
evaluation metrics and thus the comparative ranking of confidence measures. We
introduce MCQA-Eval, an evaluation framework for assessing confidence measures
in Natural Language Generation (NLG) that eliminates dependence on an explicit
correctness function by leveraging gold-standard correctness labels from
multiple-choice datasets. MCQA-Eval enables systematic comparison of both
internal state-based white-box (e.g. logit-based) and consistency-based
black-box confidence measures, providing a unified evaluation methodology
across different approaches. Through extensive experiments on multiple LLMs and
widely used QA datasets, we report that MCQA-Eval provides efficient and more
reliable assessments of confidence estimation methods than existing approaches.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Language Models (LLMs) require robust confidence estimation,\nparticularly in critical domains like healthcare and law where unreliable\noutputs can lead to significant consequences. Despite much recent work in\nconfidence estimation, current evaluation frameworks rely on correctness\nfunctions -- various heuristics that are often noisy, expensive, and possibly\nintroduce systematic biases. These methodological weaknesses tend to distort\nevaluation metrics and thus the comparative ranking of confidence measures. We\nintroduce MCQA-Eval, an evaluation framework for assessing confidence measures\nin Natural Language Generation (NLG) that eliminates dependence on an explicit\ncorrectness function by leveraging gold-standard correctness labels from\nmultiple-choice datasets. MCQA-Eval enables systematic comparison of both\ninternal state-based white-box (e.g. logit-based) and consistency-based\nblack-box confidence measures, providing a unified evaluation methodology\nacross different approaches. Through extensive experiments on multiple LLMs and\nwidely used QA datasets, we report that MCQA-Eval provides efficient and more\nreliable assessments of confidence estimation methods than existing approaches.'}","['Xiaoou Liu', 'Zhen Lin', 'Longchao Da', 'Chacha Chen', 'Shubhendu Trivedi', 'Hua Wei']",{'name': 'Hua Wei'},Hua Wei,,"[{'href': 'http://arxiv.org/abs/2502.14268v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14268v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14268v1,None,http://arxiv.org/abs/2502.14268v1,,,2518,0
http://arxiv.org/abs/2502.14272v1,True,2025-02-20T05:18:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=5, tm_min=18, tm_sec=23, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T05:18:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=5, tm_min=18, tm_sec=23, tm_wday=3, tm_yday=51, tm_isdst=0)","Capturing Nuanced Preferences: Preference-Aligned Distillation for Small
  Language Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Capturing Nuanced Preferences: Preference-Aligned Distillation for Small\n  Language Models'}","Aligning small language models (SLMs) with human values typically involves
distilling preference knowledge from large language models (LLMs). However,
existing distillation methods model preference knowledge in teacher LLMs by
comparing pairwise responses, overlooking the extent of difference between
responses. This limitation hinders student SLMs from capturing the nuanced
preferences for multiple responses. In this paper, we propose a
Preference-Aligned Distillation (PAD) framework, which models teacher's
preference knowledge as a probability distribution over all potential
preferences, thereby providing more nuanced supervisory signals. Our insight in
developing PAD is rooted in the demonstration that language models can serve as
reward functions, reflecting their intrinsic preferences. Based on this, PAD
comprises three key steps: (1) sampling diverse responses using
high-temperature; (2) computing rewards for both teacher and student to
construct their intrinsic preference; and (3) training the student's intrinsic
preference distribution to align with the teacher's. Experiments on four
mainstream alignment benchmarks demonstrate that PAD consistently and
significantly outperforms existing approaches, achieving over 20\% improvement
on AlpacaEval 2 and Arena-Hard, indicating superior alignment with human
preferences. Notably, on MT-Bench, using the \textsc{Gemma} model family, the
student trained by PAD surpasses its teacher, further validating the
effectiveness of our PAD.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Aligning small language models (SLMs) with human values typically involves\ndistilling preference knowledge from large language models (LLMs). However,\nexisting distillation methods model preference knowledge in teacher LLMs by\ncomparing pairwise responses, overlooking the extent of difference between\nresponses. This limitation hinders student SLMs from capturing the nuanced\npreferences for multiple responses. In this paper, we propose a\nPreference-Aligned Distillation (PAD) framework, which models teacher's\npreference knowledge as a probability distribution over all potential\npreferences, thereby providing more nuanced supervisory signals. Our insight in\ndeveloping PAD is rooted in the demonstration that language models can serve as\nreward functions, reflecting their intrinsic preferences. Based on this, PAD\ncomprises three key steps: (1) sampling diverse responses using\nhigh-temperature; (2) computing rewards for both teacher and student to\nconstruct their intrinsic preference; and (3) training the student's intrinsic\npreference distribution to align with the teacher's. Experiments on four\nmainstream alignment benchmarks demonstrate that PAD consistently and\nsignificantly outperforms existing approaches, achieving over 20\\% improvement\non AlpacaEval 2 and Arena-Hard, indicating superior alignment with human\npreferences. Notably, on MT-Bench, using the \\textsc{Gemma} model family, the\nstudent trained by PAD surpasses its teacher, further validating the\neffectiveness of our PAD.""}","['Yanggan Gu', 'Junzhuo Li', 'Sirui Huang', 'Xin Zou', 'Zhenghua Li', 'Xuming Hu']",{'name': 'Xuming Hu'},Xuming Hu,Under review,"[{'href': 'http://arxiv.org/abs/2502.14272v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14272v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14272v1,None,http://arxiv.org/abs/2502.14272v1,,,20,0
http://arxiv.org/abs/2502.14280v1,True,2025-02-20T05:41:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=5, tm_min=41, tm_sec=15, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T05:41:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=5, tm_min=41, tm_sec=15, tm_wday=3, tm_yday=51, tm_isdst=0)",EpMAN: Episodic Memory AttentioN for Generalizing to Longer Contexts,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'EpMAN: Episodic Memory AttentioN for Generalizing to Longer Contexts'}","Recent advances in Large Language Models (LLMs) have yielded impressive
successes on many language tasks. However, efficient processing of long
contexts using LLMs remains a significant challenge. We introduce
\textbf{EpMAN} -- a method for processing long contexts in an \textit{episodic
memory} module while \textit{holistically attending to} semantically relevant
context chunks. The output of \textit{episodic attention} is then used to
reweigh the decoder's self-attention to the stored KV cache of the context
during training and generation. When an LLM decoder is trained using
\textbf{EpMAN}, its performance on multiple challenging single-hop long-context
recall and question-answering benchmarks is found to be stronger and more
robust across the range from 16k to 256k tokens than baseline decoders trained
with self-attention, and popular retrieval-augmented generation frameworks.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Recent advances in Large Language Models (LLMs) have yielded impressive\nsuccesses on many language tasks. However, efficient processing of long\ncontexts using LLMs remains a significant challenge. We introduce\n\\textbf{EpMAN} -- a method for processing long contexts in an \\textit{episodic\nmemory} module while \\textit{holistically attending to} semantically relevant\ncontext chunks. The output of \\textit{episodic attention} is then used to\nreweigh the decoder's self-attention to the stored KV cache of the context\nduring training and generation. When an LLM decoder is trained using\n\\textbf{EpMAN}, its performance on multiple challenging single-hop long-context\nrecall and question-answering benchmarks is found to be stronger and more\nrobust across the range from 16k to 256k tokens than baseline decoders trained\nwith self-attention, and popular retrieval-augmented generation frameworks.""}","['Subhajit Chaudhury', 'Payel Das', 'Sarathkrishna Swaminathan', 'Georgios Kollias', 'Elliot Nelson', 'Khushbu Pahwa', 'Tejaswini Pedapati', 'Igor Melnyk', 'Matthew Riemer']",{'name': 'Matthew Riemer'},Matthew Riemer,,"[{'href': 'http://arxiv.org/abs/2502.14280v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14280v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14280v1,None,http://arxiv.org/abs/2502.14280v1,,,830,0
http://arxiv.org/abs/2502.14281v1,True,2025-02-20T05:41:52Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=5, tm_min=41, tm_sec=52, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T05:41:52Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=5, tm_min=41, tm_sec=52, tm_wday=3, tm_yday=51, tm_isdst=0)","Correcting Noisy Multilabel Predictions: Modeling Label Noise through
  Latent Space Shifts","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Correcting Noisy Multilabel Predictions: Modeling Label Noise through\n  Latent Space Shifts'}","Noise in data appears to be inevitable in most real-world machine learning
applications and would cause severe overfitting problems. Not only can data
features contain noise, but labels are also prone to be noisy due to human
input. In this paper, rather than noisy label learning in multiclass
classifications, we instead focus on the less explored area of noisy label
learning for multilabel classifications. Specifically, we investigate the
post-correction of predictions generated from classifiers learned with noisy
labels. The reasons are two-fold. Firstly, this approach can directly work with
the trained models to save computational resources. Secondly, it could be
applied on top of other noisy label correction techniques to achieve further
improvements. To handle this problem, we appeal to deep generative approaches
that are possible for uncertainty estimation. Our model posits that label noise
arises from a stochastic shift in the latent variable, providing a more robust
and beneficial means for noisy learning. We develop both unsupervised and
semi-supervised learning methods for our model. The extensive empirical study
presents solid evidence to that our approach is able to consistently improve
the independent models and performs better than a number of existing methods
across various noisy label settings. Moreover, a comprehensive empirical
analysis of the proposed method is carried out to validate its robustness,
including sensitivity analysis and an ablation study, among other elements.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Noise in data appears to be inevitable in most real-world machine learning\napplications and would cause severe overfitting problems. Not only can data\nfeatures contain noise, but labels are also prone to be noisy due to human\ninput. In this paper, rather than noisy label learning in multiclass\nclassifications, we instead focus on the less explored area of noisy label\nlearning for multilabel classifications. Specifically, we investigate the\npost-correction of predictions generated from classifiers learned with noisy\nlabels. The reasons are two-fold. Firstly, this approach can directly work with\nthe trained models to save computational resources. Secondly, it could be\napplied on top of other noisy label correction techniques to achieve further\nimprovements. To handle this problem, we appeal to deep generative approaches\nthat are possible for uncertainty estimation. Our model posits that label noise\narises from a stochastic shift in the latent variable, providing a more robust\nand beneficial means for noisy learning. We develop both unsupervised and\nsemi-supervised learning methods for our model. The extensive empirical study\npresents solid evidence to that our approach is able to consistently improve\nthe independent models and performs better than a number of existing methods\nacross various noisy label settings. Moreover, a comprehensive empirical\nanalysis of the proposed method is carried out to validate its robustness,\nincluding sensitivity analysis and an ablation study, among other elements.'}","['Weipeng Huang', 'Qin Li', 'Yang Xiao', 'Cheng Qiao', 'Tie Cai', 'Junwei Liao', 'Neil J. Hurley', 'Guangyuan Piao']",{'name': 'Guangyuan Piao'},Guangyuan Piao,,"[{'href': 'http://arxiv.org/abs/2502.14281v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14281v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14281v1,None,http://arxiv.org/abs/2502.14281v1,,,429,0
http://arxiv.org/abs/2502.14301v1,True,2025-02-20T06:32:45Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=6, tm_min=32, tm_sec=45, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T06:32:45Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=6, tm_min=32, tm_sec=45, tm_wday=3, tm_yday=51, tm_isdst=0)",SEA-HELM: Southeast Asian Holistic Evaluation of Language Models,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'SEA-HELM: Southeast Asian Holistic Evaluation of Language Models'}","With the rapid emergence of novel capabilities in Large Language Models
(LLMs), the need for rigorous multilingual and multicultural benchmarks that
are integrated has become more pronounced. Though existing LLM benchmarks are
capable of evaluating specific capabilities of LLMs in English as well as in
various mid- to low-resource languages, including those in the Southeast Asian
(SEA) region, a comprehensive and authentic evaluation suite for the SEA
languages has not been developed thus far. Here, we present SEA-HELM, a
holistic linguistic and cultural LLM evaluation suite that emphasizes SEA
languages, comprising five core pillars: (1) NLP Classics, (2) LLM-specifics,
(3) SEA Linguistics, (4) SEA Culture, (5) Safety. SEA-HELM currently supports
Filipino, Indonesian, Tamil, Thai, and Vietnamese. We also introduce the
SEA-HELM leaderboard, which allows users to understand models' multilingual and
multicultural performance in a systematic and user-friendly manner.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""With the rapid emergence of novel capabilities in Large Language Models\n(LLMs), the need for rigorous multilingual and multicultural benchmarks that\nare integrated has become more pronounced. Though existing LLM benchmarks are\ncapable of evaluating specific capabilities of LLMs in English as well as in\nvarious mid- to low-resource languages, including those in the Southeast Asian\n(SEA) region, a comprehensive and authentic evaluation suite for the SEA\nlanguages has not been developed thus far. Here, we present SEA-HELM, a\nholistic linguistic and cultural LLM evaluation suite that emphasizes SEA\nlanguages, comprising five core pillars: (1) NLP Classics, (2) LLM-specifics,\n(3) SEA Linguistics, (4) SEA Culture, (5) Safety. SEA-HELM currently supports\nFilipino, Indonesian, Tamil, Thai, and Vietnamese. We also introduce the\nSEA-HELM leaderboard, which allows users to understand models' multilingual and\nmulticultural performance in a systematic and user-friendly manner.""}","['Yosephine Susanto', 'Adithya Venkatadri Hulagadri', 'Jann Railey Montalan', 'Jian Gang Ngui', 'Xian Bin Yong', 'Weiqi Leong', 'Hamsawardhini Rengarajan', 'Peerat Limkonchotiwat', 'Yifan Mai', 'William Chandra Tjhi']",{'name': 'William Chandra Tjhi'},William Chandra Tjhi,,"[{'href': 'http://arxiv.org/abs/2502.14301v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14301v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14301v1,None,http://arxiv.org/abs/2502.14301v1,,,617,0
http://arxiv.org/abs/2502.14316v1,True,2025-02-20T07:02:22Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=7, tm_min=2, tm_sec=22, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T07:02:22Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=7, tm_min=2, tm_sec=22, tm_wday=3, tm_yday=51, tm_isdst=0)",Textured 3D Regenerative Morphing with 3D Diffusion Prior,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Textured 3D Regenerative Morphing with 3D Diffusion Prior'}","Textured 3D morphing creates smooth and plausible interpolation sequences
between two 3D objects, focusing on transitions in both shape and texture. This
is important for creative applications like visual effects in filmmaking.
Previous methods rely on establishing point-to-point correspondences and
determining smooth deformation trajectories, which inherently restrict them to
shape-only morphing on untextured, topologically aligned datasets. This
restriction leads to labor-intensive preprocessing and poor generalization. To
overcome these challenges, we propose a method for 3D regenerative morphing
using a 3D diffusion prior. Unlike previous methods that depend on explicit
correspondences and deformations, our method eliminates the additional need for
obtaining correspondence and uses the 3D diffusion prior to generate morphing.
Specifically, we introduce a 3D diffusion model and interpolate the source and
target information at three levels: initial noise, model parameters, and
condition features. We then explore an Attention Fusion strategy to generate
more smooth morphing sequences. To further improve the plausibility of semantic
interpolation and the generated 3D surfaces, we propose two strategies: (a)
Token Reordering, where we match approximate tokens based on semantic analysis
to guide implicit correspondences in the denoising process of the diffusion
model, and (b) Low-Frequency Enhancement, where we enhance low-frequency
signals in the tokens to improve the quality of generated surfaces.
Experimental results show that our method achieves superior smoothness and
plausibility in 3D morphing across diverse cross-category object pairs,
offering a novel regenerative method for 3D morphing with textured
representations.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Textured 3D morphing creates smooth and plausible interpolation sequences\nbetween two 3D objects, focusing on transitions in both shape and texture. This\nis important for creative applications like visual effects in filmmaking.\nPrevious methods rely on establishing point-to-point correspondences and\ndetermining smooth deformation trajectories, which inherently restrict them to\nshape-only morphing on untextured, topologically aligned datasets. This\nrestriction leads to labor-intensive preprocessing and poor generalization. To\novercome these challenges, we propose a method for 3D regenerative morphing\nusing a 3D diffusion prior. Unlike previous methods that depend on explicit\ncorrespondences and deformations, our method eliminates the additional need for\nobtaining correspondence and uses the 3D diffusion prior to generate morphing.\nSpecifically, we introduce a 3D diffusion model and interpolate the source and\ntarget information at three levels: initial noise, model parameters, and\ncondition features. We then explore an Attention Fusion strategy to generate\nmore smooth morphing sequences. To further improve the plausibility of semantic\ninterpolation and the generated 3D surfaces, we propose two strategies: (a)\nToken Reordering, where we match approximate tokens based on semantic analysis\nto guide implicit correspondences in the denoising process of the diffusion\nmodel, and (b) Low-Frequency Enhancement, where we enhance low-frequency\nsignals in the tokens to improve the quality of generated surfaces.\nExperimental results show that our method achieves superior smoothness and\nplausibility in 3D morphing across diverse cross-category object pairs,\noffering a novel regenerative method for 3D morphing with textured\nrepresentations.'}","['Songlin Yang', 'Yushi Lan', 'Honghua Chen', 'Xingang Pan']",{'name': 'Xingang Pan'},Xingang Pan,,"[{'href': 'http://arxiv.org/abs/2502.14316v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14316v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14316v1,None,http://arxiv.org/abs/2502.14316v1,,,5,0
http://arxiv.org/abs/2502.14333v1,True,2025-02-20T07:31:00Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=7, tm_min=31, tm_sec=0, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T07:31:00Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=7, tm_min=31, tm_sec=0, tm_wday=3, tm_yday=51, tm_isdst=0)","A Survey on Feedback-based Multi-step Reasoning for Large Language
  Models on Mathematics","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A Survey on Feedback-based Multi-step Reasoning for Large Language\n  Models on Mathematics'}","Recent progress in large language models (LLM) found chain-of-thought
prompting strategies to improve the reasoning ability of LLMs by encouraging
problem solving through multiple steps. Therefore, subsequent research aimed to
integrate the multi-step reasoning process into the LLM itself through process
rewards as feedback and achieved improvements over prompting strategies. Due to
the cost of step-level annotation, some turn to outcome rewards as feedback.
Aside from these training-based approaches, training-free techniques leverage
frozen LLMs or external tools for feedback at each step to enhance the
reasoning process. With the abundance of work in mathematics due to its logical
nature, we present a survey of strategies utilizing feedback at the step and
outcome levels to enhance multi-step math reasoning for LLMs. As multi-step
reasoning emerges a crucial component in scaling LLMs, we hope to establish its
foundation for easier understanding and empower further research.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Recent progress in large language models (LLM) found chain-of-thought\nprompting strategies to improve the reasoning ability of LLMs by encouraging\nproblem solving through multiple steps. Therefore, subsequent research aimed to\nintegrate the multi-step reasoning process into the LLM itself through process\nrewards as feedback and achieved improvements over prompting strategies. Due to\nthe cost of step-level annotation, some turn to outcome rewards as feedback.\nAside from these training-based approaches, training-free techniques leverage\nfrozen LLMs or external tools for feedback at each step to enhance the\nreasoning process. With the abundance of work in mathematics due to its logical\nnature, we present a survey of strategies utilizing feedback at the step and\noutcome levels to enhance multi-step math reasoning for LLMs. As multi-step\nreasoning emerges a crucial component in scaling LLMs, we hope to establish its\nfoundation for easier understanding and empower further research.'}","['Ting-Ruen Wei', 'Haowei Liu', 'Xuyang Wu', 'Yi Fang']",{'name': 'Yi Fang'},Yi Fang,,"[{'href': 'http://arxiv.org/abs/2502.14333v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14333v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14333v1,None,http://arxiv.org/abs/2502.14333v1,,,15,0
http://arxiv.org/abs/2502.14334v1,True,2025-02-20T07:42:16Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=7, tm_min=42, tm_sec=16, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T07:42:16Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=7, tm_min=42, tm_sec=16, tm_wday=3, tm_yday=51, tm_isdst=0)",Purest Quantum State Identification,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Purest Quantum State Identification'}","Precise identification of quantum states under noise constraints is essential
for quantum information processing. In this study, we generalize the classical
best arm identification problem to quantum domains, designing methods for
identifying the purest one within $K$ unknown $n$-qubit quantum states using
$N$ samples. %, with direct applications in quantum computation and quantum
communication. We propose two distinct algorithms: (1) an algorithm employing
incoherent measurements, achieving error $\exp\left(- \Omega\left(\frac{N
H_1}{\log(K) 2^n }\right) \right)$, and (2) an algorithm utilizing coherent
measurements, achieving error $\exp\left(- \Omega\left(\frac{N H_2}{\log(K)
}\right) \right)$, highlighting the power of quantum memory. Furthermore, we
establish a lower bound by proving that all strategies with fixed two-outcome
incoherent POVM must suffer error probability exceeding $ \exp\left( -
O\left(\frac{NH_1}{2^n}\right)\right)$. This framework provides concrete design
principles for overcoming sampling bottlenecks in quantum technologies.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Precise identification of quantum states under noise constraints is essential\nfor quantum information processing. In this study, we generalize the classical\nbest arm identification problem to quantum domains, designing methods for\nidentifying the purest one within $K$ unknown $n$-qubit quantum states using\n$N$ samples. %, with direct applications in quantum computation and quantum\ncommunication. We propose two distinct algorithms: (1) an algorithm employing\nincoherent measurements, achieving error $\\exp\\left(- \\Omega\\left(\\frac{N\nH_1}{\\log(K) 2^n }\\right) \\right)$, and (2) an algorithm utilizing coherent\nmeasurements, achieving error $\\exp\\left(- \\Omega\\left(\\frac{N H_2}{\\log(K)\n}\\right) \\right)$, highlighting the power of quantum memory. Furthermore, we\nestablish a lower bound by proving that all strategies with fixed two-outcome\nincoherent POVM must suffer error probability exceeding $ \\exp\\left( -\nO\\left(\\frac{NH_1}{2^n}\\right)\\right)$. This framework provides concrete design\nprinciples for overcoming sampling bottlenecks in quantum technologies.'}","['Yingqi Yu', 'Honglin Chen', 'Jun Wu', 'Wei Xie', 'Xiangyang Li']",{'name': 'Xiangyang Li'},Xiangyang Li,,"[{'href': 'http://arxiv.org/abs/2502.14334v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14334v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'quant-ph', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'quant-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14334v1,None,http://arxiv.org/abs/2502.14334v1,,,0,0
http://arxiv.org/abs/2502.14361v1,True,2025-02-20T08:40:09Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=8, tm_min=40, tm_sec=9, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T08:40:09Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=8, tm_min=40, tm_sec=9, tm_wday=3, tm_yday=51, tm_isdst=0)","Retrieval-Augmented Process Reward Model for Generalizable Mathematical
  Reasoning","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Retrieval-Augmented Process Reward Model for Generalizable Mathematical\n  Reasoning'}","While large language models (LLMs) have significantly advanced mathematical
reasoning, Process Reward Models (PRMs) have been developed to evaluate the
logical validity of reasoning steps. However, PRMs still struggle with
out-of-distribution (OOD) challenges. This paper identifies key OOD issues,
including step OOD, caused by differences in reasoning patterns across model
types and sizes, and question OOD, which arises from dataset shifts between
training data and real-world problems. To address these issues, we introduce
Retrieval-Augmented Process Reward Model (RetrievalPRM), a novel framework
designed to tackle these OOD issues. By utilizing a two-stage
retrieval-enhanced mechanism, RetrievalPRM retrieves semantically similar
questions and steps as a warmup, enhancing PRM's ability to evaluate target
steps and improving generalization and reasoning consistency across different
models and problem types. Our extensive experiments demonstrate that
RetrievalPRM outperforms existing baselines across multiple real-world
datasets. Our open-source contributions include a retrieval-enhanced dataset, a
tuning framework for PRM training, and the RetrievalPRM model, establishing a
new standard for PRM performance.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""While large language models (LLMs) have significantly advanced mathematical\nreasoning, Process Reward Models (PRMs) have been developed to evaluate the\nlogical validity of reasoning steps. However, PRMs still struggle with\nout-of-distribution (OOD) challenges. This paper identifies key OOD issues,\nincluding step OOD, caused by differences in reasoning patterns across model\ntypes and sizes, and question OOD, which arises from dataset shifts between\ntraining data and real-world problems. To address these issues, we introduce\nRetrieval-Augmented Process Reward Model (RetrievalPRM), a novel framework\ndesigned to tackle these OOD issues. By utilizing a two-stage\nretrieval-enhanced mechanism, RetrievalPRM retrieves semantically similar\nquestions and steps as a warmup, enhancing PRM's ability to evaluate target\nsteps and improving generalization and reasoning consistency across different\nmodels and problem types. Our extensive experiments demonstrate that\nRetrievalPRM outperforms existing baselines across multiple real-world\ndatasets. Our open-source contributions include a retrieval-enhanced dataset, a\ntuning framework for PRM training, and the RetrievalPRM model, establishing a\nnew standard for PRM performance.""}","['Jiachen Zhu', 'Congmin Zheng', 'Jianghao Lin', 'Kounianhua Du', 'Ying Wen', 'Yong Yu', 'Jun Wang', 'Weinan Zhang']",{'name': 'Weinan Zhang'},Weinan Zhang,,"[{'href': 'http://arxiv.org/abs/2502.14361v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14361v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14361v1,None,http://arxiv.org/abs/2502.14361v1,,,531,0
http://arxiv.org/abs/2502.14365v1,True,2025-02-20T08:42:30Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=8, tm_min=42, tm_sec=30, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T08:42:30Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=8, tm_min=42, tm_sec=30, tm_wday=3, tm_yday=51, tm_isdst=0)",Is Q-learning an Ill-posed Problem?,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Is Q-learning an Ill-posed Problem?'}","This paper investigates the instability of Q-learning in continuous
environments, a challenge frequently encountered by practitioners.
Traditionally, this instability is attributed to bootstrapping and regression
model errors. Using a representative reinforcement learning benchmark, we
systematically examine the effects of bootstrapping and model inaccuracies by
incrementally eliminating these potential error sources. Our findings reveal
that even in relatively simple benchmarks, the fundamental task of Q-learning -
iteratively learning a Q-function from policy-specific target values - can be
inherently ill-posed and prone to failure. These insights cast doubt on the
reliability of Q-learning as a universal solution for reinforcement learning
problems.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'This paper investigates the instability of Q-learning in continuous\nenvironments, a challenge frequently encountered by practitioners.\nTraditionally, this instability is attributed to bootstrapping and regression\nmodel errors. Using a representative reinforcement learning benchmark, we\nsystematically examine the effects of bootstrapping and model inaccuracies by\nincrementally eliminating these potential error sources. Our findings reveal\nthat even in relatively simple benchmarks, the fundamental task of Q-learning -\niteratively learning a Q-function from policy-specific target values - can be\ninherently ill-posed and prone to failure. These insights cast doubt on the\nreliability of Q-learning as a universal solution for reinforcement learning\nproblems.'}","['Philipp Wissmann', 'Daniel Hein', 'Steffen Udluft', 'Thomas Runkler']",{'name': 'Thomas Runkler'},Thomas Runkler,Accepted at ESANN 2025,"[{'href': 'http://arxiv.org/abs/2502.14365v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14365v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14365v1,None,http://arxiv.org/abs/2502.14365v1,,,2119,0
http://arxiv.org/abs/2502.14366v1,True,2025-02-20T08:42:47Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=8, tm_min=42, tm_sec=47, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T08:42:47Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=8, tm_min=42, tm_sec=47, tm_wday=3, tm_yday=51, tm_isdst=0)",Entropy-UID: A Method for Optimizing Information Density,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Entropy-UID: A Method for Optimizing Information Density'}","Balanced and efficient information flow is essential for optimizing language
generation models. In this work, we propose Entropy-UID, a new token selection
method that balances entropy and Uniform Information Density (UID) principles
for enhanced efficiency of text generation. Our approach adaptively adjusts
token selection by jointly minimizing entropy and surprisal, promoting more
even information distribution across generated sequences. Theoretical
validation demonstrates that Entropy-UID optimally reduces information spikes
while maintaining fluency and coherence. The method has been evulated using
information-theoretic metrics on multiple benchmark datasets, including
WikiText-2, OpenWebText, and WMT. Experimental results show that Entropy-UID
achieves lower surprisal and entropy variance compared to standard GPT-2 and
alternative heuristics, leading to more balanced and human-like text
generation. Our findings point towards the potential of leveraging
information-theoretic constraints to refine token selection strategies in
autoregressive language models.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Balanced and efficient information flow is essential for optimizing language\ngeneration models. In this work, we propose Entropy-UID, a new token selection\nmethod that balances entropy and Uniform Information Density (UID) principles\nfor enhanced efficiency of text generation. Our approach adaptively adjusts\ntoken selection by jointly minimizing entropy and surprisal, promoting more\neven information distribution across generated sequences. Theoretical\nvalidation demonstrates that Entropy-UID optimally reduces information spikes\nwhile maintaining fluency and coherence. The method has been evulated using\ninformation-theoretic metrics on multiple benchmark datasets, including\nWikiText-2, OpenWebText, and WMT. Experimental results show that Entropy-UID\nachieves lower surprisal and entropy variance compared to standard GPT-2 and\nalternative heuristics, leading to more balanced and human-like text\ngeneration. Our findings point towards the potential of leveraging\ninformation-theoretic constraints to refine token selection strategies in\nautoregressive language models.'}",['Xinpeng Shou'],{'name': 'Xinpeng Shou'},Xinpeng Shou,"5pages, 1 figures, submitting to ACL 2025","[{'href': 'http://arxiv.org/abs/2502.14366v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14366v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14366v1,None,http://arxiv.org/abs/2502.14366v1,,,0,0
http://arxiv.org/abs/2502.14382v1,True,2025-02-20T09:18:53Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=9, tm_min=18, tm_sec=53, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T09:18:53Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=9, tm_min=18, tm_sec=53, tm_wday=3, tm_yday=51, tm_isdst=0)",S*: Test Time Scaling for Code Generation,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'S*: Test Time Scaling for Code Generation'}","Increasing test-time compute for LLMs shows promise across domains but
remains underexplored in code generation, despite extensive study in math. In
this paper, we propose S*, the first hybrid test-time scaling framework that
substantially improves the coverage and selection accuracy of generated code.
S* extends the existing parallel scaling paradigm with sequential scaling to
push performance boundaries. It further leverages a novel selection mechanism
that adaptively generates distinguishing inputs for pairwise comparison,
combined with execution-grounded information to robustly identify correct
solutions. We evaluate across 12 Large Language Models and Large Reasoning
Model and show: (1) S* consistently improves performance across model families
and sizes, enabling a 3B model to outperform GPT-4o-mini; (2) S* enables
non-reasoning models to surpass reasoning models - GPT-4o-mini with S*
outperforms o1-preview by 3.7% on LiveCodeBench; (3) S* further boosts
state-of-the-art reasoning models - DeepSeek-R1-Distill-Qwen-32B with S*
achieves 85.7% on LiveCodeBench, approaching o1 (high) at 88.5%. Code will be
available under https://github.com/NovaSky-AI/SkyThought.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Increasing test-time compute for LLMs shows promise across domains but\nremains underexplored in code generation, despite extensive study in math. In\nthis paper, we propose S*, the first hybrid test-time scaling framework that\nsubstantially improves the coverage and selection accuracy of generated code.\nS* extends the existing parallel scaling paradigm with sequential scaling to\npush performance boundaries. It further leverages a novel selection mechanism\nthat adaptively generates distinguishing inputs for pairwise comparison,\ncombined with execution-grounded information to robustly identify correct\nsolutions. We evaluate across 12 Large Language Models and Large Reasoning\nModel and show: (1) S* consistently improves performance across model families\nand sizes, enabling a 3B model to outperform GPT-4o-mini; (2) S* enables\nnon-reasoning models to surpass reasoning models - GPT-4o-mini with S*\noutperforms o1-preview by 3.7% on LiveCodeBench; (3) S* further boosts\nstate-of-the-art reasoning models - DeepSeek-R1-Distill-Qwen-32B with S*\nachieves 85.7% on LiveCodeBench, approaching o1 (high) at 88.5%. Code will be\navailable under https://github.com/NovaSky-AI/SkyThought.'}","['Dacheng Li', 'Shiyi Cao', 'Chengkun Cao', 'Xiuyu Li', 'Shangyin Tan', 'Kurt Keutzer', 'Jiarong Xing', 'Joseph E. Gonzalez', 'Ion Stoica']",{'name': 'Ion Stoica'},Ion Stoica,,"[{'href': 'http://arxiv.org/abs/2502.14382v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14382v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14382v1,None,http://arxiv.org/abs/2502.14382v1,,,2468,0
http://arxiv.org/abs/2502.14442v1,True,2025-02-20T10:48:49Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=10, tm_min=48, tm_sec=49, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T10:48:49Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=10, tm_min=48, tm_sec=49, tm_wday=3, tm_yday=51, tm_isdst=0)","Stochastic Resonance Improves the Detection of Low Contrast Images in
  Deep Learning Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Stochastic Resonance Improves the Detection of Low Contrast Images in\n  Deep Learning Models'}","Stochastic resonance describes the utility of noise in improving the
detectability of weak signals in certain types of systems. It has been observed
widely in natural and engineered settings, but its utility in image
classification with rate-based neural networks has not been studied
extensively. In this analysis a simple LSTM recurrent neural network is trained
for digit recognition and classification. During the test phase, image contrast
is reduced to a point where the model fails to recognize the presence of a
stimulus. Controlled noise is added to partially recover classification
performance. The results indicate the presence of stochastic resonance in
rate-based recurrent neural networks.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Stochastic resonance describes the utility of noise in improving the\ndetectability of weak signals in certain types of systems. It has been observed\nwidely in natural and engineered settings, but its utility in image\nclassification with rate-based neural networks has not been studied\nextensively. In this analysis a simple LSTM recurrent neural network is trained\nfor digit recognition and classification. During the test phase, image contrast\nis reduced to a point where the model fails to recognize the presence of a\nstimulus. Controlled noise is added to partially recover classification\nperformance. The results indicate the presence of stochastic resonance in\nrate-based recurrent neural networks.'}",['Siegfried Ludwig'],{'name': 'Siegfried Ludwig'},Siegfried Ludwig,MSc Course Project,"[{'href': 'http://arxiv.org/abs/2502.14442v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14442v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14442v1,None,http://arxiv.org/abs/2502.14442v1,,,0,0
http://arxiv.org/abs/2502.14455v1,True,2025-02-20T11:14:55Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=11, tm_min=14, tm_sec=55, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T11:14:55Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=11, tm_min=14, tm_sec=55, tm_wday=3, tm_yday=51, tm_isdst=0)","An Efficient Ground-aerial Transportation System for Pest Control
  Enabled by AI-based Autonomous Nano-UAVs","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'An Efficient Ground-aerial Transportation System for Pest Control\n  Enabled by AI-based Autonomous Nano-UAVs'}","Efficient crop production requires early detection of pest outbreaks and
timely treatments; we consider a solution based on a fleet of multiple
autonomous miniaturized unmanned aerial vehicles (nano-UAVs) to visually detect
pests and a single slower heavy vehicle that visits the detected outbreaks to
deliver treatments. To cope with the extreme limitations aboard nano-UAVs,
e.g., low-resolution sensors and sub-100 mW computational power budget, we
design, fine-tune, and optimize a tiny image-based convolutional neural network
(CNN) for pest detection. Despite the small size of our CNN (i.e., 0.58
GOps/inference), on our dataset, it scores a mean average precision (mAP) of
0.79 in detecting harmful bugs, i.e., 14% lower mAP but 32x fewer operations
than the best-performing CNN in the literature. Our CNN runs in real-time at
6.8 frame/s, requiring 33 mW on a GWT GAP9 System-on-Chip aboard a Crazyflie
nano-UAV. Then, to cope with in-field unexpected obstacles, we leverage a
global+local path planner based on the A* algorithm. The global path planner
determines the best route for the nano-UAV to sweep the entire area, while the
local one runs up to 50 Hz aboard our nano-UAV and prevents collision by
adjusting the short-distance path. Finally, we demonstrate with in-simulator
experiments that once a 25 nano-UAVs fleet has combed a 200x200 m vineyard,
collected information can be used to plan the best path for the tractor,
visiting all and only required hotspots. In this scenario, our efficient
transportation system, compared to a traditional single-ground vehicle
performing both inspection and treatment, can save up to 20 h working time.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Efficient crop production requires early detection of pest outbreaks and\ntimely treatments; we consider a solution based on a fleet of multiple\nautonomous miniaturized unmanned aerial vehicles (nano-UAVs) to visually detect\npests and a single slower heavy vehicle that visits the detected outbreaks to\ndeliver treatments. To cope with the extreme limitations aboard nano-UAVs,\ne.g., low-resolution sensors and sub-100 mW computational power budget, we\ndesign, fine-tune, and optimize a tiny image-based convolutional neural network\n(CNN) for pest detection. Despite the small size of our CNN (i.e., 0.58\nGOps/inference), on our dataset, it scores a mean average precision (mAP) of\n0.79 in detecting harmful bugs, i.e., 14% lower mAP but 32x fewer operations\nthan the best-performing CNN in the literature. Our CNN runs in real-time at\n6.8 frame/s, requiring 33 mW on a GWT GAP9 System-on-Chip aboard a Crazyflie\nnano-UAV. Then, to cope with in-field unexpected obstacles, we leverage a\nglobal+local path planner based on the A* algorithm. The global path planner\ndetermines the best route for the nano-UAV to sweep the entire area, while the\nlocal one runs up to 50 Hz aboard our nano-UAV and prevents collision by\nadjusting the short-distance path. Finally, we demonstrate with in-simulator\nexperiments that once a 25 nano-UAVs fleet has combed a 200x200 m vineyard,\ncollected information can be used to plan the best path for the tractor,\nvisiting all and only required hotspots. In this scenario, our efficient\ntransportation system, compared to a traditional single-ground vehicle\nperforming both inspection and treatment, can save up to 20 h working time.'}","['Luca Crupi', 'Luca Butera', 'Alberto Ferrante', 'Alessandro Giusti', 'Daniele Palossi']",{'name': 'Daniele Palossi'},Daniele Palossi,,"[{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3719210', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2502.14455v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14455v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14455v1,None,http://arxiv.org/abs/2502.14455v1,,10.1145/3719210,714,0
http://arxiv.org/abs/2502.14458v1,True,2025-02-20T11:18:39Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=11, tm_min=18, tm_sec=39, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T11:18:39Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=11, tm_min=18, tm_sec=39, tm_wday=3, tm_yday=51, tm_isdst=0)","Llamba: Scaling Distilled Recurrent Models for Efficient Language
  Processing","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Llamba: Scaling Distilled Recurrent Models for Efficient Language\n  Processing'}","We introduce Llamba, a family of efficient recurrent language models
distilled from Llama-3.x into the Mamba architecture. The series includes
Llamba-1B, Llamba-3B, and Llamba-8B, which achieve higher inference throughput
and handle significantly larger batch sizes than Transformer-based models while
maintaining comparable benchmark performance. Furthermore, Llamba demonstrates
the effectiveness of cross-architecture distillation using MOHAWK (Bick et al.,
2024), achieving these results with less than 0.1% of the training data
typically used for models of similar size. To take full advantage of their
efficiency, we provide an optimized implementation of Llamba for
resource-constrained devices such as smartphones and edge platforms, offering a
practical and memory-efficient alternative to Transformers. Overall, Llamba
improves the tradeoff between speed, memory efficiency, and performance, making
high-quality language models more accessible.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'We introduce Llamba, a family of efficient recurrent language models\ndistilled from Llama-3.x into the Mamba architecture. The series includes\nLlamba-1B, Llamba-3B, and Llamba-8B, which achieve higher inference throughput\nand handle significantly larger batch sizes than Transformer-based models while\nmaintaining comparable benchmark performance. Furthermore, Llamba demonstrates\nthe effectiveness of cross-architecture distillation using MOHAWK (Bick et al.,\n2024), achieving these results with less than 0.1% of the training data\ntypically used for models of similar size. To take full advantage of their\nefficiency, we provide an optimized implementation of Llamba for\nresource-constrained devices such as smartphones and edge platforms, offering a\npractical and memory-efficient alternative to Transformers. Overall, Llamba\nimproves the tradeoff between speed, memory efficiency, and performance, making\nhigh-quality language models more accessible.'}","['Aviv Bick', 'Tobias Katsch', 'Nimit Sohoni', 'Arjun Desai', 'Albert Gu']",{'name': 'Albert Gu'},Albert Gu,,"[{'href': 'http://arxiv.org/abs/2502.14458v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14458v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14458v1,None,http://arxiv.org/abs/2502.14458v1,,,1332,0
http://arxiv.org/abs/2502.14504v1,True,2025-02-20T12:31:31Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=12, tm_min=31, tm_sec=31, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T12:31:31Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=12, tm_min=31, tm_sec=31, tm_wday=3, tm_yday=51, tm_isdst=0)","PLPHP: Per-Layer Per-Head Vision Token Pruning for Efficient Large
  Vision-Language Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'PLPHP: Per-Layer Per-Head Vision Token Pruning for Efficient Large\n  Vision-Language Models'}","Large Vision-Language Models (LVLMs) have demonstrated remarkable
capabilities across a range of multimodal tasks. However, their inference
efficiency is constrained by the large number of visual tokens processed during
decoding. To address this challenge, we propose Per-Layer Per-Head Vision Token
Pruning (PLPHP), a two-level fine-grained pruning method including Layer-Level
Retention Rate Allocation and Head-Level Vision Token Pruning. Motivated by the
Vision Token Re-attention phenomenon across decoder layers, we dynamically
adjust token retention rates layer by layer. Layers that exhibit stronger
attention to visual information preserve more vision tokens, while layers with
lower vision attention are aggressively pruned. Furthermore, PLPHP applies
pruning at the attention head level, enabling different heads within the same
layer to independently retain critical context. Experiments on multiple
benchmarks demonstrate that PLPHP delivers an 18% faster decoding speed and
reduces the Key-Value Cache (KV Cache) size by over 50%, all at the cost of
0.46% average performance drop, while also achieving notable performance
improvements in multi-image tasks. These results highlight the effectiveness of
fine-grained token pruning and contribute to advancing the efficiency and
scalability of LVLMs. Our source code will be made publicly available.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Vision-Language Models (LVLMs) have demonstrated remarkable\ncapabilities across a range of multimodal tasks. However, their inference\nefficiency is constrained by the large number of visual tokens processed during\ndecoding. To address this challenge, we propose Per-Layer Per-Head Vision Token\nPruning (PLPHP), a two-level fine-grained pruning method including Layer-Level\nRetention Rate Allocation and Head-Level Vision Token Pruning. Motivated by the\nVision Token Re-attention phenomenon across decoder layers, we dynamically\nadjust token retention rates layer by layer. Layers that exhibit stronger\nattention to visual information preserve more vision tokens, while layers with\nlower vision attention are aggressively pruned. Furthermore, PLPHP applies\npruning at the attention head level, enabling different heads within the same\nlayer to independently retain critical context. Experiments on multiple\nbenchmarks demonstrate that PLPHP delivers an 18% faster decoding speed and\nreduces the Key-Value Cache (KV Cache) size by over 50%, all at the cost of\n0.46% average performance drop, while also achieving notable performance\nimprovements in multi-image tasks. These results highlight the effectiveness of\nfine-grained token pruning and contribute to advancing the efficiency and\nscalability of LVLMs. Our source code will be made publicly available.'}","['Yu Meng', 'Kaiyuan Li', 'Chenran Huang', 'Chen Gao', 'Xinlei Chen', 'Yong Li', 'Xiaoping Zhang']",{'name': 'Xiaoping Zhang'},Xiaoping Zhang,"12 pages, 8 figures","[{'href': 'http://arxiv.org/abs/2502.14504v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14504v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14504v1,None,http://arxiv.org/abs/2502.14504v1,,,0,0
http://arxiv.org/abs/2502.14525v1,True,2025-02-20T13:00:31Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=13, tm_min=0, tm_sec=31, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T13:00:31Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=13, tm_min=0, tm_sec=31, tm_wday=3, tm_yday=51, tm_isdst=0)","Small Graph Is All You Need: DeepStateGNN for Scalable Traffic
  Forecasting","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Small Graph Is All You Need: DeepStateGNN for Scalable Traffic\n  Forecasting'}","We propose a novel Graph Neural Network (GNN) model, named DeepStateGNN, for
analyzing traffic data, demonstrating its efficacy in two critical tasks:
forecasting and reconstruction. Unlike typical GNN methods that treat each
traffic sensor as an individual graph node, DeepStateGNN clusters sensors into
higher-level graph nodes, dubbed Deep State Nodes, based on various similarity
criteria, resulting in a fixed number of nodes in a Deep State graph. The term
""Deep State"" nodes is a play on words, referencing hidden networks of power
that, like these nodes, secretly govern traffic independently of visible
sensors. These Deep State Nodes are defined by several similarity factors,
including spatial proximity (e.g., sensors located nearby in the road network),
functional similarity (e.g., sensors on similar types of freeways), and
behavioral similarity under specific conditions (e.g., traffic behavior during
rain). This clustering approach allows for dynamic and adaptive node grouping,
as sensors can belong to multiple clusters and clusters may evolve over time.
Our experimental results show that DeepStateGNN offers superior scalability and
faster training, while also delivering more accurate results than competitors.
It effectively handles large-scale sensor networks, outperforming other methods
in both traffic forecasting and reconstruction accuracy.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'We propose a novel Graph Neural Network (GNN) model, named DeepStateGNN, for\nanalyzing traffic data, demonstrating its efficacy in two critical tasks:\nforecasting and reconstruction. Unlike typical GNN methods that treat each\ntraffic sensor as an individual graph node, DeepStateGNN clusters sensors into\nhigher-level graph nodes, dubbed Deep State Nodes, based on various similarity\ncriteria, resulting in a fixed number of nodes in a Deep State graph. The term\n""Deep State"" nodes is a play on words, referencing hidden networks of power\nthat, like these nodes, secretly govern traffic independently of visible\nsensors. These Deep State Nodes are defined by several similarity factors,\nincluding spatial proximity (e.g., sensors located nearby in the road network),\nfunctional similarity (e.g., sensors on similar types of freeways), and\nbehavioral similarity under specific conditions (e.g., traffic behavior during\nrain). This clustering approach allows for dynamic and adaptive node grouping,\nas sensors can belong to multiple clusters and clusters may evolve over time.\nOur experimental results show that DeepStateGNN offers superior scalability and\nfaster training, while also delivering more accurate results than competitors.\nIt effectively handles large-scale sensor networks, outperforming other methods\nin both traffic forecasting and reconstruction accuracy.'}","['Yannick Wlker', 'Arash Hajisafi', 'Cyrus Shahabi', 'Matthias Renz']",{'name': 'Matthias Renz'},Matthias Renz,"Yannick W\""olker and Arash Hajisafi contributed equally to this work","[{'href': 'http://arxiv.org/abs/2502.14525v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14525v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14525v1,None,http://arxiv.org/abs/2502.14525v1,,,38,0
http://arxiv.org/abs/2502.14529v1,True,2025-02-20T13:02:00Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=13, tm_min=2, tm_sec=0, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T13:02:00Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=13, tm_min=2, tm_sec=0, tm_wday=3, tm_yday=51, tm_isdst=0)","CORBA: Contagious Recursive Blocking Attacks on Multi-Agent Systems
  Based on Large Language Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'CORBA: Contagious Recursive Blocking Attacks on Multi-Agent Systems\n  Based on Large Language Models'}","Large Language Model-based Multi-Agent Systems (LLM-MASs) have demonstrated
remarkable real-world capabilities, effectively collaborating to complete
complex tasks. While these systems are designed with safety mechanisms, such as
rejecting harmful instructions through alignment, their security remains
largely unexplored. This gap leaves LLM-MASs vulnerable to targeted
disruptions. In this paper, we introduce Contagious Recursive Blocking Attacks
(Corba), a novel and simple yet highly effective attack that disrupts
interactions between agents within an LLM-MAS. Corba leverages two key
properties: its contagious nature allows it to propagate across arbitrary
network topologies, while its recursive property enables sustained depletion of
computational resources. Notably, these blocking attacks often involve
seemingly benign instructions, making them particularly challenging to mitigate
using conventional alignment methods. We evaluate Corba on two widely-used
LLM-MASs, namely, AutoGen and Camel across various topologies and commercial
models. Additionally, we conduct more extensive experiments in open-ended
interactive LLM-MASs, demonstrating the effectiveness of Corba in complex
topology structures and open-source models. Our code is available at:
https://github.com/zhrli324/Corba.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Language Model-based Multi-Agent Systems (LLM-MASs) have demonstrated\nremarkable real-world capabilities, effectively collaborating to complete\ncomplex tasks. While these systems are designed with safety mechanisms, such as\nrejecting harmful instructions through alignment, their security remains\nlargely unexplored. This gap leaves LLM-MASs vulnerable to targeted\ndisruptions. In this paper, we introduce Contagious Recursive Blocking Attacks\n(Corba), a novel and simple yet highly effective attack that disrupts\ninteractions between agents within an LLM-MAS. Corba leverages two key\nproperties: its contagious nature allows it to propagate across arbitrary\nnetwork topologies, while its recursive property enables sustained depletion of\ncomputational resources. Notably, these blocking attacks often involve\nseemingly benign instructions, making them particularly challenging to mitigate\nusing conventional alignment methods. We evaluate Corba on two widely-used\nLLM-MASs, namely, AutoGen and Camel across various topologies and commercial\nmodels. Additionally, we conduct more extensive experiments in open-ended\ninteractive LLM-MASs, demonstrating the effectiveness of Corba in complex\ntopology structures and open-source models. Our code is available at:\nhttps://github.com/zhrli324/Corba.'}","['Zhenhong Zhou', 'Zherui Li', 'Jie Zhang', 'Yuanhe Zhang', 'Kun Wang', 'Yang Liu', 'Qing Guo']",{'name': 'Qing Guo'},Qing Guo,,"[{'href': 'http://arxiv.org/abs/2502.14529v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14529v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14529v1,None,http://arxiv.org/abs/2502.14529v1,,,9,0
http://arxiv.org/abs/2502.14558v1,True,2025-02-20T13:38:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=13, tm_min=38, tm_sec=36, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T13:38:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=13, tm_min=38, tm_sec=36, tm_wday=3, tm_yday=51, tm_isdst=0)",FUIA: Model Inversion Attack against Federated Unlearning,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'FUIA: Model Inversion Attack against Federated Unlearning'}","With the introduction of regulations related to the ``right to be forgotten"",
federated learning (FL) is facing new privacy compliance challenges. To address
these challenges, researchers have proposed federated unlearning (FU). However,
existing FU research has primarily focused on improving the efficiency of
unlearning, with less attention paid to the potential privacy vulnerabilities
inherent in these methods. To address this gap, we draw inspiration from
gradient inversion attacks in FL and propose the federated unlearning inversion
attack (FUIA). The FUIA is specifically designed for the three types of FU
(sample unlearning, client unlearning, and class unlearning), aiming to provide
a comprehensive analysis of the privacy leakage risks associated with FU. In
FUIA, the server acts as an honest-but-curious attacker, recording and
exploiting the model differences before and after unlearning to expose the
features and labels of forgotten data. FUIA significantly leaks the privacy of
forgotten data and can target all types of FU. This attack contradicts the goal
of FU to eliminate specific data influence, instead exploiting its
vulnerabilities to recover forgotten data and expose its privacy flaws.
Extensive experimental results show that FUIA can effectively reveal the
private information of forgotten data. To mitigate this privacy leakage, we
also explore two potential defense methods, although these come at the cost of
reduced unlearning effectiveness and the usability of the unlearned model.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'With the introduction of regulations related to the ``right to be forgotten"",\nfederated learning (FL) is facing new privacy compliance challenges. To address\nthese challenges, researchers have proposed federated unlearning (FU). However,\nexisting FU research has primarily focused on improving the efficiency of\nunlearning, with less attention paid to the potential privacy vulnerabilities\ninherent in these methods. To address this gap, we draw inspiration from\ngradient inversion attacks in FL and propose the federated unlearning inversion\nattack (FUIA). The FUIA is specifically designed for the three types of FU\n(sample unlearning, client unlearning, and class unlearning), aiming to provide\na comprehensive analysis of the privacy leakage risks associated with FU. In\nFUIA, the server acts as an honest-but-curious attacker, recording and\nexploiting the model differences before and after unlearning to expose the\nfeatures and labels of forgotten data. FUIA significantly leaks the privacy of\nforgotten data and can target all types of FU. This attack contradicts the goal\nof FU to eliminate specific data influence, instead exploiting its\nvulnerabilities to recover forgotten data and expose its privacy flaws.\nExtensive experimental results show that FUIA can effectively reveal the\nprivate information of forgotten data. To mitigate this privacy leakage, we\nalso explore two potential defense methods, although these come at the cost of\nreduced unlearning effectiveness and the usability of the unlearned model.'}","['Lei Zhou', 'Youwen Zhu']",{'name': 'Youwen Zhu'},Youwen Zhu,Initial manuscript,"[{'href': 'http://arxiv.org/abs/2502.14558v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14558v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14558v1,None,http://arxiv.org/abs/2502.14558v1,,,0,0
http://arxiv.org/abs/2502.14572v1,True,2025-02-20T13:56:21Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=13, tm_min=56, tm_sec=21, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T13:56:21Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=13, tm_min=56, tm_sec=21, tm_wday=3, tm_yday=51, tm_isdst=0)",Factor Graph-based Interpretable Neural Networks,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Factor Graph-based Interpretable Neural Networks'}","Comprehensible neural network explanations are foundations for a better
understanding of decisions, especially when the input data are infused with
malicious perturbations. Existing solutions generally mitigate the impact of
perturbations through adversarial training, yet they fail to generate
comprehensible explanations under unknown perturbations. To address this
challenge, we propose AGAIN, a fActor GrAph-based Interpretable neural Network,
which is capable of generating comprehensible explanations under unknown
perturbations. Instead of retraining like previous solutions, the proposed
AGAIN directly integrates logical rules by which logical errors in explanations
are identified and rectified during inference. Specifically, we construct the
factor graph to express logical rules between explanations and categories. By
treating logical rules as exogenous knowledge, AGAIN can identify
incomprehensible explanations that violate real-world logic. Furthermore, we
propose an interactive intervention switch strategy rectifying explanations
based on the logical guidance from the factor graph without learning
perturbations, which overcomes the inherent limitation of adversarial
training-based methods in defending only against known perturbations.
Additionally, we theoretically demonstrate the effectiveness of employing
factor graph by proving that the comprehensibility of explanations is strongly
correlated with factor graph. Extensive experiments are conducted on three
datasets and experimental results illustrate the superior performance of AGAIN
compared to state-of-the-art baselines.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Comprehensible neural network explanations are foundations for a better\nunderstanding of decisions, especially when the input data are infused with\nmalicious perturbations. Existing solutions generally mitigate the impact of\nperturbations through adversarial training, yet they fail to generate\ncomprehensible explanations under unknown perturbations. To address this\nchallenge, we propose AGAIN, a fActor GrAph-based Interpretable neural Network,\nwhich is capable of generating comprehensible explanations under unknown\nperturbations. Instead of retraining like previous solutions, the proposed\nAGAIN directly integrates logical rules by which logical errors in explanations\nare identified and rectified during inference. Specifically, we construct the\nfactor graph to express logical rules between explanations and categories. By\ntreating logical rules as exogenous knowledge, AGAIN can identify\nincomprehensible explanations that violate real-world logic. Furthermore, we\npropose an interactive intervention switch strategy rectifying explanations\nbased on the logical guidance from the factor graph without learning\nperturbations, which overcomes the inherent limitation of adversarial\ntraining-based methods in defending only against known perturbations.\nAdditionally, we theoretically demonstrate the effectiveness of employing\nfactor graph by proving that the comprehensibility of explanations is strongly\ncorrelated with factor graph. Extensive experiments are conducted on three\ndatasets and experimental results illustrate the superior performance of AGAIN\ncompared to state-of-the-art baselines.'}","['Yicong Li', 'Kuanjiu Zhou', 'Shuo Yu', 'Qiang Zhang', 'Renqiang Luo', 'Xiaodong Li', 'Feng Xia']",{'name': 'Feng Xia'},Feng Xia,The Thirteenth International Conference on Learning Representations,"[{'href': 'http://arxiv.org/abs/2502.14572v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14572v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14572v1,None,http://arxiv.org/abs/2502.14572v1,,,26,0
http://arxiv.org/abs/2502.14583v1,True,2025-02-20T14:13:24Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=14, tm_min=13, tm_sec=24, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T14:13:24Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=14, tm_min=13, tm_sec=24, tm_wday=3, tm_yday=51, tm_isdst=0)",A Theory for Conditional Generative Modeling on Multiple Data Sources,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A Theory for Conditional Generative Modeling on Multiple Data Sources'}","The success of large generative models has driven a paradigm shift,
leveraging massive multi-source data to enhance model capabilities. However,
the interaction among these sources remains theoretically underexplored. This
paper takes the first step toward a rigorous analysis of multi-source training
in conditional generative modeling, where each condition represents a distinct
data source. Specifically, we establish a general distribution estimation error
bound in average total variation distance for conditional maximum likelihood
estimation based on the bracketing number. Our result shows that when source
distributions share certain similarities and the model is expressive enough,
multi-source training guarantees a sharper bound than single-source training.
We further instantiate the general theory on conditional Gaussian estimation
and deep generative models including autoregressive and flexible energy-based
models, by characterizing their bracketing numbers. The results highlight that
the number of sources and similarity among source distributions improve the
advantage of multi-source training. Simulations and real-world experiments
validate our theory. Code is available at:
\url{https://github.com/ML-GSAI/Multi-Source-GM}.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The success of large generative models has driven a paradigm shift,\nleveraging massive multi-source data to enhance model capabilities. However,\nthe interaction among these sources remains theoretically underexplored. This\npaper takes the first step toward a rigorous analysis of multi-source training\nin conditional generative modeling, where each condition represents a distinct\ndata source. Specifically, we establish a general distribution estimation error\nbound in average total variation distance for conditional maximum likelihood\nestimation based on the bracketing number. Our result shows that when source\ndistributions share certain similarities and the model is expressive enough,\nmulti-source training guarantees a sharper bound than single-source training.\nWe further instantiate the general theory on conditional Gaussian estimation\nand deep generative models including autoregressive and flexible energy-based\nmodels, by characterizing their bracketing numbers. The results highlight that\nthe number of sources and similarity among source distributions improve the\nadvantage of multi-source training. Simulations and real-world experiments\nvalidate our theory. Code is available at:\n\\url{https://github.com/ML-GSAI/Multi-Source-GM}.'}","['Rongzhen Wang', 'Yan Zhang', 'Chenyu Zheng', 'Chongxuan Li', 'Guoqiang Wu']",{'name': 'Guoqiang Wu'},Guoqiang Wu,35 pages,"[{'href': 'http://arxiv.org/abs/2502.14583v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14583v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14583v1,None,http://arxiv.org/abs/2502.14583v1,,,72,0
http://arxiv.org/abs/2502.14620v1,True,2025-02-20T14:58:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=14, tm_min=58, tm_sec=37, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T14:58:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=14, tm_min=58, tm_sec=37, tm_wday=3, tm_yday=51, tm_isdst=0)","Exploring RWKV for Sentence Embeddings: Layer-wise Analysis and Baseline
  Comparison for Semantic Similarity","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Exploring RWKV for Sentence Embeddings: Layer-wise Analysis and Baseline\n  Comparison for Semantic Similarity'}","This paper investigates the efficacy of RWKV, a novel language model
architecture known for its linear attention mechanism, for generating sentence
embeddings in a zero-shot setting. I conduct a layer-wise analysis to evaluate
the semantic similarity captured by embeddings from different hidden layers of
a pre-trained RWKV model. The performance is assessed on the Microsoft Research
Paraphrase Corpus (MRPC) dataset using Spearman correlation and compared
against a GloVe-based baseline. My results indicate that while RWKV embeddings
capture some semantic relatedness, they underperform compared to the GloVe
baseline in terms of Spearman correlation. I also analyze the inference time
and GPU memory usage, highlighting the computational trade-offs associated with
RWKV embeddings. The findings suggest that while RWKV offers potential
advantages in terms of linear scaling, its zero-shot sentence embedding quality
for semantic similarity tasks requires further investigation and potential
task-specific fine-tuning to match or exceed simpler baselines.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'This paper investigates the efficacy of RWKV, a novel language model\narchitecture known for its linear attention mechanism, for generating sentence\nembeddings in a zero-shot setting. I conduct a layer-wise analysis to evaluate\nthe semantic similarity captured by embeddings from different hidden layers of\na pre-trained RWKV model. The performance is assessed on the Microsoft Research\nParaphrase Corpus (MRPC) dataset using Spearman correlation and compared\nagainst a GloVe-based baseline. My results indicate that while RWKV embeddings\ncapture some semantic relatedness, they underperform compared to the GloVe\nbaseline in terms of Spearman correlation. I also analyze the inference time\nand GPU memory usage, highlighting the computational trade-offs associated with\nRWKV embeddings. The findings suggest that while RWKV offers potential\nadvantages in terms of linear scaling, its zero-shot sentence embedding quality\nfor semantic similarity tasks requires further investigation and potential\ntask-specific fine-tuning to match or exceed simpler baselines.'}",['Xinghan Pan'],{'name': 'Xinghan Pan'},Xinghan Pan,"17 pages, 3 tables, preprint on ArXiV, includes detailed analysis of
  RWKV for semantic similarity tasks","[{'href': 'http://arxiv.org/abs/2502.14620v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14620v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7; I.7.3', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14620v1,None,http://arxiv.org/abs/2502.14620v1,,,0,0
http://arxiv.org/abs/2502.14637v1,True,2025-02-20T15:20:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=15, tm_min=20, tm_sec=37, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T15:20:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=15, tm_min=20, tm_sec=37, tm_wday=3, tm_yday=51, tm_isdst=0)","ReQFlow: Rectified Quaternion Flow for Efficient and High-Quality
  Protein Backbone Generation","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'ReQFlow: Rectified Quaternion Flow for Efficient and High-Quality\n  Protein Backbone Generation'}","Protein backbone generation plays a central role in de novo protein design
and is significant for many biological and medical applications. Although
diffusion and flow-based generative models provide potential solutions to this
challenging task, they often generate proteins with undesired designability and
suffer computational inefficiency. In this study, we propose a novel rectified
quaternion flow (ReQFlow) matching method for fast and high-quality protein
backbone generation. In particular, our method generates a local translation
and a 3D rotation from random noise for each residue in a protein chain, which
represents each 3D rotation as a unit quaternion and constructs its flow by
spherical linear interpolation (SLERP) in an exponential format. We train the
model by quaternion flow (QFlow) matching with guaranteed numerical stability
and rectify the QFlow model to accelerate its inference and improve the
designability of generated protein backbones, leading to the proposed ReQFlow
model. Experiments show that ReQFlow achieves state-of-the-art performance in
protein backbone generation while requiring much fewer sampling steps and
significantly less inference time (e.g., being 37x faster than RFDiffusion and
62x faster than Genie2 when generating a backbone of length 300), demonstrating
its effectiveness and efficiency. The code is available at
https://github.com/AngxiaoYue/ReQFlow.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Protein backbone generation plays a central role in de novo protein design\nand is significant for many biological and medical applications. Although\ndiffusion and flow-based generative models provide potential solutions to this\nchallenging task, they often generate proteins with undesired designability and\nsuffer computational inefficiency. In this study, we propose a novel rectified\nquaternion flow (ReQFlow) matching method for fast and high-quality protein\nbackbone generation. In particular, our method generates a local translation\nand a 3D rotation from random noise for each residue in a protein chain, which\nrepresents each 3D rotation as a unit quaternion and constructs its flow by\nspherical linear interpolation (SLERP) in an exponential format. We train the\nmodel by quaternion flow (QFlow) matching with guaranteed numerical stability\nand rectify the QFlow model to accelerate its inference and improve the\ndesignability of generated protein backbones, leading to the proposed ReQFlow\nmodel. Experiments show that ReQFlow achieves state-of-the-art performance in\nprotein backbone generation while requiring much fewer sampling steps and\nsignificantly less inference time (e.g., being 37x faster than RFDiffusion and\n62x faster than Genie2 when generating a backbone of length 300), demonstrating\nits effectiveness and efficiency. The code is available at\nhttps://github.com/AngxiaoYue/ReQFlow.'}","['Angxiao Yue', 'Zichong Wang', 'Hongteng Xu']",{'name': 'Hongteng Xu'},Hongteng Xu,,"[{'href': 'http://arxiv.org/abs/2502.14637v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14637v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14637v1,None,http://arxiv.org/abs/2502.14637v1,,,9,0
http://arxiv.org/abs/2502.14645v1,True,2025-02-20T15:32:31Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=15, tm_min=32, tm_sec=31, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T15:32:31Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=15, tm_min=32, tm_sec=31, tm_wday=3, tm_yday=51, tm_isdst=0)","Edit Once, Update Everywhere: A Simple Framework for Cross-Lingual
  Knowledge Synchronization in LLMs","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Edit Once, Update Everywhere: A Simple Framework for Cross-Lingual\n  Knowledge Synchronization in LLMs'}","Knowledge editing allows for efficient adaptation of large language models
(LLMs) to new information or corrections without requiring full retraining.
However, prior methods typically focus on either single-language editing or
basic multilingual editing, failing to achieve true cross-linguistic knowledge
synchronization. To address this, we present a simple and practical
state-of-the-art (SOTA) recipe Cross-Lingual Knowledge Democracy Edit (X-KDE),
designed to propagate knowledge from a dominant language to other languages
effectively. Our X-KDE comprises two stages: (i) Cross-lingual Edition
Instruction Tuning (XE-IT), which fine-tunes the model on a curated parallel
dataset to modify in-scope knowledge while preserving unrelated information,
and (ii) Target-language Preference Optimization (TL-PO), which applies
advanced optimization techniques to ensure consistency across languages,
fostering the transfer of updates. Additionally, we contribute a high-quality,
cross-lingual dataset, specifically designed to enhance knowledge transfer
across languages. Extensive experiments on the Bi-ZsRE and MzsRE benchmarks
show that X-KDE significantly enhances cross-lingual performance, achieving an
average improvement of +8.19%, while maintaining high accuracy in monolingual
settings.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Knowledge editing allows for efficient adaptation of large language models\n(LLMs) to new information or corrections without requiring full retraining.\nHowever, prior methods typically focus on either single-language editing or\nbasic multilingual editing, failing to achieve true cross-linguistic knowledge\nsynchronization. To address this, we present a simple and practical\nstate-of-the-art (SOTA) recipe Cross-Lingual Knowledge Democracy Edit (X-KDE),\ndesigned to propagate knowledge from a dominant language to other languages\neffectively. Our X-KDE comprises two stages: (i) Cross-lingual Edition\nInstruction Tuning (XE-IT), which fine-tunes the model on a curated parallel\ndataset to modify in-scope knowledge while preserving unrelated information,\nand (ii) Target-language Preference Optimization (TL-PO), which applies\nadvanced optimization techniques to ensure consistency across languages,\nfostering the transfer of updates. Additionally, we contribute a high-quality,\ncross-lingual dataset, specifically designed to enhance knowledge transfer\nacross languages. Extensive experiments on the Bi-ZsRE and MzsRE benchmarks\nshow that X-KDE significantly enhances cross-lingual performance, achieving an\naverage improvement of +8.19%, while maintaining high accuracy in monolingual\nsettings.'}","['Yuchen Wu', 'Liang Ding', 'Li Shen', 'Dacheng Tao']",{'name': 'Dacheng Tao'},Dacheng Tao,,"[{'href': 'http://arxiv.org/abs/2502.14645v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14645v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14645v1,None,http://arxiv.org/abs/2502.14645v1,,,264,0
http://arxiv.org/abs/2502.14676v1,True,2025-02-20T16:09:21Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=16, tm_min=9, tm_sec=21, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T16:09:21Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=16, tm_min=9, tm_sec=21, tm_wday=3, tm_yday=51, tm_isdst=0)","BP-SGCN: Behavioral Pseudo-Label Informed Sparse Graph Convolution
  Network for Pedestrian and Heterogeneous Trajectory Prediction","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'BP-SGCN: Behavioral Pseudo-Label Informed Sparse Graph Convolution\n  Network for Pedestrian and Heterogeneous Trajectory Prediction'}","Trajectory prediction allows better decision-making in applications of
autonomous vehicles or surveillance by predicting the short-term future
movement of traffic agents. It is classified into pedestrian or heterogeneous
trajectory prediction. The former exploits the relatively consistent behavior
of pedestrians, but is limited in real-world scenarios with heterogeneous
traffic agents such as cyclists and vehicles. The latter typically relies on
extra class label information to distinguish the heterogeneous agents, but such
labels are costly to annotate and cannot be generalized to represent different
behaviors within the same class of agents. In this work, we introduce the
behavioral pseudo-labels that effectively capture the behavior distributions of
pedestrians and heterogeneous agents solely based on their motion features,
significantly improving the accuracy of trajectory prediction. To implement the
framework, we propose the Behavioral Pseudo-Label Informed Sparse Graph
Convolution Network (BP-SGCN) that learns pseudo-labels and informs to a
trajectory predictor. For optimization, we propose a cascaded training scheme,
in which we first learn the pseudo-labels in an unsupervised manner, and then
perform end-to-end fine-tuning on the labels in the direction of increasing the
trajectory prediction accuracy. Experiments show that our pseudo-labels
effectively model different behavior clusters and improve trajectory
prediction. Our proposed BP-SGCN outperforms existing methods using both
pedestrian (ETH/UCY, pedestrian-only SDD) and heterogeneous agent datasets
(SDD, Argoverse 1).","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Trajectory prediction allows better decision-making in applications of\nautonomous vehicles or surveillance by predicting the short-term future\nmovement of traffic agents. It is classified into pedestrian or heterogeneous\ntrajectory prediction. The former exploits the relatively consistent behavior\nof pedestrians, but is limited in real-world scenarios with heterogeneous\ntraffic agents such as cyclists and vehicles. The latter typically relies on\nextra class label information to distinguish the heterogeneous agents, but such\nlabels are costly to annotate and cannot be generalized to represent different\nbehaviors within the same class of agents. In this work, we introduce the\nbehavioral pseudo-labels that effectively capture the behavior distributions of\npedestrians and heterogeneous agents solely based on their motion features,\nsignificantly improving the accuracy of trajectory prediction. To implement the\nframework, we propose the Behavioral Pseudo-Label Informed Sparse Graph\nConvolution Network (BP-SGCN) that learns pseudo-labels and informs to a\ntrajectory predictor. For optimization, we propose a cascaded training scheme,\nin which we first learn the pseudo-labels in an unsupervised manner, and then\nperform end-to-end fine-tuning on the labels in the direction of increasing the\ntrajectory prediction accuracy. Experiments show that our pseudo-labels\neffectively model different behavior clusters and improve trajectory\nprediction. Our proposed BP-SGCN outperforms existing methods using both\npedestrian (ETH/UCY, pedestrian-only SDD) and heterogeneous agent datasets\n(SDD, Argoverse 1).'}","['Ruochen Li', 'Stamos Katsigiannis', 'Tae-Kyun Kim', 'Hubert P. H. Shum']",{'name': 'Hubert P. H. Shum'},Hubert P. H. Shum,,"[{'href': 'http://arxiv.org/abs/2502.14676v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14676v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14676v1,None,http://arxiv.org/abs/2502.14676v1,,,3888,0
http://arxiv.org/abs/2502.14677v1,True,2025-02-20T16:09:27Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=16, tm_min=9, tm_sec=27, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T16:09:27Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=16, tm_min=9, tm_sec=27, tm_wday=3, tm_yday=51, tm_isdst=0)",Data-Constrained Synthesis of Training Data for De-Identification,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Data-Constrained Synthesis of Training Data for De-Identification'}","Many sensitive domains -- such as the clinical domain -- lack widely
available datasets due to privacy risks. The increasing generative capabilities
of large language models (LLMs) have made synthetic datasets a viable path
forward. In this study, we domain-adapt LLMs to the clinical domain and
generate synthetic clinical texts that are machine-annotated with tags for
personally identifiable information using capable encoder-based NER models. The
synthetic corpora are then used to train synthetic NER models. The results show
that training NER models using synthetic corpora incurs only a small drop in
predictive performance. The limits of this process are investigated in a
systematic ablation study -- using both Swedish and Spanish data. Our analysis
shows that smaller datasets can be sufficient for domain-adapting LLMs for data
synthesis. Instead, the effectiveness of this process is almost entirely
contingent on the performance of the machine-annotating NER models trained
using the original data.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Many sensitive domains -- such as the clinical domain -- lack widely\navailable datasets due to privacy risks. The increasing generative capabilities\nof large language models (LLMs) have made synthetic datasets a viable path\nforward. In this study, we domain-adapt LLMs to the clinical domain and\ngenerate synthetic clinical texts that are machine-annotated with tags for\npersonally identifiable information using capable encoder-based NER models. The\nsynthetic corpora are then used to train synthetic NER models. The results show\nthat training NER models using synthetic corpora incurs only a small drop in\npredictive performance. The limits of this process are investigated in a\nsystematic ablation study -- using both Swedish and Spanish data. Our analysis\nshows that smaller datasets can be sufficient for domain-adapting LLMs for data\nsynthesis. Instead, the effectiveness of this process is almost entirely\ncontingent on the performance of the machine-annotating NER models trained\nusing the original data.'}","['Thomas Vakili', 'Aron Henriksson', 'Hercules Dalianis']",{'name': 'Hercules Dalianis'},Hercules Dalianis,Under review,"[{'href': 'http://arxiv.org/abs/2502.14677v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14677v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14677v1,None,http://arxiv.org/abs/2502.14677v1,,,4220,0
http://arxiv.org/abs/2502.14681v1,True,2025-02-20T16:10:18Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=16, tm_min=10, tm_sec=18, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T16:10:18Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=16, tm_min=10, tm_sec=18, tm_wday=3, tm_yday=51, tm_isdst=0)",seqKAN: Sequence processing with Kolmogorov-Arnold Networks,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'seqKAN: Sequence processing with Kolmogorov-Arnold Networks'}","Kolmogorov-Arnold Networks (KANs) have been recently proposed as a machine
learning framework that is more interpretable and controllable than the
multi-layer perceptron. Various network architectures have been proposed within
the KAN framework targeting different tasks and application domains, including
sequence processing.
  This paper proposes seqKAN, a new KAN architecture for sequence processing.
Although multiple sequence processing KAN architectures have already been
proposed, we argue that seqKAN is more faithful to the core concept of the KAN
framework. Furthermore, we empirically demonstrate that it achieves better
results.
  The empirical evaluation is performed on generated data from a complex
physics problem on an interpolation and an extrapolation task. Using this
dataset we compared seqKAN against a prior KAN network for timeseries
prediction, recurrent deep networks, and symbolic regression. seqKAN
substantially outperforms all architectures, particularly on the extrapolation
dataset, while also being the most transparent.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Kolmogorov-Arnold Networks (KANs) have been recently proposed as a machine\nlearning framework that is more interpretable and controllable than the\nmulti-layer perceptron. Various network architectures have been proposed within\nthe KAN framework targeting different tasks and application domains, including\nsequence processing.\n  This paper proposes seqKAN, a new KAN architecture for sequence processing.\nAlthough multiple sequence processing KAN architectures have already been\nproposed, we argue that seqKAN is more faithful to the core concept of the KAN\nframework. Furthermore, we empirically demonstrate that it achieves better\nresults.\n  The empirical evaluation is performed on generated data from a complex\nphysics problem on an interpolation and an extrapolation task. Using this\ndataset we compared seqKAN against a prior KAN network for timeseries\nprediction, recurrent deep networks, and symbolic regression. seqKAN\nsubstantially outperforms all architectures, particularly on the extrapolation\ndataset, while also being the most transparent.'}","['Tatiana Boura', 'Stasinos Konstantopoulos']",{'name': 'Stasinos Konstantopoulos'},Stasinos Konstantopoulos,,"[{'href': 'http://arxiv.org/abs/2502.14681v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14681v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14681v1,None,http://arxiv.org/abs/2502.14681v1,,,778,0
http://arxiv.org/abs/2502.14704v1,True,2025-02-20T16:29:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=16, tm_min=29, tm_sec=37, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T16:29:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=16, tm_min=29, tm_sec=37, tm_wday=3, tm_yday=51, tm_isdst=0)","Not All Data are Good Labels: On the Self-supervised Labeling for Time
  Series Forecasting","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Not All Data are Good Labels: On the Self-supervised Labeling for Time\n  Series Forecasting'}","Time Series Forecasting (TSF) is a crucial task in various domains, yet
existing TSF models rely heavily on high-quality data and insufficiently
exploit all available data. This paper explores a novel self-supervised
approach to re-label time series datasets by inherently constructing candidate
datasets. During the optimization of a simple reconstruction network,
intermediates are used as pseudo labels in a self-supervised paradigm,
improving generalization for any predictor. We introduce the Self-Correction
with Adaptive Mask (SCAM), which discards overfitted components and selectively
replaces them with pseudo labels generated from reconstructions. Additionally,
we incorporate Spectral Norm Regularization (SNR) to further suppress
overfitting from a loss landscape perspective. Our experiments on eleven
real-world datasets demonstrate that SCAM consistently improves the performance
of various backbone models. This work offers a new perspective on constructing
datasets and enhancing the generalization of TSF models through self-supervised
learning.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Time Series Forecasting (TSF) is a crucial task in various domains, yet\nexisting TSF models rely heavily on high-quality data and insufficiently\nexploit all available data. This paper explores a novel self-supervised\napproach to re-label time series datasets by inherently constructing candidate\ndatasets. During the optimization of a simple reconstruction network,\nintermediates are used as pseudo labels in a self-supervised paradigm,\nimproving generalization for any predictor. We introduce the Self-Correction\nwith Adaptive Mask (SCAM), which discards overfitted components and selectively\nreplaces them with pseudo labels generated from reconstructions. Additionally,\nwe incorporate Spectral Norm Regularization (SNR) to further suppress\noverfitting from a loss landscape perspective. Our experiments on eleven\nreal-world datasets demonstrate that SCAM consistently improves the performance\nof various backbone models. This work offers a new perspective on constructing\ndatasets and enhancing the generalization of TSF models through self-supervised\nlearning.'}","['Yuxuan Yang', 'Dalin Zhang', 'Yuxuan Liang', 'Hua Lu', 'Huan Li', 'Gang Chen']",{'name': 'Gang Chen'},Gang Chen,,"[{'href': 'http://arxiv.org/abs/2502.14704v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14704v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14704v1,None,http://arxiv.org/abs/2502.14704v1,,,0,0
http://arxiv.org/abs/2502.14706v1,True,2025-02-20T16:30:45Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=16, tm_min=30, tm_sec=45, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T16:30:45Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=16, tm_min=30, tm_sec=45, tm_wday=3, tm_yday=51, tm_isdst=0)",Building reliable sim driving agents by scaling self-play,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Building reliable sim driving agents by scaling self-play'}","Simulation agents are essential for designing and testing systems that
interact with humans, such as autonomous vehicles (AVs). These agents serve
various purposes, from benchmarking AV performance to stress-testing the
system's limits, but all use cases share a key requirement: reliability. A
simulation agent should behave as intended by the designer, minimizing
unintended actions like collisions that can compromise the signal-to-noise
ratio of analyses. As a foundation for reliable sim agents, we propose scaling
self-play to thousands of scenarios on the Waymo Open Motion Dataset under
semi-realistic limits on human perception and control. Training from scratch on
a single GPU, our agents nearly solve the full training set within a day. They
generalize effectively to unseen test scenes, achieving a 99.8% goal completion
rate with less than 0.8% combined collision and off-road incidents across
10,000 held-out scenarios. Beyond in-distribution generalization, our agents
show partial robustness to out-of-distribution scenes and can be fine-tuned in
minutes to reach near-perfect performance in those cases. Demonstrations of
agent behaviors can be found at this link. We open-source both the pre-trained
agents and the complete code base. Demonstrations of agent behaviors can be
found at \url{https://sites.google.com/view/reliable-sim-agents}.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Simulation agents are essential for designing and testing systems that\ninteract with humans, such as autonomous vehicles (AVs). These agents serve\nvarious purposes, from benchmarking AV performance to stress-testing the\nsystem's limits, but all use cases share a key requirement: reliability. A\nsimulation agent should behave as intended by the designer, minimizing\nunintended actions like collisions that can compromise the signal-to-noise\nratio of analyses. As a foundation for reliable sim agents, we propose scaling\nself-play to thousands of scenarios on the Waymo Open Motion Dataset under\nsemi-realistic limits on human perception and control. Training from scratch on\na single GPU, our agents nearly solve the full training set within a day. They\ngeneralize effectively to unseen test scenes, achieving a 99.8% goal completion\nrate with less than 0.8% combined collision and off-road incidents across\n10,000 held-out scenarios. Beyond in-distribution generalization, our agents\nshow partial robustness to out-of-distribution scenes and can be fine-tuned in\nminutes to reach near-perfect performance in those cases. Demonstrations of\nagent behaviors can be found at this link. We open-source both the pre-trained\nagents and the complete code base. Demonstrations of agent behaviors can be\nfound at \\url{https://sites.google.com/view/reliable-sim-agents}.""}","['Daphne Cornelisse', 'Aarav Pandya', 'Kevin Joseph', 'Joseph Surez', 'Eugene Vinitsky']",{'name': 'Eugene Vinitsky'},Eugene Vinitsky,First version,"[{'href': 'http://arxiv.org/abs/2502.14706v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14706v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14706v1,None,http://arxiv.org/abs/2502.14706v1,,,102,0
http://arxiv.org/abs/2502.14735v1,True,2025-02-20T17:01:57Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=17, tm_min=1, tm_sec=57, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T17:01:57Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=17, tm_min=1, tm_sec=57, tm_wday=3, tm_yday=51, tm_isdst=0)","EAGER-LLM: Enhancing Large Language Models as Recommenders through
  Exogenous Behavior-Semantic Integration","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'EAGER-LLM: Enhancing Large Language Models as Recommenders through\n  Exogenous Behavior-Semantic Integration'}","Large language models (LLMs) are increasingly leveraged as foundational
backbones in the development of advanced recommender systems, offering enhanced
capabilities through their extensive knowledge and reasoning. Existing
llm-based recommender systems (RSs) often face challenges due to the
significant differences between the linguistic semantics of pre-trained LLMs
and the collaborative semantics essential for RSs. These systems use
pre-trained linguistic semantics but learn collaborative semantics from scratch
via the llm-Backbone. However, LLMs are not designed for recommendations,
leading to inefficient collaborative learning, weak result correlations, and
poor integration of traditional RS features. To address these challenges, we
propose EAGER-LLM, a decoder-only llm-based generative recommendation framework
that integrates endogenous and exogenous behavioral and semantic information in
a non-intrusive manner. Specifically, we propose 1)dual-source knowledge-rich
item indices that integrates indexing sequences for exogenous signals, enabling
efficient link-wide processing; 2)non-invasive multiscale alignment
reconstruction tasks guide the model toward a deeper understanding of both
collaborative and semantic signals; 3)an annealing adapter designed to finely
balance the model's recommendation performance with its comprehension
capabilities. We demonstrate EAGER-LLM's effectiveness through rigorous testing
on three public benchmarks.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Large language models (LLMs) are increasingly leveraged as foundational\nbackbones in the development of advanced recommender systems, offering enhanced\ncapabilities through their extensive knowledge and reasoning. Existing\nllm-based recommender systems (RSs) often face challenges due to the\nsignificant differences between the linguistic semantics of pre-trained LLMs\nand the collaborative semantics essential for RSs. These systems use\npre-trained linguistic semantics but learn collaborative semantics from scratch\nvia the llm-Backbone. However, LLMs are not designed for recommendations,\nleading to inefficient collaborative learning, weak result correlations, and\npoor integration of traditional RS features. To address these challenges, we\npropose EAGER-LLM, a decoder-only llm-based generative recommendation framework\nthat integrates endogenous and exogenous behavioral and semantic information in\na non-intrusive manner. Specifically, we propose 1)dual-source knowledge-rich\nitem indices that integrates indexing sequences for exogenous signals, enabling\nefficient link-wide processing; 2)non-invasive multiscale alignment\nreconstruction tasks guide the model toward a deeper understanding of both\ncollaborative and semantic signals; 3)an annealing adapter designed to finely\nbalance the model's recommendation performance with its comprehension\ncapabilities. We demonstrate EAGER-LLM's effectiveness through rigorous testing\non three public benchmarks.""}","['Minjie Hong', 'Yan Xia', 'Zehan Wang', 'Jieming Zhu', 'Ye Wang', 'Sihang Cai', 'Xiaoda Yang', 'Quanyu Dai', 'Zhenhua Dong', 'Zhimeng Zhang', 'Zhou Zhao']",{'name': 'Zhou Zhao'},Zhou Zhao,"9 pages, 6 figures, accpeted by WWW 2025","[{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3696410.3714933', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2502.14735v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14735v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14735v1,None,http://arxiv.org/abs/2502.14735v1,,10.1145/3696410.3714933,179,0
http://arxiv.org/abs/2502.14740v1,True,2025-02-20T17:08:43Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=17, tm_min=8, tm_sec=43, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T17:08:43Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=17, tm_min=8, tm_sec=43, tm_wday=3, tm_yday=51, tm_isdst=0)",YOLOv12: A Breakdown of the Key Architectural Features,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'YOLOv12: A Breakdown of the Key Architectural Features'}","This paper presents an architectural analysis of YOLOv12, a significant
advancement in single-stage, real-time object detection building upon the
strengths of its predecessors while introducing key improvements. The model
incorporates an optimised backbone (R-ELAN), 7x7 separable convolutions, and
FlashAttention-driven area-based attention, improving feature extraction,
enhanced efficiency, and robust detections. With multiple model variants,
similar to its predecessors, YOLOv12 offers scalable solutions for both
latency-sensitive and high-accuracy applications. Experimental results manifest
consistent gains in mean average precision (mAP) and inference speed, making
YOLOv12 a compelling choice for applications in autonomous systems, security,
and real-time analytics. By achieving an optimal balance between computational
efficiency and performance, YOLOv12 sets a new benchmark for real-time computer
vision, facilitating deployment across diverse hardware platforms, from edge
devices to high-performance clusters.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'This paper presents an architectural analysis of YOLOv12, a significant\nadvancement in single-stage, real-time object detection building upon the\nstrengths of its predecessors while introducing key improvements. The model\nincorporates an optimised backbone (R-ELAN), 7x7 separable convolutions, and\nFlashAttention-driven area-based attention, improving feature extraction,\nenhanced efficiency, and robust detections. With multiple model variants,\nsimilar to its predecessors, YOLOv12 offers scalable solutions for both\nlatency-sensitive and high-accuracy applications. Experimental results manifest\nconsistent gains in mean average precision (mAP) and inference speed, making\nYOLOv12 a compelling choice for applications in autonomous systems, security,\nand real-time analytics. By achieving an optimal balance between computational\nefficiency and performance, YOLOv12 sets a new benchmark for real-time computer\nvision, facilitating deployment across diverse hardware platforms, from edge\ndevices to high-performance clusters.'}","['Mujadded Al Rabbani Alif', 'Muhammad Hussain']",{'name': 'Muhammad Hussain'},Muhammad Hussain,,"[{'href': 'http://arxiv.org/abs/2502.14740v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14740v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14740v1,None,http://arxiv.org/abs/2502.14740v1,,,113,0
http://arxiv.org/abs/2502.14743v1,True,2025-02-20T17:12:45Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=17, tm_min=12, tm_sec=45, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T17:12:45Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=17, tm_min=12, tm_sec=45, tm_wday=3, tm_yday=51, tm_isdst=0)",Multi-Agent Coordination across Diverse Applications: A Survey,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Multi-Agent Coordination across Diverse Applications: A Survey'}","Multi-agent coordination studies the underlying mechanism enabling the
trending spread of diverse multi-agent systems (MAS) and has received
increasing attention, driven by the expansion of emerging applications and
rapid AI advances. This survey outlines the current state of coordination
research across applications through a unified understanding that answers four
fundamental coordination questions: (1) what is coordination; (2) why
coordination; (3) who to coordinate with; and (4) how to coordinate. Our
purpose is to explore existing ideas and expertise in coordination and their
connections across diverse applications, while identifying and highlighting
emerging and promising research directions. First, general coordination
problems that are essential to varied applications are identified and analyzed.
Second, a number of MAS applications are surveyed, ranging from widely studied
domains, e.g., search and rescue, warehouse automation and logistics, and
transportation systems, to emerging fields including humanoid and
anthropomorphic robots, satellite systems, and large language models (LLMs).
Finally, open challenges about the scalability, heterogeneity, and learning
mechanisms of MAS are analyzed and discussed. In particular, we identify the
hybridization of hierarchical and decentralized coordination, human-MAS
coordination, and LLM-based MAS as promising future directions.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Multi-agent coordination studies the underlying mechanism enabling the\ntrending spread of diverse multi-agent systems (MAS) and has received\nincreasing attention, driven by the expansion of emerging applications and\nrapid AI advances. This survey outlines the current state of coordination\nresearch across applications through a unified understanding that answers four\nfundamental coordination questions: (1) what is coordination; (2) why\ncoordination; (3) who to coordinate with; and (4) how to coordinate. Our\npurpose is to explore existing ideas and expertise in coordination and their\nconnections across diverse applications, while identifying and highlighting\nemerging and promising research directions. First, general coordination\nproblems that are essential to varied applications are identified and analyzed.\nSecond, a number of MAS applications are surveyed, ranging from widely studied\ndomains, e.g., search and rescue, warehouse automation and logistics, and\ntransportation systems, to emerging fields including humanoid and\nanthropomorphic robots, satellite systems, and large language models (LLMs).\nFinally, open challenges about the scalability, heterogeneity, and learning\nmechanisms of MAS are analyzed and discussed. In particular, we identify the\nhybridization of hierarchical and decentralized coordination, human-MAS\ncoordination, and LLM-based MAS as promising future directions.'}","['Lijun Sun', 'Yijun Yang', 'Qiqi Duan', 'Yuhui Shi', 'Chao Lyu', 'Yu-Cheng Chang', 'Chin-Teng Lin', 'Yang Shen']",{'name': 'Yang Shen'},Yang Shen,"23 pages, 4 figures, 2 tables","[{'href': 'http://arxiv.org/abs/2502.14743v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14743v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14743v1,None,http://arxiv.org/abs/2502.14743v1,,,497,0
http://arxiv.org/abs/2502.14759v1,True,2025-02-20T17:34:34Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=17, tm_min=34, tm_sec=34, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T17:34:34Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=17, tm_min=34, tm_sec=34, tm_wday=3, tm_yday=51, tm_isdst=0)","On the Influence of Context Size and Model Choice in Retrieval-Augmented
  Generation Systems","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'On the Influence of Context Size and Model Choice in Retrieval-Augmented\n  Generation Systems'}","Retrieval-augmented generation (RAG) has emerged as an approach to augment
large language models (LLMs) by reducing their reliance on static knowledge and
improving answer factuality. RAG retrieves relevant context snippets and
generates an answer based on them. Despite its increasing industrial adoption,
systematic exploration of RAG components is lacking, particularly regarding the
ideal size of provided context, and the choice of base LLM and retrieval
method. To help guide development of robust RAG systems, we evaluate various
context sizes, BM25 and semantic search as retrievers, and eight base LLMs.
Moving away from the usual RAG evaluation with short answers, we explore the
more challenging long-form question answering in two domains, where a good
answer has to utilize the entire context. Our findings indicate that final QA
performance improves steadily with up to 15 snippets but stagnates or declines
beyond that. Finally, we show that different general-purpose LLMs excel in the
biomedical domain than the encyclopedic one, and that open-domain evidence
retrieval in large corpora is challenging.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Retrieval-augmented generation (RAG) has emerged as an approach to augment\nlarge language models (LLMs) by reducing their reliance on static knowledge and\nimproving answer factuality. RAG retrieves relevant context snippets and\ngenerates an answer based on them. Despite its increasing industrial adoption,\nsystematic exploration of RAG components is lacking, particularly regarding the\nideal size of provided context, and the choice of base LLM and retrieval\nmethod. To help guide development of robust RAG systems, we evaluate various\ncontext sizes, BM25 and semantic search as retrievers, and eight base LLMs.\nMoving away from the usual RAG evaluation with short answers, we explore the\nmore challenging long-form question answering in two domains, where a good\nanswer has to utilize the entire context. Our findings indicate that final QA\nperformance improves steadily with up to 15 snippets but stagnates or declines\nbeyond that. Finally, we show that different general-purpose LLMs excel in the\nbiomedical domain than the encyclopedic one, and that open-domain evidence\nretrieval in large corpora is challenging.'}","['Juraj Vladika', 'Florian Matthes']",{'name': 'Florian Matthes'},Florian Matthes,Accepted to Findings of NAACL 2025,"[{'href': 'http://arxiv.org/abs/2502.14759v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14759v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14759v1,None,http://arxiv.org/abs/2502.14759v1,,,35,0
http://arxiv.org/abs/2502.14765v1,True,2025-02-20T17:40:21Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=17, tm_min=40, tm_sec=21, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T17:40:21Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=17, tm_min=40, tm_sec=21, tm_wday=3, tm_yday=51, tm_isdst=0)","Step-by-Step Fact Verification System for Medical Claims with
  Explainable Reasoning","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Step-by-Step Fact Verification System for Medical Claims with\n  Explainable Reasoning'}","Fact verification (FV) aims to assess the veracity of a claim based on
relevant evidence. The traditional approach for automated FV includes a
three-part pipeline relying on short evidence snippets and encoder-only
inference models. More recent approaches leverage the multi-turn nature of LLMs
to address FV as a step-by-step problem where questions inquiring additional
context are generated and answered until there is enough information to make a
decision. This iterative method makes the verification process rational and
explainable. While these methods have been tested for encyclopedic claims,
exploration on domain-specific and realistic claims is missing. In this work,
we apply an iterative FV system on three medical fact-checking datasets and
evaluate it with multiple settings, including different LLMs, external web
search, and structured reasoning using logic predicates. We demonstrate
improvements in the final performance over traditional approaches and the high
potential of step-by-step FV systems for domain-specific claims.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Fact verification (FV) aims to assess the veracity of a claim based on\nrelevant evidence. The traditional approach for automated FV includes a\nthree-part pipeline relying on short evidence snippets and encoder-only\ninference models. More recent approaches leverage the multi-turn nature of LLMs\nto address FV as a step-by-step problem where questions inquiring additional\ncontext are generated and answered until there is enough information to make a\ndecision. This iterative method makes the verification process rational and\nexplainable. While these methods have been tested for encyclopedic claims,\nexploration on domain-specific and realistic claims is missing. In this work,\nwe apply an iterative FV system on three medical fact-checking datasets and\nevaluate it with multiple settings, including different LLMs, external web\nsearch, and structured reasoning using logic predicates. We demonstrate\nimprovements in the final performance over traditional approaches and the high\npotential of step-by-step FV systems for domain-specific claims.'}","['Juraj Vladika', 'Ivana Hacajov', 'Florian Matthes']",{'name': 'Florian Matthes'},Florian Matthes,Accepted to NAACL 2025 (Main),"[{'href': 'http://arxiv.org/abs/2502.14765v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14765v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14765v1,None,http://arxiv.org/abs/2502.14765v1,,,35,0
http://arxiv.org/abs/2502.14767v1,True,2025-02-20T17:43:40Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=17, tm_min=43, tm_sec=40, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T17:43:40Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=17, tm_min=43, tm_sec=40, tm_wday=3, tm_yday=51, tm_isdst=0)","Tree-of-Debate: Multi-Persona Debate Trees Elicit Critical Thinking for
  Scientific Comparative Analysis","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Tree-of-Debate: Multi-Persona Debate Trees Elicit Critical Thinking for\n  Scientific Comparative Analysis'}","With the exponential growth of research facilitated by modern technology and
improved accessibility, scientific discoveries have become increasingly
fragmented within and across fields. This makes it challenging to assess the
significance, novelty, incremental findings, and equivalent ideas between
related works, particularly those from different research communities. Large
language models (LLMs) have recently demonstrated strong quantitative and
qualitative reasoning abilities, and multi-agent LLM debates have shown promise
in handling complex reasoning tasks by exploring diverse perspectives and
reasoning paths. Inspired by this, we introduce Tree-of-Debate (ToD), a
framework which converts scientific papers into LLM personas that debate their
respective novelties. To emphasize structured, critical reasoning rather than
focusing solely on outcomes, ToD dynamically constructs a debate tree, enabling
fine-grained analysis of independent novelty arguments within scholarly
articles. Through experiments on scientific literature across various domains,
evaluated by expert researchers, we demonstrate that ToD generates informative
arguments, effectively contrasts papers, and supports researchers in their
literature review.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'With the exponential growth of research facilitated by modern technology and\nimproved accessibility, scientific discoveries have become increasingly\nfragmented within and across fields. This makes it challenging to assess the\nsignificance, novelty, incremental findings, and equivalent ideas between\nrelated works, particularly those from different research communities. Large\nlanguage models (LLMs) have recently demonstrated strong quantitative and\nqualitative reasoning abilities, and multi-agent LLM debates have shown promise\nin handling complex reasoning tasks by exploring diverse perspectives and\nreasoning paths. Inspired by this, we introduce Tree-of-Debate (ToD), a\nframework which converts scientific papers into LLM personas that debate their\nrespective novelties. To emphasize structured, critical reasoning rather than\nfocusing solely on outcomes, ToD dynamically constructs a debate tree, enabling\nfine-grained analysis of independent novelty arguments within scholarly\narticles. Through experiments on scientific literature across various domains,\nevaluated by expert researchers, we demonstrate that ToD generates informative\narguments, effectively contrasts papers, and supports researchers in their\nliterature review.'}","['Priyanka Kargupta', 'Ishika Agarwal', 'Tal August', 'Jiawei Han']",{'name': 'Jiawei Han'},Jiawei Han,Code available at: https://github.com/pkargupta/tree-of-debate,"[{'href': 'http://arxiv.org/abs/2502.14767v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14767v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14767v1,None,http://arxiv.org/abs/2502.14767v1,,,661,0
http://arxiv.org/abs/2502.14768v1,True,2025-02-20T17:49:26Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=17, tm_min=49, tm_sec=26, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T17:49:26Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=17, tm_min=49, tm_sec=26, tm_wday=3, tm_yday=51, tm_isdst=0)","Logic-RL: Unleashing LLM Reasoning with Rule-Based Reinforcement
  Learning","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Logic-RL: Unleashing LLM Reasoning with Rule-Based Reinforcement\n  Learning'}","Inspired by the success of DeepSeek-R1, we explore the potential of
rule-based reinforcement learning (RL) in large reasoning models. To analyze
reasoning dynamics, we use synthetic logic puzzles as training data due to
their controllable complexity and straightforward answer verification. We make
some key technical contributions that lead to effective and stable RL training:
a system prompt that emphasizes the thinking and answering process, a stringent
format reward function that penalizes outputs for taking shortcuts, and a
straightforward training recipe that achieves stable convergence. Our 7B model
develops advanced reasoning skills-such as reflection, verification, and
summarization-that are absent from the logic corpus. Remarkably, after training
on just 5K logic problems, it demonstrates generalization abilities to the
challenging math benchmarks AIME and AMC.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Inspired by the success of DeepSeek-R1, we explore the potential of\nrule-based reinforcement learning (RL) in large reasoning models. To analyze\nreasoning dynamics, we use synthetic logic puzzles as training data due to\ntheir controllable complexity and straightforward answer verification. We make\nsome key technical contributions that lead to effective and stable RL training:\na system prompt that emphasizes the thinking and answering process, a stringent\nformat reward function that penalizes outputs for taking shortcuts, and a\nstraightforward training recipe that achieves stable convergence. Our 7B model\ndevelops advanced reasoning skills-such as reflection, verification, and\nsummarization-that are absent from the logic corpus. Remarkably, after training\non just 5K logic problems, it demonstrates generalization abilities to the\nchallenging math benchmarks AIME and AMC.'}","['Tian Xie', 'Zitian Gao', 'Qingnan Ren', 'Haoming Luo', 'Yuqian Hong', 'Bryan Dai', 'Joey Zhou', 'Kai Qiu', 'Zhirong Wu', 'Chong Luo']",{'name': 'Chong Luo'},Chong Luo,,"[{'href': 'http://arxiv.org/abs/2502.14768v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14768v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14768v1,None,http://arxiv.org/abs/2502.14768v1,,,0,0
http://arxiv.org/abs/2502.14786v1,True,2025-02-20T18:08:29Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=8, tm_sec=29, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T18:08:29Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=8, tm_sec=29, tm_wday=3, tm_yday=51, tm_isdst=0)","SigLIP 2: Multilingual Vision-Language Encoders with Improved Semantic
  Understanding, Localization, and Dense Features","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'SigLIP 2: Multilingual Vision-Language Encoders with Improved Semantic\n  Understanding, Localization, and Dense Features'}","We introduce SigLIP 2, a family of new multilingual vision-language encoders
that build on the success of the original SigLIP. In this second iteration, we
extend the original image-text training objective with several prior,
independently developed techniques into a unified recipe -- this includes
captioning-based pretraining, self-supervised losses (self-distillation, masked
prediction) and online data curation. With these changes, SigLIP 2 models
outperform their SigLIP counterparts at all model scales in core capabilities,
including zero-shot classification, image-text retrieval, and transfer
performance when extracting visual representations for Vision-Language Models
(VLMs). Furthermore, the new training recipe leads to significant improvements
on localization and dense prediction tasks. We also train variants which
support multiple resolutions and preserve the input's native aspect ratio.
Finally, we train on a more diverse data-mixture that includes de-biasing
techniques, leading to much better multilingual understanding and improved
fairness. To allow users to trade off inference cost with performance, we
release model checkpoints at four sizes: ViT-B (86M), L (303M), So400m (400M),
and g (1B).","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""We introduce SigLIP 2, a family of new multilingual vision-language encoders\nthat build on the success of the original SigLIP. In this second iteration, we\nextend the original image-text training objective with several prior,\nindependently developed techniques into a unified recipe -- this includes\ncaptioning-based pretraining, self-supervised losses (self-distillation, masked\nprediction) and online data curation. With these changes, SigLIP 2 models\noutperform their SigLIP counterparts at all model scales in core capabilities,\nincluding zero-shot classification, image-text retrieval, and transfer\nperformance when extracting visual representations for Vision-Language Models\n(VLMs). Furthermore, the new training recipe leads to significant improvements\non localization and dense prediction tasks. We also train variants which\nsupport multiple resolutions and preserve the input's native aspect ratio.\nFinally, we train on a more diverse data-mixture that includes de-biasing\ntechniques, leading to much better multilingual understanding and improved\nfairness. To allow users to trade off inference cost with performance, we\nrelease model checkpoints at four sizes: ViT-B (86M), L (303M), So400m (400M),\nand g (1B).""}","['Michael Tschannen', 'Alexey Gritsenko', 'Xiao Wang', 'Muhammad Ferjad Naeem', 'Ibrahim Alabdulmohsin', 'Nikhil Parthasarathy', 'Talfan Evans', 'Lucas Beyer', 'Ye Xia', 'Basil Mustafa', 'Olivier Hnaff', 'Jeremiah Harmsen', 'Andreas Steiner', 'Xiaohua Zhai']",{'name': 'Xiaohua Zhai'},Xiaohua Zhai,"Model checkpoints are available at
  https://github.com/google-research/big_vision/tree/main/big_vision/configs/proj/image_text/README_siglip2.md","[{'href': 'http://arxiv.org/abs/2502.14786v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14786v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14786v1,None,http://arxiv.org/abs/2502.14786v1,,,57358,0
http://arxiv.org/abs/2502.14788v1,True,2025-02-20T18:09:03Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=9, tm_sec=3, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T18:09:03Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=9, tm_sec=3, tm_wday=3, tm_yday=51, tm_isdst=0)",Ray-Tracing for Conditionally Activated Neural Networks,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Ray-Tracing for Conditionally Activated Neural Networks'}","In this paper, we introduce a novel architecture for conditionally activated
neural networks combining a hierarchical construction of multiple Mixture of
Experts (MoEs) layers with a sampling mechanism that progressively converges to
an optimized configuration of expert activation. This methodology enables the
dynamic unfolding of the network's architecture, facilitating efficient
path-specific training. Experimental results demonstrate that this approach
achieves competitive accuracy compared to conventional baselines while
significantly reducing the parameter count required for inference. Notably,
this parameter reduction correlates with the complexity of the input patterns,
a property naturally emerging from the network's operational dynamics without
necessitating explicit auxiliary penalty functions.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""In this paper, we introduce a novel architecture for conditionally activated\nneural networks combining a hierarchical construction of multiple Mixture of\nExperts (MoEs) layers with a sampling mechanism that progressively converges to\nan optimized configuration of expert activation. This methodology enables the\ndynamic unfolding of the network's architecture, facilitating efficient\npath-specific training. Experimental results demonstrate that this approach\nachieves competitive accuracy compared to conventional baselines while\nsignificantly reducing the parameter count required for inference. Notably,\nthis parameter reduction correlates with the complexity of the input patterns,\na property naturally emerging from the network's operational dynamics without\nnecessitating explicit auxiliary penalty functions.""}","['Claudio Gallicchio', 'Giuseppe Nuti']",{'name': 'Giuseppe Nuti'},Giuseppe Nuti,submitted to workshop,"[{'href': 'http://arxiv.org/abs/2502.14788v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14788v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14788v1,None,http://arxiv.org/abs/2502.14788v1,,,1,0
http://arxiv.org/abs/2502.14799v1,True,2025-02-20T18:19:57Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=19, tm_sec=57, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T18:19:57Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=19, tm_sec=57, tm_wday=3, tm_yday=51, tm_isdst=0)",A Survey on Text-Driven 360-Degree Panorama Generation,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A Survey on Text-Driven 360-Degree Panorama Generation'}","The advent of text-driven 360-degree panorama generation, enabling the
synthesis of 360-degree panoramic images directly from textual descriptions,
marks a transformative advancement in immersive visual content creation. This
innovation significantly simplifies the traditionally complex process of
producing such content. Recent progress in text-to-image diffusion models has
accelerated the rapid development in this emerging field. This survey presents
a comprehensive review of text-driven 360-degree panorama generation, offering
an in-depth analysis of state-of-the-art algorithms and their expanding
applications in 360-degree 3D scene generation. Furthermore, we critically
examine current limitations and propose promising directions for future
research. A curated project page with relevant resources and research papers is
available at https://littlewhitesea.github.io/Text-Driven-Pano-Gen/.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The advent of text-driven 360-degree panorama generation, enabling the\nsynthesis of 360-degree panoramic images directly from textual descriptions,\nmarks a transformative advancement in immersive visual content creation. This\ninnovation significantly simplifies the traditionally complex process of\nproducing such content. Recent progress in text-to-image diffusion models has\naccelerated the rapid development in this emerging field. This survey presents\na comprehensive review of text-driven 360-degree panorama generation, offering\nan in-depth analysis of state-of-the-art algorithms and their expanding\napplications in 360-degree 3D scene generation. Furthermore, we critically\nexamine current limitations and propose promising directions for future\nresearch. A curated project page with relevant resources and research papers is\navailable at https://littlewhitesea.github.io/Text-Driven-Pano-Gen/.'}","['Hai Wang', 'Xiaoyu Xiang', 'Weihao Xia', 'Jing-Hao Xue']",{'name': 'Jing-Hao Xue'},Jing-Hao Xue,,"[{'href': 'http://arxiv.org/abs/2502.14799v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14799v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14799v1,None,http://arxiv.org/abs/2502.14799v1,,,47,0
http://arxiv.org/abs/2502.14802v1,True,2025-02-20T18:26:02Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=26, tm_sec=2, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T18:26:02Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=26, tm_sec=2, tm_wday=3, tm_yday=51, tm_isdst=0)","From RAG to Memory: Non-Parametric Continual Learning for Large Language
  Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'From RAG to Memory: Non-Parametric Continual Learning for Large Language\n  Models'}","Our ability to continuously acquire, organize, and leverage knowledge is a
key feature of human intelligence that AI systems must approximate to unlock
their full potential. Given the challenges in continual learning with large
language models (LLMs), retrieval-augmented generation (RAG) has become the
dominant way to introduce new information. However, its reliance on vector
retrieval hinders its ability to mimic the dynamic and interconnected nature of
human long-term memory. Recent RAG approaches augment vector embeddings with
various structures like knowledge graphs to address some of these gaps, namely
sense-making and associativity. However, their performance on more basic
factual memory tasks drops considerably below standard RAG. We address this
unintended deterioration and propose HippoRAG 2, a framework that outperforms
standard RAG comprehensively on factual, sense-making, and associative memory
tasks. HippoRAG 2 builds upon the Personalized PageRank algorithm used in
HippoRAG and enhances it with deeper passage integration and more effective
online use of an LLM. This combination pushes this RAG system closer to the
effectiveness of human long-term memory, achieving a 7% improvement in
associative memory tasks over the state-of-the-art embedding model while also
exhibiting superior factual knowledge and sense-making memory capabilities.
This work paves the way for non-parametric continual learning for LLMs. Our
code and data will be released at https://github.com/OSU-NLP-Group/HippoRAG.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Our ability to continuously acquire, organize, and leverage knowledge is a\nkey feature of human intelligence that AI systems must approximate to unlock\ntheir full potential. Given the challenges in continual learning with large\nlanguage models (LLMs), retrieval-augmented generation (RAG) has become the\ndominant way to introduce new information. However, its reliance on vector\nretrieval hinders its ability to mimic the dynamic and interconnected nature of\nhuman long-term memory. Recent RAG approaches augment vector embeddings with\nvarious structures like knowledge graphs to address some of these gaps, namely\nsense-making and associativity. However, their performance on more basic\nfactual memory tasks drops considerably below standard RAG. We address this\nunintended deterioration and propose HippoRAG 2, a framework that outperforms\nstandard RAG comprehensively on factual, sense-making, and associative memory\ntasks. HippoRAG 2 builds upon the Personalized PageRank algorithm used in\nHippoRAG and enhances it with deeper passage integration and more effective\nonline use of an LLM. This combination pushes this RAG system closer to the\neffectiveness of human long-term memory, achieving a 7% improvement in\nassociative memory tasks over the state-of-the-art embedding model while also\nexhibiting superior factual knowledge and sense-making memory capabilities.\nThis work paves the way for non-parametric continual learning for LLMs. Our\ncode and data will be released at https://github.com/OSU-NLP-Group/HippoRAG.'}","['Bernal Jimnez Gutirrez', 'Yiheng Shu', 'Weijian Qi', 'Sizhe Zhou', 'Yu Su']",{'name': 'Yu Su'},Yu Su,"Code and data to be released at:
  https://github.com/OSU-NLP-Group/HippoRAG","[{'href': 'http://arxiv.org/abs/2502.14802v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14802v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14802v1,None,http://arxiv.org/abs/2502.14802v1,,,1,0
http://arxiv.org/abs/2502.14830v1,True,2025-02-20T18:45:43Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=45, tm_sec=43, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T18:45:43Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=45, tm_sec=43, tm_wday=3, tm_yday=51, tm_isdst=0)","Middle-Layer Representation Alignment for Cross-Lingual Transfer in
  Fine-Tuned LLMs","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Middle-Layer Representation Alignment for Cross-Lingual Transfer in\n  Fine-Tuned LLMs'}","While large language models demonstrate remarkable capabilities at
task-specific applications through fine-tuning, extending these benefits across
diverse languages is essential for broad accessibility. However, effective
cross-lingual transfer is hindered by LLM performance gaps across languages and
the scarcity of fine-tuning data in many languages. Through analysis of LLM
internal representations from over 1,000+ language pairs, we discover that
middle layers exhibit the strongest potential for cross-lingual alignment.
Building on this finding, we propose a middle-layer alignment objective
integrated into task-specific training. Our experiments on slot filling,
machine translation, and structured text generation show consistent
improvements in cross-lingual transfer, especially to lower-resource languages.
The method is robust to the choice of alignment languages and generalizes to
languages unseen during alignment. Furthermore, we show that separately trained
alignment modules can be merged with existing task-specific modules, improving
cross-lingual capabilities without full re-training. Our code is publicly
available (https://github.com/dannigt/mid-align).","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'While large language models demonstrate remarkable capabilities at\ntask-specific applications through fine-tuning, extending these benefits across\ndiverse languages is essential for broad accessibility. However, effective\ncross-lingual transfer is hindered by LLM performance gaps across languages and\nthe scarcity of fine-tuning data in many languages. Through analysis of LLM\ninternal representations from over 1,000+ language pairs, we discover that\nmiddle layers exhibit the strongest potential for cross-lingual alignment.\nBuilding on this finding, we propose a middle-layer alignment objective\nintegrated into task-specific training. Our experiments on slot filling,\nmachine translation, and structured text generation show consistent\nimprovements in cross-lingual transfer, especially to lower-resource languages.\nThe method is robust to the choice of alignment languages and generalizes to\nlanguages unseen during alignment. Furthermore, we show that separately trained\nalignment modules can be merged with existing task-specific modules, improving\ncross-lingual capabilities without full re-training. Our code is publicly\navailable (https://github.com/dannigt/mid-align).'}","['Danni Liu', 'Jan Niehues']",{'name': 'Jan Niehues'},Jan Niehues,,"[{'href': 'http://arxiv.org/abs/2502.14830v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14830v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14830v1,None,http://arxiv.org/abs/2502.14830v1,,,33,0
http://arxiv.org/abs/2502.14837v1,True,2025-02-20T18:50:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=50, tm_sec=42, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T18:50:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=50, tm_sec=42, tm_wday=3, tm_yday=51, tm_isdst=0)","Towards Economical Inference: Enabling DeepSeek's Multi-Head Latent
  Attention in Any Transformer-based LLMs","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Towards Economical Inference: Enabling DeepSeek's Multi-Head Latent\n  Attention in Any Transformer-based LLMs""}","Multi-head Latent Attention (MLA) is an innovative architecture proposed by
DeepSeek, designed to ensure efficient and economical inference by
significantly compressing the Key-Value (KV) cache into a latent vector.
Compared to MLA, standard LLMs employing Multi-Head Attention (MHA) and its
variants such as Grouped-Query Attention (GQA) exhibit significant cost
disadvantages. Enabling well-trained LLMs (e.g., Llama) to rapidly adapt to MLA
without pre-training from scratch is both meaningful and challenging. This
paper proposes the first data-efficient fine-tuning method for transitioning
from MHA to MLA (MHA2MLA), which includes two key components: for partial-RoPE,
we remove RoPE from dimensions of queries and keys that contribute less to the
attention scores, for low-rank approximation, we introduce joint SVD
approximations based on the pre-trained parameters of keys and values. These
carefully designed strategies enable MHA2MLA to recover performance using only
a small fraction (0.3% to 0.6%) of the data, significantly reducing inference
costs while seamlessly integrating with compression techniques such as KV cache
quantization. For example, the KV cache size of Llama2-7B is reduced by 92.19%,
with only a 0.5% drop in LongBench performance.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Multi-head Latent Attention (MLA) is an innovative architecture proposed by\nDeepSeek, designed to ensure efficient and economical inference by\nsignificantly compressing the Key-Value (KV) cache into a latent vector.\nCompared to MLA, standard LLMs employing Multi-Head Attention (MHA) and its\nvariants such as Grouped-Query Attention (GQA) exhibit significant cost\ndisadvantages. Enabling well-trained LLMs (e.g., Llama) to rapidly adapt to MLA\nwithout pre-training from scratch is both meaningful and challenging. This\npaper proposes the first data-efficient fine-tuning method for transitioning\nfrom MHA to MLA (MHA2MLA), which includes two key components: for partial-RoPE,\nwe remove RoPE from dimensions of queries and keys that contribute less to the\nattention scores, for low-rank approximation, we introduce joint SVD\napproximations based on the pre-trained parameters of keys and values. These\ncarefully designed strategies enable MHA2MLA to recover performance using only\na small fraction (0.3% to 0.6%) of the data, significantly reducing inference\ncosts while seamlessly integrating with compression techniques such as KV cache\nquantization. For example, the KV cache size of Llama2-7B is reduced by 92.19%,\nwith only a 0.5% drop in LongBench performance.'}","['Tao Ji', 'Bin Guo', 'Yuanbin Wu', 'Qipeng Guo', 'Lixing Shen', 'Zhan Chen', 'Xipeng Qiu', 'Qi Zhang', 'Tao Gui']",{'name': 'Tao Gui'},Tao Gui,"16 pages, 8 figures","[{'href': 'http://arxiv.org/abs/2502.14837v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14837v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14837v1,None,http://arxiv.org/abs/2502.14837v1,,,125,0
http://arxiv.org/abs/2502.14838v1,True,2025-02-20T18:51:12Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=51, tm_sec=12, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T18:51:12Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=51, tm_sec=12, tm_wday=3, tm_yday=51, tm_isdst=0)",Revealing and Mitigating Over-Attention in Knowledge Editing,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Revealing and Mitigating Over-Attention in Knowledge Editing'}","Large Language Models have demonstrated superior performance across a wide
range of tasks, but they still exhibit undesirable errors due to incorrect
knowledge learned from the training data. To avoid this, knowledge editing
methods emerged to precisely edit the specific model knowledge via efficiently
modifying a very small percentage of parameters. % However, those methods can
lead to the problem of Specificity Failure: when the content related to the
edited knowledge occurs in the context, it can inadvertently corrupt other
pre-existing knowledge. However, those methods can lead to the problem of
Specificity Failure, where the existing knowledge and capabilities are severely
degraded due to editing. Our preliminary indicates that Specificity Failure
primarily stems from the model's attention heads assigning excessive attention
scores to entities related to the edited knowledge, thereby unduly focusing on
specific snippets within the context, which we denote as the Attention Drift
phenomenon. To mitigate such Attention Drift issue, we introduce a simple yet
effective method Selective Attention Drift Restriction}(SADR), which introduces
an additional regularization term during the knowledge editing process to
restrict changes in the attention weight distribution, thereby preventing undue
focus on the edited entity. Experiments on five frequently used strong LLMs
demonstrate the effectiveness of our method, where SADR can significantly
mitigate Specificity Failure in the predominant knowledge editing tasks.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Large Language Models have demonstrated superior performance across a wide\nrange of tasks, but they still exhibit undesirable errors due to incorrect\nknowledge learned from the training data. To avoid this, knowledge editing\nmethods emerged to precisely edit the specific model knowledge via efficiently\nmodifying a very small percentage of parameters. % However, those methods can\nlead to the problem of Specificity Failure: when the content related to the\nedited knowledge occurs in the context, it can inadvertently corrupt other\npre-existing knowledge. However, those methods can lead to the problem of\nSpecificity Failure, where the existing knowledge and capabilities are severely\ndegraded due to editing. Our preliminary indicates that Specificity Failure\nprimarily stems from the model's attention heads assigning excessive attention\nscores to entities related to the edited knowledge, thereby unduly focusing on\nspecific snippets within the context, which we denote as the Attention Drift\nphenomenon. To mitigate such Attention Drift issue, we introduce a simple yet\neffective method Selective Attention Drift Restriction}(SADR), which introduces\nan additional regularization term during the knowledge editing process to\nrestrict changes in the attention weight distribution, thereby preventing undue\nfocus on the edited entity. Experiments on five frequently used strong LLMs\ndemonstrate the effectiveness of our method, where SADR can significantly\nmitigate Specificity Failure in the predominant knowledge editing tasks.""}","['Pinzheng Wang', 'Zecheng Tang', 'Keyan Zhou', 'Juntao Li', 'Qiaoming Zhu', 'Min Zhang']",{'name': 'Min Zhang'},Min Zhang,,"[{'href': 'http://arxiv.org/abs/2502.14838v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14838v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14838v1,None,http://arxiv.org/abs/2502.14838v1,,,72,0
http://arxiv.org/abs/2502.14864v1,True,2025-02-20T18:59:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=59, tm_sec=42, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T18:59:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=59, tm_sec=42, tm_wday=3, tm_yday=51, tm_isdst=0)","Benchmarking Multimodal RAG through a Chart-based Document
  Question-Answering Generation Framework","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Benchmarking Multimodal RAG through a Chart-based Document\n  Question-Answering Generation Framework'}","Multimodal Retrieval-Augmented Generation (MRAG) enhances reasoning
capabilities by integrating external knowledge. However, existing benchmarks
primarily focus on simple image-text interactions, overlooking complex visual
formats like charts that are prevalent in real-world applications. In this
work, we introduce a novel task, Chart-based MRAG, to address this limitation.
To semi-automatically generate high-quality evaluation samples, we propose
CHARt-based document question-answering GEneration (CHARGE), a framework that
produces evaluation data through structured keypoint extraction, crossmodal
verification, and keypoint-based generation. By combining CHARGE with expert
validation, we construct Chart-MRAG Bench, a comprehensive benchmark for
chart-based MRAG evaluation, featuring 4,738 question-answering pairs across 8
domains from real-world documents. Our evaluation reveals three critical
limitations in current approaches: (1) unified multimodal embedding retrieval
methods struggles in chart-based scenarios, (2) even with ground-truth
retrieval, state-of-the-art MLLMs achieve only 58.19% Correctness and 73.87%
Coverage scores, and (3) MLLMs demonstrate consistent text-over-visual modality
bias during Chart-based MRAG reasoning. The CHARGE and Chart-MRAG Bench are
released at https://github.com/Nomothings/CHARGE.git.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Multimodal Retrieval-Augmented Generation (MRAG) enhances reasoning\ncapabilities by integrating external knowledge. However, existing benchmarks\nprimarily focus on simple image-text interactions, overlooking complex visual\nformats like charts that are prevalent in real-world applications. In this\nwork, we introduce a novel task, Chart-based MRAG, to address this limitation.\nTo semi-automatically generate high-quality evaluation samples, we propose\nCHARt-based document question-answering GEneration (CHARGE), a framework that\nproduces evaluation data through structured keypoint extraction, crossmodal\nverification, and keypoint-based generation. By combining CHARGE with expert\nvalidation, we construct Chart-MRAG Bench, a comprehensive benchmark for\nchart-based MRAG evaluation, featuring 4,738 question-answering pairs across 8\ndomains from real-world documents. Our evaluation reveals three critical\nlimitations in current approaches: (1) unified multimodal embedding retrieval\nmethods struggles in chart-based scenarios, (2) even with ground-truth\nretrieval, state-of-the-art MLLMs achieve only 58.19% Correctness and 73.87%\nCoverage scores, and (3) MLLMs demonstrate consistent text-over-visual modality\nbias during Chart-based MRAG reasoning. The CHARGE and Chart-MRAG Bench are\nreleased at https://github.com/Nomothings/CHARGE.git.'}","['Yuming Yang', 'Jiang Zhong', 'Li Jin', 'Jingwang Huang', 'Jingpeng Gao', 'Qing Liu', 'Yang Bai', 'Jingyuan Zhang', 'Rui Jiang', 'Kaiwen Wei']",{'name': 'Kaiwen Wei'},Kaiwen Wei,,"[{'href': 'http://arxiv.org/abs/2502.14864v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14864v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14864v1,None,http://arxiv.org/abs/2502.14864v1,,,1,0
http://arxiv.org/abs/2502.10614v1,True,2025-02-15T00:27:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=0, tm_min=27, tm_sec=37, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T00:27:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=0, tm_min=27, tm_sec=37, tm_wday=5, tm_yday=46, tm_isdst=0)","Optimizing CNN Architectures for Advanced Thoracic Disease
  Classification","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Optimizing CNN Architectures for Advanced Thoracic Disease\n  Classification'}","Machine learning, particularly convolutional neural networks (CNNs), has
shown promise in medical image analysis, especially for thoracic disease
detection using chest X-ray images. In this study, we evaluate various CNN
architectures, including binary classification, multi-label classification, and
ResNet50 models, to address challenges like dataset imbalance, variations in
image quality, and hidden biases. We introduce advanced preprocessing
techniques such as principal component analysis (PCA) for image compression and
propose a novel class-weighted loss function to mitigate imbalance issues. Our
results highlight the potential of CNNs in medical imaging but emphasize that
issues like unbalanced datasets and variations in image acquisition methods
must be addressed for optimal model performance.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Machine learning, particularly convolutional neural networks (CNNs), has\nshown promise in medical image analysis, especially for thoracic disease\ndetection using chest X-ray images. In this study, we evaluate various CNN\narchitectures, including binary classification, multi-label classification, and\nResNet50 models, to address challenges like dataset imbalance, variations in\nimage quality, and hidden biases. We introduce advanced preprocessing\ntechniques such as principal component analysis (PCA) for image compression and\npropose a novel class-weighted loss function to mitigate imbalance issues. Our\nresults highlight the potential of CNNs in medical imaging but emphasize that\nissues like unbalanced datasets and variations in image acquisition methods\nmust be addressed for optimal model performance.'}",['Tejas Mirthipati'],{'name': 'Tejas Mirthipati'},Tejas Mirthipati,,"[{'href': 'http://arxiv.org/abs/2502.10614v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10614v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10614v1,None,http://arxiv.org/abs/2502.10614v1,,,0,0
http://arxiv.org/abs/2502.10631v1,True,2025-02-15T01:49:35Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=1, tm_min=49, tm_sec=35, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T01:49:35Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=1, tm_min=49, tm_sec=35, tm_wday=5, tm_yday=46, tm_isdst=0)","ControllableGPT: A Ground-Up Designed Controllable GPT for Molecule
  Optimization","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'ControllableGPT: A Ground-Up Designed Controllable GPT for Molecule\n  Optimization'}","Large Language Models (LLMs) employ three popular training approaches: Masked
Language Models (MLM), Causal Language Models (CLM), and Sequence-to-Sequence
Models (seq2seq). However, each approach has its strengths and limitations, and
faces challenges in addressing specific tasks that require controllable and
bidirectional generation, such as drug optimization. To address this challenge,
inspired by the biological processes of growth and evolution, which involve the
expansion, shrinking, and mutation of sequences, we introduce ControllableGPT.
This initiative represents the first effort to combine the advantages of MLM,
CLM, and seq2seq into a single unified, controllable GPT framework. It enables
the precise management of specific locations and ranges within a sequence,
allowing for expansion, reduction, or mutation over chosen or random lengths,
while maintaining the integrity of any specified positions or subsequences. In
this work, we designed ControllableGPT for drug optimization from the ground
up, which included proposing the Causally Masked Seq2seq (CMS) objective,
developing the training corpus, introducing a novel pre-training approach, and
devising a unique generation process. We demonstrate the effectiveness and
controllability of ControllableGPT by conducting experiments on drug
optimization tasks for both viral and cancer benchmarks, surpassing competing
baselines.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Language Models (LLMs) employ three popular training approaches: Masked\nLanguage Models (MLM), Causal Language Models (CLM), and Sequence-to-Sequence\nModels (seq2seq). However, each approach has its strengths and limitations, and\nfaces challenges in addressing specific tasks that require controllable and\nbidirectional generation, such as drug optimization. To address this challenge,\ninspired by the biological processes of growth and evolution, which involve the\nexpansion, shrinking, and mutation of sequences, we introduce ControllableGPT.\nThis initiative represents the first effort to combine the advantages of MLM,\nCLM, and seq2seq into a single unified, controllable GPT framework. It enables\nthe precise management of specific locations and ranges within a sequence,\nallowing for expansion, reduction, or mutation over chosen or random lengths,\nwhile maintaining the integrity of any specified positions or subsequences. In\nthis work, we designed ControllableGPT for drug optimization from the ground\nup, which included proposing the Causally Masked Seq2seq (CMS) objective,\ndeveloping the training corpus, introducing a novel pre-training approach, and\ndevising a unique generation process. We demonstrate the effectiveness and\ncontrollability of ControllableGPT by conducting experiments on drug\noptimization tasks for both viral and cancer benchmarks, surpassing competing\nbaselines.'}","['Xuefeng Liu', 'Songhao Jiang', 'Bo Li', 'Rick Stevens']",{'name': 'Rick Stevens'},Rick Stevens,,"[{'href': 'http://arxiv.org/abs/2502.10631v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10631v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-bio.BM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10631v1,None,http://arxiv.org/abs/2502.10631v1,,,20,0
http://arxiv.org/abs/2502.10636v1,True,2025-02-15T02:25:49Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=2, tm_min=25, tm_sec=49, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T02:25:49Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=2, tm_min=25, tm_sec=49, tm_wday=5, tm_yday=46, tm_isdst=0)","USER-VLM 360: Personalized Vision Language Models with User-aware Tuning
  for Social Human-Robot Interactions","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'USER-VLM 360: Personalized Vision Language Models with User-aware Tuning\n  for Social Human-Robot Interactions'}","The integration of vision-language models into robotic systems constitutes a
significant advancement in enabling machines to interact with their
surroundings in a more intuitive manner. While VLMs offer rich multimodal
reasoning, existing approaches lack user-specific adaptability, often relying
on generic interaction paradigms that fail to account for individual
behavioral, contextual, or socio-emotional nuances. When customization is
attempted, ethical concerns arise from unmitigated biases in user data, risking
exclusion or unfair treatment. To address these dual challenges, we propose
User-VLM 360{\deg}, a holistic framework integrating multimodal user modeling
with bias-aware optimization. Our approach features: (1) user-aware tuning that
adapts interactions in real time using visual-linguistic signals; (2) bias
mitigation via preference optimization; and (3) curated 360{\deg} socio-emotive
interaction datasets annotated with demographic, emotion, and relational
metadata. Evaluations across eight benchmarks demonstrate state-of-the-art
results: +35.3% F1 in personalized VQA, +47.5% F1 in facial features
understanding, 15% bias reduction, and 30X speedup over baselines. Ablation
studies confirm component efficacy, and deployment on the Pepper robot
validates real-time adaptability across diverse users. We open-source
parameter-efficient 3B/10B models and an ethical verification framework for
responsible adaptation.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The integration of vision-language models into robotic systems constitutes a\nsignificant advancement in enabling machines to interact with their\nsurroundings in a more intuitive manner. While VLMs offer rich multimodal\nreasoning, existing approaches lack user-specific adaptability, often relying\non generic interaction paradigms that fail to account for individual\nbehavioral, contextual, or socio-emotional nuances. When customization is\nattempted, ethical concerns arise from unmitigated biases in user data, risking\nexclusion or unfair treatment. To address these dual challenges, we propose\nUser-VLM 360{\\deg}, a holistic framework integrating multimodal user modeling\nwith bias-aware optimization. Our approach features: (1) user-aware tuning that\nadapts interactions in real time using visual-linguistic signals; (2) bias\nmitigation via preference optimization; and (3) curated 360{\\deg} socio-emotive\ninteraction datasets annotated with demographic, emotion, and relational\nmetadata. Evaluations across eight benchmarks demonstrate state-of-the-art\nresults: +35.3% F1 in personalized VQA, +47.5% F1 in facial features\nunderstanding, 15% bias reduction, and 30X speedup over baselines. Ablation\nstudies confirm component efficacy, and deployment on the Pepper robot\nvalidates real-time adaptability across diverse users. We open-source\nparameter-efficient 3B/10B models and an ethical verification framework for\nresponsible adaptation.'}","['Hamed Rahimi', 'Adil Bahaj', 'Mouad Abrini', 'Mahdi Khoramshahi', 'Mounir Ghogho', 'Mohamed Chetouani']",{'name': 'Mohamed Chetouani'},Mohamed Chetouani,,"[{'href': 'http://arxiv.org/abs/2502.10636v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10636v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10636v1,None,http://arxiv.org/abs/2502.10636v1,,,20,0
http://arxiv.org/abs/2502.10637v1,True,2025-02-15T02:25:57Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=2, tm_min=25, tm_sec=57, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T02:25:57Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=2, tm_min=25, tm_sec=57, tm_wday=5, tm_yday=46, tm_isdst=0)",Proof of Response,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Proof of Response'}","We present a mechanism that for a network of participants allows one
participant of the network (Alice) to request some data from another
participant (Bob) and either receive a response from Bob within a
known-in-advance, bounded time b, or receive a proof that at least one edge on
the way to Bob was broken within b, or receive a streaming payment proportional
to time passed beyond b during which neither was received. This mechanism
allows for building downstream applications that require provable responses
from other participants, such as decentralized storage solutions, decentralized
AI agents, and more.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'We present a mechanism that for a network of participants allows one\nparticipant of the network (Alice) to request some data from another\nparticipant (Bob) and either receive a response from Bob within a\nknown-in-advance, bounded time b, or receive a proof that at least one edge on\nthe way to Bob was broken within b, or receive a streaming payment proportional\nto time passed beyond b during which neither was received. This mechanism\nallows for building downstream applications that require provable responses\nfrom other participants, such as decentralized storage solutions, decentralized\nAI agents, and more.'}","['Illia Polosukhin', 'Alex Skidanov']",{'name': 'Alex Skidanov'},Alex Skidanov,,"[{'href': 'http://arxiv.org/abs/2502.10637v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10637v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.DC', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.DC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10637v1,None,http://arxiv.org/abs/2502.10637v1,,,119234,0
http://arxiv.org/abs/2502.10678v1,True,2025-02-15T05:31:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=5, tm_min=31, tm_sec=37, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T05:31:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=5, tm_min=31, tm_sec=37, tm_wday=5, tm_yday=46, tm_isdst=0)","GenComUI: Exploring Generative Visual Aids as Medium to Support
  Task-Oriented Human-Robot Communication","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'GenComUI: Exploring Generative Visual Aids as Medium to Support\n  Task-Oriented Human-Robot Communication'}","This work investigates the integration of generative visual aids in
human-robot task communication. We developed GenComUI, a system powered by
large language models that dynamically generates contextual visual aids (such
as map annotations, path indicators, and animations) to support verbal task
communication and facilitate the generation of customized task programs for the
robot. This system was informed by a formative study that examined how humans
use external visual tools to assist verbal communication in spatial tasks. To
evaluate its effectiveness, we conducted a user experiment (n = 20) comparing
GenComUI with a voice-only baseline. The results demonstrate that generative
visual aids, through both qualitative and quantitative analysis, enhance verbal
task communication by providing continuous visual feedback, thus promoting
natural and effective human-robot communication. Additionally, the study offers
a set of design implications, emphasizing how dynamically generated visual aids
can serve as an effective communication medium in human-robot interaction.
These findings underscore the potential of generative visual aids to inform the
design of more intuitive and effective human-robot communication, particularly
for complex communication scenarios in human-robot interaction and LLM-based
end-user development.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'This work investigates the integration of generative visual aids in\nhuman-robot task communication. We developed GenComUI, a system powered by\nlarge language models that dynamically generates contextual visual aids (such\nas map annotations, path indicators, and animations) to support verbal task\ncommunication and facilitate the generation of customized task programs for the\nrobot. This system was informed by a formative study that examined how humans\nuse external visual tools to assist verbal communication in spatial tasks. To\nevaluate its effectiveness, we conducted a user experiment (n = 20) comparing\nGenComUI with a voice-only baseline. The results demonstrate that generative\nvisual aids, through both qualitative and quantitative analysis, enhance verbal\ntask communication by providing continuous visual feedback, thus promoting\nnatural and effective human-robot communication. Additionally, the study offers\na set of design implications, emphasizing how dynamically generated visual aids\ncan serve as an effective communication medium in human-robot interaction.\nThese findings underscore the potential of generative visual aids to inform the\ndesign of more intuitive and effective human-robot communication, particularly\nfor complex communication scenarios in human-robot interaction and LLM-based\nend-user development.'}","['Yate Ge', 'Meiying Li', 'Xipeng Huang', 'Yuanda Hu', 'Qi Wang', 'Xiaohua Sun', 'Weiwei Guo']",{'name': 'Weiwei Guo'},Weiwei Guo,To appear at ACM CHI '25,"[{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3706598.3714238', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2502.10678v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10678v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.5.2; H.5.3; I.2.7; I.2.0', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10678v1,None,http://arxiv.org/abs/2502.10678v1,,10.1145/3706598.3714238,26,0
http://arxiv.org/abs/2502.10699v1,True,2025-02-15T07:06:10Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=7, tm_min=6, tm_sec=10, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T07:06:10Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=7, tm_min=6, tm_sec=10, tm_wday=5, tm_yday=46, tm_isdst=0)","Exploring Synaptic Resonance in Large Language Models: A Novel Approach
  to Contextual Memory Integration","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Exploring Synaptic Resonance in Large Language Models: A Novel Approach\n  to Contextual Memory Integration'}","Contextual memory integration remains a high challenge in the development of
language models, particularly in tasks that require maintaining coherence over
extended sequences. Traditional approaches, such as self-attention mechanisms
and memory-augmented architectures, often prioritize short-term dependencies,
leading to fragmentation and inconsistency in long-range contextual
understanding. Inspired by principles of synaptic plasticity observed in
biological neural systems, a novel mechanism, Synaptic Resonance, is introduced
to dynamically reinforce relevant memory pathways during training and
inference. Unlike static memory representations, this mechanism continuously
adjusts synaptic weight matrices based on contextual relevance, allowing for
improved information retention without excessive computational overhead.
Evaluations conducted on an open-source language model demonstrate reductions
in perplexity, enhancements in contextual coherence, and increased robustness
against input noise, highlighting the effectiveness of reinforcement-driven
memory modulation. Comparative analysis against baseline models further reveals
that the proposed approach achieves higher memory retention efficiency while
maintaining computational feasibility. The architectural modifications
integrate seamlessly into existing transformer-based frameworks, ensuring
stable convergence and efficient inference without sacrificing scalability.
Applications benefiting from improved long-term contextual consistency, such as
dialogue systems and document summarization, stand to gain from this approach.
Empirical findings suggest that dynamically reinforced memory pathways offer a
promising alternative to conventional memory mechanisms, addressing
longstanding limitations in extended sequence modeling.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Contextual memory integration remains a high challenge in the development of\nlanguage models, particularly in tasks that require maintaining coherence over\nextended sequences. Traditional approaches, such as self-attention mechanisms\nand memory-augmented architectures, often prioritize short-term dependencies,\nleading to fragmentation and inconsistency in long-range contextual\nunderstanding. Inspired by principles of synaptic plasticity observed in\nbiological neural systems, a novel mechanism, Synaptic Resonance, is introduced\nto dynamically reinforce relevant memory pathways during training and\ninference. Unlike static memory representations, this mechanism continuously\nadjusts synaptic weight matrices based on contextual relevance, allowing for\nimproved information retention without excessive computational overhead.\nEvaluations conducted on an open-source language model demonstrate reductions\nin perplexity, enhancements in contextual coherence, and increased robustness\nagainst input noise, highlighting the effectiveness of reinforcement-driven\nmemory modulation. Comparative analysis against baseline models further reveals\nthat the proposed approach achieves higher memory retention efficiency while\nmaintaining computational feasibility. The architectural modifications\nintegrate seamlessly into existing transformer-based frameworks, ensuring\nstable convergence and efficient inference without sacrificing scalability.\nApplications benefiting from improved long-term contextual consistency, such as\ndialogue systems and document summarization, stand to gain from this approach.\nEmpirical findings suggest that dynamically reinforced memory pathways offer a\npromising alternative to conventional memory mechanisms, addressing\nlongstanding limitations in extended sequence modeling.'}","['George Applegarth', 'Christian Weatherstone', 'Maximilian Hollingsworth', 'Henry Middlebrook', 'Marcus Irvin']",{'name': 'Marcus Irvin'},Marcus Irvin,,"[{'href': 'http://arxiv.org/abs/2502.10699v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10699v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10699v1,None,http://arxiv.org/abs/2502.10699v1,,,0,0
http://arxiv.org/abs/2502.10718v1,True,2025-02-15T08:19:20Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=8, tm_min=19, tm_sec=20, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T08:19:20Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=8, tm_min=19, tm_sec=20, tm_wday=5, tm_yday=46, tm_isdst=0)","Hyperdimensional Intelligent Sensing for Efficient Real-Time Audio
  Processing on Extreme Edge","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Hyperdimensional Intelligent Sensing for Efficient Real-Time Audio\n  Processing on Extreme Edge'}","The escalating challenges of managing vast sensor-generated data,
particularly in audio applications, necessitate innovative solutions. Current
systems face significant computational and storage demands, especially in
real-time applications like gunshot detection systems (GSDS), and the
proliferation of edge sensors exacerbates these issues. This paper proposes a
groundbreaking approach with a near-sensor model tailored for intelligent
audio-sensing frameworks. Utilizing a Fast Fourier Transform (FFT) module,
convolutional neural network (CNN) layers, and HyperDimensional Computing
(HDC), our model excels in low-energy, rapid inference, and online learning. It
is highly adaptable for efficient ASIC design implementation, offering superior
energy efficiency compared to conventional embedded CPUs or GPUs, and is
compatible with the trend of shrinking microphone sensor sizes. Comprehensive
evaluations at both software and hardware levels underscore the model's
efficacy. Software assessments through detailed ROC curve analysis revealed a
delicate balance between energy conservation and quality loss, achieving up to
82.1% energy savings with only 1.39% quality loss. Hardware evaluations
highlight the model's commendable energy efficiency when implemented via ASIC
design, especially with the Google Edge TPU, showcasing its superiority over
prevalent embedded CPUs and GPUs.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""The escalating challenges of managing vast sensor-generated data,\nparticularly in audio applications, necessitate innovative solutions. Current\nsystems face significant computational and storage demands, especially in\nreal-time applications like gunshot detection systems (GSDS), and the\nproliferation of edge sensors exacerbates these issues. This paper proposes a\ngroundbreaking approach with a near-sensor model tailored for intelligent\naudio-sensing frameworks. Utilizing a Fast Fourier Transform (FFT) module,\nconvolutional neural network (CNN) layers, and HyperDimensional Computing\n(HDC), our model excels in low-energy, rapid inference, and online learning. It\nis highly adaptable for efficient ASIC design implementation, offering superior\nenergy efficiency compared to conventional embedded CPUs or GPUs, and is\ncompatible with the trend of shrinking microphone sensor sizes. Comprehensive\nevaluations at both software and hardware levels underscore the model's\nefficacy. Software assessments through detailed ROC curve analysis revealed a\ndelicate balance between energy conservation and quality loss, achieving up to\n82.1% energy savings with only 1.39% quality loss. Hardware evaluations\nhighlight the model's commendable energy efficiency when implemented via ASIC\ndesign, especially with the Google Edge TPU, showcasing its superiority over\nprevalent embedded CPUs and GPUs.""}","['Sanggeon Yun', 'Ryozo Masukawa', 'Hanning Chen', 'SungHeon Jeong', 'Wenjun Huang', 'Arghavan Rezvani', 'Minhyoung Na', 'Yoshiki Yamaguchi', 'Mohsen Imani']",{'name': 'Mohsen Imani'},Mohsen Imani,Accepted to IEEE Access,"[{'href': 'http://arxiv.org/abs/2502.10718v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10718v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.SD', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.SD', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'eess.AS', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10718v1,None,http://arxiv.org/abs/2502.10718v1,,,244,0
http://arxiv.org/abs/2502.10762v1,True,2025-02-15T11:00:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=11, tm_min=0, tm_sec=36, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T11:00:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=11, tm_min=0, tm_sec=36, tm_wday=5, tm_yday=46, tm_isdst=0)","Bone Soups: A Seek-and-Soup Model Merging Approach for Controllable
  Multi-Objective Generation","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Bone Soups: A Seek-and-Soup Model Merging Approach for Controllable\n  Multi-Objective Generation'}","User information needs are often highly diverse and varied. A key challenge
in current research is how to achieve controllable multi-objective generation
while enabling rapid adaptation to accommodate diverse user demands during test
time. Existing solutions, such as Rewarded Soup, focus on merging language
models individually tuned on single objectives. While easy to implement and
widely used, these approaches face limitations in achieving optimal performance
due to their disregard for the impacts of competing objectives on model tuning.
To address this issue, we propose Bone Soup, a novel model merging approach
that first seeks a series of backbone models by considering the impacts of
multiple objectives and then makes the soup (i.e., merge the backbone models).
Specifically, Bone Soup begins by training multiple backbone models for
different objectives using multi-objective reinforcement learning. Each
backbone model is guided by a combination of backbone reward signals. To ensure
that these models are optimal for the Pareto front, the backbone rewards are
crafted by combining standard reward functions into basis vectors, which can
then be modified through a rule-based construction method. Bone Soup leverages
a symmetric circulant matrix mapping to generate the merging coefficients,
which are used to merge the backbone models according to user preferences.
Extensive experimental results demonstrate that Bone Soup exhibits strong
controllability and Pareto optimality in controllable multi-objective
generation, providing a more effective and efficient approach to addressing
diverse user needs at test time.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'User information needs are often highly diverse and varied. A key challenge\nin current research is how to achieve controllable multi-objective generation\nwhile enabling rapid adaptation to accommodate diverse user demands during test\ntime. Existing solutions, such as Rewarded Soup, focus on merging language\nmodels individually tuned on single objectives. While easy to implement and\nwidely used, these approaches face limitations in achieving optimal performance\ndue to their disregard for the impacts of competing objectives on model tuning.\nTo address this issue, we propose Bone Soup, a novel model merging approach\nthat first seeks a series of backbone models by considering the impacts of\nmultiple objectives and then makes the soup (i.e., merge the backbone models).\nSpecifically, Bone Soup begins by training multiple backbone models for\ndifferent objectives using multi-objective reinforcement learning. Each\nbackbone model is guided by a combination of backbone reward signals. To ensure\nthat these models are optimal for the Pareto front, the backbone rewards are\ncrafted by combining standard reward functions into basis vectors, which can\nthen be modified through a rule-based construction method. Bone Soup leverages\na symmetric circulant matrix mapping to generate the merging coefficients,\nwhich are used to merge the backbone models according to user preferences.\nExtensive experimental results demonstrate that Bone Soup exhibits strong\ncontrollability and Pareto optimality in controllable multi-objective\ngeneration, providing a more effective and efficient approach to addressing\ndiverse user needs at test time.'}","['Guofu Xie', 'Xiao Zhang', 'Ting Yao', 'Yunsheng Shi']",{'name': 'Yunsheng Shi'},Yunsheng Shi,work in progress,"[{'href': 'http://arxiv.org/abs/2502.10762v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10762v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10762v1,None,http://arxiv.org/abs/2502.10762v1,,,3,0
http://arxiv.org/abs/2502.10768v1,True,2025-02-15T11:17:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=11, tm_min=17, tm_sec=37, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T11:17:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=11, tm_min=17, tm_sec=37, tm_wday=5, tm_yday=46, tm_isdst=0)","Evaluating improvements on using Large Language Models (LLMs) for
  property extraction in the Open Research Knowledge Graph (ORKG)","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Evaluating improvements on using Large Language Models (LLMs) for\n  property extraction in the Open Research Knowledge Graph (ORKG)'}","Current research highlights the great potential of Large Language Models
(LLMs) for constructing Scholarly Knowledge Graphs (SKGs). One particularly
complex step in this process is relation extraction, aimed at identifying
suitable properties to describe the content of research. This study builds
directly on previous research of three Open Research Knowledge Graph (ORKG)
team members who assessed the readiness of LLMs such as GPT-3.5, Llama 2, and
Mistral for property extraction in scientific literature. Given the moderate
performance observed, the previous work concluded that fine-tuning is needed to
improve these models' alignment with scientific tasks and their emulation of
human expertise. Expanding on this prior experiment, this study evaluates the
impact of advanced prompt engineering techniques and demonstrates that these
techniques can highly significantly enhance the results. Additionally, this
study extends the property extraction process to include property matching to
existing ORKG properties, which are retrieved via the API. The evaluation
reveals that results generated through advanced prompt engineering achieve a
higher proportion of matches with ORKG properties, further emphasizing the
enhanced alignment achieved. Moreover, this lays the groundwork for addressing
challenges such as the inconsistency of ORKG properties, an issue highlighted
in prior studies. By assigning unique URIs and using standardized terminology,
this work increases the consistency of the properties, fulfilling a crucial
aspect of Linked Data and FAIR principles - core commitments of ORKG. This, in
turn, significantly enhances the applicability of ORKG content for subsequent
tasks such as comparisons of research publications. Finally, the study
concludes with recommendations for future improvements in the overall property
extraction process.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Current research highlights the great potential of Large Language Models\n(LLMs) for constructing Scholarly Knowledge Graphs (SKGs). One particularly\ncomplex step in this process is relation extraction, aimed at identifying\nsuitable properties to describe the content of research. This study builds\ndirectly on previous research of three Open Research Knowledge Graph (ORKG)\nteam members who assessed the readiness of LLMs such as GPT-3.5, Llama 2, and\nMistral for property extraction in scientific literature. Given the moderate\nperformance observed, the previous work concluded that fine-tuning is needed to\nimprove these models' alignment with scientific tasks and their emulation of\nhuman expertise. Expanding on this prior experiment, this study evaluates the\nimpact of advanced prompt engineering techniques and demonstrates that these\ntechniques can highly significantly enhance the results. Additionally, this\nstudy extends the property extraction process to include property matching to\nexisting ORKG properties, which are retrieved via the API. The evaluation\nreveals that results generated through advanced prompt engineering achieve a\nhigher proportion of matches with ORKG properties, further emphasizing the\nenhanced alignment achieved. Moreover, this lays the groundwork for addressing\nchallenges such as the inconsistency of ORKG properties, an issue highlighted\nin prior studies. By assigning unique URIs and using standardized terminology,\nthis work increases the consistency of the properties, fulfilling a crucial\naspect of Linked Data and FAIR principles - core commitments of ORKG. This, in\nturn, significantly enhances the applicability of ORKG content for subsequent\ntasks such as comparisons of research publications. Finally, the study\nconcludes with recommendations for future improvements in the overall property\nextraction process.""}",['Sandra Schaftner'],{'name': 'Sandra Schaftner'},Sandra Schaftner,,"[{'href': 'http://arxiv.org/abs/2502.10768v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10768v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10768v1,None,http://arxiv.org/abs/2502.10768v1,,,0,0
http://arxiv.org/abs/2502.10776v1,True,2025-02-15T11:44:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=11, tm_min=44, tm_sec=15, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T11:44:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=11, tm_min=44, tm_sec=15, tm_wday=5, tm_yday=46, tm_isdst=0)","A Distillation-based Future-aware Graph Neural Network for Stock Trend
  Prediction","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A Distillation-based Future-aware Graph Neural Network for Stock Trend\n  Prediction'}","Stock trend prediction involves forecasting the future price movements by
analyzing historical data and various market indicators. With the advancement
of machine learning, graph neural networks (GNNs) have been extensively
employed in stock prediction due to their powerful capability to capture
spatiotemporal dependencies of stocks. However, despite the efforts of various
GNN stock predictors to enhance predictive performance, the improvements remain
limited, as they focus solely on analyzing historical spatiotemporal
dependencies, overlooking the correlation between historical and future
patterns. In this study, we propose a novel distillation-based future-aware GNN
framework (DishFT-GNN) for stock trend prediction. Specifically, DishFT-GNN
trains a teacher model and a student model, iteratively. The teacher model
learns to capture the correlation between distribution shifts of historical and
future data, which is then utilized as intermediate supervision to guide the
student model to learn future-aware spatiotemporal embeddings for accurate
prediction. Through extensive experiments on two real-world datasets, we verify
the state-of-the-art performance of DishFT-GNN.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Stock trend prediction involves forecasting the future price movements by\nanalyzing historical data and various market indicators. With the advancement\nof machine learning, graph neural networks (GNNs) have been extensively\nemployed in stock prediction due to their powerful capability to capture\nspatiotemporal dependencies of stocks. However, despite the efforts of various\nGNN stock predictors to enhance predictive performance, the improvements remain\nlimited, as they focus solely on analyzing historical spatiotemporal\ndependencies, overlooking the correlation between historical and future\npatterns. In this study, we propose a novel distillation-based future-aware GNN\nframework (DishFT-GNN) for stock trend prediction. Specifically, DishFT-GNN\ntrains a teacher model and a student model, iteratively. The teacher model\nlearns to capture the correlation between distribution shifts of historical and\nfuture data, which is then utilized as intermediate supervision to guide the\nstudent model to learn future-aware spatiotemporal embeddings for accurate\nprediction. Through extensive experiments on two real-world datasets, we verify\nthe state-of-the-art performance of DishFT-GNN.'}","['Zhipeng Liu', 'Peibo Duan', 'Mingyang Geng', 'Bin Zhang']",{'name': 'Bin Zhang'},Bin Zhang,,"[{'href': 'http://arxiv.org/abs/2502.10776v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10776v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-fin.PM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10776v1,None,http://arxiv.org/abs/2502.10776v1,,,305,0
http://arxiv.org/abs/2502.10793v1,True,2025-02-15T13:24:21Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=13, tm_min=24, tm_sec=21, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T13:24:21Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=13, tm_min=24, tm_sec=21, tm_wday=5, tm_yday=46, tm_isdst=0)","Dynamic Influence Tracker: Measuring Time-Varying Sample Influence
  During Training","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Dynamic Influence Tracker: Measuring Time-Varying Sample Influence\n  During Training'}","Existing methods for measuring training sample influence on models only
provide static, overall measurements, overlooking how sample influence changes
during training. We propose Dynamic Influence Tracker (DIT), which captures the
time-varying sample influence across arbitrary time windows during training.
  DIT offers three key insights: 1) Samples show different time-varying
influence patterns, with some samples important in the early training stage
while others become important later. 2) Sample influences show a weak
correlation between early and late stages, demonstrating that the model
undergoes distinct learning phases with shifting priorities. 3) Analyzing
influence during the convergence period provides more efficient and accurate
detection of corrupted samples than full-training analysis. Supported by
theoretical guarantees without assuming loss convexity or model convergence,
DIT significantly outperforms existing methods, achieving up to 0.99
correlation with ground truth and above 98\% accuracy in detecting corrupted
samples in complex architectures.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Existing methods for measuring training sample influence on models only\nprovide static, overall measurements, overlooking how sample influence changes\nduring training. We propose Dynamic Influence Tracker (DIT), which captures the\ntime-varying sample influence across arbitrary time windows during training.\n  DIT offers three key insights: 1) Samples show different time-varying\ninfluence patterns, with some samples important in the early training stage\nwhile others become important later. 2) Sample influences show a weak\ncorrelation between early and late stages, demonstrating that the model\nundergoes distinct learning phases with shifting priorities. 3) Analyzing\ninfluence during the convergence period provides more efficient and accurate\ndetection of corrupted samples than full-training analysis. Supported by\ntheoretical guarantees without assuming loss convexity or model convergence,\nDIT significantly outperforms existing methods, achieving up to 0.99\ncorrelation with ground truth and above 98\\% accuracy in detecting corrupted\nsamples in complex architectures.'}","['Jie Xu', 'Zihan Wu']",{'name': 'Zihan Wu'},Zihan Wu,,"[{'href': 'http://arxiv.org/abs/2502.10793v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10793v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10793v1,None,http://arxiv.org/abs/2502.10793v1,,,7,0
http://arxiv.org/abs/2502.10801v1,True,2025-02-15T13:45:19Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=13, tm_min=45, tm_sec=19, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T13:45:19Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=13, tm_min=45, tm_sec=19, tm_wday=5, tm_yday=46, tm_isdst=0)","FaceSwapGuard: Safeguarding Facial Privacy from DeepFake Threats through
  Identity Obfuscation","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'FaceSwapGuard: Safeguarding Facial Privacy from DeepFake Threats through\n  Identity Obfuscation'}","DeepFakes pose a significant threat to our society. One representative
DeepFake application is face-swapping, which replaces the identity in a facial
image with that of a victim. Although existing methods partially mitigate these
risks by degrading the quality of swapped images, they often fail to disrupt
the identity transformation effectively. To fill this gap, we propose
FaceSwapGuard (FSG), a novel black-box defense mechanism against deepfake
face-swapping threats. Specifically, FSG introduces imperceptible perturbations
to a user's facial image, disrupting the features extracted by identity
encoders. When shared online, these perturbed images mislead face-swapping
techniques, causing them to generate facial images with identities
significantly different from the original user. Extensive experiments
demonstrate the effectiveness of FSG against multiple face-swapping techniques,
reducing the face match rate from 90\% (without defense) to below 10\%. Both
qualitative and quantitative studies further confirm its ability to confuse
human perception, highlighting its practical utility. Additionally, we
investigate key factors that may influence FSG and evaluate its robustness
against various adaptive adversaries.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""DeepFakes pose a significant threat to our society. One representative\nDeepFake application is face-swapping, which replaces the identity in a facial\nimage with that of a victim. Although existing methods partially mitigate these\nrisks by degrading the quality of swapped images, they often fail to disrupt\nthe identity transformation effectively. To fill this gap, we propose\nFaceSwapGuard (FSG), a novel black-box defense mechanism against deepfake\nface-swapping threats. Specifically, FSG introduces imperceptible perturbations\nto a user's facial image, disrupting the features extracted by identity\nencoders. When shared online, these perturbed images mislead face-swapping\ntechniques, causing them to generate facial images with identities\nsignificantly different from the original user. Extensive experiments\ndemonstrate the effectiveness of FSG against multiple face-swapping techniques,\nreducing the face match rate from 90\\% (without defense) to below 10\\%. Both\nqualitative and quantitative studies further confirm its ability to confuse\nhuman perception, highlighting its practical utility. Additionally, we\ninvestigate key factors that may influence FSG and evaluate its robustness\nagainst various adaptive adversaries.""}","['Li Wang', 'Zheng Li', 'Xuhong Zhang', 'Shouling Ji', 'Shanqing Guo']",{'name': 'Shanqing Guo'},Shanqing Guo,,"[{'href': 'http://arxiv.org/abs/2502.10801v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10801v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10801v1,None,http://arxiv.org/abs/2502.10801v1,,,197,0
http://arxiv.org/abs/2502.10803v1,True,2025-02-15T13:55:34Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=13, tm_min=55, tm_sec=34, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T13:55:34Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=13, tm_min=55, tm_sec=34, tm_wday=5, tm_yday=46, tm_isdst=0)","PDA: Generalizable Detection of AI-Generated Images via Post-hoc
  Distribution Alignment","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'PDA: Generalizable Detection of AI-Generated Images via Post-hoc\n  Distribution Alignment'}","The rapid advancement of generative models has led to the proliferation of
highly realistic AI-generated images, posing significant challenges for
detection methods to generalize across diverse and evolving generative
techniques. Existing approaches often fail to adapt to unknown models without
costly retraining, limiting their practicability. To fill this gap, we propose
Post-hoc Distribution Alignment (PDA), a novel approach for the generalizable
detection for AI-generated images. The key idea is to use the known generative
model to regenerate undifferentiated test images. This process aligns the
distributions of the re-generated real images with the known fake images,
enabling effective distinction from unknown fake images. PDA employs a two-step
detection framework: 1) evaluating whether a test image aligns with the known
fake distribution based on deep k-nearest neighbor (KNN) distance, and 2)
re-generating test images using known generative models to create pseudo-fake
images for further classification. This alignment strategy allows PDA to
effectively detect fake images without relying on unseen data or requiring
retraining. Extensive experiments demonstrate the superiority of PDA, achieving
96.73\% average accuracy across six state-of-the-art generative models,
including GANs, diffusion models, and text-to-image models, and improving by
16.07\% over the best baseline. Through t-SNE visualizations and KNN distance
analysis, we provide insights into PDA's effectiveness in separating real and
fake images. Our work provides a flexible and effective solution for real-world
fake image detection, advancing the generalization ability of detection
systems.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""The rapid advancement of generative models has led to the proliferation of\nhighly realistic AI-generated images, posing significant challenges for\ndetection methods to generalize across diverse and evolving generative\ntechniques. Existing approaches often fail to adapt to unknown models without\ncostly retraining, limiting their practicability. To fill this gap, we propose\nPost-hoc Distribution Alignment (PDA), a novel approach for the generalizable\ndetection for AI-generated images. The key idea is to use the known generative\nmodel to regenerate undifferentiated test images. This process aligns the\ndistributions of the re-generated real images with the known fake images,\nenabling effective distinction from unknown fake images. PDA employs a two-step\ndetection framework: 1) evaluating whether a test image aligns with the known\nfake distribution based on deep k-nearest neighbor (KNN) distance, and 2)\nre-generating test images using known generative models to create pseudo-fake\nimages for further classification. This alignment strategy allows PDA to\neffectively detect fake images without relying on unseen data or requiring\nretraining. Extensive experiments demonstrate the superiority of PDA, achieving\n96.73\\% average accuracy across six state-of-the-art generative models,\nincluding GANs, diffusion models, and text-to-image models, and improving by\n16.07\\% over the best baseline. Through t-SNE visualizations and KNN distance\nanalysis, we provide insights into PDA's effectiveness in separating real and\nfake images. Our work provides a flexible and effective solution for real-world\nfake image detection, advancing the generalization ability of detection\nsystems.""}","['Li Wang', 'Wenyu Chen', 'Zheng Li', 'Shanqing Guo']",{'name': 'Shanqing Guo'},Shanqing Guo,,"[{'href': 'http://arxiv.org/abs/2502.10803v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10803v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10803v1,None,http://arxiv.org/abs/2502.10803v1,,,193,0
http://arxiv.org/abs/2502.10807v2,True,2025-02-18T02:00:07Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=2, tm_min=0, tm_sec=7, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-15T14:23:43Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=14, tm_min=23, tm_sec=43, tm_wday=5, tm_yday=46, tm_isdst=0)",HybriDNA: A Hybrid Transformer-Mamba2 Long-Range DNA Language Model,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'HybriDNA: A Hybrid Transformer-Mamba2 Long-Range DNA Language Model'}","Advances in natural language processing and large language models have
sparked growing interest in modeling DNA, often referred to as the ""language of
life"". However, DNA modeling poses unique challenges. First, it requires the
ability to process ultra-long DNA sequences while preserving single-nucleotide
resolution, as individual nucleotides play a critical role in DNA function.
Second, success in this domain requires excelling at both generative and
understanding tasks: generative tasks hold potential for therapeutic and
industrial applications, while understanding tasks provide crucial insights
into biological mechanisms and diseases. To address these challenges, we
propose HybriDNA, a decoder-only DNA language model that incorporates a hybrid
Transformer-Mamba2 architecture, seamlessly integrating the strengths of
attention mechanisms with selective state-space models. This hybrid design
enables HybriDNA to efficiently process DNA sequences up to 131kb in length
with single-nucleotide resolution. HybriDNA achieves state-of-the-art
performance across 33 DNA understanding datasets curated from the BEND, GUE,
and LRB benchmarks, and demonstrates exceptional capability in generating
synthetic cis-regulatory elements (CREs) with desired properties. Furthermore,
we show that HybriDNA adheres to expected scaling laws, with performance
improving consistently as the model scales from 300M to 3B and 7B parameters.
These findings underscore HybriDNA's versatility and its potential to advance
DNA research and applications, paving the way for innovations in understanding
and engineering the ""language of life"".","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Advances in natural language processing and large language models have\nsparked growing interest in modeling DNA, often referred to as the ""language of\nlife"". However, DNA modeling poses unique challenges. First, it requires the\nability to process ultra-long DNA sequences while preserving single-nucleotide\nresolution, as individual nucleotides play a critical role in DNA function.\nSecond, success in this domain requires excelling at both generative and\nunderstanding tasks: generative tasks hold potential for therapeutic and\nindustrial applications, while understanding tasks provide crucial insights\ninto biological mechanisms and diseases. To address these challenges, we\npropose HybriDNA, a decoder-only DNA language model that incorporates a hybrid\nTransformer-Mamba2 architecture, seamlessly integrating the strengths of\nattention mechanisms with selective state-space models. This hybrid design\nenables HybriDNA to efficiently process DNA sequences up to 131kb in length\nwith single-nucleotide resolution. HybriDNA achieves state-of-the-art\nperformance across 33 DNA understanding datasets curated from the BEND, GUE,\nand LRB benchmarks, and demonstrates exceptional capability in generating\nsynthetic cis-regulatory elements (CREs) with desired properties. Furthermore,\nwe show that HybriDNA adheres to expected scaling laws, with performance\nimproving consistently as the model scales from 300M to 3B and 7B parameters.\nThese findings underscore HybriDNA\'s versatility and its potential to advance\nDNA research and applications, paving the way for innovations in understanding\nand engineering the ""language of life"".'}","['Mingqian Ma', 'Guoqing Liu', 'Chuan Cao', 'Pan Deng', 'Tri Dao', 'Albert Gu', 'Peiran Jin', 'Zhao Yang', 'Yingce Xia', 'Renqian Luo', 'Pipi Hu', 'Zun Wang', 'Yuan-Jyue Chen', 'Haiguang Liu', 'Tao Qin']",{'name': 'Tao Qin'},Tao Qin,Project page: https://hybridna-project.github.io/HybriDNA-Project/,"[{'href': 'http://arxiv.org/abs/2502.10807v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10807v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-bio.GN', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10807v2,None,http://arxiv.org/abs/2502.10807v2,,,10497,0
http://arxiv.org/abs/2502.10822v1,True,2025-02-15T14:55:40Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=14, tm_min=55, tm_sec=40, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T14:55:40Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=14, tm_min=55, tm_sec=40, tm_wday=5, tm_yday=46, tm_isdst=0)","NeuroAMP: A Novel End-to-end General Purpose Deep Neural Amplifier for
  Personalized Hearing Aids","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'NeuroAMP: A Novel End-to-end General Purpose Deep Neural Amplifier for\n  Personalized Hearing Aids'}","The prevalence of hearing aids is increasing. However, optimizing the
amplification processes of hearing aids remains challenging due to the
complexity of integrating multiple modular components in traditional methods.
To address this challenge, we present NeuroAMP, a novel deep neural network
designed for end-to-end, personalized amplification in hearing aids. NeuroAMP
leverages both spectral features and the listener's audiogram as inputs, and we
investigate four architectures: Convolutional Neural Network (CNN), Long
Short-Term Memory (LSTM), Convolutional Recurrent Neural Network (CRNN), and
Transformer. We also introduce Denoising NeuroAMP, an extension that integrates
noise reduction along with amplification capabilities for improved performance
in real-world scenarios. To enhance generalization, a comprehensive data
augmentation strategy was employed during training on diverse speech (TIMIT and
TMHINT) and music (Cadenza Challenge MUSIC) datasets. Evaluation using the
Hearing Aid Speech Perception Index (HASPI), Hearing Aid Speech Quality Index
(HASQI), and Hearing Aid Audio Quality Index (HAAQI) demonstrates that the
Transformer architecture within NeuroAMP achieves the best performance, with
SRCC scores of 0.9927 (HASQI) and 0.9905 (HASPI) on TIMIT, and 0.9738 (HAAQI)
on the Cadenza Challenge MUSIC dataset. Notably, our data augmentation strategy
maintains high performance on unseen datasets (e.g., VCTK, MUSDB18-HQ).
Furthermore, Denoising NeuroAMP outperforms both the conventional NAL-R+WDRC
approach and a two-stage baseline on the VoiceBank+DEMAND dataset, achieving a
10% improvement in both HASPI (0.90) and HASQI (0.59) scores. These results
highlight the potential of NeuroAMP and Denoising NeuroAMP to deliver notable
improvements in personalized hearing aid amplification.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""The prevalence of hearing aids is increasing. However, optimizing the\namplification processes of hearing aids remains challenging due to the\ncomplexity of integrating multiple modular components in traditional methods.\nTo address this challenge, we present NeuroAMP, a novel deep neural network\ndesigned for end-to-end, personalized amplification in hearing aids. NeuroAMP\nleverages both spectral features and the listener's audiogram as inputs, and we\ninvestigate four architectures: Convolutional Neural Network (CNN), Long\nShort-Term Memory (LSTM), Convolutional Recurrent Neural Network (CRNN), and\nTransformer. We also introduce Denoising NeuroAMP, an extension that integrates\nnoise reduction along with amplification capabilities for improved performance\nin real-world scenarios. To enhance generalization, a comprehensive data\naugmentation strategy was employed during training on diverse speech (TIMIT and\nTMHINT) and music (Cadenza Challenge MUSIC) datasets. Evaluation using the\nHearing Aid Speech Perception Index (HASPI), Hearing Aid Speech Quality Index\n(HASQI), and Hearing Aid Audio Quality Index (HAAQI) demonstrates that the\nTransformer architecture within NeuroAMP achieves the best performance, with\nSRCC scores of 0.9927 (HASQI) and 0.9905 (HASPI) on TIMIT, and 0.9738 (HAAQI)\non the Cadenza Challenge MUSIC dataset. Notably, our data augmentation strategy\nmaintains high performance on unseen datasets (e.g., VCTK, MUSDB18-HQ).\nFurthermore, Denoising NeuroAMP outperforms both the conventional NAL-R+WDRC\napproach and a two-stage baseline on the VoiceBank+DEMAND dataset, achieving a\n10% improvement in both HASPI (0.90) and HASQI (0.59) scores. These results\nhighlight the potential of NeuroAMP and Denoising NeuroAMP to deliver notable\nimprovements in personalized hearing aid amplification.""}","['Shafique Ahmed', 'Ryandhimas E. Zezario', 'Hui-Guan Yuan', 'Amir Hussain', 'Hsin-Min Wang', 'Wei-Ho Chung', 'Yu Tsao']",{'name': 'Yu Tsao'},Yu Tsao,,"[{'href': 'http://arxiv.org/abs/2502.10822v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10822v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'eess.AS', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'eess.AS', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SD', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10822v1,None,http://arxiv.org/abs/2502.10822v1,,,1636,0
http://arxiv.org/abs/2502.10828v1,True,2025-02-15T15:07:01Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=15, tm_min=7, tm_sec=1, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T15:07:01Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=15, tm_min=7, tm_sec=1, tm_wday=5, tm_yday=46, tm_isdst=0)",The Vendiscope: An Algorithmic Microscope For Data Collections,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The Vendiscope: An Algorithmic Microscope For Data Collections'}","The evolution of microscopy, beginning with its invention in the late 16th
century, has continuously enhanced our ability to explore and understand the
microscopic world, enabling increasingly detailed observations of structures
and phenomena. In parallel, the rise of data-driven science has underscored the
need for sophisticated methods to explore and understand the composition of
complex data collections. This paper introduces the Vendiscope, the first
algorithmic microscope designed to extend traditional microscopy to
computational analysis. The Vendiscope leverages the Vendi scores -- a family
of differentiable diversity metrics rooted in ecology and quantum mechanics --
and assigns weights to data points based on their contribution to the overall
diversity of the collection. These weights enable high-resolution data analysis
at scale. We demonstrate this across biology, materials science, and machine
learning (ML). We analyzed the $250$ million protein sequences in the protein
universe, discovering that over $200$ million are near-duplicates and that
AlphaFold fails on proteins with Gene Ontology (GO) functions that contribute
most to diversity. Applying the Vendiscope to the Materials Project database
led to similar findings: more than $85\%$ of the crystals with formation energy
data are near-duplicates and ML models perform poorly on materials that enhance
diversity. Additionally, the Vendiscope can be used to study phenomena such as
memorization in generative models. We used the Vendiscope to identify memorized
training samples from $13$ different generative models and found that the
best-performing ones often memorize the training samples that contribute least
to diversity. Our findings demonstrate that the Vendiscope can serve as a
powerful tool for data-driven science.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The evolution of microscopy, beginning with its invention in the late 16th\ncentury, has continuously enhanced our ability to explore and understand the\nmicroscopic world, enabling increasingly detailed observations of structures\nand phenomena. In parallel, the rise of data-driven science has underscored the\nneed for sophisticated methods to explore and understand the composition of\ncomplex data collections. This paper introduces the Vendiscope, the first\nalgorithmic microscope designed to extend traditional microscopy to\ncomputational analysis. The Vendiscope leverages the Vendi scores -- a family\nof differentiable diversity metrics rooted in ecology and quantum mechanics --\nand assigns weights to data points based on their contribution to the overall\ndiversity of the collection. These weights enable high-resolution data analysis\nat scale. We demonstrate this across biology, materials science, and machine\nlearning (ML). We analyzed the $250$ million protein sequences in the protein\nuniverse, discovering that over $200$ million are near-duplicates and that\nAlphaFold fails on proteins with Gene Ontology (GO) functions that contribute\nmost to diversity. Applying the Vendiscope to the Materials Project database\nled to similar findings: more than $85\\%$ of the crystals with formation energy\ndata are near-duplicates and ML models perform poorly on materials that enhance\ndiversity. Additionally, the Vendiscope can be used to study phenomena such as\nmemorization in generative models. We used the Vendiscope to identify memorized\ntraining samples from $13$ different generative models and found that the\nbest-performing ones often memorize the training samples that contribute least\nto diversity. Our findings demonstrate that the Vendiscope can serve as a\npowerful tool for data-driven science.'}","['Amey P. Pasarkar', 'Adji Bousso Dieng']",{'name': 'Adji Bousso Dieng'},Adji Bousso Dieng,"This paper introduces the concept of ""algorithmic microscopes"" and
  proposes the Vendiscope, an algorithmic microscope for data-driven science","[{'href': 'http://arxiv.org/abs/2502.10828v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10828v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cond-mat.mtrl-sci', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-bio.QM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10828v1,None,http://arxiv.org/abs/2502.10828v1,,,136,0
http://arxiv.org/abs/2502.10871v1,True,2025-02-15T18:08:51Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=18, tm_min=8, tm_sec=51, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T18:08:51Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=18, tm_min=8, tm_sec=51, tm_wday=5, tm_yday=46, tm_isdst=0)","The Representation and Recall of Interwoven Structured Knowledge in
  LLMs: A Geometric and Layered Analysis","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The Representation and Recall of Interwoven Structured Knowledge in\n  LLMs: A Geometric and Layered Analysis'}","This study investigates how large language models (LLMs) represent and recall
multi-associated attributes across transformer layers. We show that
intermediate layers encode factual knowledge by superimposing related
attributes in overlapping spaces, along with effective recall even when
attributes are not explicitly prompted. In contrast, later layers refine
linguistic patterns and progressively separate attribute representations,
optimizing task-specific outputs while appropriately narrowing attribute
recall. We identify diverse encoding patterns including, for the first time,
the observation of 3D spiral structures when exploring information related to
the periodic table of elements. Our findings reveal a dynamic transition in
attribute representations across layers, contributing to mechanistic
interpretability and providing insights for understanding how LLMs handle
complex, interrelated knowledge.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'This study investigates how large language models (LLMs) represent and recall\nmulti-associated attributes across transformer layers. We show that\nintermediate layers encode factual knowledge by superimposing related\nattributes in overlapping spaces, along with effective recall even when\nattributes are not explicitly prompted. In contrast, later layers refine\nlinguistic patterns and progressively separate attribute representations,\noptimizing task-specific outputs while appropriately narrowing attribute\nrecall. We identify diverse encoding patterns including, for the first time,\nthe observation of 3D spiral structures when exploring information related to\nthe periodic table of elements. Our findings reveal a dynamic transition in\nattribute representations across layers, contributing to mechanistic\ninterpretability and providing insights for understanding how LLMs handle\ncomplex, interrelated knowledge.'}","['Ge Lei', 'Samuel J. Cooper']",{'name': 'Samuel J. Cooper'},Samuel J. Cooper,,"[{'href': 'http://arxiv.org/abs/2502.10871v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10871v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10871v1,None,http://arxiv.org/abs/2502.10871v1,,,10,0
http://arxiv.org/abs/2502.10875v1,True,2025-02-15T18:18:00Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=18, tm_min=18, tm_sec=0, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T18:18:00Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=18, tm_min=18, tm_sec=0, tm_wday=5, tm_yday=46, tm_isdst=0)","A Geometric Approach to Personalized Recommendation with Set-Theoretic
  Constraints Using Box Embeddings","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A Geometric Approach to Personalized Recommendation with Set-Theoretic\n  Constraints Using Box Embeddings'}","Personalized item recommendation typically suffers from data sparsity, which
is most often addressed by learning vector representations of users and items
via low-rank matrix factorization. While this effectively densifies the matrix
by assuming users and movies can be represented by linearly dependent latent
features, it does not capture more complicated interactions. For example,
vector representations struggle with set-theoretic relationships, such as
negation and intersection, e.g. recommending a movie that is ""comedy and
action, but not romance"". In this work, we formulate the problem of
personalized item recommendation as matrix completion where rows are
set-theoretically dependent. To capture this set-theoretic dependence we
represent each user and attribute by a hyper-rectangle or box (i.e. a Cartesian
product of intervals). Box embeddings can intuitively be understood as
trainable Venn diagrams, and thus not only inherently represent similarity (via
the Jaccard index), but also naturally and faithfully support arbitrary
set-theoretic relationships. Queries involving set-theoretic constraints can be
efficiently computed directly on the embedding space by performing geometric
operations on the representations. We empirically demonstrate the superiority
of box embeddings over vector-based neural methods on both simple and complex
item recommendation queries by up to 30 \% overall.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Personalized item recommendation typically suffers from data sparsity, which\nis most often addressed by learning vector representations of users and items\nvia low-rank matrix factorization. While this effectively densifies the matrix\nby assuming users and movies can be represented by linearly dependent latent\nfeatures, it does not capture more complicated interactions. For example,\nvector representations struggle with set-theoretic relationships, such as\nnegation and intersection, e.g. recommending a movie that is ""comedy and\naction, but not romance"". In this work, we formulate the problem of\npersonalized item recommendation as matrix completion where rows are\nset-theoretically dependent. To capture this set-theoretic dependence we\nrepresent each user and attribute by a hyper-rectangle or box (i.e. a Cartesian\nproduct of intervals). Box embeddings can intuitively be understood as\ntrainable Venn diagrams, and thus not only inherently represent similarity (via\nthe Jaccard index), but also naturally and faithfully support arbitrary\nset-theoretic relationships. Queries involving set-theoretic constraints can be\nefficiently computed directly on the embedding space by performing geometric\noperations on the representations. We empirically demonstrate the superiority\nof box embeddings over vector-based neural methods on both simple and complex\nitem recommendation queries by up to 30 \\% overall.'}","['Shib Dasgupta', 'Michael Boratko', 'Andrew McCallum']",{'name': 'Andrew McCallum'},Andrew McCallum,,"[{'href': 'http://arxiv.org/abs/2502.10875v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10875v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10875v1,None,http://arxiv.org/abs/2502.10875v1,,,1026,0
http://arxiv.org/abs/2502.10878v1,True,2025-02-15T18:28:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=18, tm_min=28, tm_sec=36, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T18:28:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=18, tm_min=28, tm_sec=36, tm_wday=5, tm_yday=46, tm_isdst=0)","Broadcast Channel Cooperative Gain: An Operational Interpretation of
  Partial Information Decomposition","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Broadcast Channel Cooperative Gain: An Operational Interpretation of\n  Partial Information Decomposition'}","Partial information decomposition has recently found applications in
biological signal processing and machine learning. Despite its impacts, the
decomposition was introduced through an informal and heuristic route, and its
exact operational meaning is unclear. In this work, we fill this gap by
connecting partial information decomposition to the capacity of the broadcast
channel, which has been well-studied in the information theory literature. We
show that the synergistic information in the decomposition can be rigorously
interpreted as the cooperative gain, or a lower bound of this gain, on the
corresponding broadcast channel. This interpretation can help practitioners to
better explain and expand the applications of the partial information
decomposition technique.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Partial information decomposition has recently found applications in\nbiological signal processing and machine learning. Despite its impacts, the\ndecomposition was introduced through an informal and heuristic route, and its\nexact operational meaning is unclear. In this work, we fill this gap by\nconnecting partial information decomposition to the capacity of the broadcast\nchannel, which has been well-studied in the information theory literature. We\nshow that the synergistic information in the decomposition can be rigorously\ninterpreted as the cooperative gain, or a lower bound of this gain, on the\ncorresponding broadcast channel. This interpretation can help practitioners to\nbetter explain and expand the applications of the partial information\ndecomposition technique.'}","['Chao Tian', 'Shlomo Shamai']",{'name': 'Shlomo Shamai'},Shlomo Shamai,"9 pages, 1 figure","[{'href': 'http://arxiv.org/abs/2502.10878v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10878v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.IT', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.IT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.IT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10878v1,Shitz,http://arxiv.org/abs/2502.10878v1,,,41631,0
http://arxiv.org/abs/2502.10883v1,True,2025-02-15T19:10:35Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=19, tm_min=10, tm_sec=35, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T19:10:35Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=19, tm_min=10, tm_sec=35, tm_wday=5, tm_yday=46, tm_isdst=0)","Learning Identifiable Structures Helps Avoid Bias in DNN-based
  Supervised Causal Learning","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Learning Identifiable Structures Helps Avoid Bias in DNN-based\n  Supervised Causal Learning'}","Causal discovery is a structured prediction task that aims to predict causal
relations among variables based on their data samples. Supervised Causal
Learning (SCL) is an emerging paradigm in this field. Existing Deep Neural
Network (DNN)-based methods commonly adopt the ""Node-Edge approach"", in which
the model first computes an embedding vector for each variable-node, then uses
these variable-wise representations to concurrently and independently predict
for each directed causal-edge. In this paper, we first show that this
architecture has some systematic bias that cannot be mitigated regardless of
model size and data size. We then propose SiCL, a DNN-based SCL method that
predicts a skeleton matrix together with a v-tensor (a third-order tensor
representing the v-structures). According to the Markov Equivalence Class (MEC)
theory, both the skeleton and the v-structures are identifiable causal
structures under the canonical MEC setting, so predictions about skeleton and
v-structures do not suffer from the identifiability limit in causal discovery,
thus SiCL can avoid the systematic bias in Node-Edge architecture, and enable
consistent estimators for causal discovery. Moreover, SiCL is also equipped
with a specially designed pairwise encoder module with a unidirectional
attention layer to model both internal and external relationships of pairs of
nodes. Experimental results on both synthetic and real-world benchmarks show
that SiCL significantly outperforms other DNN-based SCL approaches.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Causal discovery is a structured prediction task that aims to predict causal\nrelations among variables based on their data samples. Supervised Causal\nLearning (SCL) is an emerging paradigm in this field. Existing Deep Neural\nNetwork (DNN)-based methods commonly adopt the ""Node-Edge approach"", in which\nthe model first computes an embedding vector for each variable-node, then uses\nthese variable-wise representations to concurrently and independently predict\nfor each directed causal-edge. In this paper, we first show that this\narchitecture has some systematic bias that cannot be mitigated regardless of\nmodel size and data size. We then propose SiCL, a DNN-based SCL method that\npredicts a skeleton matrix together with a v-tensor (a third-order tensor\nrepresenting the v-structures). According to the Markov Equivalence Class (MEC)\ntheory, both the skeleton and the v-structures are identifiable causal\nstructures under the canonical MEC setting, so predictions about skeleton and\nv-structures do not suffer from the identifiability limit in causal discovery,\nthus SiCL can avoid the systematic bias in Node-Edge architecture, and enable\nconsistent estimators for causal discovery. Moreover, SiCL is also equipped\nwith a specially designed pairwise encoder module with a unidirectional\nattention layer to model both internal and external relationships of pairs of\nnodes. Experimental results on both synthetic and real-world benchmarks show\nthat SiCL significantly outperforms other DNN-based SCL approaches.'}","['Jiaru Zhang', 'Rui Ding', 'Qiang Fu', 'Bojun Huang', 'Zizhen Deng', 'Yang Hua', 'Haibing Guan', 'Shi Han', 'Dongmei Zhang']",{'name': 'Dongmei Zhang'},Dongmei Zhang,,"[{'href': 'http://arxiv.org/abs/2502.10883v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10883v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ME', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10883v1,None,http://arxiv.org/abs/2502.10883v1,,,1000,0
http://arxiv.org/abs/2502.10894v1,True,2025-02-15T20:18:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=20, tm_min=18, tm_sec=37, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T20:18:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=20, tm_min=18, tm_sec=37, tm_wday=5, tm_yday=46, tm_isdst=0)",Bridging the Sim-to-Real Gap for Athletic Loco-Manipulation,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Bridging the Sim-to-Real Gap for Athletic Loco-Manipulation'}","Achieving athletic loco-manipulation on robots requires moving beyond
traditional tracking rewards - which simply guide the robot along a reference
trajectory - to task rewards that drive truly dynamic, goal-oriented behaviors.
Commands such as ""throw the ball as far as you can"" or ""lift the weight as
quickly as possible"" compel the robot to exhibit the agility and power inherent
in athletic performance. However, training solely with task rewards introduces
two major challenges: these rewards are prone to exploitation (reward hacking),
and the exploration process can lack sufficient direction. To address these
issues, we propose a two-stage training pipeline. First, we introduce the
Unsupervised Actuator Net (UAN), which leverages real-world data to bridge the
sim-to-real gap for complex actuation mechanisms without requiring access to
torque sensing. UAN mitigates reward hacking by ensuring that the learned
behaviors remain robust and transferable. Second, we use a pre-training and
fine-tuning strategy that leverages reference trajectories as initial hints to
guide exploration. With these innovations, our robot athlete learns to lift,
throw, and drag with remarkable fidelity from simulation to reality.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Achieving athletic loco-manipulation on robots requires moving beyond\ntraditional tracking rewards - which simply guide the robot along a reference\ntrajectory - to task rewards that drive truly dynamic, goal-oriented behaviors.\nCommands such as ""throw the ball as far as you can"" or ""lift the weight as\nquickly as possible"" compel the robot to exhibit the agility and power inherent\nin athletic performance. However, training solely with task rewards introduces\ntwo major challenges: these rewards are prone to exploitation (reward hacking),\nand the exploration process can lack sufficient direction. To address these\nissues, we propose a two-stage training pipeline. First, we introduce the\nUnsupervised Actuator Net (UAN), which leverages real-world data to bridge the\nsim-to-real gap for complex actuation mechanisms without requiring access to\ntorque sensing. UAN mitigates reward hacking by ensuring that the learned\nbehaviors remain robust and transferable. Second, we use a pre-training and\nfine-tuning strategy that leverages reference trajectories as initial hints to\nguide exploration. With these innovations, our robot athlete learns to lift,\nthrow, and drag with remarkable fidelity from simulation to reality.'}","['Nolan Fey', 'Gabriel B. Margolis', 'Martin Peticco', 'Pulkit Agrawal']",{'name': 'Pulkit Agrawal'},Pulkit Agrawal,Project website: http://uan.csail.mit.edu,"[{'href': 'http://arxiv.org/abs/2502.10894v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10894v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10894v1,None,http://arxiv.org/abs/2502.10894v1,,,671,0
http://arxiv.org/abs/2502.10899v1,True,2025-02-15T20:36:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=20, tm_min=36, tm_sec=15, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T20:36:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=20, tm_min=36, tm_sec=15, tm_wday=5, tm_yday=46, tm_isdst=0)",Breaking Down the Hierarchy: A New Approach to Leukemia Classification,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Breaking Down the Hierarchy: A New Approach to Leukemia Classification'}","The complexities inherent to leukemia, multifaceted cancer affecting white
blood cells, pose considerable diagnostic and treatment challenges, primarily
due to reliance on laborious morphological analyses and expert judgment that
are susceptible to errors. Addressing these challenges, this study presents a
refined, comprehensive strategy leveraging advanced deep-learning techniques
for the classification of leukemia subtypes. We commence by developing a
hierarchical label taxonomy, paving the way for differentiating between various
subtypes of leukemia. The research further introduces a novel hierarchical
approach inspired by clinical procedures capable of accurately classifying
diverse types of leukemia alongside reactive and healthy cells. An integral
part of this study involves a meticulous examination of the performance of
Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) as
classifiers. The proposed method exhibits an impressive success rate, achieving
approximately 90\% accuracy across all leukemia subtypes, as substantiated by
our experimental results. A visual representation of the experimental findings
is provided to enhance the model's explainability and aid in understanding the
classification process.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""The complexities inherent to leukemia, multifaceted cancer affecting white\nblood cells, pose considerable diagnostic and treatment challenges, primarily\ndue to reliance on laborious morphological analyses and expert judgment that\nare susceptible to errors. Addressing these challenges, this study presents a\nrefined, comprehensive strategy leveraging advanced deep-learning techniques\nfor the classification of leukemia subtypes. We commence by developing a\nhierarchical label taxonomy, paving the way for differentiating between various\nsubtypes of leukemia. The research further introduces a novel hierarchical\napproach inspired by clinical procedures capable of accurately classifying\ndiverse types of leukemia alongside reactive and healthy cells. An integral\npart of this study involves a meticulous examination of the performance of\nConvolutional Neural Networks (CNNs) and Vision Transformers (ViTs) as\nclassifiers. The proposed method exhibits an impressive success rate, achieving\napproximately 90\\% accuracy across all leukemia subtypes, as substantiated by\nour experimental results. A visual representation of the experimental findings\nis provided to enhance the model's explainability and aid in understanding the\nclassification process.""}","['Ibraheem Hamdi', 'Hosam El-Gendy', 'Ahmed Sharshar', 'Mohamed Saeed', 'Muhammad Ridzuan', 'Shahrukh K. Hashmi', 'Naveed Syed', 'Imran Mirza', 'Shakir Hussain', 'Amira Mahmoud Abdalla', 'Mohammad Yaqub']",{'name': 'Mohammad Yaqub'},Mohammad Yaqub,"9 pages, 11 figures","[{'title': 'doi', 'href': 'http://dx.doi.org/10.1007/978-3-031-47076-9_11', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2502.10899v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10899v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10899v1,None,http://arxiv.org/abs/2502.10899v1,"Lecture Notes in Computer Science (LNCS,volume 14313) - 2023",10.1007/978-3-031-47076-9_11,168,0
http://arxiv.org/abs/2502.10908v1,True,2025-02-15T21:05:07Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=21, tm_min=5, tm_sec=7, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T21:05:07Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=21, tm_min=5, tm_sec=7, tm_wday=5, tm_yday=46, tm_isdst=0)","Automatic Quality Assessment of First Trimester Crown-Rump-Length
  Ultrasound Images","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Automatic Quality Assessment of First Trimester Crown-Rump-Length\n  Ultrasound Images'}","Fetal gestational age (GA) is vital clinical information that is estimated
during pregnancy in order to assess fetal growth. This is usually performed by
measuring the crown-rump-length (CRL) on an ultrasound image in the Dating scan
which is then correlated with fetal age and growth trajectory. A major issue
when performing the CRL measurement is ensuring that the image is acquired at
the correct view, otherwise it could be misleading. Although clinical
guidelines specify the criteria for the correct CRL view, sonographers may not
regularly adhere to such rules. In this paper, we propose a new deep
learning-based solution that is able to verify the adherence of a CRL image to
clinical guidelines in order to assess image quality and facilitate accurate
estimation of GA. We first segment out important fetal structures then use the
localized structures to perform a clinically-guided mapping that verifies the
adherence of criteria. The segmentation method combines the benefits of
Convolutional Neural Network (CNN) and the Vision Transformer (ViT) to segment
fetal structures in ultrasound images and localize important fetal landmarks.
For segmentation purposes, we compare our proposed work with UNet and show that
our CNN/ViT-based method outperforms an optimized version of UNet. Furthermore,
we compare the output of the mapping with classification CNNs when assessing
the clinical criteria and the overall acceptability of CRL images. We show that
the proposed mapping is not only explainable but also more accurate than the
best performing classification CNNs.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Fetal gestational age (GA) is vital clinical information that is estimated\nduring pregnancy in order to assess fetal growth. This is usually performed by\nmeasuring the crown-rump-length (CRL) on an ultrasound image in the Dating scan\nwhich is then correlated with fetal age and growth trajectory. A major issue\nwhen performing the CRL measurement is ensuring that the image is acquired at\nthe correct view, otherwise it could be misleading. Although clinical\nguidelines specify the criteria for the correct CRL view, sonographers may not\nregularly adhere to such rules. In this paper, we propose a new deep\nlearning-based solution that is able to verify the adherence of a CRL image to\nclinical guidelines in order to assess image quality and facilitate accurate\nestimation of GA. We first segment out important fetal structures then use the\nlocalized structures to perform a clinically-guided mapping that verifies the\nadherence of criteria. The segmentation method combines the benefits of\nConvolutional Neural Network (CNN) and the Vision Transformer (ViT) to segment\nfetal structures in ultrasound images and localize important fetal landmarks.\nFor segmentation purposes, we compare our proposed work with UNet and show that\nour CNN/ViT-based method outperforms an optimized version of UNet. Furthermore,\nwe compare the output of the mapping with classification CNNs when assessing\nthe clinical criteria and the overall acceptability of CRL images. We show that\nthe proposed mapping is not only explainable but also more accurate than the\nbest performing classification CNNs.'}","['Sevim Cengiz', 'Ibraheem Hamdi', 'Mohammad Yaqub']",{'name': 'Mohammad Yaqub'},Mohammad Yaqub,"9 pages, 2 figures","[{'title': 'doi', 'href': 'http://dx.doi.org/10.1007/978-3-031-16902-1_17', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2502.10908v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10908v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10908v1,None,http://arxiv.org/abs/2502.10908v1,Springer Lecture Notes in Computer Science (LNCS) - 2022,10.1007/978-3-031-16902-1_17,1682,0
http://arxiv.org/abs/2502.10928v1,True,2025-02-15T23:37:32Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=23, tm_min=37, tm_sec=32, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T23:37:32Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=23, tm_min=37, tm_sec=32, tm_wday=5, tm_yday=46, tm_isdst=0)","Semantic Specialization in MoE Appears with Scale: A Study of DeepSeek
  R1 Expert Specialization","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Semantic Specialization in MoE Appears with Scale: A Study of DeepSeek\n  R1 Expert Specialization'}","DeepSeek-R1, the largest open-source Mixture-of-Experts (MoE) model, has
demonstrated reasoning capabilities comparable to proprietary frontier models.
Prior research has explored expert routing in MoE models, but findings suggest
that expert selection is often token-dependent rather than semantically driven.
Given DeepSeek-R1's enhanced reasoning abilities, we investigate whether its
routing mechanism exhibits greater semantic specialization than previous MoE
models. To explore this, we conduct two key experiments: (1) a word sense
disambiguation task, where we examine expert activation patterns for words with
differing senses, and (2) a cognitive reasoning analysis, where we assess
DeepSeek-R1's structured thought process in an interactive task setting of
DiscoveryWorld. We conclude that DeepSeek-R1's routing mechanism is more
semantically aware and it engages in structured cognitive processes.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""DeepSeek-R1, the largest open-source Mixture-of-Experts (MoE) model, has\ndemonstrated reasoning capabilities comparable to proprietary frontier models.\nPrior research has explored expert routing in MoE models, but findings suggest\nthat expert selection is often token-dependent rather than semantically driven.\nGiven DeepSeek-R1's enhanced reasoning abilities, we investigate whether its\nrouting mechanism exhibits greater semantic specialization than previous MoE\nmodels. To explore this, we conduct two key experiments: (1) a word sense\ndisambiguation task, where we examine expert activation patterns for words with\ndiffering senses, and (2) a cognitive reasoning analysis, where we assess\nDeepSeek-R1's structured thought process in an interactive task setting of\nDiscoveryWorld. We conclude that DeepSeek-R1's routing mechanism is more\nsemantically aware and it engages in structured cognitive processes.""}","['Matthew Lyle Olson', 'Neale Ratzlaff', 'Musashi Hinck', 'Man Luo', 'Sungduk Yu', 'Chendi Xue', 'Vasudev Lal']",{'name': 'Vasudev Lal'},Vasudev Lal,,"[{'href': 'http://arxiv.org/abs/2502.10928v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10928v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10928v1,None,http://arxiv.org/abs/2502.10928v1,,,57,0
http://arxiv.org/abs/2502.10937v1,True,2025-02-16T00:19:07Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=0, tm_min=19, tm_sec=7, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T00:19:07Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=0, tm_min=19, tm_sec=7, tm_wday=6, tm_yday=47, tm_isdst=0)","SCALE: Towards Collaborative Content Analysis in Social Science with
  Large Language Model Agents and Human Intervention","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'SCALE: Towards Collaborative Content Analysis in Social Science with\n  Large Language Model Agents and Human Intervention'}","Content analysis breaks down complex and unstructured texts into
theory-informed numerical categories. Particularly, in social science, this
process usually relies on multiple rounds of manual annotation, domain expert
discussion, and rule-based refinement. In this paper, we introduce SCALE, a
novel multi-agent framework that effectively $\underline{\textbf{S}}$imulates
$\underline{\textbf{C}}$ontent $\underline{\textbf{A}}$nalysis via
$\underline{\textbf{L}}$arge language model (LLM)
ag$\underline{\textbf{E}}$nts. SCALE imitates key phases of content analysis,
including text coding, collaborative discussion, and dynamic codebook
evolution, capturing the reflective depth and adaptive discussions of human
researchers. Furthermore, by integrating diverse modes of human intervention,
SCALE is augmented with expert input to further enhance its performance.
Extensive evaluations on real-world datasets demonstrate that SCALE achieves
human-approximated performance across various complex content analysis tasks,
offering an innovative potential for future social science research.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Content analysis breaks down complex and unstructured texts into\ntheory-informed numerical categories. Particularly, in social science, this\nprocess usually relies on multiple rounds of manual annotation, domain expert\ndiscussion, and rule-based refinement. In this paper, we introduce SCALE, a\nnovel multi-agent framework that effectively $\\underline{\\textbf{S}}$imulates\n$\\underline{\\textbf{C}}$ontent $\\underline{\\textbf{A}}$nalysis via\n$\\underline{\\textbf{L}}$arge language model (LLM)\nag$\\underline{\\textbf{E}}$nts. SCALE imitates key phases of content analysis,\nincluding text coding, collaborative discussion, and dynamic codebook\nevolution, capturing the reflective depth and adaptive discussions of human\nresearchers. Furthermore, by integrating diverse modes of human intervention,\nSCALE is augmented with expert input to further enhance its performance.\nExtensive evaluations on real-world datasets demonstrate that SCALE achieves\nhuman-approximated performance across various complex content analysis tasks,\noffering an innovative potential for future social science research.'}","['Chengshuai Zhao', 'Zhen Tan', 'Chau-Wai Wong', 'Xinyan Zhao', 'Tianlong Chen', 'Huan Liu']",{'name': 'Huan Liu'},Huan Liu,,"[{'href': 'http://arxiv.org/abs/2502.10937v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10937v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10937v1,None,http://arxiv.org/abs/2502.10937v1,,,295,0
http://arxiv.org/abs/2502.10954v2,True,2025-02-18T03:41:03Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=3, tm_min=41, tm_sec=3, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-16T02:17:05Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=2, tm_min=17, tm_sec=5, tm_wday=6, tm_yday=47, tm_isdst=0)",Learning to Stop Overthinking at Test Time,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Learning to Stop Overthinking at Test Time'}","Test time scaling is currently one of the most active research areas that
shows promise after training time scaling has reached its limits. Deep-thinking
(DT) models are a class of recurrent models that can perform easy-to-hard
generalization by assigning more compute to harder test samples. However, due
to their inability to determine the complexity of a test sample, DT models have
to use a large amount of computation for both easy and hard test samples.
Excessive test time computation is wasteful and can cause the ``overthinking''
problem where more test time computation leads to worse results. In this paper,
we introduce a test time training method for determining the optimal amount of
computation needed for each sample during test time. We also propose
Conv-LiGRU, a novel recurrent architecture for efficient and robust visual
reasoning. Extensive experiments demonstrate that Conv-LiGRU is more stable
than DT, effectively mitigates the ``overthinking'' phenomenon, and achieves
superior accuracy.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Test time scaling is currently one of the most active research areas that\nshows promise after training time scaling has reached its limits. Deep-thinking\n(DT) models are a class of recurrent models that can perform easy-to-hard\ngeneralization by assigning more compute to harder test samples. However, due\nto their inability to determine the complexity of a test sample, DT models have\nto use a large amount of computation for both easy and hard test samples.\nExcessive test time computation is wasteful and can cause the ``overthinking''\nproblem where more test time computation leads to worse results. In this paper,\nwe introduce a test time training method for determining the optimal amount of\ncomputation needed for each sample during test time. We also propose\nConv-LiGRU, a novel recurrent architecture for efficient and robust visual\nreasoning. Extensive experiments demonstrate that Conv-LiGRU is more stable\nthan DT, effectively mitigates the ``overthinking'' phenomenon, and achieves\nsuperior accuracy.""}","['Hieu Tran Bao', 'Nguyen Cong Dat', 'Nguyen Duc Anh', 'Hoang Thanh-Tung']",{'name': 'Hoang Thanh-Tung'},Hoang Thanh-Tung,,"[{'href': 'http://arxiv.org/abs/2502.10954v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10954v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10954v2,None,http://arxiv.org/abs/2502.10954v2,,,0,0
http://arxiv.org/abs/2502.10955v1,True,2025-02-16T02:22:27Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=2, tm_min=22, tm_sec=27, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T02:22:27Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=2, tm_min=22, tm_sec=27, tm_wday=6, tm_yday=47, tm_isdst=0)","A recurrent vision transformer shows signatures of primate visual
  attention","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A recurrent vision transformer shows signatures of primate visual\n  attention'}","Attention is fundamental to both biological and artificial intelligence, yet
research on animal attention and AI self attention remains largely
disconnected. We propose a Recurrent Vision Transformer (Recurrent ViT) that
integrates self-attention with recurrent memory, allowing both current inputs
and stored information to guide attention allocation. Trained solely via sparse
reward feedback on a spatially cued orientation change detection task, a
paradigm used in primate studies, our model exhibits primate like signatures of
attention, including improved accuracy and faster responses for cued stimuli
that scale with cue validity. Analysis of self-attention maps reveals dynamic
spatial prioritization with reactivation prior to expected changes, and
targeted perturbations produce performance shifts similar to those observed in
primate frontal eye fields and superior colliculus. These findings demonstrate
that incorporating recurrent feedback into self attention can capture key
aspects of primate visual attention.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Attention is fundamental to both biological and artificial intelligence, yet\nresearch on animal attention and AI self attention remains largely\ndisconnected. We propose a Recurrent Vision Transformer (Recurrent ViT) that\nintegrates self-attention with recurrent memory, allowing both current inputs\nand stored information to guide attention allocation. Trained solely via sparse\nreward feedback on a spatially cued orientation change detection task, a\nparadigm used in primate studies, our model exhibits primate like signatures of\nattention, including improved accuracy and faster responses for cued stimuli\nthat scale with cue validity. Analysis of self-attention maps reveals dynamic\nspatial prioritization with reactivation prior to expected changes, and\ntargeted perturbations produce performance shifts similar to those observed in\nprimate frontal eye fields and superior colliculus. These findings demonstrate\nthat incorporating recurrent feedback into self attention can capture key\naspects of primate visual attention.'}","['Jonathan Morgan', 'Badr Albanna', 'James P. Herman']",{'name': 'James P. Herman'},James P. Herman,,"[{'href': 'http://arxiv.org/abs/2502.10955v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10955v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-bio.NC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10955v1,None,http://arxiv.org/abs/2502.10955v1,,,0,0
http://arxiv.org/abs/2502.10976v1,True,2025-02-16T03:37:13Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=3, tm_min=37, tm_sec=13, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T03:37:13Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=3, tm_min=37, tm_sec=13, tm_wday=6, tm_yday=47, tm_isdst=0)",QuOTE: Question-Oriented Text Embeddings,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'QuOTE: Question-Oriented Text Embeddings'}","We present QuOTE (Question-Oriented Text Embeddings), a novel enhancement to
retrieval-augmented generation (RAG) systems, aimed at improving document
representation for accurate and nuanced retrieval. Unlike traditional RAG
pipelines, which rely on embedding raw text chunks, QuOTE augments chunks with
hypothetical questions that the chunk can potentially answer, enriching the
representation space. This better aligns document embeddings with user query
semantics, and helps address issues such as ambiguity and context-dependent
relevance. Through extensive experiments across diverse benchmarks, we
demonstrate that QuOTE significantly enhances retrieval accuracy, including in
multi-hop question-answering tasks. Our findings highlight the versatility of
question generation as a fundamental indexing strategy, opening new avenues for
integrating question generation into retrieval-based AI pipelines.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'We present QuOTE (Question-Oriented Text Embeddings), a novel enhancement to\nretrieval-augmented generation (RAG) systems, aimed at improving document\nrepresentation for accurate and nuanced retrieval. Unlike traditional RAG\npipelines, which rely on embedding raw text chunks, QuOTE augments chunks with\nhypothetical questions that the chunk can potentially answer, enriching the\nrepresentation space. This better aligns document embeddings with user query\nsemantics, and helps address issues such as ambiguity and context-dependent\nrelevance. Through extensive experiments across diverse benchmarks, we\ndemonstrate that QuOTE significantly enhances retrieval accuracy, including in\nmulti-hop question-answering tasks. Our findings highlight the versatility of\nquestion generation as a fundamental indexing strategy, opening new avenues for\nintegrating question generation into retrieval-based AI pipelines.'}","['Andrew Neeser', 'Kaylen Latimer', 'Aadyant Khatri', 'Chris Latimer', 'Naren Ramakrishnan']",{'name': 'Naren Ramakrishnan'},Naren Ramakrishnan,,"[{'href': 'http://arxiv.org/abs/2502.10976v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10976v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.3', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10976v1,None,http://arxiv.org/abs/2502.10976v1,,,3,0
http://arxiv.org/abs/2502.10985v1,True,2025-02-16T04:07:33Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=4, tm_min=7, tm_sec=33, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T04:07:33Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=4, tm_min=7, tm_sec=33, tm_wday=6, tm_yday=47, tm_isdst=0)",Is Elo Rating Reliable? A Study Under Model Misspecification,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Is Elo Rating Reliable? A Study Under Model Misspecification'}","Elo rating, widely used for skill assessment across diverse domains ranging
from competitive games to large language models, is often understood as an
incremental update algorithm for estimating a stationary Bradley-Terry (BT)
model. However, our empirical analysis of practical matching datasets reveals
two surprising findings: (1) Most games deviate significantly from the
assumptions of the BT model and stationarity, raising questions on the
reliability of Elo. (2) Despite these deviations, Elo frequently outperforms
more complex rating systems, such as mElo and pairwise models, which are
specifically designed to account for non-BT components in the data,
particularly in terms of win rate prediction. This paper explains this
unexpected phenomenon through three key perspectives: (a) We reinterpret Elo as
an instance of online gradient descent, which provides no-regret guarantees
even in misspecified and non-stationary settings. (b) Through extensive
synthetic experiments on data generated from transitive but non-BT models, such
as strongly or weakly stochastic transitive models, we show that the
''sparsity'' of practical matching data is a critical factor behind Elo's
superior performance in prediction compared to more complex rating systems. (c)
We observe a strong correlation between Elo's predictive accuracy and its
ranking performance, further supporting its effectiveness in ranking.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Elo rating, widely used for skill assessment across diverse domains ranging\nfrom competitive games to large language models, is often understood as an\nincremental update algorithm for estimating a stationary Bradley-Terry (BT)\nmodel. However, our empirical analysis of practical matching datasets reveals\ntwo surprising findings: (1) Most games deviate significantly from the\nassumptions of the BT model and stationarity, raising questions on the\nreliability of Elo. (2) Despite these deviations, Elo frequently outperforms\nmore complex rating systems, such as mElo and pairwise models, which are\nspecifically designed to account for non-BT components in the data,\nparticularly in terms of win rate prediction. This paper explains this\nunexpected phenomenon through three key perspectives: (a) We reinterpret Elo as\nan instance of online gradient descent, which provides no-regret guarantees\neven in misspecified and non-stationary settings. (b) Through extensive\nsynthetic experiments on data generated from transitive but non-BT models, such\nas strongly or weakly stochastic transitive models, we show that the\n''sparsity'' of practical matching data is a critical factor behind Elo's\nsuperior performance in prediction compared to more complex rating systems. (c)\nWe observe a strong correlation between Elo's predictive accuracy and its\nranking performance, further supporting its effectiveness in ranking.""}","['Shange Tang', 'Yuanhao Wang', 'Chi Jin']",{'name': 'Chi Jin'},Chi Jin,23pages,"[{'href': 'http://arxiv.org/abs/2502.10985v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10985v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ME', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10985v1,None,http://arxiv.org/abs/2502.10985v1,,,8,0
http://arxiv.org/abs/2502.10999v1,True,2025-02-16T05:30:18Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=5, tm_min=30, tm_sec=18, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T05:30:18Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=5, tm_min=30, tm_sec=18, tm_wday=6, tm_yday=47, tm_isdst=0)","ControlText: Unlocking Controllable Fonts in Multilingual Text Rendering
  without Font Annotations","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'ControlText: Unlocking Controllable Fonts in Multilingual Text Rendering\n  without Font Annotations'}","This work demonstrates that diffusion models can achieve font-controllable
multilingual text rendering using just raw images without font label
annotations. Visual text rendering remains a significant challenge. While
recent methods condition diffusion on glyphs, it is impossible to retrieve
exact font annotations from large-scale, real-world datasets, which prevents
user-specified font control. To address this, we propose a data-driven solution
that integrates the conditional diffusion model with a text segmentation model,
utilizing segmentation masks to capture and represent fonts in pixel space in a
self-supervised manner, thereby eliminating the need for any ground-truth
labels and enabling users to customize text rendering with any multilingual
font of their choice. The experiment provides a proof of concept of our
algorithm in zero-shot text and font editing across diverse fonts and
languages, providing valuable insights for the community and industry toward
achieving generalized visual text rendering.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'This work demonstrates that diffusion models can achieve font-controllable\nmultilingual text rendering using just raw images without font label\nannotations. Visual text rendering remains a significant challenge. While\nrecent methods condition diffusion on glyphs, it is impossible to retrieve\nexact font annotations from large-scale, real-world datasets, which prevents\nuser-specified font control. To address this, we propose a data-driven solution\nthat integrates the conditional diffusion model with a text segmentation model,\nutilizing segmentation masks to capture and represent fonts in pixel space in a\nself-supervised manner, thereby eliminating the need for any ground-truth\nlabels and enabling users to customize text rendering with any multilingual\nfont of their choice. The experiment provides a proof of concept of our\nalgorithm in zero-shot text and font editing across diverse fonts and\nlanguages, providing valuable insights for the community and industry toward\nachieving generalized visual text rendering.'}","['Bowen Jiang', 'Yuan Yuan', 'Xinyi Bai', 'Zhuoqun Hao', 'Alyson Yin', 'Yaojie Hu', 'Wenyu Liao', 'Lyle Ungar', 'Camillo J. Taylor']",{'name': 'Camillo J. Taylor'},Camillo J. Taylor,"This is preliminary work and code will be released at
  github.com/bowen-upenn/ControlText","[{'href': 'http://arxiv.org/abs/2502.10999v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.10999v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.10999v1,None,http://arxiv.org/abs/2502.10999v1,,,11263,0
http://arxiv.org/abs/2502.11001v1,True,2025-02-16T05:45:19Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=5, tm_min=45, tm_sec=19, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T05:45:19Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=5, tm_min=45, tm_sec=19, tm_wday=6, tm_yday=47, tm_isdst=0)","CL-MFAP: A Contrastive Learning-Based Multimodal Foundation Model for
  Molecular Property Prediction and Antibiotic Screening","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'CL-MFAP: A Contrastive Learning-Based Multimodal Foundation Model for\n  Molecular Property Prediction and Antibiotic Screening'}","Due to the rise in antimicrobial resistance, identifying novel compounds with
antibiotic potential is crucial for combatting this global health issue.
However, traditional drug development methods are costly and inefficient.
Recognizing the pressing need for more effective solutions, researchers have
turned to machine learning techniques to streamline the prediction and
development of novel antibiotic compounds. While foundation models have shown
promise in antibiotic discovery, current mainstream efforts still fall short of
fully leveraging the potential of multimodal molecular data. Recent studies
suggest that contrastive learning frameworks utilizing multimodal data exhibit
excellent performance in representation learning across various domains.
Building upon this, we introduce CL-MFAP, an unsupervised contrastive learning
(CL)-based multimodal foundation (MF) model specifically tailored for
discovering small molecules with potential antibiotic properties (AP) using
three types of molecular data. This model employs 1.6 million bioactive
molecules with drug-like properties from the ChEMBL dataset to jointly pretrain
three encoders: (1) a transformer-based encoder with rotary position embedding
for processing SMILES strings; (2) another transformer-based encoder,
incorporating a novel bi-level routing attention mechanism to handle molecular
graph representations; and (3) a Morgan fingerprint encoder using a multilayer
perceptron, to achieve the contrastive learning purpose. The CL-MFAP
outperforms baseline models in antibiotic property prediction by effectively
utilizing different molecular modalities and demonstrates superior
domain-specific performance when fine-tuned for antibiotic-related property
prediction tasks.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Due to the rise in antimicrobial resistance, identifying novel compounds with\nantibiotic potential is crucial for combatting this global health issue.\nHowever, traditional drug development methods are costly and inefficient.\nRecognizing the pressing need for more effective solutions, researchers have\nturned to machine learning techniques to streamline the prediction and\ndevelopment of novel antibiotic compounds. While foundation models have shown\npromise in antibiotic discovery, current mainstream efforts still fall short of\nfully leveraging the potential of multimodal molecular data. Recent studies\nsuggest that contrastive learning frameworks utilizing multimodal data exhibit\nexcellent performance in representation learning across various domains.\nBuilding upon this, we introduce CL-MFAP, an unsupervised contrastive learning\n(CL)-based multimodal foundation (MF) model specifically tailored for\ndiscovering small molecules with potential antibiotic properties (AP) using\nthree types of molecular data. This model employs 1.6 million bioactive\nmolecules with drug-like properties from the ChEMBL dataset to jointly pretrain\nthree encoders: (1) a transformer-based encoder with rotary position embedding\nfor processing SMILES strings; (2) another transformer-based encoder,\nincorporating a novel bi-level routing attention mechanism to handle molecular\ngraph representations; and (3) a Morgan fingerprint encoder using a multilayer\nperceptron, to achieve the contrastive learning purpose. The CL-MFAP\noutperforms baseline models in antibiotic property prediction by effectively\nutilizing different molecular modalities and demonstrates superior\ndomain-specific performance when fine-tuned for antibiotic-related property\nprediction tasks.'}","['Gen Zhou', 'Sugitha Janarthanan', 'Yutong Lu', 'Pingzhao Hu']",{'name': 'Pingzhao Hu'},Pingzhao Hu,"Gen Zhou and Sugitha Janarthanan contributed equally; Accepted at
  ICLR 2025","[{'href': 'http://arxiv.org/abs/2502.11001v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11001v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'q-bio.BM', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'q-bio.BM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-bio.QM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11001v1,None,http://arxiv.org/abs/2502.11001v1,,,0,0
http://arxiv.org/abs/2502.11026v2,True,2025-02-19T02:44:40Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=2, tm_min=44, tm_sec=40, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-16T07:22:00Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=7, tm_min=22, tm_sec=0, tm_wday=6, tm_yday=47, tm_isdst=0)",Simplify RLHF as Reward-Weighted SFT: A Variational Method,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Simplify RLHF as Reward-Weighted SFT: A Variational Method'}","Reinforcement Learning from Human Feedback (RLHF) is crucial for aligning
Large Language Models (LLMs) with human values. However, RLHF has been
continuously challenged by its high complexity in implementation and
computation consumption. Even with recent simplifications, such as Direct
Preference Optimization (DPO) and Advantage Leftover Lunch (A-LoL), the
problems of over-fitting and training instability remain hindering the
alignment process from the expected optimal performance. To address the
existing challenges, we propose a novel simplification of RLHF from the
perspective of variational inference, called $\textbf{V}$ariational
$\textbf{A}$lignment with $\textbf{R}$e-weighting ($\textbf{VAR}$). More
specifically, by directly minimizing the distribution gap between the learning
LLM policy and the optimal solution of RLHF, we transform the alignment
objective into a reward-driven re-weighted supervised fine-tuning (SFT) form,
which only requires minor adjustment on the SFT loss to obtain noticeable
improvement on training stability and effectiveness. On comprehensive alignment
and generation benchmarks, our VAR method has numerically achieved competitive
performance in LLM alignment helpfulness and harmlessness.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Reinforcement Learning from Human Feedback (RLHF) is crucial for aligning\nLarge Language Models (LLMs) with human values. However, RLHF has been\ncontinuously challenged by its high complexity in implementation and\ncomputation consumption. Even with recent simplifications, such as Direct\nPreference Optimization (DPO) and Advantage Leftover Lunch (A-LoL), the\nproblems of over-fitting and training instability remain hindering the\nalignment process from the expected optimal performance. To address the\nexisting challenges, we propose a novel simplification of RLHF from the\nperspective of variational inference, called $\\textbf{V}$ariational\n$\\textbf{A}$lignment with $\\textbf{R}$e-weighting ($\\textbf{VAR}$). More\nspecifically, by directly minimizing the distribution gap between the learning\nLLM policy and the optimal solution of RLHF, we transform the alignment\nobjective into a reward-driven re-weighted supervised fine-tuning (SFT) form,\nwhich only requires minor adjustment on the SFT loss to obtain noticeable\nimprovement on training stability and effectiveness. On comprehensive alignment\nand generation benchmarks, our VAR method has numerically achieved competitive\nperformance in LLM alignment helpfulness and harmlessness.'}","['Yuhao Du', 'Zhuo Li', 'Pengyu Cheng', 'Zhihong Chen', 'Yuejiao Xie', 'Xiang Wan', 'Anningzhe Gao']",{'name': 'Anningzhe Gao'},Anningzhe Gao,,"[{'href': 'http://arxiv.org/abs/2502.11026v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11026v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11026v2,None,http://arxiv.org/abs/2502.11026v2,,,1593,0
http://arxiv.org/abs/2502.11037v1,True,2025-02-16T08:36:43Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=8, tm_min=36, tm_sec=43, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T08:36:43Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=8, tm_min=36, tm_sec=43, tm_wday=6, tm_yday=47, tm_isdst=0)",Deep Incomplete Multi-view Learning via Cyclic Permutation of VAEs,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Deep Incomplete Multi-view Learning via Cyclic Permutation of VAEs'}","Multi-View Representation Learning (MVRL) aims to derive a unified
representation from multi-view data by leveraging shared and complementary
information across views. However, when views are irregularly missing, the
incomplete data can lead to representations that lack sufficiency and
consistency. To address this, we propose Multi-View Permutation of Variational
Auto-Encoders (MVP), which excavates invariant relationships between views in
incomplete data. MVP establishes inter-view correspondences in the latent space
of Variational Auto-Encoders, enabling the inference of missing views and the
aggregation of more sufficient information. To derive a valid Evidence Lower
Bound (ELBO) for learning, we apply permutations to randomly reorder variables
for cross-view generation and then partition them by views to maintain
invariant meanings under permutations. Additionally, we enhance consistency by
introducing an informational prior with cyclic permutations of posteriors,
which turns the regularization term into a similarity measure across
distributions. We demonstrate the effectiveness of our approach on seven
diverse datasets with varying missing ratios, achieving superior performance in
multi-view clustering and generation tasks.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Multi-View Representation Learning (MVRL) aims to derive a unified\nrepresentation from multi-view data by leveraging shared and complementary\ninformation across views. However, when views are irregularly missing, the\nincomplete data can lead to representations that lack sufficiency and\nconsistency. To address this, we propose Multi-View Permutation of Variational\nAuto-Encoders (MVP), which excavates invariant relationships between views in\nincomplete data. MVP establishes inter-view correspondences in the latent space\nof Variational Auto-Encoders, enabling the inference of missing views and the\naggregation of more sufficient information. To derive a valid Evidence Lower\nBound (ELBO) for learning, we apply permutations to randomly reorder variables\nfor cross-view generation and then partition them by views to maintain\ninvariant meanings under permutations. Additionally, we enhance consistency by\nintroducing an informational prior with cyclic permutations of posteriors,\nwhich turns the regularization term into a similarity measure across\ndistributions. We demonstrate the effectiveness of our approach on seven\ndiverse datasets with varying missing ratios, achieving superior performance in\nmulti-view clustering and generation tasks.'}","['Xin Gao', 'Jian Pu']",{'name': 'Jian Pu'},Jian Pu,"10 pages, 4 figures, ICLR 2025","[{'href': 'http://arxiv.org/abs/2502.11037v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11037v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11037v1,None,http://arxiv.org/abs/2502.11037v1,,,0,0
http://arxiv.org/abs/2502.11054v3,True,2025-02-19T15:36:47Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=15, tm_min=36, tm_sec=47, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-16T09:27:44Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=9, tm_min=27, tm_sec=44, tm_wday=6, tm_yday=47, tm_isdst=0)","Reasoning-Augmented Conversation for Multi-Turn Jailbreak Attacks on
  Large Language Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Reasoning-Augmented Conversation for Multi-Turn Jailbreak Attacks on\n  Large Language Models'}","Multi-turn jailbreak attacks simulate real-world human interactions by
engaging large language models (LLMs) in iterative dialogues, exposing critical
safety vulnerabilities. However, existing methods often struggle to balance
semantic coherence with attack effectiveness, resulting in either benign
semantic drift or ineffective detection evasion. To address this challenge, we
propose Reasoning-Augmented Conversation, a novel multi-turn jailbreak
framework that reformulates harmful queries into benign reasoning tasks and
leverages LLMs' strong reasoning capabilities to compromise safety alignment.
Specifically, we introduce an attack state machine framework to systematically
model problem translation and iterative reasoning, ensuring coherent query
generation across multiple turns. Building on this framework, we design
gain-guided exploration, self-play, and rejection feedback modules to preserve
attack semantics, enhance effectiveness, and sustain reasoning-driven attack
progression. Extensive experiments on multiple LLMs demonstrate that RACE
achieves state-of-the-art attack effectiveness in complex conversational
scenarios, with attack success rates (ASRs) increasing by up to 96%. Notably,
our approach achieves ASRs of 82% and 92% against leading commercial models,
OpenAI o1 and DeepSeek R1, underscoring its potency. We release our code at
https://github.com/NY1024/RACE to facilitate further research in this critical
domain.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Multi-turn jailbreak attacks simulate real-world human interactions by\nengaging large language models (LLMs) in iterative dialogues, exposing critical\nsafety vulnerabilities. However, existing methods often struggle to balance\nsemantic coherence with attack effectiveness, resulting in either benign\nsemantic drift or ineffective detection evasion. To address this challenge, we\npropose Reasoning-Augmented Conversation, a novel multi-turn jailbreak\nframework that reformulates harmful queries into benign reasoning tasks and\nleverages LLMs' strong reasoning capabilities to compromise safety alignment.\nSpecifically, we introduce an attack state machine framework to systematically\nmodel problem translation and iterative reasoning, ensuring coherent query\ngeneration across multiple turns. Building on this framework, we design\ngain-guided exploration, self-play, and rejection feedback modules to preserve\nattack semantics, enhance effectiveness, and sustain reasoning-driven attack\nprogression. Extensive experiments on multiple LLMs demonstrate that RACE\nachieves state-of-the-art attack effectiveness in complex conversational\nscenarios, with attack success rates (ASRs) increasing by up to 96%. Notably,\nour approach achieves ASRs of 82% and 92% against leading commercial models,\nOpenAI o1 and DeepSeek R1, underscoring its potency. We release our code at\nhttps://github.com/NY1024/RACE to facilitate further research in this critical\ndomain.""}","['Zonghao Ying', 'Deyue Zhang', 'Zonglei Jing', 'Yisong Xiao', 'Quanchen Zou', 'Aishan Liu', 'Siyuan Liang', 'Xiangzheng Zhang', 'Xianglong Liu', 'Dacheng Tao']",{'name': 'Dacheng Tao'},Dacheng Tao,,"[{'href': 'http://arxiv.org/abs/2502.11054v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11054v3', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11054v3,None,http://arxiv.org/abs/2502.11054v3,,,248,0
http://arxiv.org/abs/2502.11057v1,True,2025-02-16T09:46:17Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=9, tm_min=46, tm_sec=17, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T09:46:17Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=9, tm_min=46, tm_sec=17, tm_wday=6, tm_yday=47, tm_isdst=0)","A Physics-Informed Machine Learning Framework for Safe and Optimal
  Control of Autonomous Systems","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A Physics-Informed Machine Learning Framework for Safe and Optimal\n  Control of Autonomous Systems'}","As autonomous systems become more ubiquitous in daily life, ensuring high
performance with guaranteed safety is crucial. However, safety and performance
could be competing objectives, which makes their co-optimization difficult.
Learning-based methods, such as Constrained Reinforcement Learning (CRL),
achieve strong performance but lack formal safety guarantees due to safety
being enforced as soft constraints, limiting their use in safety-critical
settings. Conversely, formal methods such as Hamilton-Jacobi (HJ) Reachability
Analysis and Control Barrier Functions (CBFs) provide rigorous safety
assurances but often neglect performance, resulting in overly conservative
controllers. To bridge this gap, we formulate the co-optimization of safety and
performance as a state-constrained optimal control problem, where performance
objectives are encoded via a cost function and safety requirements are imposed
as state constraints. We demonstrate that the resultant value function
satisfies a Hamilton-Jacobi-Bellman (HJB) equation, which we approximate
efficiently using a novel physics-informed machine learning framework. In
addition, we introduce a conformal prediction-based verification strategy to
quantify the learning errors, recovering a high-confidence safety value
function, along with a probabilistic error bound on performance degradation.
Through several case studies, we demonstrate the efficacy of the proposed
framework in enabling scalable learning of safe and performant controllers for
complex, high-dimensional autonomous systems.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'As autonomous systems become more ubiquitous in daily life, ensuring high\nperformance with guaranteed safety is crucial. However, safety and performance\ncould be competing objectives, which makes their co-optimization difficult.\nLearning-based methods, such as Constrained Reinforcement Learning (CRL),\nachieve strong performance but lack formal safety guarantees due to safety\nbeing enforced as soft constraints, limiting their use in safety-critical\nsettings. Conversely, formal methods such as Hamilton-Jacobi (HJ) Reachability\nAnalysis and Control Barrier Functions (CBFs) provide rigorous safety\nassurances but often neglect performance, resulting in overly conservative\ncontrollers. To bridge this gap, we formulate the co-optimization of safety and\nperformance as a state-constrained optimal control problem, where performance\nobjectives are encoded via a cost function and safety requirements are imposed\nas state constraints. We demonstrate that the resultant value function\nsatisfies a Hamilton-Jacobi-Bellman (HJB) equation, which we approximate\nefficiently using a novel physics-informed machine learning framework. In\naddition, we introduce a conformal prediction-based verification strategy to\nquantify the learning errors, recovering a high-confidence safety value\nfunction, along with a probabilistic error bound on performance degradation.\nThrough several case studies, we demonstrate the efficacy of the proposed\nframework in enabling scalable learning of safe and performant controllers for\ncomplex, high-dimensional autonomous systems.'}","['Manan Tayal', 'Aditya Singh', 'Shishir Kolathaya', 'Somil Bansal']",{'name': 'Somil Bansal'},Somil Bansal,"15Pages, 12 Figures. First two authors have contributed equally","[{'href': 'http://arxiv.org/abs/2502.11057v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11057v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'eess.SY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11057v1,None,http://arxiv.org/abs/2502.11057v1,,,3053,0
http://arxiv.org/abs/2502.11089v1,True,2025-02-16T11:53:44Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=11, tm_min=53, tm_sec=44, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T11:53:44Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=11, tm_min=53, tm_sec=44, tm_wday=6, tm_yday=47, tm_isdst=0)","Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse
  Attention","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse\n  Attention'}","Long-context modeling is crucial for next-generation language models, yet the
high computational cost of standard attention mechanisms poses significant
computational challenges. Sparse attention offers a promising direction for
improving efficiency while maintaining model capabilities. We present NSA, a
Natively trainable Sparse Attention mechanism that integrates algorithmic
innovations with hardware-aligned optimizations to achieve efficient
long-context modeling. NSA employs a dynamic hierarchical sparse strategy,
combining coarse-grained token compression with fine-grained token selection to
preserve both global context awareness and local precision. Our approach
advances sparse attention design with two key innovations: (1) We achieve
substantial speedups through arithmetic intensity-balanced algorithm design,
with implementation optimizations for modern hardware. (2) We enable end-to-end
training, reducing pretraining computation without sacrificing model
performance. As shown in Figure 1, experiments show the model pretrained with
NSA maintains or exceeds Full Attention models across general benchmarks,
long-context tasks, and instruction-based reasoning. Meanwhile, NSA achieves
substantial speedups over Full Attention on 64k-length sequences across
decoding, forward propagation, and backward propagation, validating its
efficiency throughout the model lifecycle.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Long-context modeling is crucial for next-generation language models, yet the\nhigh computational cost of standard attention mechanisms poses significant\ncomputational challenges. Sparse attention offers a promising direction for\nimproving efficiency while maintaining model capabilities. We present NSA, a\nNatively trainable Sparse Attention mechanism that integrates algorithmic\ninnovations with hardware-aligned optimizations to achieve efficient\nlong-context modeling. NSA employs a dynamic hierarchical sparse strategy,\ncombining coarse-grained token compression with fine-grained token selection to\npreserve both global context awareness and local precision. Our approach\nadvances sparse attention design with two key innovations: (1) We achieve\nsubstantial speedups through arithmetic intensity-balanced algorithm design,\nwith implementation optimizations for modern hardware. (2) We enable end-to-end\ntraining, reducing pretraining computation without sacrificing model\nperformance. As shown in Figure 1, experiments show the model pretrained with\nNSA maintains or exceeds Full Attention models across general benchmarks,\nlong-context tasks, and instruction-based reasoning. Meanwhile, NSA achieves\nsubstantial speedups over Full Attention on 64k-length sequences across\ndecoding, forward propagation, and backward propagation, validating its\nefficiency throughout the model lifecycle.'}","['Jingyang Yuan', 'Huazuo Gao', 'Damai Dai', 'Junyu Luo', 'Liang Zhao', 'Zhengyan Zhang', 'Zhenda Xie', 'Y. X. Wei', 'Lean Wang', 'Zhiping Xiao', 'Yuqing Wang', 'Chong Ruan', 'Ming Zhang', 'Wenfeng Liang', 'Wangding Zeng']",{'name': 'Wangding Zeng'},Wangding Zeng,,"[{'href': 'http://arxiv.org/abs/2502.11089v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11089v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11089v1,None,http://arxiv.org/abs/2502.11089v1,,,1947,0
http://arxiv.org/abs/2502.11098v1,True,2025-02-16T12:26:58Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=12, tm_min=26, tm_sec=58, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T12:26:58Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=12, tm_min=26, tm_sec=58, tm_wday=6, tm_yday=47, tm_isdst=0)","Talk Structurally, Act Hierarchically: A Collaborative Framework for LLM
  Multi-Agent Systems","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Talk Structurally, Act Hierarchically: A Collaborative Framework for LLM\n  Multi-Agent Systems'}","Recent advancements in LLM-based multi-agent (LLM-MA) systems have shown
promise, yet significant challenges remain in managing communication and
refinement when agents collaborate on complex tasks. In this paper, we propose
\textit{Talk Structurally, Act Hierarchically (TalkHier)}, a novel framework
that introduces a structured communication protocol for context-rich exchanges
and a hierarchical refinement system to address issues such as incorrect
outputs, falsehoods, and biases. \textit{TalkHier} surpasses various types of
SoTA, including inference scaling model (OpenAI-o1), open-source multi-agent
models (e.g., AgentVerse), and majority voting strategies on current LLM and
single-agent baselines (e.g., ReAct, GPT4o), across diverse tasks, including
open-domain question answering, domain-specific selective questioning, and
practical advertisement text generation. These results highlight its potential
to set a new standard for LLM-MA systems, paving the way for more effective,
adaptable, and collaborative multi-agent frameworks. The code is available
https://github.com/sony/talkhier.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Recent advancements in LLM-based multi-agent (LLM-MA) systems have shown\npromise, yet significant challenges remain in managing communication and\nrefinement when agents collaborate on complex tasks. In this paper, we propose\n\\textit{Talk Structurally, Act Hierarchically (TalkHier)}, a novel framework\nthat introduces a structured communication protocol for context-rich exchanges\nand a hierarchical refinement system to address issues such as incorrect\noutputs, falsehoods, and biases. \\textit{TalkHier} surpasses various types of\nSoTA, including inference scaling model (OpenAI-o1), open-source multi-agent\nmodels (e.g., AgentVerse), and majority voting strategies on current LLM and\nsingle-agent baselines (e.g., ReAct, GPT4o), across diverse tasks, including\nopen-domain question answering, domain-specific selective questioning, and\npractical advertisement text generation. These results highlight its potential\nto set a new standard for LLM-MA systems, paving the way for more effective,\nadaptable, and collaborative multi-agent frameworks. The code is available\nhttps://github.com/sony/talkhier.'}","['Zhao Wang', 'Sota Moriyama', 'Wei-Yao Wang', 'Briti Gangopadhyay', 'Shingo Takamatsu']",{'name': 'Shingo Takamatsu'},Shingo Takamatsu,,"[{'href': 'http://arxiv.org/abs/2502.11098v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11098v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11098v1,None,http://arxiv.org/abs/2502.11098v1,,,120,0
http://arxiv.org/abs/2502.11140v1,True,2025-02-16T14:09:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=14, tm_min=9, tm_sec=42, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T14:09:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=14, tm_min=9, tm_sec=42, tm_wday=6, tm_yday=47, tm_isdst=0)","VisPath: Automated Visualization Code Synthesis via Multi-Path Reasoning
  and Feedback-Driven Optimization","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'VisPath: Automated Visualization Code Synthesis via Multi-Path Reasoning\n  and Feedback-Driven Optimization'}","Unprecedented breakthroughs in Large Language Models (LLMs) has amplified its
penetration into application of automated visualization code generation.
Few-shot prompting and query expansion techniques have notably enhanced data
visualization performance, however, still fail to overcome ambiguity and
complexity of natural language queries - imposing an inherent burden for manual
human intervention. To mitigate such limitations, we propose a holistic
framework VisPath : A Multi-Path Reasoning and Feedback-Driven Optimization
Framework for Visualization Code Generation, which systematically enhances code
quality through structured reasoning and refinement. VisPath is a multi-stage
framework, specially designed to handle underspecified queries. To generate a
robust final visualization code, it first utilizes initial query to generate
diverse reformulated queries via Chain-of-Thought (CoT) prompting, each
representing a distinct reasoning path. Refined queries are used to produce
candidate visualization scripts, consequently executed to generate multiple
images. Comprehensively assessing correctness and quality of outputs, VisPath
generates feedback for each image, which are then fed to aggregation module to
generate optimal result. Extensive experiments on benchmarks including
MatPlotBench and the Qwen-Agent Code Interpreter Benchmark show that VisPath
significantly outperforms state-of-the-art (SOTA) methods, increased up to
average 17%, offering a more reliable solution for AI-driven visualization code
generation.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Unprecedented breakthroughs in Large Language Models (LLMs) has amplified its\npenetration into application of automated visualization code generation.\nFew-shot prompting and query expansion techniques have notably enhanced data\nvisualization performance, however, still fail to overcome ambiguity and\ncomplexity of natural language queries - imposing an inherent burden for manual\nhuman intervention. To mitigate such limitations, we propose a holistic\nframework VisPath : A Multi-Path Reasoning and Feedback-Driven Optimization\nFramework for Visualization Code Generation, which systematically enhances code\nquality through structured reasoning and refinement. VisPath is a multi-stage\nframework, specially designed to handle underspecified queries. To generate a\nrobust final visualization code, it first utilizes initial query to generate\ndiverse reformulated queries via Chain-of-Thought (CoT) prompting, each\nrepresenting a distinct reasoning path. Refined queries are used to produce\ncandidate visualization scripts, consequently executed to generate multiple\nimages. Comprehensively assessing correctness and quality of outputs, VisPath\ngenerates feedback for each image, which are then fed to aggregation module to\ngenerate optimal result. Extensive experiments on benchmarks including\nMatPlotBench and the Qwen-Agent Code Interpreter Benchmark show that VisPath\nsignificantly outperforms state-of-the-art (SOTA) methods, increased up to\naverage 17%, offering a more reliable solution for AI-driven visualization code\ngeneration.'}","['Wonduk Seo', 'Seungyong Lee', 'Daye Kang', 'Zonghao Yuan', 'Seunghyun Lee']",{'name': 'Seunghyun Lee'},Seunghyun Lee,"14 pages, 3 figures, 4 tables","[{'href': 'http://arxiv.org/abs/2502.11140v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11140v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.SE', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.SE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11140v1,None,http://arxiv.org/abs/2502.11140v1,,,0,0
http://arxiv.org/abs/2502.11141v1,True,2025-02-16T14:13:04Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=14, tm_min=13, tm_sec=4, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T14:13:04Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=14, tm_min=13, tm_sec=4, tm_wday=6, tm_yday=47, tm_isdst=0)",Cognitive Neural Architecture Search Reveals Hierarchical Entailment,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Cognitive Neural Architecture Search Reveals Hierarchical Entailment'}","Recent research has suggested that the brain is more shallow than previously
thought, challenging the traditionally assumed hierarchical structure of the
ventral visual pathway. Here, we demonstrate that optimizing convolutional
network architectures for brain-alignment via evolutionary neural architecture
search results in models with clear representational hierarchies. Despite
having random weights, the identified models achieve brain-alignment scores
surpassing even those of pretrained classification models - as measured by both
regression and representational similarity analysis. Furthermore, through
traditional supervised training, architectures optimized for alignment with
late ventral regions become competitive classification models. These findings
suggest that hierarchical structure is a fundamental mechanism of primate
visual processing. Finally, this work demonstrates the potential of neural
architecture search as a framework for computational cognitive neuroscience
research that could reduce the field's reliance on manually designed
convolutional networks.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Recent research has suggested that the brain is more shallow than previously\nthought, challenging the traditionally assumed hierarchical structure of the\nventral visual pathway. Here, we demonstrate that optimizing convolutional\nnetwork architectures for brain-alignment via evolutionary neural architecture\nsearch results in models with clear representational hierarchies. Despite\nhaving random weights, the identified models achieve brain-alignment scores\nsurpassing even those of pretrained classification models - as measured by both\nregression and representational similarity analysis. Furthermore, through\ntraditional supervised training, architectures optimized for alignment with\nlate ventral regions become competitive classification models. These findings\nsuggest that hierarchical structure is a fundamental mechanism of primate\nvisual processing. Finally, this work demonstrates the potential of neural\narchitecture search as a framework for computational cognitive neuroscience\nresearch that could reduce the field's reliance on manually designed\nconvolutional networks.""}","['Lukas Kuhn', 'Sari Saba-Sadiya', 'Gemma Roig']",{'name': 'Gemma Roig'},Gemma Roig,,"[{'href': 'http://arxiv.org/abs/2502.11141v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11141v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-bio.QM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11141v1,None,http://arxiv.org/abs/2502.11141v1,,,1,0
http://arxiv.org/abs/2502.11142v1,True,2025-02-16T14:17:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=14, tm_min=17, tm_sec=36, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T14:17:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=14, tm_min=17, tm_sec=36, tm_wday=6, tm_yday=47, tm_isdst=0)","NavRAG: Generating User Demand Instructions for Embodied Navigation
  through Retrieval-Augmented LLM","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'NavRAG: Generating User Demand Instructions for Embodied Navigation\n  through Retrieval-Augmented LLM'}","Vision-and-Language Navigation (VLN) is an essential skill for embodied
agents, allowing them to navigate in 3D environments following natural language
instructions. High-performance navigation models require a large amount of
training data, the high cost of manually annotating data has seriously hindered
this field. Therefore, some previous methods translate trajectory videos into
step-by-step instructions for expanding data, but such instructions do not
match well with users' communication styles that briefly describe destinations
or state specific needs. Moreover, local navigation trajectories overlook
global context and high-level task planning. To address these issues, we
propose NavRAG, a retrieval-augmented generation (RAG) framework that generates
user demand instructions for VLN. NavRAG leverages LLM to build a hierarchical
scene description tree for 3D scene understanding from global layout to local
details, then simulates various user roles with specific demands to retrieve
from the scene tree, generating diverse instructions with LLM. We annotate over
2 million navigation instructions across 861 scenes and evaluate the data
quality and navigation performance of trained models.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Vision-and-Language Navigation (VLN) is an essential skill for embodied\nagents, allowing them to navigate in 3D environments following natural language\ninstructions. High-performance navigation models require a large amount of\ntraining data, the high cost of manually annotating data has seriously hindered\nthis field. Therefore, some previous methods translate trajectory videos into\nstep-by-step instructions for expanding data, but such instructions do not\nmatch well with users' communication styles that briefly describe destinations\nor state specific needs. Moreover, local navigation trajectories overlook\nglobal context and high-level task planning. To address these issues, we\npropose NavRAG, a retrieval-augmented generation (RAG) framework that generates\nuser demand instructions for VLN. NavRAG leverages LLM to build a hierarchical\nscene description tree for 3D scene understanding from global layout to local\ndetails, then simulates various user roles with specific demands to retrieve\nfrom the scene tree, generating diverse instructions with LLM. We annotate over\n2 million navigation instructions across 861 scenes and evaluate the data\nquality and navigation performance of trained models.""}","['Zihan Wang', 'Yaohui Zhu', 'Gim Hee Lee', 'Yachun Fan']",{'name': 'Yachun Fan'},Yachun Fan,,"[{'href': 'http://arxiv.org/abs/2502.11142v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11142v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11142v1,None,http://arxiv.org/abs/2502.11142v1,,,0,0
http://arxiv.org/abs/2502.11184v1,True,2025-02-16T16:12:40Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=16, tm_min=12, tm_sec=40, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T16:12:40Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=16, tm_min=12, tm_sec=40, tm_wday=6, tm_yday=47, tm_isdst=0)","Can't See the Forest for the Trees: Benchmarking Multimodal Safety
  Awareness for Multimodal LLMs","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Can't See the Forest for the Trees: Benchmarking Multimodal Safety\n  Awareness for Multimodal LLMs""}","Multimodal Large Language Models (MLLMs) have expanded the capabilities of
traditional language models by enabling interaction through both text and
images. However, ensuring the safety of these models remains a significant
challenge, particularly in accurately identifying whether multimodal content is
safe or unsafe-a capability we term safety awareness. In this paper, we
introduce MMSafeAware, the first comprehensive multimodal safety awareness
benchmark designed to evaluate MLLMs across 29 safety scenarios with 1500
carefully curated image-prompt pairs. MMSafeAware includes both unsafe and
over-safety subsets to assess models abilities to correctly identify unsafe
content and avoid over-sensitivity that can hinder helpfulness. Evaluating nine
widely used MLLMs using MMSafeAware reveals that current models are not
sufficiently safe and often overly sensitive; for example, GPT-4V misclassifies
36.1% of unsafe inputs as safe and 59.9% of benign inputs as unsafe. We further
explore three methods to improve safety awareness-prompting-based approaches,
visual contrastive decoding, and vision-centric reasoning fine-tuning-but find
that none achieve satisfactory performance. Our findings highlight the profound
challenges in developing MLLMs with robust safety awareness, underscoring the
need for further research in this area. All the code and data will be publicly
available to facilitate future research.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Multimodal Large Language Models (MLLMs) have expanded the capabilities of\ntraditional language models by enabling interaction through both text and\nimages. However, ensuring the safety of these models remains a significant\nchallenge, particularly in accurately identifying whether multimodal content is\nsafe or unsafe-a capability we term safety awareness. In this paper, we\nintroduce MMSafeAware, the first comprehensive multimodal safety awareness\nbenchmark designed to evaluate MLLMs across 29 safety scenarios with 1500\ncarefully curated image-prompt pairs. MMSafeAware includes both unsafe and\nover-safety subsets to assess models abilities to correctly identify unsafe\ncontent and avoid over-sensitivity that can hinder helpfulness. Evaluating nine\nwidely used MLLMs using MMSafeAware reveals that current models are not\nsufficiently safe and often overly sensitive; for example, GPT-4V misclassifies\n36.1% of unsafe inputs as safe and 59.9% of benign inputs as unsafe. We further\nexplore three methods to improve safety awareness-prompting-based approaches,\nvisual contrastive decoding, and vision-centric reasoning fine-tuning-but find\nthat none achieve satisfactory performance. Our findings highlight the profound\nchallenges in developing MLLMs with robust safety awareness, underscoring the\nneed for further research in this area. All the code and data will be publicly\navailable to facilitate future research.'}","['Wenxuan Wang', 'Xiaoyuan Liu', 'Kuiyi Gao', 'Jen-tse Huang', 'Youliang Yuan', 'Pinjia He', 'Shuai Wang', 'Zhaopeng Tu']",{'name': 'Zhaopeng Tu'},Zhaopeng Tu,,"[{'href': 'http://arxiv.org/abs/2502.11184v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11184v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11184v1,None,http://arxiv.org/abs/2502.11184v1,,,1599,0
http://arxiv.org/abs/2502.11191v1,True,2025-02-16T16:34:49Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=16, tm_min=34, tm_sec=49, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T16:34:49Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=16, tm_min=34, tm_sec=49, tm_wday=6, tm_yday=47, tm_isdst=0)","Primus: A Pioneering Collection of Open-Source Datasets for
  Cybersecurity LLM Training","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Primus: A Pioneering Collection of Open-Source Datasets for\n  Cybersecurity LLM Training'}","Large Language Models (LLMs) have shown remarkable advancements in
specialized fields such as finance, law, and medicine. However, in
cybersecurity, we have noticed a lack of open-source datasets, with a
particular lack of high-quality cybersecurity pretraining corpora, even though
much research indicates that LLMs acquire their knowledge during pretraining.
To address this, we present a comprehensive suite of datasets covering all
major training stages, including pretraining, instruction fine-tuning, and
reasoning distillation with cybersecurity-specific self-reflection data.
Extensive ablation studies demonstrate their effectiveness on public
cybersecurity benchmarks. In particular, continual pre-training on our dataset
yields a 15.88% improvement in the aggregate score, while reasoning
distillation leads to a 10% gain in security certification (CISSP). We will
release all datasets and trained cybersecurity LLMs under the ODC-BY and MIT
licenses to encourage further research in the community. For access to all
datasets and model weights, please refer to
https://huggingface.co/collections/trendmicro-ailab/primus-67b1fd27052b802b4af9d243.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Language Models (LLMs) have shown remarkable advancements in\nspecialized fields such as finance, law, and medicine. However, in\ncybersecurity, we have noticed a lack of open-source datasets, with a\nparticular lack of high-quality cybersecurity pretraining corpora, even though\nmuch research indicates that LLMs acquire their knowledge during pretraining.\nTo address this, we present a comprehensive suite of datasets covering all\nmajor training stages, including pretraining, instruction fine-tuning, and\nreasoning distillation with cybersecurity-specific self-reflection data.\nExtensive ablation studies demonstrate their effectiveness on public\ncybersecurity benchmarks. In particular, continual pre-training on our dataset\nyields a 15.88% improvement in the aggregate score, while reasoning\ndistillation leads to a 10% gain in security certification (CISSP). We will\nrelease all datasets and trained cybersecurity LLMs under the ODC-BY and MIT\nlicenses to encourage further research in the community. For access to all\ndatasets and model weights, please refer to\nhttps://huggingface.co/collections/trendmicro-ailab/primus-67b1fd27052b802b4af9d243.'}","['Yao-Ching Yu', 'Tsun-Han Chiang', 'Cheng-Wei Tsai', 'Chien-Ming Huang', 'Wen-Kwang Tsao']",{'name': 'Wen-Kwang Tsao'},Wen-Kwang Tsao,,"[{'href': 'http://arxiv.org/abs/2502.11191v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11191v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11191v1,None,http://arxiv.org/abs/2502.11191v1,,,0,0
http://arxiv.org/abs/2502.11211v1,True,2025-02-16T17:21:05Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=17, tm_min=21, tm_sec=5, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T17:21:05Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=17, tm_min=21, tm_sec=5, tm_wday=6, tm_yday=47, tm_isdst=0)",A Survey of LLM-based Agents in Medicine: How far are we from Baymax?,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A Survey of LLM-based Agents in Medicine: How far are we from Baymax?'}","Large Language Models (LLMs) are transforming healthcare through the
development of LLM-based agents that can understand, reason about, and assist
with medical tasks. This survey provides a comprehensive review of LLM-based
agents in medicine, examining their architectures, applications, and
challenges. We analyze the key components of medical agent systems, including
system profiles, clinical planning mechanisms, medical reasoning frameworks,
and external capacity enhancement. The survey covers major application
scenarios such as clinical decision support, medical documentation, training
simulations, and healthcare service optimization. We discuss evaluation
frameworks and metrics used to assess these agents' performance in healthcare
settings. While LLM-based agents show promise in enhancing healthcare delivery,
several challenges remain, including hallucination management, multimodal
integration, implementation barriers, and ethical considerations. The survey
concludes by highlighting future research directions, including advances in
medical reasoning inspired by recent developments in LLM architectures,
integration with physical systems, and improvements in training simulations.
This work provides researchers and practitioners with a structured overview of
the current state and future prospects of LLM-based agents in medicine.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Large Language Models (LLMs) are transforming healthcare through the\ndevelopment of LLM-based agents that can understand, reason about, and assist\nwith medical tasks. This survey provides a comprehensive review of LLM-based\nagents in medicine, examining their architectures, applications, and\nchallenges. We analyze the key components of medical agent systems, including\nsystem profiles, clinical planning mechanisms, medical reasoning frameworks,\nand external capacity enhancement. The survey covers major application\nscenarios such as clinical decision support, medical documentation, training\nsimulations, and healthcare service optimization. We discuss evaluation\nframeworks and metrics used to assess these agents' performance in healthcare\nsettings. While LLM-based agents show promise in enhancing healthcare delivery,\nseveral challenges remain, including hallucination management, multimodal\nintegration, implementation barriers, and ethical considerations. The survey\nconcludes by highlighting future research directions, including advances in\nmedical reasoning inspired by recent developments in LLM architectures,\nintegration with physical systems, and improvements in training simulations.\nThis work provides researchers and practitioners with a structured overview of\nthe current state and future prospects of LLM-based agents in medicine.""}","['Wenxuan Wang', 'Zizhan Ma', 'Zheng Wang', 'Chenghan Wu', 'Wenting Chen', 'Xiang Li', 'Yixuan Yuan']",{'name': 'Yixuan Yuan'},Yixuan Yuan,,"[{'href': 'http://arxiv.org/abs/2502.11211v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11211v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11211v1,None,http://arxiv.org/abs/2502.11211v1,,,85,0
http://arxiv.org/abs/2502.11213v1,True,2025-02-16T17:25:50Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=17, tm_min=25, tm_sec=50, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T17:25:50Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=17, tm_min=25, tm_sec=50, tm_wday=6, tm_yday=47, tm_isdst=0)",Stochastic Optimization of Inventory at Large-scale Supply Chains,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Stochastic Optimization of Inventory at Large-scale Supply Chains'}","Today's global supply chains face growing challenges due to rapidly changing
market conditions, increased network complexity and inter-dependency, and
dynamic uncertainties in supply, demand, and other factors. To combat these
challenges, organizations employ Material Requirements Planning (MRP) software
solutions to set inventory stock buffers - for raw materials, work-in-process
goods, and finished products - to help them meet customer service levels.
However, holding excess inventory further complicates operations and can lock
up millions of dollars of capital that could be otherwise deployed.
Furthermore, most commercially available MRP solutions fall short in
considering uncertainties and do not result in optimal solutions for modern
enterprises.
  At C3 AI, we fundamentally reformulate the inventory management problem as a
constrained stochastic optimization. We then propose a simulation-optimization
framework that minimizes inventory and related costs while maintaining desired
service levels. The framework's goal is to find the optimal reorder parameters
that minimize costs subject to a pre-defined service-level constraint and all
other real-world operational constraints. These optimal reorder parameters can
be fed back into an MRP system to drive optimal order placement, or used to
place optimal orders directly. This approach has proven successful in reducing
inventory levels by 10-35 percent, resulting in hundreds of millions of dollars
of economic benefit for major enterprises at a global scale.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Today's global supply chains face growing challenges due to rapidly changing\nmarket conditions, increased network complexity and inter-dependency, and\ndynamic uncertainties in supply, demand, and other factors. To combat these\nchallenges, organizations employ Material Requirements Planning (MRP) software\nsolutions to set inventory stock buffers - for raw materials, work-in-process\ngoods, and finished products - to help them meet customer service levels.\nHowever, holding excess inventory further complicates operations and can lock\nup millions of dollars of capital that could be otherwise deployed.\nFurthermore, most commercially available MRP solutions fall short in\nconsidering uncertainties and do not result in optimal solutions for modern\nenterprises.\n  At C3 AI, we fundamentally reformulate the inventory management problem as a\nconstrained stochastic optimization. We then propose a simulation-optimization\nframework that minimizes inventory and related costs while maintaining desired\nservice levels. The framework's goal is to find the optimal reorder parameters\nthat minimize costs subject to a pre-defined service-level constraint and all\nother real-world operational constraints. These optimal reorder parameters can\nbe fed back into an MRP system to drive optimal order placement, or used to\nplace optimal orders directly. This approach has proven successful in reducing\ninventory levels by 10-35 percent, resulting in hundreds of millions of dollars\nof economic benefit for major enterprises at a global scale.""}","['Zhaoyang Larry Jin', 'Mehdi Maasoumy', 'Yimin Liu', 'Zeshi Zheng', 'Zizhuo Ren']",{'name': 'Zizhuo Ren'},Zizhuo Ren,,"[{'href': 'http://arxiv.org/abs/2502.11213v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11213v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'math.OC', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'math.OC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11213v1,None,http://arxiv.org/abs/2502.11213v1,,,0,0
http://arxiv.org/abs/2502.11239v2,True,2025-02-18T03:35:48Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=3, tm_min=35, tm_sec=48, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-16T19:12:32Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=19, tm_min=12, tm_sec=32, tm_wday=6, tm_yday=47, tm_isdst=0)","Towards identifying possible fault-tolerant advantage of quantum linear
  system algorithms in terms of space, time and energy","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Towards identifying possible fault-tolerant advantage of quantum linear\n  system algorithms in terms of space, time and energy'}","Quantum computing, a prominent non-Von Neumann paradigm beyond Moore's law,
can offer superpolynomial speedups for certain problems. Yet its advantages in
efficiency for tasks like machine learning remain under investigation, and
quantum noise complicates resource estimations and classical comparisons. We
provide a detailed estimation of space, time, and energy resources for
fault-tolerant superconducting devices running the Harrow-Hassidim-Lloyd (HHL)
algorithm, a quantum linear system solver relevant to linear algebra and
machine learning. Excluding memory and data transfer, possible quantum
advantages over the classical conjugate gradient method could emerge at $N
\approx 2^{33} \sim 2^{48}$ or even lower, requiring ${O}(10^5)$ physical
qubits, ${O}(10^{12}\sim10^{13})$ Joules, and ${O}(10^6)$ seconds under surface
code fault-tolerance with three types of magic state distillation (15-1,
116-12, 225-1). Key parameters include condition number, sparsity, and
precision $\kappa, s\approx{O}(10\sim100)$, $\epsilon\sim0.01$, and physical
error $10^{-5}$. Our resource estimator adjusts $N, \kappa, s, \epsilon$,
providing a map of quantum-classical boundaries and revealing where a practical
quantum advantage may arise. Our work quantitatively determine how advanced a
fault-tolerant quantum computer should be to achieve possible, significant
benefits on problems related to real-world.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Quantum computing, a prominent non-Von Neumann paradigm beyond Moore's law,\ncan offer superpolynomial speedups for certain problems. Yet its advantages in\nefficiency for tasks like machine learning remain under investigation, and\nquantum noise complicates resource estimations and classical comparisons. We\nprovide a detailed estimation of space, time, and energy resources for\nfault-tolerant superconducting devices running the Harrow-Hassidim-Lloyd (HHL)\nalgorithm, a quantum linear system solver relevant to linear algebra and\nmachine learning. Excluding memory and data transfer, possible quantum\nadvantages over the classical conjugate gradient method could emerge at $N\n\\approx 2^{33} \\sim 2^{48}$ or even lower, requiring ${O}(10^5)$ physical\nqubits, ${O}(10^{12}\\sim10^{13})$ Joules, and ${O}(10^6)$ seconds under surface\ncode fault-tolerance with three types of magic state distillation (15-1,\n116-12, 225-1). Key parameters include condition number, sparsity, and\nprecision $\\kappa, s\\approx{O}(10\\sim100)$, $\\epsilon\\sim0.01$, and physical\nerror $10^{-5}$. Our resource estimator adjusts $N, \\kappa, s, \\epsilon$,\nproviding a map of quantum-classical boundaries and revealing where a practical\nquantum advantage may arise. Our work quantitatively determine how advanced a\nfault-tolerant quantum computer should be to achieve possible, significant\nbenefits on problems related to real-world.""}","['Yue Tu', 'Mark Dubynskyi', 'Mohammadhossein Mohammadisiahroudi', 'Ekaterina Riashchentceva', 'Jinglei Cheng', 'Dmitry Ryashchentsev', 'Tams Terlaky', 'Junyu Liu']",{'name': 'Junyu Liu'},Junyu Liu,"28 pages, many figures. v2: correcting typos","[{'href': 'http://arxiv.org/abs/2502.11239v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11239v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'quant-ph', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'quant-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.OC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11239v2,None,http://arxiv.org/abs/2502.11239v2,,,116,0
http://arxiv.org/abs/2502.11251v1,True,2025-02-16T20:11:39Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=20, tm_min=11, tm_sec=39, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T20:11:39Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=20, tm_min=11, tm_sec=39, tm_wday=6, tm_yday=47, tm_isdst=0)",Explaining Necessary Truths,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Explaining Necessary Truths'}","Knowing the truth is rarely enough -- we also seek out reasons why the fact
is true. While much is known about how we explain contingent truths, we
understand less about how we explain facts, such as those in mathematics, that
are true as a matter of logical necessity. We present a framework, based in
computational complexity, where explanations for deductive truths co-emerge
with discoveries of simplifying steps during the search process. When such
structures are missing, we revert, in turn, to error-based reasons, where a
(corrected) mistake can serve as fictitious, but explanatory,
contingency-cause: not making the mistake serves as a reason why the truth
takes the form it does. We simulate human subjects, using GPT-4o, presented
with SAT puzzles of varying complexity and reasonableness, validating our
theory and showing how its predictions can be tested in future human studies.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Knowing the truth is rarely enough -- we also seek out reasons why the fact\nis true. While much is known about how we explain contingent truths, we\nunderstand less about how we explain facts, such as those in mathematics, that\nare true as a matter of logical necessity. We present a framework, based in\ncomputational complexity, where explanations for deductive truths co-emerge\nwith discoveries of simplifying steps during the search process. When such\nstructures are missing, we revert, in turn, to error-based reasons, where a\n(corrected) mistake can serve as fictitious, but explanatory,\ncontingency-cause: not making the mistake serves as a reason why the truth\ntakes the form it does. We simulate human subjects, using GPT-4o, presented\nwith SAT puzzles of varying complexity and reasonableness, validating our\ntheory and showing how its predictions can be tested in future human studies.'}","['Glce Karde', 'Simon DeDeo']",{'name': 'Simon DeDeo'},Simon DeDeo,"7 pages, in review","[{'href': 'http://arxiv.org/abs/2502.11251v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11251v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.HO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-bio.NC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '97C30 (Primary), 91E10 (Secondary)', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11251v1,None,http://arxiv.org/abs/2502.11251v1,,,18,0
http://arxiv.org/abs/2502.11267v1,True,2025-02-16T20:54:26Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=20, tm_min=54, tm_sec=26, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T20:54:26Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=20, tm_min=54, tm_sec=26, tm_wday=6, tm_yday=47, tm_isdst=0)","Prompting in the Dark: Assessing Human Performance in Prompt Engineering
  for Data Labeling When Gold Labels Are Absent","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Prompting in the Dark: Assessing Human Performance in Prompt Engineering\n  for Data Labeling When Gold Labels Are Absent'}","Millions of users prompt large language models (LLMs) for various tasks, but
how good are people at prompt engineering? Do users actually get closer to
their desired outcome over multiple iterations of their prompts? These
questions are crucial when no gold-standard labels are available to measure
progress. This paper investigates a scenario in LLM-powered data labeling,
""prompting in the dark,"" where users iteratively prompt LLMs to label data
without using manually-labeled benchmarks. We developed PromptingSheet, a
Google Sheets add-on that enables users to compose, revise, and iteratively
label data through spreadsheets. Through a study with 20 participants, we found
that prompting in the dark was highly unreliable-only 9 participants improved
labeling accuracy after four or more iterations. Automated prompt optimization
tools like DSPy also struggled when few gold labels were available. Our
findings highlight the importance of gold labels and the needs, as well as the
risks, of automated support in human prompt engineering, providing insights for
future tool design.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Millions of users prompt large language models (LLMs) for various tasks, but\nhow good are people at prompt engineering? Do users actually get closer to\ntheir desired outcome over multiple iterations of their prompts? These\nquestions are crucial when no gold-standard labels are available to measure\nprogress. This paper investigates a scenario in LLM-powered data labeling,\n""prompting in the dark,"" where users iteratively prompt LLMs to label data\nwithout using manually-labeled benchmarks. We developed PromptingSheet, a\nGoogle Sheets add-on that enables users to compose, revise, and iteratively\nlabel data through spreadsheets. Through a study with 20 participants, we found\nthat prompting in the dark was highly unreliable-only 9 participants improved\nlabeling accuracy after four or more iterations. Automated prompt optimization\ntools like DSPy also struggled when few gold labels were available. Our\nfindings highlight the importance of gold labels and the needs, as well as the\nrisks, of automated support in human prompt engineering, providing insights for\nfuture tool design.'}","['Zeyu He', 'Saniya Naphade', ""Ting-Hao 'Kenneth' Huang""]","{'name': ""Ting-Hao 'Kenneth' Huang""}",Ting-Hao 'Kenneth' Huang,Accepted By CHI 2025,"[{'title': 'doi', 'href': 'http://dx.doi.org/10.1145/3706598.3714319', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2502.11267v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11267v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11267v1,None,http://arxiv.org/abs/2502.11267v1,,10.1145/3706598.3714319,21,0
http://arxiv.org/abs/2502.11269v1,True,2025-02-16T21:06:33Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=21, tm_min=6, tm_sec=33, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T21:06:33Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=21, tm_min=6, tm_sec=33, tm_wday=6, tm_yday=47, tm_isdst=0)","Unlocking the Potential of Generative AI through Neuro-Symbolic
  Architectures: Benefits and Limitations","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Unlocking the Potential of Generative AI through Neuro-Symbolic\n  Architectures: Benefits and Limitations'}","Neuro-symbolic artificial intelligence (NSAI) represents a transformative
approach in artificial intelligence (AI) by combining deep learning's ability
to handle large-scale and unstructured data with the structured reasoning of
symbolic methods. By leveraging their complementary strengths, NSAI enhances
generalization, reasoning, and scalability while addressing key challenges such
as transparency and data efficiency. This paper systematically studies diverse
NSAI architectures, highlighting their unique approaches to integrating neural
and symbolic components. It examines the alignment of contemporary AI
techniques such as retrieval-augmented generation, graph neural networks,
reinforcement learning, and multi-agent systems with NSAI paradigms. This study
then evaluates these architectures against comprehensive set of criteria,
including generalization, reasoning capabilities, transferability, and
interpretability, therefore providing a comparative analysis of their
respective strengths and limitations. Notably, the Neuro > Symbolic < Neuro
model consistently outperforms its counterparts across all evaluation metrics.
This result aligns with state-of-the-art research that highlight the efficacy
of such architectures in harnessing advanced technologies like multi-agent
systems.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Neuro-symbolic artificial intelligence (NSAI) represents a transformative\napproach in artificial intelligence (AI) by combining deep learning's ability\nto handle large-scale and unstructured data with the structured reasoning of\nsymbolic methods. By leveraging their complementary strengths, NSAI enhances\ngeneralization, reasoning, and scalability while addressing key challenges such\nas transparency and data efficiency. This paper systematically studies diverse\nNSAI architectures, highlighting their unique approaches to integrating neural\nand symbolic components. It examines the alignment of contemporary AI\ntechniques such as retrieval-augmented generation, graph neural networks,\nreinforcement learning, and multi-agent systems with NSAI paradigms. This study\nthen evaluates these architectures against comprehensive set of criteria,\nincluding generalization, reasoning capabilities, transferability, and\ninterpretability, therefore providing a comparative analysis of their\nrespective strengths and limitations. Notably, the Neuro > Symbolic < Neuro\nmodel consistently outperforms its counterparts across all evaluation metrics.\nThis result aligns with state-of-the-art research that highlight the efficacy\nof such architectures in harnessing advanced technologies like multi-agent\nsystems.""}","['Oualid Bougzime', 'Samir Jabbar', 'Christophe Cruz', 'Frdric Demoly']",{'name': 'Frdric Demoly'},Frdric Demoly,"54 pages, 7 figures","[{'href': 'http://arxiv.org/abs/2502.11269v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11269v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11269v1,None,http://arxiv.org/abs/2502.11269v1,,,1585,0
http://arxiv.org/abs/2502.11273v1,True,2025-02-16T21:30:26Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=21, tm_min=30, tm_sec=26, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T21:30:26Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=21, tm_min=30, tm_sec=26, tm_wday=6, tm_yday=47, tm_isdst=0)","FairFare: A Tool for Crowdsourcing Rideshare Data to Empower Labor
  Organizers","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'FairFare: A Tool for Crowdsourcing Rideshare Data to Empower Labor\n  Organizers'}","Rideshare workers experience unpredictable working conditions due to gig work
platforms' reliance on opaque AI and algorithmic systems. In response to these
challenges, we found that labor organizers want data to help them advocate for
legislation to increase the transparency and accountability of these platforms.
To address this need, we collaborated with a Colorado-based rideshare union to
develop FairFare, a tool that crowdsources and analyzes workers' data to
estimate the take rate -- the percentage of the rider price retained by the
rideshare platform. We deployed FairFare with our partner organization that
collaborated with us in collecting data on 76,000+ trips from 45 drivers over
18 months. During evaluation interviews, organizers reported that FairFare
helped influence the bill language and passage of Colorado Senate Bill 24-75,
calling for greater transparency and data disclosure of platform operations,
and create a national narrative. Finally, we reflect on complexities of
translating quantitative data into policy outcomes, nature of community based
audits, and design implications for future transparency tools.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Rideshare workers experience unpredictable working conditions due to gig work\nplatforms' reliance on opaque AI and algorithmic systems. In response to these\nchallenges, we found that labor organizers want data to help them advocate for\nlegislation to increase the transparency and accountability of these platforms.\nTo address this need, we collaborated with a Colorado-based rideshare union to\ndevelop FairFare, a tool that crowdsources and analyzes workers' data to\nestimate the take rate -- the percentage of the rider price retained by the\nrideshare platform. We deployed FairFare with our partner organization that\ncollaborated with us in collecting data on 76,000+ trips from 45 drivers over\n18 months. During evaluation interviews, organizers reported that FairFare\nhelped influence the bill language and passage of Colorado Senate Bill 24-75,\ncalling for greater transparency and data disclosure of platform operations,\nand create a national narrative. Finally, we reflect on complexities of\ntranslating quantitative data into policy outcomes, nature of community based\naudits, and design implications for future transparency tools.""}","['Dana Calacci', 'Varun Nagaraj Rao', 'Samantha Dalal', 'Catherine Di', 'Kok-Wei Pua', 'Andrew Schwartz', 'Danny Spitzberg', 'Andrs Monroy-Hernndez']",{'name': 'Andrs Monroy-Hernndez'},Andrs Monroy-Hernndez,FairFare is hosted at: https://getfairfare.org/,"[{'href': 'http://arxiv.org/abs/2502.11273v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11273v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11273v1,None,http://arxiv.org/abs/2502.11273v1,,,22,0
http://arxiv.org/abs/2502.11291v1,True,2025-02-16T22:26:18Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=22, tm_min=26, tm_sec=18, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T22:26:18Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=22, tm_min=26, tm_sec=18, tm_wday=6, tm_yday=47, tm_isdst=0)","Dialogue-based Explanations for Logical Reasoning using Structured
  Argumentation","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Dialogue-based Explanations for Logical Reasoning using Structured\n  Argumentation'}","The problem of explaining inconsistency-tolerant reasoning in knowledge bases
(KBs) is a prominent topic in Artificial Intelligence (AI). While there is some
work on this problem, the explanations provided by existing approaches often
lack critical information or fail to be expressive enough for non-binary
conflicts. In this paper, we identify structural weaknesses of the
state-of-the-art and propose a generic argumentation-based approach to address
these problems. This approach is defined for logics involving reasoning with
maximal consistent subsets and shows how any such logic can be translated to
argumentation. Our work provides dialogue models as dialectic-proof procedures
to compute and explain a query answer wrt inconsistency-tolerant semantics.
This allows us to construct dialectical proof trees as explanations, which are
more expressive and arguably more intuitive than existing explanation
formalisms.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The problem of explaining inconsistency-tolerant reasoning in knowledge bases\n(KBs) is a prominent topic in Artificial Intelligence (AI). While there is some\nwork on this problem, the explanations provided by existing approaches often\nlack critical information or fail to be expressive enough for non-binary\nconflicts. In this paper, we identify structural weaknesses of the\nstate-of-the-art and propose a generic argumentation-based approach to address\nthese problems. This approach is defined for logics involving reasoning with\nmaximal consistent subsets and shows how any such logic can be translated to\nargumentation. Our work provides dialogue models as dialectic-proof procedures\nto compute and explain a query answer wrt inconsistency-tolerant semantics.\nThis allows us to construct dialectical proof trees as explanations, which are\nmore expressive and arguably more intuitive than existing explanation\nformalisms.'}","['Loan Ho', 'Stefan Schlobach']",{'name': 'Stefan Schlobach'},Stefan Schlobach,"45 pages, 8 gigures, journal","[{'href': 'http://arxiv.org/abs/2502.11291v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11291v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.DB', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11291v1,None,http://arxiv.org/abs/2502.11291v1,,,17,0
http://arxiv.org/abs/2502.11298v1,True,2025-02-16T22:52:14Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=22, tm_min=52, tm_sec=14, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T22:52:14Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=22, tm_min=52, tm_sec=14, tm_wday=6, tm_yday=47, tm_isdst=0)","Integrating Language Models for Enhanced Network State Monitoring in
  DRL-Based SFC Provisioning","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Integrating Language Models for Enhanced Network State Monitoring in\n  DRL-Based SFC Provisioning'}","Efficient Service Function Chain (SFC) provisioning and Virtual Network
Function (VNF) placement are critical for enhancing network performance in
modern architectures such as Software-Defined Networking (SDN) and Network
Function Virtualization (NFV). While Deep Reinforcement Learning (DRL) aids
decision-making in dynamic network environments, its reliance on structured
inputs and predefined rules limits adaptability in unforeseen scenarios.
Additionally, incorrect actions by a DRL agent may require numerous training
iterations to correct, potentially reinforcing suboptimal policies and
degrading performance. This paper integrates DRL with Language Models (LMs),
specifically Bidirectional Encoder Representations from Transformers (BERT) and
DistilBERT, to enhance network management. By feeding final VNF allocations
from DRL into the LM, the system can process and respond to queries related to
SFCs, DCs, and VNFs, enabling real-time insights into resource utilization,
bottleneck detection, and future demand planning. The LMs are fine-tuned to our
domain-specific dataset using Low-Rank Adaptation (LoRA). Results show that
BERT outperforms DistilBERT with a lower test loss (0.28 compared to 0.36) and
higher confidence (0.83 compared to 0.74), though BERT requires approximately
46% more processing time.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Efficient Service Function Chain (SFC) provisioning and Virtual Network\nFunction (VNF) placement are critical for enhancing network performance in\nmodern architectures such as Software-Defined Networking (SDN) and Network\nFunction Virtualization (NFV). While Deep Reinforcement Learning (DRL) aids\ndecision-making in dynamic network environments, its reliance on structured\ninputs and predefined rules limits adaptability in unforeseen scenarios.\nAdditionally, incorrect actions by a DRL agent may require numerous training\niterations to correct, potentially reinforcing suboptimal policies and\ndegrading performance. This paper integrates DRL with Language Models (LMs),\nspecifically Bidirectional Encoder Representations from Transformers (BERT) and\nDistilBERT, to enhance network management. By feeding final VNF allocations\nfrom DRL into the LM, the system can process and respond to queries related to\nSFCs, DCs, and VNFs, enabling real-time insights into resource utilization,\nbottleneck detection, and future demand planning. The LMs are fine-tuned to our\ndomain-specific dataset using Low-Rank Adaptation (LoRA). Results show that\nBERT outperforms DistilBERT with a lower test loss (0.28 compared to 0.36) and\nhigher confidence (0.83 compared to 0.74), though BERT requires approximately\n46% more processing time.'}","['Parisa Fard Moshiri', 'Murat Arda Onsu', 'Poonam Lohan', 'Burak Kantarci', 'Emil Janulewicz']",{'name': 'Emil Janulewicz'},Emil Janulewicz,"6 pages, 5 figures, submitted to 30th IEEE International Symposium on
  Computers and Communications (ISCC) 2025","[{'href': 'http://arxiv.org/abs/2502.11298v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11298v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.NI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.NI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11298v1,None,http://arxiv.org/abs/2502.11298v1,,,7008,0
http://arxiv.org/abs/2502.11300v1,True,2025-02-16T22:54:44Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=22, tm_min=54, tm_sec=44, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T22:54:44Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=22, tm_min=54, tm_sec=44, tm_wday=6, tm_yday=47, tm_isdst=0)","CORDIAL: Can Multimodal Large Language Models Effectively Understand
  Coherence Relationships?","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'CORDIAL: Can Multimodal Large Language Models Effectively Understand\n  Coherence Relationships?'}","Multimodal Large Language Models (MLLMs) are renowned for their superior
instruction-following and reasoning capabilities across diverse problem
domains. However, existing benchmarks primarily focus on assessing factual and
logical correctness in downstream tasks, with limited emphasis on evaluating
MLLMs' ability to interpret pragmatic cues and intermodal relationships. To
address this gap, we assess the competency of MLLMs in performing Multimodal
Discourse Analysis (MDA) using Coherence Relations. Our benchmark, CORDIAL,
encompasses a broad spectrum of Coherence Relations across 3 different
discourse domains at varying levels of granularity. Through our experiments on
10+ MLLMs employing different prompting strategies, we show that even top
models like Gemini 1.5 Pro and GPT-4o fail to match the performance of simple
classifier-based baselines. This study emphasizes the need to move beyond
similarity-based metrics and adopt a discourse-driven framework for evaluating
MLLMs, providing a more nuanced assessment of their capabilities. The benchmark
and code are available at: https://github.com/aashish2000/CORDIAL.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Multimodal Large Language Models (MLLMs) are renowned for their superior\ninstruction-following and reasoning capabilities across diverse problem\ndomains. However, existing benchmarks primarily focus on assessing factual and\nlogical correctness in downstream tasks, with limited emphasis on evaluating\nMLLMs' ability to interpret pragmatic cues and intermodal relationships. To\naddress this gap, we assess the competency of MLLMs in performing Multimodal\nDiscourse Analysis (MDA) using Coherence Relations. Our benchmark, CORDIAL,\nencompasses a broad spectrum of Coherence Relations across 3 different\ndiscourse domains at varying levels of granularity. Through our experiments on\n10+ MLLMs employing different prompting strategies, we show that even top\nmodels like Gemini 1.5 Pro and GPT-4o fail to match the performance of simple\nclassifier-based baselines. This study emphasizes the need to move beyond\nsimilarity-based metrics and adopt a discourse-driven framework for evaluating\nMLLMs, providing a more nuanced assessment of their capabilities. The benchmark\nand code are available at: https://github.com/aashish2000/CORDIAL.""}","['Aashish Anantha Ramakrishnan', 'Aadarsh Anantha Ramakrishnan', 'Dongwon Lee']",{'name': 'Dongwon Lee'},Dongwon Lee,,"[{'href': 'http://arxiv.org/abs/2502.11300v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11300v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7; I.2.10', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11300v1,None,http://arxiv.org/abs/2502.11300v1,,,3,0
http://arxiv.org/abs/2502.11304v1,True,2025-02-16T23:03:26Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=23, tm_min=3, tm_sec=26, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T23:03:26Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=23, tm_min=3, tm_sec=26, tm_wday=6, tm_yday=47, tm_isdst=0)","Leveraging Multimodal-LLMs Assisted by Instance Segmentation for
  Intelligent Traffic Monitoring","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Leveraging Multimodal-LLMs Assisted by Instance Segmentation for\n  Intelligent Traffic Monitoring'}","A robust and efficient traffic monitoring system is essential for smart
cities and Intelligent Transportation Systems (ITS), using sensors and cameras
to track vehicle movements, optimize traffic flow, reduce congestion, enhance
road safety, and enable real-time adaptive traffic control. Traffic monitoring
models must comprehensively understand dynamic urban conditions and provide an
intuitive user interface for effective management. This research leverages the
LLaVA visual grounding multimodal large language model (LLM) for traffic
monitoring tasks on the real-time Quanser Interactive Lab simulation platform,
covering scenarios like intersections, congestion, and collisions. Cameras
placed at multiple urban locations collect real-time images from the
simulation, which are fed into the LLaVA model with queries for analysis. An
instance segmentation model integrated into the cameras highlights key elements
such as vehicles and pedestrians, enhancing training and throughput. The system
achieves 84.3% accuracy in recognizing vehicle locations and 76.4% in
determining steering direction, outperforming traditional models.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A robust and efficient traffic monitoring system is essential for smart\ncities and Intelligent Transportation Systems (ITS), using sensors and cameras\nto track vehicle movements, optimize traffic flow, reduce congestion, enhance\nroad safety, and enable real-time adaptive traffic control. Traffic monitoring\nmodels must comprehensively understand dynamic urban conditions and provide an\nintuitive user interface for effective management. This research leverages the\nLLaVA visual grounding multimodal large language model (LLM) for traffic\nmonitoring tasks on the real-time Quanser Interactive Lab simulation platform,\ncovering scenarios like intersections, congestion, and collisions. Cameras\nplaced at multiple urban locations collect real-time images from the\nsimulation, which are fed into the LLaVA model with queries for analysis. An\ninstance segmentation model integrated into the cameras highlights key elements\nsuch as vehicles and pedestrians, enhancing training and throughput. The system\nachieves 84.3% accuracy in recognizing vehicle locations and 76.4% in\ndetermining steering direction, outperforming traditional models.'}","['Murat Arda Onsu', 'Poonam Lohan', 'Burak Kantarci', 'Aisha Syed', 'Matthew Andrews', 'Sean Kennedy']",{'name': 'Sean Kennedy'},Sean Kennedy,"6 pages, 7 figures, submitted to 30th IEEE International Symposium on
  Computers and Communications (ISCC) 2025","[{'href': 'http://arxiv.org/abs/2502.11304v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11304v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11304v1,None,http://arxiv.org/abs/2502.11304v1,,,6799,0
http://arxiv.org/abs/2502.11308v2,True,2025-02-18T10:07:55Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=10, tm_min=7, tm_sec=55, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-16T23:11:13Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=23, tm_min=11, tm_sec=13, tm_wday=6, tm_yday=47, tm_isdst=0)","ALGEN: Few-shot Inversion Attacks on Textual Embeddings using Alignment
  and Generation","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'ALGEN: Few-shot Inversion Attacks on Textual Embeddings using Alignment\n  and Generation'}","With the growing popularity of Large Language Models (LLMs) and vector
databases, private textual data is increasingly processed and stored as
numerical embeddings. However, recent studies have proven that such embeddings
are vulnerable to inversion attacks, where original text is reconstructed to
reveal sensitive information. Previous research has largely assumed access to
millions of sentences to train attack models, e.g., through data leakage or
nearly unrestricted API access. With our method, a single data point is
sufficient for a partially successful inversion attack. With as little as 1k
data samples, performance reaches an optimum across a range of black-box
encoders, without training on leaked data. We present a Few-shot Textual
Embedding Inversion Attack using ALignment and GENeration (ALGEN), by aligning
victim embeddings to the attack space and using a generative model to
reconstruct text. We find that ALGEN attacks can be effectively transferred
across domains and languages, revealing key information. We further examine a
variety of defense mechanisms against ALGEN, and find that none are effective,
highlighting the vulnerabilities posed by inversion attacks. By significantly
lowering the cost of inversion and proving that embedding spaces can be aligned
through one-step optimization, we establish a new textual embedding inversion
paradigm with broader applications for embedding alignment in NLP.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'With the growing popularity of Large Language Models (LLMs) and vector\ndatabases, private textual data is increasingly processed and stored as\nnumerical embeddings. However, recent studies have proven that such embeddings\nare vulnerable to inversion attacks, where original text is reconstructed to\nreveal sensitive information. Previous research has largely assumed access to\nmillions of sentences to train attack models, e.g., through data leakage or\nnearly unrestricted API access. With our method, a single data point is\nsufficient for a partially successful inversion attack. With as little as 1k\ndata samples, performance reaches an optimum across a range of black-box\nencoders, without training on leaked data. We present a Few-shot Textual\nEmbedding Inversion Attack using ALignment and GENeration (ALGEN), by aligning\nvictim embeddings to the attack space and using a generative model to\nreconstruct text. We find that ALGEN attacks can be effectively transferred\nacross domains and languages, revealing key information. We further examine a\nvariety of defense mechanisms against ALGEN, and find that none are effective,\nhighlighting the vulnerabilities posed by inversion attacks. By significantly\nlowering the cost of inversion and proving that embedding spaces can be aligned\nthrough one-step optimization, we establish a new textual embedding inversion\nparadigm with broader applications for embedding alignment in NLP.'}","['Yiyi Chen', 'Qiongkai Xu', 'Johannes Bjerva']",{'name': 'Johannes Bjerva'},Johannes Bjerva,"18 pages, 13 tables, 6 figures","[{'href': 'http://arxiv.org/abs/2502.11308v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11308v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2; J.6', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11308v2,None,http://arxiv.org/abs/2502.11308v2,,,44,0
http://arxiv.org/abs/2502.11355v1,True,2025-02-17T02:11:17Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=2, tm_min=11, tm_sec=17, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T02:11:17Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=2, tm_min=11, tm_sec=17, tm_wday=0, tm_yday=48, tm_isdst=0)","""Nuclear Deployed!"": Analyzing Catastrophic Risks in Decision-making of
  Autonomous LLM Agents","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': '""Nuclear Deployed!"": Analyzing Catastrophic Risks in Decision-making of\n  Autonomous LLM Agents'}","Large language models (LLMs) are evolving into autonomous decision-makers,
raising concerns about catastrophic risks in high-stakes scenarios,
particularly in Chemical, Biological, Radiological and Nuclear (CBRN) domains.
Based on the insight that such risks can originate from trade-offs between the
agent's Helpful, Harmlessness and Honest (HHH) goals, we build a novel
three-stage evaluation framework, which is carefully constructed to effectively
and naturally expose such risks. We conduct 14,400 agentic simulations across
12 advanced LLMs, with extensive experiments and analysis. Results reveal that
LLM agents can autonomously engage in catastrophic behaviors and deception,
without being deliberately induced. Furthermore, stronger reasoning abilities
often increase, rather than mitigate, these risks. We also show that these
agents can violate instructions and superior commands. On the whole, we
empirically prove the existence of catastrophic risks in autonomous LLM agents.
We will release our code upon request.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Large language models (LLMs) are evolving into autonomous decision-makers,\nraising concerns about catastrophic risks in high-stakes scenarios,\nparticularly in Chemical, Biological, Radiological and Nuclear (CBRN) domains.\nBased on the insight that such risks can originate from trade-offs between the\nagent's Helpful, Harmlessness and Honest (HHH) goals, we build a novel\nthree-stage evaluation framework, which is carefully constructed to effectively\nand naturally expose such risks. We conduct 14,400 agentic simulations across\n12 advanced LLMs, with extensive experiments and analysis. Results reveal that\nLLM agents can autonomously engage in catastrophic behaviors and deception,\nwithout being deliberately induced. Furthermore, stronger reasoning abilities\noften increase, rather than mitigate, these risks. We also show that these\nagents can violate instructions and superior commands. On the whole, we\nempirically prove the existence of catastrophic risks in autonomous LLM agents.\nWe will release our code upon request.""}","['Rongwu Xu', 'Xiaojian Li', 'Shuo Chen', 'Wei Xu']",{'name': 'Wei Xu'},Wei Xu,"Our code will be available at
  https://github.com/pillowsofwind/LLM-CBRN-Risks","[{'href': 'http://arxiv.org/abs/2502.11355v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11355v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11355v1,None,http://arxiv.org/abs/2502.11355v1,,,40,0
http://arxiv.org/abs/2502.11356v1,True,2025-02-17T02:11:17Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=2, tm_min=11, tm_sec=17, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T02:11:17Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=2, tm_min=11, tm_sec=17, tm_wday=0, tm_yday=48, tm_isdst=0)","SAIF: A Sparse Autoencoder Framework for Interpreting and Steering
  Instruction Following of Language Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'SAIF: A Sparse Autoencoder Framework for Interpreting and Steering\n  Instruction Following of Language Models'}","The ability of large language models (LLMs) to follow instructions is crucial
for their practical applications, yet the underlying mechanisms remain poorly
understood. This paper presents a novel framework that leverages sparse
autoencoders (SAE) to interpret how instruction following works in these
models. We demonstrate how the features we identify can effectively steer model
outputs to align with given instructions. Through analysis of SAE latent
activations, we identify specific latents responsible for instruction following
behavior. Our findings reveal that instruction following capabilities are
encoded by a distinct set of instruction-relevant SAE latents. These latents
both show semantic proximity to relevant instructions and demonstrate causal
effects on model behavior. Our research highlights several crucial factors for
achieving effective steering performance: precise feature identification, the
role of final layer, and optimal instruction positioning. Additionally, we
demonstrate that our methodology scales effectively across SAEs and LLMs of
varying sizes.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The ability of large language models (LLMs) to follow instructions is crucial\nfor their practical applications, yet the underlying mechanisms remain poorly\nunderstood. This paper presents a novel framework that leverages sparse\nautoencoders (SAE) to interpret how instruction following works in these\nmodels. We demonstrate how the features we identify can effectively steer model\noutputs to align with given instructions. Through analysis of SAE latent\nactivations, we identify specific latents responsible for instruction following\nbehavior. Our findings reveal that instruction following capabilities are\nencoded by a distinct set of instruction-relevant SAE latents. These latents\nboth show semantic proximity to relevant instructions and demonstrate causal\neffects on model behavior. Our research highlights several crucial factors for\nachieving effective steering performance: precise feature identification, the\nrole of final layer, and optimal instruction positioning. Additionally, we\ndemonstrate that our methodology scales effectively across SAEs and LLMs of\nvarying sizes.'}","['Zirui He', 'Haiyan Zhao', 'Yiran Qiao', 'Fan Yang', 'Ali Payani', 'Jing Ma', 'Mengnan Du']",{'name': 'Mengnan Du'},Mengnan Du,"21 pages, 11 figures, 6 tables","[{'href': 'http://arxiv.org/abs/2502.11356v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11356v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11356v1,None,http://arxiv.org/abs/2502.11356v1,,,526,0
http://arxiv.org/abs/2502.11367v1,True,2025-02-17T02:30:45Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=2, tm_min=30, tm_sec=45, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T02:30:45Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=2, tm_min=30, tm_sec=45, tm_wday=0, tm_yday=48, tm_isdst=0)",Sparse Autoencoder Features for Classifications and Transferability,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Sparse Autoencoder Features for Classifications and Transferability'}","Sparse Autoencoders (SAEs) provide potentials for uncovering structured,
human-interpretable representations in Large Language Models (LLMs), making
them a crucial tool for transparent and controllable AI systems. We
systematically analyze SAE for interpretable feature extraction from LLMs in
safety-critical classification tasks. Our framework evaluates (1) model-layer
selection and scaling properties, (2) SAE architectural configurations,
including width and pooling strategies, and (3) the effect of binarizing
continuous SAE activations. SAE-derived features achieve macro F1 > 0.8,
outperforming hidden-state and BoW baselines while demonstrating cross-model
transfer from Gemma 2 2B to 9B-IT models. These features generalize in a
zero-shot manner to cross-lingual toxicity detection and visual classification
tasks. Our analysis highlights the significant impact of pooling strategies and
binarization thresholds, showing that binarization offers an efficient
alternative to traditional feature selection while maintaining or improving
performance. These findings establish new best practices for SAE-based
interpretability and enable scalable, transparent deployment of LLMs in
real-world applications. Full repo: https://github.com/shan23chen/MOSAIC.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Sparse Autoencoders (SAEs) provide potentials for uncovering structured,\nhuman-interpretable representations in Large Language Models (LLMs), making\nthem a crucial tool for transparent and controllable AI systems. We\nsystematically analyze SAE for interpretable feature extraction from LLMs in\nsafety-critical classification tasks. Our framework evaluates (1) model-layer\nselection and scaling properties, (2) SAE architectural configurations,\nincluding width and pooling strategies, and (3) the effect of binarizing\ncontinuous SAE activations. SAE-derived features achieve macro F1 > 0.8,\noutperforming hidden-state and BoW baselines while demonstrating cross-model\ntransfer from Gemma 2 2B to 9B-IT models. These features generalize in a\nzero-shot manner to cross-lingual toxicity detection and visual classification\ntasks. Our analysis highlights the significant impact of pooling strategies and\nbinarization thresholds, showing that binarization offers an efficient\nalternative to traditional feature selection while maintaining or improving\nperformance. These findings establish new best practices for SAE-based\ninterpretability and enable scalable, transparent deployment of LLMs in\nreal-world applications. Full repo: https://github.com/shan23chen/MOSAIC.'}","['Jack Gallifant', 'Shan Chen', 'Kuleen Sasse', 'Hugo Aerts', 'Thomas Hartvigsen', 'Danielle S. Bitterman']",{'name': 'Danielle S. Bitterman'},Danielle S. Bitterman,,"[{'href': 'http://arxiv.org/abs/2502.11367v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11367v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11367v1,None,http://arxiv.org/abs/2502.11367v1,,,406,0
http://arxiv.org/abs/2502.11379v1,True,2025-02-17T02:49:26Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=2, tm_min=49, tm_sec=26, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T02:49:26Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=2, tm_min=49, tm_sec=26, tm_wday=0, tm_yday=48, tm_isdst=0)","CCJA: Context-Coherent Jailbreak Attack for Aligned Large Language
  Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'CCJA: Context-Coherent Jailbreak Attack for Aligned Large Language\n  Models'}","Despite explicit alignment efforts for large language models (LLMs), they can
still be exploited to trigger unintended behaviors, a phenomenon known as
""jailbreaking."" Current jailbreak attack methods mainly focus on discrete
prompt manipulations targeting closed-source LLMs, relying on manually crafted
prompt templates and persuasion rules. However, as the capabilities of
open-source LLMs improve, ensuring their safety becomes increasingly crucial.
In such an environment, the accessibility of model parameters and gradient
information by potential attackers exacerbates the severity of jailbreak
threats. To address this research gap, we propose a novel
\underline{C}ontext-\underline{C}oherent \underline{J}ailbreak
\underline{A}ttack (CCJA). We define jailbreak attacks as an optimization
problem within the embedding space of masked language models. Through
combinatorial optimization, we effectively balance the jailbreak attack success
rate with semantic coherence. Extensive evaluations show that our method not
only maintains semantic consistency but also surpasses state-of-the-art
baselines in attack effectiveness. Additionally, by integrating semantically
coherent jailbreak prompts generated by our method into widely used black-box
methodologies, we observe a notable enhancement in their success rates when
targeting closed-source commercial LLMs. This highlights the security threat
posed by open-source LLMs to commercial counterparts. We will open-source our
code if the paper is accepted.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Despite explicit alignment efforts for large language models (LLMs), they can\nstill be exploited to trigger unintended behaviors, a phenomenon known as\n""jailbreaking."" Current jailbreak attack methods mainly focus on discrete\nprompt manipulations targeting closed-source LLMs, relying on manually crafted\nprompt templates and persuasion rules. However, as the capabilities of\nopen-source LLMs improve, ensuring their safety becomes increasingly crucial.\nIn such an environment, the accessibility of model parameters and gradient\ninformation by potential attackers exacerbates the severity of jailbreak\nthreats. To address this research gap, we propose a novel\n\\underline{C}ontext-\\underline{C}oherent \\underline{J}ailbreak\n\\underline{A}ttack (CCJA). We define jailbreak attacks as an optimization\nproblem within the embedding space of masked language models. Through\ncombinatorial optimization, we effectively balance the jailbreak attack success\nrate with semantic coherence. Extensive evaluations show that our method not\nonly maintains semantic consistency but also surpasses state-of-the-art\nbaselines in attack effectiveness. Additionally, by integrating semantically\ncoherent jailbreak prompts generated by our method into widely used black-box\nmethodologies, we observe a notable enhancement in their success rates when\ntargeting closed-source commercial LLMs. This highlights the security threat\nposed by open-source LLMs to commercial counterparts. We will open-source our\ncode if the paper is accepted.'}","['Guanghao Zhou', 'Panjia Qiu', 'Mingyuan Fan', 'Cen Chen', 'Mingyuan Chu', 'Xin Zhang', 'Jun Zhou']",{'name': 'Jun Zhou'},Jun Zhou,,"[{'href': 'http://arxiv.org/abs/2502.11379v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11379v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11379v1,None,http://arxiv.org/abs/2502.11379v1,,,67,0
http://arxiv.org/abs/2502.11433v3,True,2025-02-19T03:40:56Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=3, tm_min=40, tm_sec=56, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-17T04:45:53Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=4, tm_min=45, tm_sec=53, tm_wday=0, tm_yday=48, tm_isdst=0)","FLAG-Trader: Fusion LLM-Agent with Gradient-based Reinforcement Learning
  for Financial Trading","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'FLAG-Trader: Fusion LLM-Agent with Gradient-based Reinforcement Learning\n  for Financial Trading'}","Large language models (LLMs) fine-tuned on multimodal financial data have
demonstrated impressive reasoning capabilities in various financial tasks.
However, they often struggle with multi-step, goal-oriented scenarios in
interactive financial markets, such as trading, where complex agentic
approaches are required to improve decision-making. To address this, we propose
\textsc{FLAG-Trader}, a unified architecture integrating linguistic processing
(via LLMs) with gradient-driven reinforcement learning (RL) policy
optimization, in which a partially fine-tuned LLM acts as the policy network,
leveraging pre-trained knowledge while adapting to the financial domain through
parameter-efficient fine-tuning. Through policy gradient optimization driven by
trading rewards, our framework not only enhances LLM performance in trading but
also improves results on other financial-domain tasks. We present extensive
empirical evidence to validate these enhancements.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large language models (LLMs) fine-tuned on multimodal financial data have\ndemonstrated impressive reasoning capabilities in various financial tasks.\nHowever, they often struggle with multi-step, goal-oriented scenarios in\ninteractive financial markets, such as trading, where complex agentic\napproaches are required to improve decision-making. To address this, we propose\n\\textsc{FLAG-Trader}, a unified architecture integrating linguistic processing\n(via LLMs) with gradient-driven reinforcement learning (RL) policy\noptimization, in which a partially fine-tuned LLM acts as the policy network,\nleveraging pre-trained knowledge while adapting to the financial domain through\nparameter-efficient fine-tuning. Through policy gradient optimization driven by\ntrading rewards, our framework not only enhances LLM performance in trading but\nalso improves results on other financial-domain tasks. We present extensive\nempirical evidence to validate these enhancements.'}","['Guojun Xiong', 'Zhiyang Deng', 'Keyi Wang', 'Yupeng Cao', 'Haohang Li', 'Yangyang Yu', 'Xueqing Peng', 'Mingquan Lin', 'Kaleb E Smith', 'Xiao-Yang Liu', 'Jimin Huang', 'Sophia Ananiadou', 'Qianqian Xie']",{'name': 'Qianqian Xie'},Qianqian Xie,,"[{'href': 'http://arxiv.org/abs/2502.11433v3', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11433v3', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-fin.TR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11433v3,None,http://arxiv.org/abs/2502.11433v3,,,939,0
http://arxiv.org/abs/2502.11435v1,True,2025-02-17T04:50:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=4, tm_min=50, tm_sec=37, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T04:50:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=4, tm_min=50, tm_sec=37, tm_wday=0, tm_yday=48, tm_isdst=0)",SMART: Self-Aware Agent for Tool Overuse Mitigation,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'SMART: Self-Aware Agent for Tool Overuse Mitigation'}","Current Large Language Model (LLM) agents demonstrate strong reasoning and
tool use capabilities, but often lack self-awareness, failing to balance these
approaches effectively. This imbalance leads to Tool Overuse, where models
unnecessarily rely on external tools for tasks solvable with parametric
knowledge, increasing computational overhead. Inspired by human metacognition,
we introduce SMART (Strategic Model-Aware Reasoning with Tools), a paradigm
that enhances an agent's self-awareness to optimize task handling and reduce
tool overuse. To support this paradigm, we introduce SMART-ER, a dataset
spanning three domains, where reasoning alternates between parametric knowledge
and tool-dependent steps, with each step enriched by rationales explaining when
tools are necessary. Through supervised training, we develop SMARTAgent, a
family of models that dynamically balance parametric knowledge and tool use.
Evaluations show that SMARTAgent reduces tool use by 24% while improving
performance by over 37%, enabling 7B-scale models to match its 70B counterpart
and GPT-4o. Additionally, SMARTAgent generalizes to out-of-distribution test
data like GSM8K and MINTQA, maintaining accuracy with just one-fifth the tool
calls. These highlight the potential of strategic tool use to enhance
reasoning, mitigate overuse, and bridge the gap between model size and
performance, advancing intelligent and resource-efficient agent designs.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Current Large Language Model (LLM) agents demonstrate strong reasoning and\ntool use capabilities, but often lack self-awareness, failing to balance these\napproaches effectively. This imbalance leads to Tool Overuse, where models\nunnecessarily rely on external tools for tasks solvable with parametric\nknowledge, increasing computational overhead. Inspired by human metacognition,\nwe introduce SMART (Strategic Model-Aware Reasoning with Tools), a paradigm\nthat enhances an agent's self-awareness to optimize task handling and reduce\ntool overuse. To support this paradigm, we introduce SMART-ER, a dataset\nspanning three domains, where reasoning alternates between parametric knowledge\nand tool-dependent steps, with each step enriched by rationales explaining when\ntools are necessary. Through supervised training, we develop SMARTAgent, a\nfamily of models that dynamically balance parametric knowledge and tool use.\nEvaluations show that SMARTAgent reduces tool use by 24% while improving\nperformance by over 37%, enabling 7B-scale models to match its 70B counterpart\nand GPT-4o. Additionally, SMARTAgent generalizes to out-of-distribution test\ndata like GSM8K and MINTQA, maintaining accuracy with just one-fifth the tool\ncalls. These highlight the potential of strategic tool use to enhance\nreasoning, mitigate overuse, and bridge the gap between model size and\nperformance, advancing intelligent and resource-efficient agent designs.""}","['Cheng Qian', 'Emre Can Acikgoz', 'Hongru Wang', 'Xiusi Chen', 'Avirup Sil', 'Dilek Hakkani-Tr', 'Gokhan Tur', 'Heng Ji']",{'name': 'Heng Ji'},Heng Ji,"18 pages, 8 tables, 7 figures","[{'href': 'http://arxiv.org/abs/2502.11435v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11435v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11435v1,None,http://arxiv.org/abs/2502.11435v1,,,4799,0
http://arxiv.org/abs/2502.11439v1,True,2025-02-17T04:54:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=4, tm_min=54, tm_sec=42, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T04:54:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=4, tm_min=54, tm_sec=42, tm_wday=0, tm_yday=48, tm_isdst=0)",An Efficient Row-Based Sparse Fine-Tuning,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'An Efficient Row-Based Sparse Fine-Tuning'}","Fine-tuning is an important step in adapting foundation models such as large
language models to downstream tasks. To make this step more accessible to users
with limited computational budgets, it is crucial to develop fine-tuning
methods that are memory and computationally efficient. Sparse Fine-tuning (SFT)
and Low-rank adaptation (LoRA) are two frameworks that have emerged for
addressing this problem and have been adopted widely in practice. In this work,
we develop a new SFT framework, based on ideas from neural network pruning. At
a high level, we first identify ""important"" neurons/nodes using feature
importance metrics from network pruning (specifically, we use the structural
pruning method), and then perform fine-tuning by restricting to weights
involving these neurons. Using experiments on common language tasks, we
demonstrate that our method significantly improves the memory efficiency of SFT
without increasing training time complexity and implementation complexity,
while achieving accuracy comparable to state-of-the-art methods such as LoRA
and its variants.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Fine-tuning is an important step in adapting foundation models such as large\nlanguage models to downstream tasks. To make this step more accessible to users\nwith limited computational budgets, it is crucial to develop fine-tuning\nmethods that are memory and computationally efficient. Sparse Fine-tuning (SFT)\nand Low-rank adaptation (LoRA) are two frameworks that have emerged for\naddressing this problem and have been adopted widely in practice. In this work,\nwe develop a new SFT framework, based on ideas from neural network pruning. At\na high level, we first identify ""important"" neurons/nodes using feature\nimportance metrics from network pruning (specifically, we use the structural\npruning method), and then perform fine-tuning by restricting to weights\ninvolving these neurons. Using experiments on common language tasks, we\ndemonstrate that our method significantly improves the memory efficiency of SFT\nwithout increasing training time complexity and implementation complexity,\nwhile achieving accuracy comparable to state-of-the-art methods such as LoRA\nand its variants.'}","['Cen-Jhih Li', 'Aditya Bhaskara']",{'name': 'Aditya Bhaskara'},Aditya Bhaskara,,"[{'href': 'http://arxiv.org/abs/2502.11439v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11439v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11439v1,None,http://arxiv.org/abs/2502.11439v1,,,0,0
http://arxiv.org/abs/2502.11442v1,True,2025-02-17T04:58:14Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=4, tm_min=58, tm_sec=14, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T04:58:14Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=4, tm_min=58, tm_sec=14, tm_wday=0, tm_yday=48, tm_isdst=0)","Multi-Turn Multi-Modal Question Clarification for Enhanced
  Conversational Understanding","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Multi-Turn Multi-Modal Question Clarification for Enhanced\n  Conversational Understanding'}","Conversational query clarification enables users to refine their search
queries through interactive dialogue, improving search effectiveness.
Traditional approaches rely on text-based clarifying questions, which often
fail to capture complex user preferences, particularly those involving visual
attributes. While recent work has explored single-turn multi-modal
clarification with images alongside text, such methods do not fully support the
progressive nature of user intent refinement over multiple turns. Motivated by
this, we introduce the Multi-turn Multi-modal Clarifying Questions (MMCQ) task,
which combines text and visual modalities to refine user queries in a
multi-turn conversation. To facilitate this task, we create a large-scale
dataset named ClariMM comprising over 13k multi-turn interactions and 33k
question-answer pairs containing multi-modal clarifying questions. We propose
Mario, a retrieval framework that employs a two-phase ranking strategy: initial
retrieval with BM25, followed by a multi-modal generative re-ranking model that
integrates textual and visual information from conversational history. Our
experiments show that multi-turn multi-modal clarification outperforms
uni-modal and single-turn approaches, improving MRR by 12.88%. The gains are
most significant in longer interactions, demonstrating the value of progressive
refinement for complex queries.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Conversational query clarification enables users to refine their search\nqueries through interactive dialogue, improving search effectiveness.\nTraditional approaches rely on text-based clarifying questions, which often\nfail to capture complex user preferences, particularly those involving visual\nattributes. While recent work has explored single-turn multi-modal\nclarification with images alongside text, such methods do not fully support the\nprogressive nature of user intent refinement over multiple turns. Motivated by\nthis, we introduce the Multi-turn Multi-modal Clarifying Questions (MMCQ) task,\nwhich combines text and visual modalities to refine user queries in a\nmulti-turn conversation. To facilitate this task, we create a large-scale\ndataset named ClariMM comprising over 13k multi-turn interactions and 33k\nquestion-answer pairs containing multi-modal clarifying questions. We propose\nMario, a retrieval framework that employs a two-phase ranking strategy: initial\nretrieval with BM25, followed by a multi-modal generative re-ranking model that\nintegrates textual and visual information from conversational history. Our\nexperiments show that multi-turn multi-modal clarification outperforms\nuni-modal and single-turn approaches, improving MRR by 12.88%. The gains are\nmost significant in longer interactions, demonstrating the value of progressive\nrefinement for complex queries.'}","['Kimia Ramezan', 'Alireza Amiri Bavandpour', 'Yifei Yuan', 'Clemencia Siro', 'Mohammad Aliannejadi']",{'name': 'Mohammad Aliannejadi'},Mohammad Aliannejadi,,"[{'href': 'http://arxiv.org/abs/2502.11442v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11442v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11442v1,None,http://arxiv.org/abs/2502.11442v1,,,1899,0
http://arxiv.org/abs/2502.11482v1,True,2025-02-17T06:35:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=6, tm_min=35, tm_sec=42, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T06:35:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=6, tm_min=35, tm_sec=42, tm_wday=0, tm_yday=48, tm_isdst=0)","DATA: Decomposed Attention-based Task Adaptation for Rehearsal-Free
  Continual Learning","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'DATA: Decomposed Attention-based Task Adaptation for Rehearsal-Free\n  Continual Learning'}","Continual learning (CL) is essential for Large Language Models (LLMs) to
adapt to evolving real-world demands, yet they are susceptible to catastrophic
forgetting (CF). While traditional CF solutions rely on expensive data
rehearsal, recent rehearsal-free methods employ model-based and
regularization-based strategies to address this issue. However, these
approaches often neglect the model's plasticity, which is crucial to achieving
optimal performance on newly learned tasks. Consequently, a key challenge in CL
is striking a balance between preserving plasticity and mitigating CF. To
tackle this challenge, we propose the $\textbf{D}$ecomposed
$\textbf{A}$ttention-based $\textbf{T}$ask $\textbf{A}$daptation (DATA), which
explicitly decouples and learns both task-specific and task-shared knowledge
using high-rank and low-rank task adapters (e.g., LoRAs). For new tasks, DATA
dynamically adjusts the weights of adapters of different ranks based on their
relevance and distinction from previous tasks, allowing the model to acquire
new task-specific skills while effectively retaining previously learned
knowledge. Specifically, we implement a decomposed component weighting strategy
comprising learnable components that collectively generate attention-based
weights, allowing the model to integrate and utilize diverse knowledge from
each DATA. Extensive experiments on three widely used benchmarks demonstrate
that our proposed method achieves state-of-the-art performance. Notably, our
approach significantly enhances model plasticity and mitigates CF by extending
learnable components and employing stochastic restoration during training
iterations.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Continual learning (CL) is essential for Large Language Models (LLMs) to\nadapt to evolving real-world demands, yet they are susceptible to catastrophic\nforgetting (CF). While traditional CF solutions rely on expensive data\nrehearsal, recent rehearsal-free methods employ model-based and\nregularization-based strategies to address this issue. However, these\napproaches often neglect the model's plasticity, which is crucial to achieving\noptimal performance on newly learned tasks. Consequently, a key challenge in CL\nis striking a balance between preserving plasticity and mitigating CF. To\ntackle this challenge, we propose the $\\textbf{D}$ecomposed\n$\\textbf{A}$ttention-based $\\textbf{T}$ask $\\textbf{A}$daptation (DATA), which\nexplicitly decouples and learns both task-specific and task-shared knowledge\nusing high-rank and low-rank task adapters (e.g., LoRAs). For new tasks, DATA\ndynamically adjusts the weights of adapters of different ranks based on their\nrelevance and distinction from previous tasks, allowing the model to acquire\nnew task-specific skills while effectively retaining previously learned\nknowledge. Specifically, we implement a decomposed component weighting strategy\ncomprising learnable components that collectively generate attention-based\nweights, allowing the model to integrate and utilize diverse knowledge from\neach DATA. Extensive experiments on three widely used benchmarks demonstrate\nthat our proposed method achieves state-of-the-art performance. Notably, our\napproach significantly enhances model plasticity and mitigates CF by extending\nlearnable components and employing stochastic restoration during training\niterations.""}","['Huanxuan Liao', 'Shizhu He', 'Yupu Hao', 'Jun Zhao', 'Kang Liu']",{'name': 'Kang Liu'},Kang Liu,,"[{'href': 'http://arxiv.org/abs/2502.11482v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11482v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11482v1,None,http://arxiv.org/abs/2502.11482v1,,,6698,0
http://arxiv.org/abs/2502.11492v1,True,2025-02-17T06:54:49Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=6, tm_min=54, tm_sec=49, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T06:54:49Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=6, tm_min=54, tm_sec=49, tm_wday=0, tm_yday=48, tm_isdst=0)","Why Vision Language Models Struggle with Visual Arithmetic? Towards
  Enhanced Chart and Geometry Understanding","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Why Vision Language Models Struggle with Visual Arithmetic? Towards\n  Enhanced Chart and Geometry Understanding'}","Vision Language Models (VLMs) have achieved remarkable progress in multimodal
tasks, yet they often struggle with visual arithmetic, seemingly simple
capabilities like object counting or length comparison, which are essential for
relevant complex tasks like chart understanding and geometric reasoning. In
this work, we first investigate the root causes of this deficiency through a
suite of probing tasks focusing on basic visual arithmetic. Our analysis
reveals that while pre-trained vision encoders typically capture sufficient
information, the text decoder often fails to decode it correctly for arithmetic
reasoning. To address this, we propose CogAlign, a novel post-training strategy
inspired by Piaget's theory of cognitive development. CogAlign trains VLMs to
recognize invariant properties under visual transformations. We demonstrate
that this approach significantly improves the performance of three diverse VLMs
on our proposed probing tasks. Furthermore, CogAlign enhances performance by an
average of 4.6% on CHOCOLATE and 2.9% on MATH-VISION, outperforming or matching
supervised fine-tuning methods while requiring only 60% less training data.
These results highlight the effectiveness and generalizability of CogAlign in
improving fundamental visual arithmetic capabilities and their transfer to
downstream tasks.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Vision Language Models (VLMs) have achieved remarkable progress in multimodal\ntasks, yet they often struggle with visual arithmetic, seemingly simple\ncapabilities like object counting or length comparison, which are essential for\nrelevant complex tasks like chart understanding and geometric reasoning. In\nthis work, we first investigate the root causes of this deficiency through a\nsuite of probing tasks focusing on basic visual arithmetic. Our analysis\nreveals that while pre-trained vision encoders typically capture sufficient\ninformation, the text decoder often fails to decode it correctly for arithmetic\nreasoning. To address this, we propose CogAlign, a novel post-training strategy\ninspired by Piaget's theory of cognitive development. CogAlign trains VLMs to\nrecognize invariant properties under visual transformations. We demonstrate\nthat this approach significantly improves the performance of three diverse VLMs\non our proposed probing tasks. Furthermore, CogAlign enhances performance by an\naverage of 4.6% on CHOCOLATE and 2.9% on MATH-VISION, outperforming or matching\nsupervised fine-tuning methods while requiring only 60% less training data.\nThese results highlight the effectiveness and generalizability of CogAlign in\nimproving fundamental visual arithmetic capabilities and their transfer to\ndownstream tasks.""}","['Kung-Hsiang Huang', 'Can Qin', 'Haoyi Qiu', 'Philippe Laban', 'Shafiq Joty', 'Caiming Xiong', 'Chien-Sheng Wu']",{'name': 'Chien-Sheng Wu'},Chien-Sheng Wu,,"[{'href': 'http://arxiv.org/abs/2502.11492v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11492v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11492v1,None,http://arxiv.org/abs/2502.11492v1,,,1223,0
http://arxiv.org/abs/2502.11504v1,True,2025-02-17T07:11:46Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=7, tm_min=11, tm_sec=46, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T07:11:46Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=7, tm_min=11, tm_sec=46, tm_wday=0, tm_yday=48, tm_isdst=0)","Accelerated Gradient-based Design Optimization Via Differentiable
  Physics-Informed Neural Operator: A Composites Autoclave Processing Case
  Study","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Accelerated Gradient-based Design Optimization Via Differentiable\n  Physics-Informed Neural Operator: A Composites Autoclave Processing Case\n  Study'}","Simulation and optimization are crucial for advancing the engineering design
of complex systems and processes. Traditional optimization methods require
substantial computational time and effort due to their reliance on
resource-intensive simulations, such as finite element analysis, and the
complexity of rigorous optimization algorithms. Data-agnostic AI-based
surrogate models, such as Physics-Informed Neural Operators (PINOs), offer a
promising alternative to these conventional simulations, providing drastically
reduced inference time, unparalleled data efficiency, and zero-shot
super-resolution capability. However, the predictive accuracy of these models
is often constrained to small, low-dimensional design spaces or systems with
relatively simple dynamics. To address this, we introduce a novel
Physics-Informed DeepONet (PIDON) architecture, which extends the capabilities
of conventional neural operators to effectively model the nonlinear behavior of
complex engineering systems across high-dimensional design spaces and a wide
range of dynamic design configurations. This new architecture outperforms
existing SOTA models, enabling better predictions across broader design spaces.
Leveraging PIDON's differentiability, we integrate a gradient-based
optimization approach using the Adam optimizer to efficiently determine optimal
design variables. This forms an end-to-end gradient-based optimization
framework that accelerates the design process while enhancing scalability and
efficiency. We demonstrate the effectiveness of this framework in the
optimization of aerospace-grade composites curing processes achieving a 3x
speedup in obtaining optimal design variables compared to gradient-free
methods. Beyond composites processing, the proposed model has the potential to
be used as a scalable and efficient optimization tool for broader applications
in advanced engineering and digital twin systems.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Simulation and optimization are crucial for advancing the engineering design\nof complex systems and processes. Traditional optimization methods require\nsubstantial computational time and effort due to their reliance on\nresource-intensive simulations, such as finite element analysis, and the\ncomplexity of rigorous optimization algorithms. Data-agnostic AI-based\nsurrogate models, such as Physics-Informed Neural Operators (PINOs), offer a\npromising alternative to these conventional simulations, providing drastically\nreduced inference time, unparalleled data efficiency, and zero-shot\nsuper-resolution capability. However, the predictive accuracy of these models\nis often constrained to small, low-dimensional design spaces or systems with\nrelatively simple dynamics. To address this, we introduce a novel\nPhysics-Informed DeepONet (PIDON) architecture, which extends the capabilities\nof conventional neural operators to effectively model the nonlinear behavior of\ncomplex engineering systems across high-dimensional design spaces and a wide\nrange of dynamic design configurations. This new architecture outperforms\nexisting SOTA models, enabling better predictions across broader design spaces.\nLeveraging PIDON's differentiability, we integrate a gradient-based\noptimization approach using the Adam optimizer to efficiently determine optimal\ndesign variables. This forms an end-to-end gradient-based optimization\nframework that accelerates the design process while enhancing scalability and\nefficiency. We demonstrate the effectiveness of this framework in the\noptimization of aerospace-grade composites curing processes achieving a 3x\nspeedup in obtaining optimal design variables compared to gradient-free\nmethods. Beyond composites processing, the proposed model has the potential to\nbe used as a scalable and efficient optimization tool for broader applications\nin advanced engineering and digital twin systems.""}","['Janak M. Patel', 'Milad Ramezankhani', 'Anirudh Deodhar', 'Dagnachew Birru']",{'name': 'Dagnachew Birru'},Dagnachew Birru,"15 pages, 7 figures","[{'href': 'http://arxiv.org/abs/2502.11504v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11504v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.NA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11504v1,None,http://arxiv.org/abs/2502.11504v1,,,405,0
http://arxiv.org/abs/2502.11518v1,True,2025-02-17T07:39:34Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=7, tm_min=39, tm_sec=34, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T07:39:34Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=7, tm_min=39, tm_sec=34, tm_wday=0, tm_yday=48, tm_isdst=0)",Generative Multi-Agent Collaboration in Embodied AI: A Systematic Review,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Generative Multi-Agent Collaboration in Embodied AI: A Systematic Review'}","Embodied multi-agent systems (EMAS) have attracted growing attention for
their potential to address complex, real-world challenges in areas such as
logistics and robotics. Recent advances in foundation models pave the way for
generative agents capable of richer communication and adaptive problem-solving.
This survey provides a systematic examination of how EMAS can benefit from
these generative capabilities. We propose a taxonomy that categorizes EMAS by
system architectures and embodiment modalities, emphasizing how collaboration
spans both physical and virtual contexts. Central building blocks, perception,
planning, communication, and feedback, are then analyzed to illustrate how
generative techniques bolster system robustness and flexibility. Through
concrete examples, we demonstrate the transformative effects of integrating
foundation models into embodied, multi-agent frameworks. Finally, we discuss
challenges and future directions, underlining the significant promise of EMAS
to reshape the landscape of AI-driven collaboration.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Embodied multi-agent systems (EMAS) have attracted growing attention for\ntheir potential to address complex, real-world challenges in areas such as\nlogistics and robotics. Recent advances in foundation models pave the way for\ngenerative agents capable of richer communication and adaptive problem-solving.\nThis survey provides a systematic examination of how EMAS can benefit from\nthese generative capabilities. We propose a taxonomy that categorizes EMAS by\nsystem architectures and embodiment modalities, emphasizing how collaboration\nspans both physical and virtual contexts. Central building blocks, perception,\nplanning, communication, and feedback, are then analyzed to illustrate how\ngenerative techniques bolster system robustness and flexibility. Through\nconcrete examples, we demonstrate the transformative effects of integrating\nfoundation models into embodied, multi-agent frameworks. Finally, we discuss\nchallenges and future directions, underlining the significant promise of EMAS\nto reshape the landscape of AI-driven collaboration.'}","['Di Wu', 'Xian Wei', 'Guang Chen', 'Hao Shen', 'Xiangfeng Wang', 'Wenhao Li', 'Bo Jin']",{'name': 'Bo Jin'},Bo Jin,18 pages,"[{'href': 'http://arxiv.org/abs/2502.11518v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11518v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11518v1,None,http://arxiv.org/abs/2502.11518v1,,,799,0
http://arxiv.org/abs/2502.11569v1,True,2025-02-17T08:59:16Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=8, tm_min=59, tm_sec=16, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T08:59:16Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=8, tm_min=59, tm_sec=16, tm_wday=0, tm_yday=48, tm_isdst=0)",Towards Reasoning Ability of Small Language Models,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Towards Reasoning Ability of Small Language Models'}","Reasoning has long been viewed as an emergent property of large language
models (LLMs), appearing at or above a certain scale ($\sim$100B parameters).
However, recent studies challenge this assumption, showing that small language
models (SLMs) can also achieve competitive reasoning performance. SLMs are
increasingly favored for their efficiency and deployability. However, there is
a lack of systematic study on the reasoning abilities of diverse SLMs,
including those trained from scratch or derived from LLMs through quantization,
pruning, and distillation. This raises a critical question: Can SLMs achieve
reasoning abilities comparable to LLMs? In this work, we systematically survey,
benchmark, and analyze 72 SLMs from six model families across 14 reasoning
benchmarks. For reliable evaluation, we examine four evaluation methods and
compare four LLM judges against human evaluations on 800 data points. We repeat
all experiments three times to ensure a robust performance assessment.
Additionally, we analyze the impact of different prompting strategies in small
models. Beyond accuracy, we also evaluate model robustness under adversarial
conditions and intermediate reasoning steps. Our findings challenge the
assumption that scaling is the only way to achieve strong reasoning. Instead,
we foresee a future where SLMs with strong reasoning capabilities can be
developed through structured training or post-training compression. They can
serve as efficient alternatives to LLMs for reasoning-intensive tasks.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Reasoning has long been viewed as an emergent property of large language\nmodels (LLMs), appearing at or above a certain scale ($\\sim$100B parameters).\nHowever, recent studies challenge this assumption, showing that small language\nmodels (SLMs) can also achieve competitive reasoning performance. SLMs are\nincreasingly favored for their efficiency and deployability. However, there is\na lack of systematic study on the reasoning abilities of diverse SLMs,\nincluding those trained from scratch or derived from LLMs through quantization,\npruning, and distillation. This raises a critical question: Can SLMs achieve\nreasoning abilities comparable to LLMs? In this work, we systematically survey,\nbenchmark, and analyze 72 SLMs from six model families across 14 reasoning\nbenchmarks. For reliable evaluation, we examine four evaluation methods and\ncompare four LLM judges against human evaluations on 800 data points. We repeat\nall experiments three times to ensure a robust performance assessment.\nAdditionally, we analyze the impact of different prompting strategies in small\nmodels. Beyond accuracy, we also evaluate model robustness under adversarial\nconditions and intermediate reasoning steps. Our findings challenge the\nassumption that scaling is the only way to achieve strong reasoning. Instead,\nwe foresee a future where SLMs with strong reasoning capabilities can be\ndeveloped through structured training or post-training compression. They can\nserve as efficient alternatives to LLMs for reasoning-intensive tasks.'}","['Gaurav Srivastava', 'Shuxiang Cao', 'Xuan Wang']",{'name': 'Xuan Wang'},Xuan Wang,,"[{'href': 'http://arxiv.org/abs/2502.11569v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11569v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11569v1,None,http://arxiv.org/abs/2502.11569v1,,,0,0
http://arxiv.org/abs/2502.11617v1,True,2025-02-17T10:00:24Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=10, tm_min=0, tm_sec=24, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T10:00:24Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=10, tm_min=0, tm_sec=24, tm_wday=0, tm_yday=48, tm_isdst=0)",In-Context Parametric Inference: Point or Distribution Estimators?,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'In-Context Parametric Inference: Point or Distribution Estimators?'}","Bayesian and frequentist inference are two fundamental paradigms in
statistical estimation. Bayesian methods treat hypotheses as random variables,
incorporating priors and updating beliefs via Bayes' theorem, whereas
frequentist methods assume fixed but unknown hypotheses, relying on estimators
like maximum likelihood. While extensive research has compared these
approaches, the frequentist paradigm of obtaining point estimates has become
predominant in deep learning, as Bayesian inference is challenging due to the
computational complexity and the approximation gap of posterior estimation
methods. However, a good understanding of trade-offs between the two approaches
is lacking in the regime of amortized estimators, where in-context learners are
trained to estimate either point values via maximum likelihood or maximum a
posteriori estimation, or full posteriors using normalizing flows, score-based
diffusion samplers, or diagonal Gaussian approximations, conditioned on
observations. To help resolve this, we conduct a rigorous comparative analysis
spanning diverse problem settings, from linear models to shallow neural
networks, with a robust evaluation framework assessing both in-distribution and
out-of-distribution generalization on tractable tasks. Our experiments indicate
that amortized point estimators generally outperform posterior inference,
though the latter remain competitive in some low-dimensional problems, and we
further discuss why this might be the case.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Bayesian and frequentist inference are two fundamental paradigms in\nstatistical estimation. Bayesian methods treat hypotheses as random variables,\nincorporating priors and updating beliefs via Bayes' theorem, whereas\nfrequentist methods assume fixed but unknown hypotheses, relying on estimators\nlike maximum likelihood. While extensive research has compared these\napproaches, the frequentist paradigm of obtaining point estimates has become\npredominant in deep learning, as Bayesian inference is challenging due to the\ncomputational complexity and the approximation gap of posterior estimation\nmethods. However, a good understanding of trade-offs between the two approaches\nis lacking in the regime of amortized estimators, where in-context learners are\ntrained to estimate either point values via maximum likelihood or maximum a\nposteriori estimation, or full posteriors using normalizing flows, score-based\ndiffusion samplers, or diagonal Gaussian approximations, conditioned on\nobservations. To help resolve this, we conduct a rigorous comparative analysis\nspanning diverse problem settings, from linear models to shallow neural\nnetworks, with a robust evaluation framework assessing both in-distribution and\nout-of-distribution generalization on tractable tasks. Our experiments indicate\nthat amortized point estimators generally outperform posterior inference,\nthough the latter remain competitive in some low-dimensional problems, and we\nfurther discuss why this might be the case.""}","['Sarthak Mittal', 'Yoshua Bengio', 'Nikolay Malkin', 'Guillaume Lajoie']",{'name': 'Guillaume Lajoie'},Guillaume Lajoie,,"[{'href': 'http://arxiv.org/abs/2502.11617v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11617v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11617v1,None,http://arxiv.org/abs/2502.11617v1,,,11957,0
http://arxiv.org/abs/2502.11639v1,True,2025-02-17T10:33:24Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=10, tm_min=33, tm_sec=24, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T10:33:24Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=10, tm_min=33, tm_sec=24, tm_wday=0, tm_yday=48, tm_isdst=0)",Neural Interpretable Reasoning,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Neural Interpretable Reasoning'}","We formalize a novel modeling framework for achieving interpretability in
deep learning, anchored in the principle of inference equivariance. While the
direct verification of interpretability scales exponentially with the number of
variables of the system, we show that this complexity can be mitigated by
treating interpretability as a Markovian property and employing neural
re-parametrization techniques. Building on these insights, we propose a new
modeling paradigm -- neural generation and interpretable execution -- that
enables scalable verification of equivariance. This paradigm provides a general
approach for designing Neural Interpretable Reasoners that are not only
expressive but also transparent.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'We formalize a novel modeling framework for achieving interpretability in\ndeep learning, anchored in the principle of inference equivariance. While the\ndirect verification of interpretability scales exponentially with the number of\nvariables of the system, we show that this complexity can be mitigated by\ntreating interpretability as a Markovian property and employing neural\nre-parametrization techniques. Building on these insights, we propose a new\nmodeling paradigm -- neural generation and interpretable execution -- that\nenables scalable verification of equivariance. This paradigm provides a general\napproach for designing Neural Interpretable Reasoners that are not only\nexpressive but also transparent.'}","['Pietro Barbiero', 'Giuseppe Marra', 'Gabriele Ciravegna', 'David Debot', 'Francesco De Santis', 'Michelangelo Diligenti', 'Mateo Espinosa Zarlenga', 'Francesco Giannini']",{'name': 'Francesco Giannini'},Francesco Giannini,,"[{'href': 'http://arxiv.org/abs/2502.11639v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11639v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11639v1,None,http://arxiv.org/abs/2502.11639v1,,,2638,0
http://arxiv.org/abs/2502.11658v2,True,2025-02-18T09:24:14Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=9, tm_min=24, tm_sec=14, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-17T10:49:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=10, tm_min=49, tm_sec=23, tm_wday=0, tm_yday=48, tm_isdst=0)","""I'm not for sale"" -- Perceptions and limited awareness of privacy risks
  by digital natives about location data","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': '""I\'m not for sale"" -- Perceptions and limited awareness of privacy risks\n  by digital natives about location data'}","Although mobile devices benefit users in their daily lives in numerous ways,
they also raise several privacy concerns. For instance, they can reveal
sensitive information that can be inferred from location data. This location
data is shared through service providers as well as mobile applications.
Understanding how and with whom users share their location data -- as well as
users' perception of the underlying privacy risks --, are important notions to
grasp in order to design usable privacy-enhancing technologies. In this work,
we perform a quantitative and qualitative analysis of smartphone users'
awareness, perception and self-reported behavior towards location data-sharing
through a survey of n=99 young adult participants (i.e., digital natives). We
compare stated practices with actual behaviors to better understand their
mental models, and survey participants' understanding of privacy risks before
and after the inspection of location traces and the information that can be
inferred therefrom.
  Our empirical results show that participants have risky privacy practices:
about 54% of participants underestimate the number of mobile applications to
which they have granted access to their data, and 33% forget or do not think of
revoking access to their data. Also, by using a demonstrator to perform
inferences from location data, we observe that slightly more than half of
participants (57%) are surprised by the extent of potentially inferred
information, and that 47% intend to reduce access to their data via permissions
as a result of using the demonstrator. Last, a majority of participants have
little knowledge of the tools to better protect themselves, but are nonetheless
willing to follow suggestions to improve privacy (51%). Educating people,
including digital natives, about privacy risks through transparency tools seems
a promising approach.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Although mobile devices benefit users in their daily lives in numerous ways,\nthey also raise several privacy concerns. For instance, they can reveal\nsensitive information that can be inferred from location data. This location\ndata is shared through service providers as well as mobile applications.\nUnderstanding how and with whom users share their location data -- as well as\nusers' perception of the underlying privacy risks --, are important notions to\ngrasp in order to design usable privacy-enhancing technologies. In this work,\nwe perform a quantitative and qualitative analysis of smartphone users'\nawareness, perception and self-reported behavior towards location data-sharing\nthrough a survey of n=99 young adult participants (i.e., digital natives). We\ncompare stated practices with actual behaviors to better understand their\nmental models, and survey participants' understanding of privacy risks before\nand after the inspection of location traces and the information that can be\ninferred therefrom.\n  Our empirical results show that participants have risky privacy practices:\nabout 54% of participants underestimate the number of mobile applications to\nwhich they have granted access to their data, and 33% forget or do not think of\nrevoking access to their data. Also, by using a demonstrator to perform\ninferences from location data, we observe that slightly more than half of\nparticipants (57%) are surprised by the extent of potentially inferred\ninformation, and that 47% intend to reduce access to their data via permissions\nas a result of using the demonstrator. Last, a majority of participants have\nlittle knowledge of the tools to better protect themselves, but are nonetheless\nwilling to follow suggestions to improve privacy (51%). Educating people,\nincluding digital natives, about privacy risks through transparency tools seems\na promising approach.""}","['Antoine Boutet', 'Victor Morel']",{'name': 'Victor Morel'},Victor Morel,"Submitted to ICWSM on January 15, 2025","[{'href': 'http://arxiv.org/abs/2502.11658v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11658v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11658v2,None,http://arxiv.org/abs/2502.11658v2,,,0,0
http://arxiv.org/abs/2502.11671v1,True,2025-02-17T11:00:40Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=11, tm_min=0, tm_sec=40, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T11:00:40Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=11, tm_min=0, tm_sec=40, tm_wday=0, tm_yday=48, tm_isdst=0)",Diversity-Oriented Data Augmentation with Large Language Models,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Diversity-Oriented Data Augmentation with Large Language Models'}","Data augmentation is an essential technique in natural language processing
(NLP) for enriching training datasets by generating diverse samples. This
process is crucial for improving the robustness and generalization capabilities
of NLP models. However, a significant challenge remains: \textit{Insufficient
Attention to Sample Distribution Diversity}. Most existing methods focus on
increasing the sample numbers while neglecting the sample distribution
diversity, which can lead to model overfitting. In response, we explore data
augmentation's impact on dataset diversity and propose a
\textbf{\underline{D}}iversity-\textbf{\underline{o}}riented data
\textbf{\underline{Aug}}mentation framework (\textbf{DoAug}). %
\(\mathscr{DoAug}\) Specifically, we utilize a diversity-oriented fine-tuning
approach to train an LLM as a diverse paraphraser, which is capable of
augmenting textual datasets by generating diversified paraphrases. Then, we
apply the LLM paraphraser to a selected coreset of highly informative samples
and integrate the paraphrases with the original data to create a more diverse
augmented dataset. Finally, we conduct extensive experiments on 12 real-world
textual datasets. The results show that our fine-tuned LLM augmenter improves
diversity while preserving label consistency, thereby enhancing the robustness
and performance of downstream tasks. Specifically, it achieves an average
performance gain of \(10.52\%\), surpassing the runner-up baseline with more
than three percentage points.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Data augmentation is an essential technique in natural language processing\n(NLP) for enriching training datasets by generating diverse samples. This\nprocess is crucial for improving the robustness and generalization capabilities\nof NLP models. However, a significant challenge remains: \\textit{Insufficient\nAttention to Sample Distribution Diversity}. Most existing methods focus on\nincreasing the sample numbers while neglecting the sample distribution\ndiversity, which can lead to model overfitting. In response, we explore data\naugmentation's impact on dataset diversity and propose a\n\\textbf{\\underline{D}}iversity-\\textbf{\\underline{o}}riented data\n\\textbf{\\underline{Aug}}mentation framework (\\textbf{DoAug}). %\n\\(\\mathscr{DoAug}\\) Specifically, we utilize a diversity-oriented fine-tuning\napproach to train an LLM as a diverse paraphraser, which is capable of\naugmenting textual datasets by generating diversified paraphrases. Then, we\napply the LLM paraphraser to a selected coreset of highly informative samples\nand integrate the paraphrases with the original data to create a more diverse\naugmented dataset. Finally, we conduct extensive experiments on 12 real-world\ntextual datasets. The results show that our fine-tuned LLM augmenter improves\ndiversity while preserving label consistency, thereby enhancing the robustness\nand performance of downstream tasks. Specifically, it achieves an average\nperformance gain of \\(10.52\\%\\), surpassing the runner-up baseline with more\nthan three percentage points.""}","['Zaitian Wang', 'Jinghan Zhang', 'Xinhao Zhang', 'Kunpeng Liu', 'Pengfei Wang', 'Yuanchun Zhou']",{'name': 'Yuanchun Zhou'},Yuanchun Zhou,,"[{'href': 'http://arxiv.org/abs/2502.11671v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11671v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11671v1,None,http://arxiv.org/abs/2502.11671v1,,,605,0
http://arxiv.org/abs/2502.11687v1,True,2025-02-17T11:25:28Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=11, tm_min=25, tm_sec=28, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T11:25:28Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=11, tm_min=25, tm_sec=28, tm_wday=0, tm_yday=48, tm_isdst=0)","ReVeil: Unconstrained Concealed Backdoor Attack on Deep Neural Networks
  using Machine Unlearning","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'ReVeil: Unconstrained Concealed Backdoor Attack on Deep Neural Networks\n  using Machine Unlearning'}","Backdoor attacks embed hidden functionalities in deep neural networks (DNN),
triggering malicious behavior with specific inputs. Advanced defenses monitor
anomalous DNN inferences to detect such attacks. However, concealed backdoors
evade detection by maintaining a low pre-deployment attack success rate (ASR)
and restoring high ASR post-deployment via machine unlearning. Existing
concealed backdoors are often constrained by requiring white-box or black-box
access or auxiliary data, limiting their practicality when such access or data
is unavailable. This paper introduces ReVeil, a concealed backdoor attack
targeting the data collection phase of the DNN training pipeline, requiring no
model access or auxiliary data. ReVeil maintains low pre-deployment ASR across
four datasets and four trigger patterns, successfully evades three popular
backdoor detection methods, and restores high ASR post-deployment through
machine unlearning.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Backdoor attacks embed hidden functionalities in deep neural networks (DNN),\ntriggering malicious behavior with specific inputs. Advanced defenses monitor\nanomalous DNN inferences to detect such attacks. However, concealed backdoors\nevade detection by maintaining a low pre-deployment attack success rate (ASR)\nand restoring high ASR post-deployment via machine unlearning. Existing\nconcealed backdoors are often constrained by requiring white-box or black-box\naccess or auxiliary data, limiting their practicality when such access or data\nis unavailable. This paper introduces ReVeil, a concealed backdoor attack\ntargeting the data collection phase of the DNN training pipeline, requiring no\nmodel access or auxiliary data. ReVeil maintains low pre-deployment ASR across\nfour datasets and four trigger patterns, successfully evades three popular\nbackdoor detection methods, and restores high ASR post-deployment through\nmachine unlearning.'}","['Manaar Alam', 'Hithem Lamri', 'Michail Maniatakos']",{'name': 'Michail Maniatakos'},Michail Maniatakos,"This paper is accepted at 62nd Design Automation Conference (DAC)
  2025","[{'href': 'http://arxiv.org/abs/2502.11687v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11687v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11687v1,None,http://arxiv.org/abs/2502.11687v1,,,2876,0
http://arxiv.org/abs/2502.11705v1,True,2025-02-17T11:44:11Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=11, tm_min=44, tm_sec=11, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T11:44:11Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=11, tm_min=44, tm_sec=11, tm_wday=0, tm_yday=48, tm_isdst=0)",LLM Agents Making Agent Tools,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'LLM Agents Making Agent Tools'}","Tool use has turned large language models (LLMs) into powerful agents that
can perform complex multi-step tasks by dynamically utilising external software
components. However, these tools must be implemented in advance by human
developers, hindering the applicability of LLM agents in domains which demand
large numbers of highly specialised tools, like in life sciences and medicine.
Motivated by the growing trend of scientific studies accompanied by public code
repositories, we propose ToolMaker, a novel agentic framework that autonomously
transforms papers with code into LLM-compatible tools. Given a short task
description and a repository URL, ToolMaker autonomously installs required
dependencies and generates code to perform the task, using a closed-loop
self-correction mechanism to iteratively diagnose and rectify errors. To
evaluate our approach, we introduce a benchmark comprising 15 diverse and
complex computational tasks spanning both medical and non-medical domains with
over 100 unit tests to objectively assess tool correctness and robustness.
ToolMaker correctly implements 80% of the tasks, substantially outperforming
current state-of-the-art software engineering agents. ToolMaker therefore is a
step towards fully autonomous agent-based scientific workflows.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Tool use has turned large language models (LLMs) into powerful agents that\ncan perform complex multi-step tasks by dynamically utilising external software\ncomponents. However, these tools must be implemented in advance by human\ndevelopers, hindering the applicability of LLM agents in domains which demand\nlarge numbers of highly specialised tools, like in life sciences and medicine.\nMotivated by the growing trend of scientific studies accompanied by public code\nrepositories, we propose ToolMaker, a novel agentic framework that autonomously\ntransforms papers with code into LLM-compatible tools. Given a short task\ndescription and a repository URL, ToolMaker autonomously installs required\ndependencies and generates code to perform the task, using a closed-loop\nself-correction mechanism to iteratively diagnose and rectify errors. To\nevaluate our approach, we introduce a benchmark comprising 15 diverse and\ncomplex computational tasks spanning both medical and non-medical domains with\nover 100 unit tests to objectively assess tool correctness and robustness.\nToolMaker correctly implements 80% of the tasks, substantially outperforming\ncurrent state-of-the-art software engineering agents. ToolMaker therefore is a\nstep towards fully autonomous agent-based scientific workflows.'}","['Georg Wlflein', 'Dyke Ferber', 'Daniel Truhn', 'Ognjen Arandjelovi', 'Jakob Nikolas Kather']",{'name': 'Jakob Nikolas Kather'},Jakob Nikolas Kather,,"[{'href': 'http://arxiv.org/abs/2502.11705v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11705v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11705v1,None,http://arxiv.org/abs/2502.11705v1,,,636,0
http://arxiv.org/abs/2502.11756v1,True,2025-02-17T12:52:10Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=12, tm_min=52, tm_sec=10, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T12:52:10Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=12, tm_min=52, tm_sec=10, tm_wday=0, tm_yday=48, tm_isdst=0)",On the Computation of the Fisher Information in Continual Learning,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'On the Computation of the Fisher Information in Continual Learning'}","One of the most popular methods for continual learning with deep neural
networks is Elastic Weight Consolidation (EWC), which involves computing the
Fisher Information. The exact way in which the Fisher Information is computed
is however rarely described, and multiple different implementations for it can
be found online. This blog post discusses and empirically compares several
often-used implementations, which highlights that many currently reported
results for EWC could likely be improved by changing the way the Fisher
Information is computed.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'One of the most popular methods for continual learning with deep neural\nnetworks is Elastic Weight Consolidation (EWC), which involves computing the\nFisher Information. The exact way in which the Fisher Information is computed\nis however rarely described, and multiple different implementations for it can\nbe found online. This blog post discusses and empirically compares several\noften-used implementations, which highlights that many currently reported\nresults for EWC could likely be improved by changing the way the Fisher\nInformation is computed.'}",['Gido M. van de Ven'],{'name': 'Gido M. van de Ven'},Gido M. van de Ven,To appear in the blogpost track at ICLR 2025,"[{'href': 'http://arxiv.org/abs/2502.11756v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11756v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11756v1,None,http://arxiv.org/abs/2502.11756v1,,,2958,0
http://arxiv.org/abs/2502.11812v1,True,2025-02-17T13:59:41Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=13, tm_min=59, tm_sec=41, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T13:59:41Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=13, tm_min=59, tm_sec=41, tm_wday=0, tm_yday=48, tm_isdst=0)","Towards Understanding Fine-Tuning Mechanisms of LLMs via Circuit
  Analysis","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Towards Understanding Fine-Tuning Mechanisms of LLMs via Circuit\n  Analysis'}","Fine-tuning significantly improves the performance of Large Language Models
(LLMs), yet its underlying mechanisms remain poorly understood. This paper aims
to provide an in-depth interpretation of the fine-tuning process through
circuit analysis, a popular tool in Mechanistic Interpretability (MI). Unlike
previous studies
\cite{prakash2024finetuningenhancesexistingmechanisms,chhabra2024neuroplasticity}
that focus on tasks where pre-trained models already perform well, we develop a
set of mathematical tasks where fine-tuning yields substantial performance
gains, which are closer to the practical setting. In our experiments, we
identify circuits at various checkpoints during fine-tuning and examine the
interplay between circuit analysis, fine-tuning methods, and task complexities.
First, we find that while circuits maintain high node similarity before and
after fine-tuning, their edges undergo significant changes, which is in
contrast to the previous work
\cite{prakash2024finetuningenhancesexistingmechanisms,chhabra2024neuroplasticity}
that show circuits only add some additional components after fine-tuning. Based
on these observations, we develop a circuit-aware Low-Rank Adaptation (LoRA)
method, which assigns ranks to layers based on edge changes in the circuits.
Experimental results demonstrate that our circuit-based LoRA algorithm achieves
an average performance improvement of 2.46\% over standard LoRA with similar
parameter sizes. Furthermore, we explore how combining circuits from subtasks
can enhance fine-tuning in compositional tasks, providing new insights into the
design of such tasks and deepening the understanding of circuit dynamics and
fine-tuning mechanisms.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Fine-tuning significantly improves the performance of Large Language Models\n(LLMs), yet its underlying mechanisms remain poorly understood. This paper aims\nto provide an in-depth interpretation of the fine-tuning process through\ncircuit analysis, a popular tool in Mechanistic Interpretability (MI). Unlike\nprevious studies\n\\cite{prakash2024finetuningenhancesexistingmechanisms,chhabra2024neuroplasticity}\nthat focus on tasks where pre-trained models already perform well, we develop a\nset of mathematical tasks where fine-tuning yields substantial performance\ngains, which are closer to the practical setting. In our experiments, we\nidentify circuits at various checkpoints during fine-tuning and examine the\ninterplay between circuit analysis, fine-tuning methods, and task complexities.\nFirst, we find that while circuits maintain high node similarity before and\nafter fine-tuning, their edges undergo significant changes, which is in\ncontrast to the previous work\n\\cite{prakash2024finetuningenhancesexistingmechanisms,chhabra2024neuroplasticity}\nthat show circuits only add some additional components after fine-tuning. Based\non these observations, we develop a circuit-aware Low-Rank Adaptation (LoRA)\nmethod, which assigns ranks to layers based on edge changes in the circuits.\nExperimental results demonstrate that our circuit-based LoRA algorithm achieves\nan average performance improvement of 2.46\\% over standard LoRA with similar\nparameter sizes. Furthermore, we explore how combining circuits from subtasks\ncan enhance fine-tuning in compositional tasks, providing new insights into the\ndesign of such tasks and deepening the understanding of circuit dynamics and\nfine-tuning mechanisms.'}","['Xu Wang', 'Yan Hu', 'Wenyu Du', 'Reynold Cheng', 'Benyou Wang', 'Difan Zou']",{'name': 'Difan Zou'},Difan Zou,25 pages,"[{'href': 'http://arxiv.org/abs/2502.11812v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11812v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11812v1,None,http://arxiv.org/abs/2502.11812v1,,,8,0
http://arxiv.org/abs/2502.11817v1,True,2025-02-17T14:09:51Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=14, tm_min=9, tm_sec=51, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T14:09:51Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=14, tm_min=9, tm_sec=51, tm_wday=0, tm_yday=48, tm_isdst=0)",AAKT: Enhancing Knowledge Tracing with Alternate Autoregressive Modeling,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'AAKT: Enhancing Knowledge Tracing with Alternate Autoregressive Modeling'}","Knowledge Tracing (KT) aims to predict students' future performances based on
their former exercises and additional information in educational settings. KT
has received significant attention since it facilitates personalized
experiences in educational situations. Simultaneously, the autoregressive
modeling on the sequence of former exercises has been proven effective for this
task. One of the primary challenges in autoregressive modeling for Knowledge
Tracing is effectively representing the anterior (pre-response) and posterior
(post-response) states of learners across exercises. Existing methods often
employ complex model architectures to update learner states using question and
response records. In this study, we propose a novel perspective on knowledge
tracing task by treating it as a generative process, consistent with the
principles of autoregressive models. We demonstrate that knowledge states can
be directly represented through autoregressive encodings on a question-response
alternate sequence, where model generate the most probable representation in
hidden state space by analyzing history interactions. This approach underpins
our framework, termed Alternate Autoregressive Knowledge Tracing (AAKT).
Additionally, we incorporate supplementary educational information, such as
question-related skills, into our framework through an auxiliary task, and
include extra exercise details, like response time, as additional inputs. Our
proposed framework is implemented using advanced autoregressive technologies
from Natural Language Generation (NLG) for both training and prediction.
Empirical evaluations on four real-world KT datasets indicate that AAKT
consistently outperforms all baseline models in terms of AUC, ACC, and RMSE.
Furthermore, extensive ablation studies and visualized analysis validate the
effectiveness of key components in AAKT.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Knowledge Tracing (KT) aims to predict students' future performances based on\ntheir former exercises and additional information in educational settings. KT\nhas received significant attention since it facilitates personalized\nexperiences in educational situations. Simultaneously, the autoregressive\nmodeling on the sequence of former exercises has been proven effective for this\ntask. One of the primary challenges in autoregressive modeling for Knowledge\nTracing is effectively representing the anterior (pre-response) and posterior\n(post-response) states of learners across exercises. Existing methods often\nemploy complex model architectures to update learner states using question and\nresponse records. In this study, we propose a novel perspective on knowledge\ntracing task by treating it as a generative process, consistent with the\nprinciples of autoregressive models. We demonstrate that knowledge states can\nbe directly represented through autoregressive encodings on a question-response\nalternate sequence, where model generate the most probable representation in\nhidden state space by analyzing history interactions. This approach underpins\nour framework, termed Alternate Autoregressive Knowledge Tracing (AAKT).\nAdditionally, we incorporate supplementary educational information, such as\nquestion-related skills, into our framework through an auxiliary task, and\ninclude extra exercise details, like response time, as additional inputs. Our\nproposed framework is implemented using advanced autoregressive technologies\nfrom Natural Language Generation (NLG) for both training and prediction.\nEmpirical evaluations on four real-world KT datasets indicate that AAKT\nconsistently outperforms all baseline models in terms of AUC, ACC, and RMSE.\nFurthermore, extensive ablation studies and visualized analysis validate the\neffectiveness of key components in AAKT.""}","['Hao Zhou', 'Wenge Rong', 'Jianfei Zhang', 'Qing Sun', 'Yuanxin Ouyang', 'Zhang Xiong']",{'name': 'Zhang Xiong'},Zhang Xiong,,"[{'title': 'doi', 'href': 'http://dx.doi.org/10.1109/TLT.2024.3521898', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2502.11817v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11817v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11817v1,None,http://arxiv.org/abs/2502.11817v1,"IEEE Transactions on Learning Technologies, vol. 18, pp. 25-38,
  2025",10.1109/TLT.2024.3521898,4505,0
http://arxiv.org/abs/2502.11829v1,True,2025-02-17T14:25:45Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=14, tm_min=25, tm_sec=45, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T14:25:45Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=14, tm_min=25, tm_sec=45, tm_wday=0, tm_yday=48, tm_isdst=0)","Code-Vision: Evaluating Multimodal LLMs Logic Understanding and Code
  Generation Capabilities","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Code-Vision: Evaluating Multimodal LLMs Logic Understanding and Code\n  Generation Capabilities'}","This paper introduces Code-Vision, a benchmark designed to evaluate the
logical understanding and code generation capabilities of Multimodal Large
Language Models (MLLMs). It challenges MLLMs to generate a correct program that
fulfills specific functionality requirements based on a given flowchart, which
visually represents the desired algorithm or process. Code-Vision comprises
three subsets: HumanEval-V, Algorithm, and MATH, which evaluate MLLMs' coding
abilities across basic programming, algorithmic, and mathematical
problem-solving domains. Our experiments evaluate 12 MLLMs on Code-Vision.
Experimental results demonstrate that there is a large performance difference
between proprietary and open-source models. On Hard problems, GPT-4o can
achieve 79.3% pass@1, but the best open-source model only achieves 15%. Further
experiments reveal that Code-Vision can pose unique challenges compared to
other multimodal reasoning benchmarks MMCode and MathVista. We also explore the
reason for the poor performance of the open-source models. All data and codes
are available at https://github.com/wanghanbinpanda/CodeVision.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""This paper introduces Code-Vision, a benchmark designed to evaluate the\nlogical understanding and code generation capabilities of Multimodal Large\nLanguage Models (MLLMs). It challenges MLLMs to generate a correct program that\nfulfills specific functionality requirements based on a given flowchart, which\nvisually represents the desired algorithm or process. Code-Vision comprises\nthree subsets: HumanEval-V, Algorithm, and MATH, which evaluate MLLMs' coding\nabilities across basic programming, algorithmic, and mathematical\nproblem-solving domains. Our experiments evaluate 12 MLLMs on Code-Vision.\nExperimental results demonstrate that there is a large performance difference\nbetween proprietary and open-source models. On Hard problems, GPT-4o can\nachieve 79.3% pass@1, but the best open-source model only achieves 15%. Further\nexperiments reveal that Code-Vision can pose unique challenges compared to\nother multimodal reasoning benchmarks MMCode and MathVista. We also explore the\nreason for the poor performance of the open-source models. All data and codes\nare available at https://github.com/wanghanbinpanda/CodeVision.""}","['Hanbin Wang', 'Xiaoxuan Zhou', 'Zhipeng Xu', 'Keyuan Cheng', 'Yuxin Zuo', 'Kai Tian', 'Jingwei Song', 'Junting Lu', 'Wenhui Hu', 'Xueyang Liu']",{'name': 'Xueyang Liu'},Xueyang Liu,15 pages,"[{'href': 'http://arxiv.org/abs/2502.11829v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11829v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11829v1,None,http://arxiv.org/abs/2502.11829v1,,,65,0
http://arxiv.org/abs/2502.11843v1,True,2025-02-17T14:36:39Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=14, tm_min=36, tm_sec=39, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T14:36:39Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=14, tm_min=36, tm_sec=39, tm_wday=0, tm_yday=48, tm_isdst=0)",Can LLM Agents Maintain a Persona in Discourse?,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Can LLM Agents Maintain a Persona in Discourse?'}","Large Language Models (LLMs) are widely used as conversational agents,
exploiting their capabilities in various sectors such as education, law,
medicine, and more. However, LLMs are often subjected to context-shifting
behaviour, resulting in a lack of consistent and interpretable
personality-aligned interactions. Adherence to psychological traits lacks
comprehensive analysis, especially in the case of dyadic (pairwise)
conversations. We examine this challenge from two viewpoints, initially using
two conversation agents to generate a discourse on a certain topic with an
assigned personality from the OCEAN framework (Openness, Conscientiousness,
Extraversion, Agreeableness, and Neuroticism) as High/Low for each trait. This
is followed by using multiple judge agents to infer the original traits
assigned to explore prediction consistency, inter-model agreement, and
alignment with the assigned personality. Our findings indicate that while LLMs
can be guided toward personality-driven dialogue, their ability to maintain
personality traits varies significantly depending on the combination of models
and discourse settings. These inconsistencies emphasise the challenges in
achieving stable and interpretable personality-aligned interactions in LLMs.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Language Models (LLMs) are widely used as conversational agents,\nexploiting their capabilities in various sectors such as education, law,\nmedicine, and more. However, LLMs are often subjected to context-shifting\nbehaviour, resulting in a lack of consistent and interpretable\npersonality-aligned interactions. Adherence to psychological traits lacks\ncomprehensive analysis, especially in the case of dyadic (pairwise)\nconversations. We examine this challenge from two viewpoints, initially using\ntwo conversation agents to generate a discourse on a certain topic with an\nassigned personality from the OCEAN framework (Openness, Conscientiousness,\nExtraversion, Agreeableness, and Neuroticism) as High/Low for each trait. This\nis followed by using multiple judge agents to infer the original traits\nassigned to explore prediction consistency, inter-model agreement, and\nalignment with the assigned personality. Our findings indicate that while LLMs\ncan be guided toward personality-driven dialogue, their ability to maintain\npersonality traits varies significantly depending on the combination of models\nand discourse settings. These inconsistencies emphasise the challenges in\nachieving stable and interpretable personality-aligned interactions in LLMs.'}","['Pranav Bhandari', 'Nicolas Fay', 'Michael Wise', 'Amitava Datta', 'Stephanie Meek', 'Usman Naseem', 'Mehwish Nasim']",{'name': 'Mehwish Nasim'},Mehwish Nasim,,"[{'href': 'http://arxiv.org/abs/2502.11843v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11843v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11843v1,None,http://arxiv.org/abs/2502.11843v1,,,34,0
http://arxiv.org/abs/2502.11844v2,True,2025-02-20T14:52:31Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=14, tm_min=52, tm_sec=31, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-17T14:37:47Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=14, tm_min=37, tm_sec=47, tm_wday=0, tm_yday=48, tm_isdst=0)",BaxBench: Can LLMs Generate Correct and Secure Backends?,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'BaxBench: Can LLMs Generate Correct and Secure Backends?'}","The automatic generation of programs has long been a fundamental challenge in
computer science. Recent benchmarks have shown that large language models
(LLMs) can effectively generate code at the function level, make code edits,
and solve algorithmic coding tasks. However, to achieve full automation, LLMs
should be able to generate production-quality, self-contained application
modules. To evaluate the capabilities of LLMs in solving this challenge, we
introduce BaxBench, a novel evaluation benchmark consisting of 392 tasks for
the generation of backend applications. We focus on backends for three critical
reasons: (i) they are practically relevant, building the core components of
most modern web and cloud software, (ii) they are difficult to get right,
requiring multiple functions and files to achieve the desired functionality,
and (iii) they are security-critical, as they are exposed to untrusted
third-parties, making secure solutions that prevent deployment-time attacks an
imperative. BaxBench validates the functionality of the generated applications
with comprehensive test cases, and assesses their security exposure by
executing end-to-end exploits. Our experiments reveal key limitations of
current LLMs in both functionality and security: (i) even the best model,
OpenAI o1, achieves a mere 60% on code correctness; (ii) on average, we could
successfully execute security exploits on more than half of the correct
programs generated by each LLM; and (iii) in less popular backend frameworks,
models further struggle to generate correct and secure applications. Progress
on BaxBench signifies important steps towards autonomous and secure software
development with LLMs.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The automatic generation of programs has long been a fundamental challenge in\ncomputer science. Recent benchmarks have shown that large language models\n(LLMs) can effectively generate code at the function level, make code edits,\nand solve algorithmic coding tasks. However, to achieve full automation, LLMs\nshould be able to generate production-quality, self-contained application\nmodules. To evaluate the capabilities of LLMs in solving this challenge, we\nintroduce BaxBench, a novel evaluation benchmark consisting of 392 tasks for\nthe generation of backend applications. We focus on backends for three critical\nreasons: (i) they are practically relevant, building the core components of\nmost modern web and cloud software, (ii) they are difficult to get right,\nrequiring multiple functions and files to achieve the desired functionality,\nand (iii) they are security-critical, as they are exposed to untrusted\nthird-parties, making secure solutions that prevent deployment-time attacks an\nimperative. BaxBench validates the functionality of the generated applications\nwith comprehensive test cases, and assesses their security exposure by\nexecuting end-to-end exploits. Our experiments reveal key limitations of\ncurrent LLMs in both functionality and security: (i) even the best model,\nOpenAI o1, achieves a mere 60% on code correctness; (ii) on average, we could\nsuccessfully execute security exploits on more than half of the correct\nprograms generated by each LLM; and (iii) in less popular backend frameworks,\nmodels further struggle to generate correct and secure applications. Progress\non BaxBench signifies important steps towards autonomous and secure software\ndevelopment with LLMs.'}","['Mark Vero', 'Niels Mndler', 'Victor Chibotaru', 'Veselin Raychev', 'Maximilian Baader', 'Nikola Jovanovi', 'Jingxuan He', 'Martin Vechev']",{'name': 'Martin Vechev'},Martin Vechev,,"[{'href': 'http://arxiv.org/abs/2502.11844v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11844v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.PL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11844v2,None,http://arxiv.org/abs/2502.11844v2,,,16876,0
http://arxiv.org/abs/2502.11850v1,True,2025-02-17T14:44:12Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=14, tm_min=44, tm_sec=12, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T14:44:12Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=14, tm_min=44, tm_sec=12, tm_wday=0, tm_yday=48, tm_isdst=0)","Steering the LoCoMotif: Using Domain Knowledge in Time Series Motif
  Discovery","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Steering the LoCoMotif: Using Domain Knowledge in Time Series Motif\n  Discovery'}","Time Series Motif Discovery (TSMD) identifies repeating patterns in time
series data, but its unsupervised nature might result in motifs that are not
interesting to the user. To address this, we propose a framework that allows
the user to impose constraints on the motifs to be discovered, where
constraints can easily be defined according to the properties of the desired
motifs in the application domain. We also propose an efficient implementation
of the framework, the LoCoMotif-DoK algorithm. We demonstrate that
LoCoMotif-DoK can effectively leverage domain knowledge in real and synthetic
data, outperforming other TSMD techniques which only support a limited form of
domain knowledge.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Time Series Motif Discovery (TSMD) identifies repeating patterns in time\nseries data, but its unsupervised nature might result in motifs that are not\ninteresting to the user. To address this, we propose a framework that allows\nthe user to impose constraints on the motifs to be discovered, where\nconstraints can easily be defined according to the properties of the desired\nmotifs in the application domain. We also propose an efficient implementation\nof the framework, the LoCoMotif-DoK algorithm. We demonstrate that\nLoCoMotif-DoK can effectively leverage domain knowledge in real and synthetic\ndata, outperforming other TSMD techniques which only support a limited form of\ndomain knowledge.'}","['Aras Yurtman', 'Daan Van Wesenbeeck', 'Wannes Meert', 'Hendrik Blockeel']",{'name': 'Hendrik Blockeel'},Hendrik Blockeel,,"[{'href': 'http://arxiv.org/abs/2502.11850v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11850v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11850v1,None,http://arxiv.org/abs/2502.11850v1,,,3137,0
http://arxiv.org/abs/2502.11880v1,True,2025-02-17T15:06:28Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=15, tm_min=6, tm_sec=28, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T15:06:28Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=15, tm_min=6, tm_sec=28, tm_wday=0, tm_yday=48, tm_isdst=0)",Bitnet.cpp: Efficient Edge Inference for Ternary LLMs,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Bitnet.cpp: Efficient Edge Inference for Ternary LLMs'}","The advent of 1-bit large language models (LLMs), led by BitNet b1.58, has
spurred interest in ternary LLMs. Despite this, research and practical
applications focusing on efficient edge inference for ternary LLMs remain
scarce. To bridge this gap, we introduce Bitnet.cpp, an inference system
optimized for BitNet b1.58 and ternary LLMs. Given that mixed-precision matrix
multiplication (mpGEMM) constitutes the bulk of inference time in ternary LLMs,
Bitnet.cpp incorporates a novel mpGEMM library to facilitate
sub-2-bits-per-weight, efficient and lossless inference. The library features
two core solutions: Ternary Lookup Table (TL), which addresses spatial
inefficiencies of previous bit-wise methods, and Int2 with a Scale (I2_S),
which ensures lossless edge inference, both enabling high-speed inference. Our
experiments show that Bitnet.cpp achieves up to a 6.25x increase in speed over
full-precision baselines and up to 2.32x over low-bit baselines, setting new
benchmarks in the field. Additionally, we expand TL to element-wise lookup
table (ELUT) for low-bit LLMs in the appendix, presenting both theoretical and
empirical evidence of its considerable potential. Bitnet.cpp is publicly
available at https://github.com/microsoft/BitNet/tree/paper , offering a
sophisticated solution for the efficient and practical deployment of edge LLMs.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The advent of 1-bit large language models (LLMs), led by BitNet b1.58, has\nspurred interest in ternary LLMs. Despite this, research and practical\napplications focusing on efficient edge inference for ternary LLMs remain\nscarce. To bridge this gap, we introduce Bitnet.cpp, an inference system\noptimized for BitNet b1.58 and ternary LLMs. Given that mixed-precision matrix\nmultiplication (mpGEMM) constitutes the bulk of inference time in ternary LLMs,\nBitnet.cpp incorporates a novel mpGEMM library to facilitate\nsub-2-bits-per-weight, efficient and lossless inference. The library features\ntwo core solutions: Ternary Lookup Table (TL), which addresses spatial\ninefficiencies of previous bit-wise methods, and Int2 with a Scale (I2_S),\nwhich ensures lossless edge inference, both enabling high-speed inference. Our\nexperiments show that Bitnet.cpp achieves up to a 6.25x increase in speed over\nfull-precision baselines and up to 2.32x over low-bit baselines, setting new\nbenchmarks in the field. Additionally, we expand TL to element-wise lookup\ntable (ELUT) for low-bit LLMs in the appendix, presenting both theoretical and\nempirical evidence of its considerable potential. Bitnet.cpp is publicly\navailable at https://github.com/microsoft/BitNet/tree/paper , offering a\nsophisticated solution for the efficient and practical deployment of edge LLMs.'}","['Jinheng Wang', 'Hansong Zhou', 'Ting Song', 'Shijie Cao', 'Yan Xia', 'Ting Cao', 'Jianyu Wei', 'Shuming Ma', 'Hongyu Wang', 'Furu Wei']",{'name': 'Furu Wei'},Furu Wei,"18 pages, 11 figures","[{'href': 'http://arxiv.org/abs/2502.11880v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11880v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.DC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11880v1,None,http://arxiv.org/abs/2502.11880v1,,,4583,0
http://arxiv.org/abs/2502.11886v1,True,2025-02-17T15:13:29Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=15, tm_min=13, tm_sec=29, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T15:13:29Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=15, tm_min=13, tm_sec=29, tm_wday=0, tm_yday=48, tm_isdst=0)",LIMR: Less is More for RL Scaling,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'LIMR: Less is More for RL Scaling'}","In this paper, we ask: what truly determines the effectiveness of RL training
data for enhancing language models' reasoning capabilities? While recent
advances like o1, Deepseek R1, and Kimi1.5 demonstrate RL's potential, the lack
of transparency about training data requirements has hindered systematic
progress. Starting directly from base models without distillation, we challenge
the assumption that scaling up RL training data inherently improves
performance. we demonstrate that a strategically selected subset of just 1,389
samples can outperform the full 8,523-sample dataset. We introduce Learning
Impact Measurement (LIM), an automated method to evaluate and prioritize
training samples based on their alignment with model learning trajectories,
enabling efficient resource utilization and scalable implementation. Our method
achieves comparable or even superior performance using only 1,389 samples
versus the full 8,523 samples dataset. Notably, while recent data-efficient
approaches (e.g., LIMO and s1) show promise with 32B-scale models, we find it
significantly underperforms at 7B-scale through supervised fine-tuning (SFT).
In contrast, our RL-based LIMR achieves 16.7% higher accuracy on AIME24 and
outperforms LIMO and s1 by 13.0% and 22.2% on MATH500. These results
fundamentally reshape our understanding of RL scaling in LLMs, demonstrating
that precise sample selection, rather than data scale, may be the key to
unlocking enhanced reasoning capabilities. For reproducible research and future
innovation, we are open-sourcing LIMR, including implementation of LIM,
training and evaluation code, curated datasets, and trained models at
https://github.com/GAIR-NLP/LIMR.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""In this paper, we ask: what truly determines the effectiveness of RL training\ndata for enhancing language models' reasoning capabilities? While recent\nadvances like o1, Deepseek R1, and Kimi1.5 demonstrate RL's potential, the lack\nof transparency about training data requirements has hindered systematic\nprogress. Starting directly from base models without distillation, we challenge\nthe assumption that scaling up RL training data inherently improves\nperformance. we demonstrate that a strategically selected subset of just 1,389\nsamples can outperform the full 8,523-sample dataset. We introduce Learning\nImpact Measurement (LIM), an automated method to evaluate and prioritize\ntraining samples based on their alignment with model learning trajectories,\nenabling efficient resource utilization and scalable implementation. Our method\nachieves comparable or even superior performance using only 1,389 samples\nversus the full 8,523 samples dataset. Notably, while recent data-efficient\napproaches (e.g., LIMO and s1) show promise with 32B-scale models, we find it\nsignificantly underperforms at 7B-scale through supervised fine-tuning (SFT).\nIn contrast, our RL-based LIMR achieves 16.7% higher accuracy on AIME24 and\noutperforms LIMO and s1 by 13.0% and 22.2% on MATH500. These results\nfundamentally reshape our understanding of RL scaling in LLMs, demonstrating\nthat precise sample selection, rather than data scale, may be the key to\nunlocking enhanced reasoning capabilities. For reproducible research and future\ninnovation, we are open-sourcing LIMR, including implementation of LIM,\ntraining and evaluation code, curated datasets, and trained models at\nhttps://github.com/GAIR-NLP/LIMR.""}","['Xuefeng Li', 'Haoyang Zou', 'Pengfei Liu']",{'name': 'Pengfei Liu'},Pengfei Liu,6pages,"[{'href': 'http://arxiv.org/abs/2502.11886v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11886v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11886v1,None,http://arxiv.org/abs/2502.11886v1,,,98,0
http://arxiv.org/abs/2502.11887v1,True,2025-02-17T15:13:41Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=15, tm_min=13, tm_sec=41, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T15:13:41Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=15, tm_min=13, tm_sec=41, tm_wday=0, tm_yday=48, tm_isdst=0)",Stonefish: Supporting Machine Learning Research in Marine Robotics,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Stonefish: Supporting Machine Learning Research in Marine Robotics'}","Simulations are highly valuable in marine robotics, offering a cost-effective
and controlled environment for testing in the challenging conditions of
underwater and surface operations. Given the high costs and logistical
difficulties of real-world trials, simulators capable of capturing the
operational conditions of subsea environments have become key in developing and
refining algorithms for remotely-operated and autonomous underwater vehicles.
This paper highlights recent enhancements to the Stonefish simulator, an
advanced open-source platform supporting development and testing of marine
robotics solutions. Key updates include a suite of additional sensors, such as
an event-based camera, a thermal camera, and an optical flow camera, as well
as, visual light communication, support for tethered operations, improved
thruster modelling, more flexible hydrodynamics, and enhanced sonar accuracy.
These developments and an automated annotation tool significantly bolster
Stonefish's role in marine robotics research, especially in the field of
machine learning, where training data with a known ground truth is hard or
impossible to collect.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Simulations are highly valuable in marine robotics, offering a cost-effective\nand controlled environment for testing in the challenging conditions of\nunderwater and surface operations. Given the high costs and logistical\ndifficulties of real-world trials, simulators capable of capturing the\noperational conditions of subsea environments have become key in developing and\nrefining algorithms for remotely-operated and autonomous underwater vehicles.\nThis paper highlights recent enhancements to the Stonefish simulator, an\nadvanced open-source platform supporting development and testing of marine\nrobotics solutions. Key updates include a suite of additional sensors, such as\nan event-based camera, a thermal camera, and an optical flow camera, as well\nas, visual light communication, support for tethered operations, improved\nthruster modelling, more flexible hydrodynamics, and enhanced sonar accuracy.\nThese developments and an automated annotation tool significantly bolster\nStonefish's role in marine robotics research, especially in the field of\nmachine learning, where training data with a known ground truth is hard or\nimpossible to collect.""}","['Michele Grimaldi', 'Patryk Cieslak', 'Eduardo Ochoa', 'Vibhav Bharti', 'Hayat Rajani', 'Ignacio Carlucho', 'Maria Koskinopoulou', 'Yvan R. Petillot', 'Nuno Gracias']",{'name': 'Nuno Gracias'},Nuno Gracias,Accepted as full paper at ICRA 2025,"[{'href': 'http://arxiv.org/abs/2502.11887v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11887v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'eess.SY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11887v1,None,http://arxiv.org/abs/2502.11887v1,,,352,0
http://arxiv.org/abs/2502.11925v1,True,2025-02-17T15:35:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=15, tm_min=35, tm_sec=36, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T15:35:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=15, tm_min=35, tm_sec=36, tm_wday=0, tm_yday=48, tm_isdst=0)","GRAPHGPT-O: Synergistic Multimodal Comprehension and Generation on
  Graphs","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'GRAPHGPT-O: Synergistic Multimodal Comprehension and Generation on\n  Graphs'}","The rapid development of Multimodal Large Language Models (MLLMs) has enabled
the integration of multiple modalities, including texts and images, within the
large language model (LLM) framework. However, texts and images are usually
interconnected, forming a multimodal attributed graph (MMAG). It is
underexplored how MLLMs can incorporate the relational information
(\textit{i.e.}, graph structure) and semantic information (\textit{i.e.,} texts
and images) on such graphs for multimodal comprehension and generation. In this
paper, we propose GraphGPT-o, which supports omni-multimodal understanding and
creation on MMAGs. We first comprehensively study linearization variants to
transform semantic and structural information as input for MLLMs. Then, we
propose a hierarchical aligner that enables deep graph encoding, bridging the
gap between MMAGs and MLLMs. Finally, we explore the inference choices,
adapting MLLM to interleaved text and image generation in graph scenarios.
Extensive experiments on three datasets from different domains demonstrate the
effectiveness of our proposed method. Datasets and codes will be open-sourced
upon acceptance.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The rapid development of Multimodal Large Language Models (MLLMs) has enabled\nthe integration of multiple modalities, including texts and images, within the\nlarge language model (LLM) framework. However, texts and images are usually\ninterconnected, forming a multimodal attributed graph (MMAG). It is\nunderexplored how MLLMs can incorporate the relational information\n(\\textit{i.e.}, graph structure) and semantic information (\\textit{i.e.,} texts\nand images) on such graphs for multimodal comprehension and generation. In this\npaper, we propose GraphGPT-o, which supports omni-multimodal understanding and\ncreation on MMAGs. We first comprehensively study linearization variants to\ntransform semantic and structural information as input for MLLMs. Then, we\npropose a hierarchical aligner that enables deep graph encoding, bridging the\ngap between MMAGs and MLLMs. Finally, we explore the inference choices,\nadapting MLLM to interleaved text and image generation in graph scenarios.\nExtensive experiments on three datasets from different domains demonstrate the\neffectiveness of our proposed method. Datasets and codes will be open-sourced\nupon acceptance.'}","['Yi Fang', 'Bowen Jin', 'Jiacheng Shen', 'Sirui Ding', 'Qiaoyu Tan', 'Jiawei Han']",{'name': 'Jiawei Han'},Jiawei Han,,"[{'href': 'http://arxiv.org/abs/2502.11925v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11925v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11925v1,None,http://arxiv.org/abs/2502.11925v1,,,708,0
http://arxiv.org/abs/2502.11969v1,True,2025-02-17T16:18:07Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=16, tm_min=18, tm_sec=7, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T16:18:07Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=16, tm_min=18, tm_sec=7, tm_wday=0, tm_yday=48, tm_isdst=0)",Learning Generalizable Prompt for CLIP with Class Similarity Knowledge,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Learning Generalizable Prompt for CLIP with Class Similarity Knowledge'}","In vision-language models (VLMs), prompt tuning has shown its effectiveness
in adapting models to downstream tasks. However, learned prompts struggle to
generalize to unseen classes, as they tend to overfit to the classes that are
targeted during prompt tuning. Examining failure cases, we observed that
learned prompts disrupt the semantics of unseen classes, generating text
embeddings with incorrect semantic relationships among classes. To address
this, we propose Similarity Alignment Regularization (SAR), which regularizes
learnable prompts to preserve the semantic relationships among classes captured
by hand-crafted prompts. Specifically, we first obtain novel classes related to
base classes using ChatGPT-4o and utilize them as potential unseen classes
during prompt tuning. Then, by targeting both base and novel classes, SAR
aligns the similarity relationships among text embeddings generated by
learnable prompts with the similarity relationships from hand-crafted prompts.
Extensive experiments applying SAR to existing prompt tuning methods
demonstrate its effectiveness in improving generalization to unseen classes.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'In vision-language models (VLMs), prompt tuning has shown its effectiveness\nin adapting models to downstream tasks. However, learned prompts struggle to\ngeneralize to unseen classes, as they tend to overfit to the classes that are\ntargeted during prompt tuning. Examining failure cases, we observed that\nlearned prompts disrupt the semantics of unseen classes, generating text\nembeddings with incorrect semantic relationships among classes. To address\nthis, we propose Similarity Alignment Regularization (SAR), which regularizes\nlearnable prompts to preserve the semantic relationships among classes captured\nby hand-crafted prompts. Specifically, we first obtain novel classes related to\nbase classes using ChatGPT-4o and utilize them as potential unseen classes\nduring prompt tuning. Then, by targeting both base and novel classes, SAR\naligns the similarity relationships among text embeddings generated by\nlearnable prompts with the similarity relationships from hand-crafted prompts.\nExtensive experiments applying SAR to existing prompt tuning methods\ndemonstrate its effectiveness in improving generalization to unseen classes.'}","['Sehun Jung', 'Hyang-won Lee']",{'name': 'Hyang-won Lee'},Hyang-won Lee,,"[{'href': 'http://arxiv.org/abs/2502.11969v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11969v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11969v1,None,http://arxiv.org/abs/2502.11969v1,,,16,0
http://arxiv.org/abs/2502.11981v1,True,2025-02-17T16:22:46Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=16, tm_min=22, tm_sec=46, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T16:22:46Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=16, tm_min=22, tm_sec=46, tm_wday=0, tm_yday=48, tm_isdst=0)","Machine Learning Should Maximize Welfare, Not (Only) Accuracy","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Machine Learning Should Maximize Welfare, Not (Only) Accuracy'}","Decades of research in machine learning have given us powerful tools for
making accurate predictions. But when used in social settings and on human
inputs, better accuracy does not immediately translate to better social
outcomes. This may not be surprising given that conventional learning
frameworks are not designed to express societal preferences -- let alone
promote them. This position paper argues that machine learning is currently
missing, and can gain much from incorporating, a proper notion of social
welfare. The field of welfare economics asks: how should we allocate limited
resources to self-interested agents in a way that maximizes social benefit? We
argue that this perspective applies to many modern applications of machine
learning in social contexts, and advocate for its adoption. Rather than
disposing of prediction, we aim to leverage this forte of machine learning for
promoting social welfare. We demonstrate this idea by proposing a conceptual
framework that gradually transitions from accuracy maximization (with awareness
to welfare) to welfare maximization (via accurate prediction). We detail
applications and use-cases for which our framework can be effective, identify
technical challenges and practical opportunities, and highlight future avenues
worth pursuing.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Decades of research in machine learning have given us powerful tools for\nmaking accurate predictions. But when used in social settings and on human\ninputs, better accuracy does not immediately translate to better social\noutcomes. This may not be surprising given that conventional learning\nframeworks are not designed to express societal preferences -- let alone\npromote them. This position paper argues that machine learning is currently\nmissing, and can gain much from incorporating, a proper notion of social\nwelfare. The field of welfare economics asks: how should we allocate limited\nresources to self-interested agents in a way that maximizes social benefit? We\nargue that this perspective applies to many modern applications of machine\nlearning in social contexts, and advocate for its adoption. Rather than\ndisposing of prediction, we aim to leverage this forte of machine learning for\npromoting social welfare. We demonstrate this idea by proposing a conceptual\nframework that gradually transitions from accuracy maximization (with awareness\nto welfare) to welfare maximization (via accurate prediction). We detail\napplications and use-cases for which our framework can be effective, identify\ntechnical challenges and practical opportunities, and highlight future avenues\nworth pursuing.'}","['Nir Rosenfeld', 'Haifeng Xu']",{'name': 'Haifeng Xu'},Haifeng Xu,,"[{'href': 'http://arxiv.org/abs/2502.11981v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11981v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11981v1,None,http://arxiv.org/abs/2502.11981v1,,,2,0
http://arxiv.org/abs/2502.11989v1,True,2025-02-17T16:28:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=16, tm_min=28, tm_sec=15, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T16:28:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=16, tm_min=28, tm_sec=15, tm_wday=0, tm_yday=48, tm_isdst=0)","Characterizing Photorealism and Artifacts in Diffusion Model-Generated
  Images","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Characterizing Photorealism and Artifacts in Diffusion Model-Generated\n  Images'}","Diffusion model-generated images can appear indistinguishable from authentic
photographs, but these images often contain artifacts and implausibilities that
reveal their AI-generated provenance. Given the challenge to public trust in
media posed by photorealistic AI-generated images, we conducted a large-scale
experiment measuring human detection accuracy on 450 diffusion-model generated
images and 149 real images. Based on collecting 749,828 observations and 34,675
comments from 50,444 participants, we find that scene complexity of an image,
artifact types within an image, display time of an image, and human curation of
AI-generated images all play significant roles in how accurately people
distinguish real from AI-generated images. Additionally, we propose a taxonomy
characterizing artifacts often appearing in images generated by diffusion
models. Our empirical observations and taxonomy offer nuanced insights into the
capabilities and limitations of diffusion models to generate photorealistic
images in 2024.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Diffusion model-generated images can appear indistinguishable from authentic\nphotographs, but these images often contain artifacts and implausibilities that\nreveal their AI-generated provenance. Given the challenge to public trust in\nmedia posed by photorealistic AI-generated images, we conducted a large-scale\nexperiment measuring human detection accuracy on 450 diffusion-model generated\nimages and 149 real images. Based on collecting 749,828 observations and 34,675\ncomments from 50,444 participants, we find that scene complexity of an image,\nartifact types within an image, display time of an image, and human curation of\nAI-generated images all play significant roles in how accurately people\ndistinguish real from AI-generated images. Additionally, we propose a taxonomy\ncharacterizing artifacts often appearing in images generated by diffusion\nmodels. Our empirical observations and taxonomy offer nuanced insights into the\ncapabilities and limitations of diffusion models to generate photorealistic\nimages in 2024.'}","['Negar Kamali', 'Karyn Nakamura', 'Aakriti Kumar', 'Angelos Chatzimparmpas', 'Jessica Hullman', 'Matthew Groh']",{'name': 'Matthew Groh'},Matthew Groh,"26 pages, 24 Figures, Accepted by ACM CHI 2025","[{'href': 'http://arxiv.org/abs/2502.11989v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11989v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11989v1,None,http://arxiv.org/abs/2502.11989v1,,,556,0
http://arxiv.org/abs/2502.12018v1,True,2025-02-17T16:52:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=16, tm_min=52, tm_sec=42, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T16:52:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=16, tm_min=52, tm_sec=42, tm_wday=0, tm_yday=48, tm_isdst=0)",Atom of Thoughts for Markov LLM Test-Time Scaling,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Atom of Thoughts for Markov LLM Test-Time Scaling'}","Large Language Models (LLMs) achieve superior performance through
training-time scaling, and test-time scaling further enhances their
capabilities by conducting effective reasoning during inference. However, as
the scale of reasoning increases, existing test-time scaling methods suffer
from accumulated historical information, which not only wastes computational
resources but also interferes with effective reasoning. To address this issue,
we observe that complex reasoning progress is often achieved by solving a
sequence of independent subquestions, each being self-contained and verifiable.
These subquestions are essentially atomic questions, relying primarily on their
current state rather than accumulated history, similar to the memoryless
transitions in a Markov process. Based on this observation, we propose Atom of
Thoughts (AoT), where each state transition in the reasoning process consists
of decomposing the current question into a dependency-based directed acyclic
graph and contracting its subquestions, forming a new atomic question state.
This iterative decomposition-contraction process continues until reaching
directly solvable atomic questions, naturally realizing Markov transitions
between question states. Furthermore, these atomic questions can be seamlessly
integrated into existing test-time scaling methods, enabling AoT to serve as a
plug-in enhancement for improving reasoning capabilities. Experiments across
six benchmarks demonstrate the effectiveness of AoT both as a standalone
framework and a plug-in enhancement. Notably, on HotpotQA, when applied to
gpt-4o-mini, AoT achieves an 80.6% F1 score, surpassing o3-mini by 3.4% and
DeepSeek-R1 by 10.6%. The code will be available at
https://github.com/qixucen/atom.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Language Models (LLMs) achieve superior performance through\ntraining-time scaling, and test-time scaling further enhances their\ncapabilities by conducting effective reasoning during inference. However, as\nthe scale of reasoning increases, existing test-time scaling methods suffer\nfrom accumulated historical information, which not only wastes computational\nresources but also interferes with effective reasoning. To address this issue,\nwe observe that complex reasoning progress is often achieved by solving a\nsequence of independent subquestions, each being self-contained and verifiable.\nThese subquestions are essentially atomic questions, relying primarily on their\ncurrent state rather than accumulated history, similar to the memoryless\ntransitions in a Markov process. Based on this observation, we propose Atom of\nThoughts (AoT), where each state transition in the reasoning process consists\nof decomposing the current question into a dependency-based directed acyclic\ngraph and contracting its subquestions, forming a new atomic question state.\nThis iterative decomposition-contraction process continues until reaching\ndirectly solvable atomic questions, naturally realizing Markov transitions\nbetween question states. Furthermore, these atomic questions can be seamlessly\nintegrated into existing test-time scaling methods, enabling AoT to serve as a\nplug-in enhancement for improving reasoning capabilities. Experiments across\nsix benchmarks demonstrate the effectiveness of AoT both as a standalone\nframework and a plug-in enhancement. Notably, on HotpotQA, when applied to\ngpt-4o-mini, AoT achieves an 80.6% F1 score, surpassing o3-mini by 3.4% and\nDeepSeek-R1 by 10.6%. The code will be available at\nhttps://github.com/qixucen/atom.'}","['Fengwei Teng', 'Zhaoyang Yu', 'Quan Shi', 'Jiayi Zhang', 'Chenglin Wu', 'Yuyu Luo']",{'name': 'Yuyu Luo'},Yuyu Luo,,"[{'href': 'http://arxiv.org/abs/2502.12018v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12018v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12018v1,None,http://arxiv.org/abs/2502.12018v1,,,56,0
http://arxiv.org/abs/2502.12048v2,True,2025-02-18T22:49:49Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=22, tm_min=49, tm_sec=49, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-17T17:16:41Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=17, tm_min=16, tm_sec=41, tm_wday=0, tm_yday=48, tm_isdst=0)","A Survey on Bridging EEG Signals and Generative AI: From Image and Text
  to Beyond","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A Survey on Bridging EEG Signals and Generative AI: From Image and Text\n  to Beyond'}","Integration of Brain-Computer Interfaces (BCIs) and Generative Artificial
Intelligence (GenAI) has opened new frontiers in brain signal decoding,
enabling assistive communication, neural representation learning, and
multimodal integration. BCIs, particularly those leveraging
Electroencephalography (EEG), provide a non-invasive means of translating
neural activity into meaningful outputs. Recent advances in deep learning,
including Generative Adversarial Networks (GANs) and Transformer-based Large
Language Models (LLMs), have significantly improved EEG-based generation of
images, text, and speech. This paper provides a literature review of the
state-of-the-art in EEG-based multimodal generation, focusing on (i)
EEG-to-image generation through GANs, Variational Autoencoders (VAEs), and
Diffusion Models, and (ii) EEG-to-text generation leveraging Transformer based
language models and contrastive learning methods. Additionally, we discuss the
emerging domain of EEG-to-speech synthesis, an evolving multimodal frontier. We
highlight key datasets, use cases, challenges, and EEG feature encoding methods
that underpin generative approaches. By providing a structured overview of
EEG-based generative AI, this survey aims to equip researchers and
practitioners with insights to advance neural decoding, enhance assistive
technologies, and expand the frontiers of brain-computer interaction.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Integration of Brain-Computer Interfaces (BCIs) and Generative Artificial\nIntelligence (GenAI) has opened new frontiers in brain signal decoding,\nenabling assistive communication, neural representation learning, and\nmultimodal integration. BCIs, particularly those leveraging\nElectroencephalography (EEG), provide a non-invasive means of translating\nneural activity into meaningful outputs. Recent advances in deep learning,\nincluding Generative Adversarial Networks (GANs) and Transformer-based Large\nLanguage Models (LLMs), have significantly improved EEG-based generation of\nimages, text, and speech. This paper provides a literature review of the\nstate-of-the-art in EEG-based multimodal generation, focusing on (i)\nEEG-to-image generation through GANs, Variational Autoencoders (VAEs), and\nDiffusion Models, and (ii) EEG-to-text generation leveraging Transformer based\nlanguage models and contrastive learning methods. Additionally, we discuss the\nemerging domain of EEG-to-speech synthesis, an evolving multimodal frontier. We\nhighlight key datasets, use cases, challenges, and EEG feature encoding methods\nthat underpin generative approaches. By providing a structured overview of\nEEG-based generative AI, this survey aims to equip researchers and\npractitioners with insights to advance neural decoding, enhance assistive\ntechnologies, and expand the frontiers of brain-computer interaction.'}","['Shreya Shukla', 'Jose Torres', 'Abhijit Mishra', 'Jacek Gwizdka', 'Shounak Roychowdhury']",{'name': 'Shounak Roychowdhury'},Shounak Roychowdhury,,"[{'href': 'http://arxiv.org/abs/2502.12048v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12048v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12048v2,None,http://arxiv.org/abs/2502.12048v2,,,3,0
http://arxiv.org/abs/2502.12066v1,True,2025-02-17T17:35:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=17, tm_min=35, tm_sec=42, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T17:35:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=17, tm_min=35, tm_sec=42, tm_wday=0, tm_yday=48, tm_isdst=0)","CONSTRUCTA: Automating Commercial Construction Schedules in Fabrication
  Facilities with Large Language Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'CONSTRUCTA: Automating Commercial Construction Schedules in Fabrication\n  Facilities with Large Language Models'}","Automating planning with LLMs presents transformative opportunities for
traditional industries, yet remains underexplored. In commercial construction,
the complexity of automated scheduling often requires manual intervention to
ensure precision. We propose CONSTRUCTA, a novel framework leveraging LLMs to
optimize construction schedules in complex projects like semiconductor
fabrication. CONSTRUCTA addresses key challenges by: (1) integrating
construction-specific knowledge through static RAG; (2) employing
context-sampling techniques inspired by architectural expertise to provide
relevant input; and (3) deploying Construction DPO to align schedules with
expert preferences using RLHF. Experiments on proprietary data demonstrate
performance improvements of +42.3% in missing value prediction, +79.1% in
dependency analysis, and +28.9% in automated planning compared to baseline
methods, showcasing its potential to revolutionize construction workflows and
inspire domain-specific LLM advancements.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Automating planning with LLMs presents transformative opportunities for\ntraditional industries, yet remains underexplored. In commercial construction,\nthe complexity of automated scheduling often requires manual intervention to\nensure precision. We propose CONSTRUCTA, a novel framework leveraging LLMs to\noptimize construction schedules in complex projects like semiconductor\nfabrication. CONSTRUCTA addresses key challenges by: (1) integrating\nconstruction-specific knowledge through static RAG; (2) employing\ncontext-sampling techniques inspired by architectural expertise to provide\nrelevant input; and (3) deploying Construction DPO to align schedules with\nexpert preferences using RLHF. Experiments on proprietary data demonstrate\nperformance improvements of +42.3% in missing value prediction, +79.1% in\ndependency analysis, and +28.9% in automated planning compared to baseline\nmethods, showcasing its potential to revolutionize construction workflows and\ninspire domain-specific LLM advancements.'}","['Yifan Zhang', 'Xue Yang']",{'name': 'Xue Yang'},Xue Yang,,"[{'href': 'http://arxiv.org/abs/2502.12066v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12066v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12066v1,None,http://arxiv.org/abs/2502.12066v1,,,0,0
http://arxiv.org/abs/2502.12108v1,True,2025-02-17T18:29:24Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=29, tm_sec=24, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T18:29:24Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=29, tm_sec=24, tm_wday=0, tm_yday=48, tm_isdst=0)",Using the Path of Least Resistance to Explain Deep Networks,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Using the Path of Least Resistance to Explain Deep Networks'}","Integrated Gradients (IG), a widely used axiomatic path-based attribution
method, assigns importance scores to input features by integrating model
gradients along a straight path from a baseline to the input. While effective
in some cases, we show that straight paths can lead to flawed attributions. In
this paper, we identify the cause of these misattributions and propose an
alternative approach that treats the input space as a Riemannian manifold,
computing attributions by integrating gradients along geodesics. We call this
method Geodesic Integrated Gradients (GIG). To approximate geodesic paths, we
introduce two techniques: a k-Nearest Neighbours-based approach for smaller
models and a Stochastic Variational Inference-based method for larger ones.
Additionally, we propose a new axiom, Strong Completeness, extending the axioms
satisfied by IG. We show that this property is desirable for attribution
methods and that GIG is the only method that satisfies it. Through experiments
on both synthetic and real-world data, we demonstrate that GIG outperforms
existing explainability methods, including IG.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Integrated Gradients (IG), a widely used axiomatic path-based attribution\nmethod, assigns importance scores to input features by integrating model\ngradients along a straight path from a baseline to the input. While effective\nin some cases, we show that straight paths can lead to flawed attributions. In\nthis paper, we identify the cause of these misattributions and propose an\nalternative approach that treats the input space as a Riemannian manifold,\ncomputing attributions by integrating gradients along geodesics. We call this\nmethod Geodesic Integrated Gradients (GIG). To approximate geodesic paths, we\nintroduce two techniques: a k-Nearest Neighbours-based approach for smaller\nmodels and a Stochastic Variational Inference-based method for larger ones.\nAdditionally, we propose a new axiom, Strong Completeness, extending the axioms\nsatisfied by IG. We show that this property is desirable for attribution\nmethods and that GIG is the only method that satisfies it. Through experiments\non both synthetic and real-world data, we demonstrate that GIG outperforms\nexisting explainability methods, including IG.'}","['Sina Salek', 'Joseph Enguehard']",{'name': 'Joseph Enguehard'},Joseph Enguehard,,"[{'href': 'http://arxiv.org/abs/2502.12108v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12108v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12108v1,None,http://arxiv.org/abs/2502.12108v1,,,164,0
http://arxiv.org/abs/2502.12119v1,True,2025-02-17T18:43:41Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=43, tm_sec=41, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T18:43:41Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=43, tm_sec=41, tm_wday=0, tm_yday=48, tm_isdst=0)","PRISM: Self-Pruning Intrinsic Selection Method for Training-Free
  Multimodal Data Selection","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'PRISM: Self-Pruning Intrinsic Selection Method for Training-Free\n  Multimodal Data Selection'}","Visual instruction tuning refines pre-trained Multimodal Large Language
Models (MLLMs) to enhance their real-world task performance. However, the rapid
expansion of visual instruction datasets introduces significant data
redundancy, leading to excessive computational costs. Existing data selection
methods predominantly rely on proxy models or loss-based metrics, both of which
impose substantial computational overheads due to the necessity of model
inference and backpropagation. To address this challenge, we propose PRISM, a
novel training-free approach for efficient multimodal data selection. Unlike
existing methods, PRISM eliminates the reliance on proxy models, warm-up
pretraining, and gradient-based optimization. Instead, it leverages Pearson
correlation analysis to quantify the intrinsic visual encoding properties of
MLLMs, computing a task-specific correlation score to identify high-value
instances. This not only enbles data-efficient selection,but maintains the
original performance. Empirical evaluations across multiple MLLMs demonstrate
that PRISM reduces the overall time required for visual instruction tuning and
data selection to just 30% of conventional methods, while surpassing fully
fine-tuned models across eight multimodal and three language understanding
benchmarks, achieving a 101.7% relative improvement in final performance.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Visual instruction tuning refines pre-trained Multimodal Large Language\nModels (MLLMs) to enhance their real-world task performance. However, the rapid\nexpansion of visual instruction datasets introduces significant data\nredundancy, leading to excessive computational costs. Existing data selection\nmethods predominantly rely on proxy models or loss-based metrics, both of which\nimpose substantial computational overheads due to the necessity of model\ninference and backpropagation. To address this challenge, we propose PRISM, a\nnovel training-free approach for efficient multimodal data selection. Unlike\nexisting methods, PRISM eliminates the reliance on proxy models, warm-up\npretraining, and gradient-based optimization. Instead, it leverages Pearson\ncorrelation analysis to quantify the intrinsic visual encoding properties of\nMLLMs, computing a task-specific correlation score to identify high-value\ninstances. This not only enbles data-efficient selection,but maintains the\noriginal performance. Empirical evaluations across multiple MLLMs demonstrate\nthat PRISM reduces the overall time required for visual instruction tuning and\ndata selection to just 30% of conventional methods, while surpassing fully\nfine-tuned models across eight multimodal and three language understanding\nbenchmarks, achieving a 101.7% relative improvement in final performance.'}","['Jinhe Bi', 'Yifan Wang', 'Danqi Yan', 'Xun Xiao', 'Artur Hecker', 'Volker Tresp', 'Yunpu Ma']",{'name': 'Yunpu Ma'},Yunpu Ma,,"[{'href': 'http://arxiv.org/abs/2502.12119v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12119v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12119v1,None,http://arxiv.org/abs/2502.12119v1,,,2814,0
http://arxiv.org/abs/2502.12120v1,True,2025-02-17T18:45:25Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=45, tm_sec=25, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T18:45:25Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=45, tm_sec=25, tm_wday=0, tm_yday=48, tm_isdst=0)",LLMs on the Line: Data Determines Loss-to-Loss Scaling Laws,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'LLMs on the Line: Data Determines Loss-to-Loss Scaling Laws'}","Scaling laws guide the development of large language models (LLMs) by
offering estimates for the optimal balance of model size, tokens, and compute.
More recently, loss-to-loss scaling laws that relate losses across pretraining
datasets and downstream tasks have emerged as a powerful tool for understanding
and improving LLM performance. In this work, we investigate which factors most
strongly influence loss-to-loss scaling. Our experiments reveal that the
pretraining data and tokenizer determine the scaling trend. In contrast, model
size, optimization hyperparameters, and even significant architectural
differences, such as between transformer-based models like Llama and
state-space models like Mamba, have limited impact. Consequently, practitioners
should carefully curate suitable pretraining datasets for optimal downstream
performance, while architectures and other settings can be freely optimized for
training efficiency.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Scaling laws guide the development of large language models (LLMs) by\noffering estimates for the optimal balance of model size, tokens, and compute.\nMore recently, loss-to-loss scaling laws that relate losses across pretraining\ndatasets and downstream tasks have emerged as a powerful tool for understanding\nand improving LLM performance. In this work, we investigate which factors most\nstrongly influence loss-to-loss scaling. Our experiments reveal that the\npretraining data and tokenizer determine the scaling trend. In contrast, model\nsize, optimization hyperparameters, and even significant architectural\ndifferences, such as between transformer-based models like Llama and\nstate-space models like Mamba, have limited impact. Consequently, practitioners\nshould carefully curate suitable pretraining datasets for optimal downstream\nperformance, while architectures and other settings can be freely optimized for\ntraining efficiency.'}","['Prasanna Mayilvahanan', 'Thaddus Wiedemer', 'Sayak Mallick', 'Matthias Bethge', 'Wieland Brendel']",{'name': 'Wieland Brendel'},Wieland Brendel,,"[{'href': 'http://arxiv.org/abs/2502.12120v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12120v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12120v1,None,http://arxiv.org/abs/2502.12120v1,,,12822,0
http://arxiv.org/abs/2502.12149v1,True,2025-02-17T18:58:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=58, tm_sec=36, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T18:58:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=58, tm_sec=36, tm_wday=0, tm_yday=48, tm_isdst=0)",HARBOR: Exploring Persona Dynamics in Multi-Agent Competition,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'HARBOR: Exploring Persona Dynamics in Multi-Agent Competition'}","We investigate factors contributing to LLM agents' success in competitive
multi-agent environments, using auctions as a testbed where agents bid to
maximize profit. The agents are equipped with bidding domain knowledge,
distinct personas that reflect item preferences, and a memory of auction
history. Our work extends the classic auction scenario by creating a realistic
environment where multiple agents bid on houses, weighing aspects such as size,
location, and budget to secure the most desirable homes at the lowest prices.
Particularly, we investigate three key questions: (a) How does a persona
influence an agent's behavior in a competitive setting? (b) Can an agent
effectively profile its competitors' behavior during auctions? (c) How can
persona profiling be leveraged to create an advantage using strategies such as
theory of mind? Through a series of experiments, we analyze the behaviors of
LLM agents and shed light on new findings. Our testbed, called HARBOR, offers a
valuable platform for deepening our understanding of multi-agent workflows in
competitive environments.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""We investigate factors contributing to LLM agents' success in competitive\nmulti-agent environments, using auctions as a testbed where agents bid to\nmaximize profit. The agents are equipped with bidding domain knowledge,\ndistinct personas that reflect item preferences, and a memory of auction\nhistory. Our work extends the classic auction scenario by creating a realistic\nenvironment where multiple agents bid on houses, weighing aspects such as size,\nlocation, and budget to secure the most desirable homes at the lowest prices.\nParticularly, we investigate three key questions: (a) How does a persona\ninfluence an agent's behavior in a competitive setting? (b) Can an agent\neffectively profile its competitors' behavior during auctions? (c) How can\npersona profiling be leveraged to create an advantage using strategies such as\ntheory of mind? Through a series of experiments, we analyze the behaviors of\nLLM agents and shed light on new findings. Our testbed, called HARBOR, offers a\nvaluable platform for deepening our understanding of multi-agent workflows in\ncompetitive environments.""}","['Kenan Jiang', 'Li Xiong', 'Fei Liu']",{'name': 'Fei Liu'},Fei Liu,,"[{'href': 'http://arxiv.org/abs/2502.12149v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12149v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12149v1,None,http://arxiv.org/abs/2502.12149v1,,,0,0
http://arxiv.org/abs/2502.12154v1,True,2025-02-17T18:59:50Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=59, tm_sec=50, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T18:59:50Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=59, tm_sec=50, tm_wday=0, tm_yday=48, tm_isdst=0)",Diffusion Models without Classifier-free Guidance,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Diffusion Models without Classifier-free Guidance'}","This paper presents Model-guidance (MG), a novel objective for training
diffusion model that addresses and removes of the commonly used Classifier-free
guidance (CFG). Our innovative approach transcends the standard modeling of
solely data distribution to incorporating the posterior probability of
conditions. The proposed technique originates from the idea of CFG and is easy
yet effective, making it a plug-and-play module for existing models. Our method
significantly accelerates the training process, doubles the inference speed,
and achieve exceptional quality that parallel and even surpass concurrent
diffusion models with CFG. Extensive experiments demonstrate the effectiveness,
efficiency, scalability on different models and datasets. Finally, we establish
state-of-the-art performance on ImageNet 256 benchmarks with an FID of 1.34.
Our code is available at https://github.com/tzco/Diffusion-wo-CFG.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'This paper presents Model-guidance (MG), a novel objective for training\ndiffusion model that addresses and removes of the commonly used Classifier-free\nguidance (CFG). Our innovative approach transcends the standard modeling of\nsolely data distribution to incorporating the posterior probability of\nconditions. The proposed technique originates from the idea of CFG and is easy\nyet effective, making it a plug-and-play module for existing models. Our method\nsignificantly accelerates the training process, doubles the inference speed,\nand achieve exceptional quality that parallel and even surpass concurrent\ndiffusion models with CFG. Extensive experiments demonstrate the effectiveness,\nefficiency, scalability on different models and datasets. Finally, we establish\nstate-of-the-art performance on ImageNet 256 benchmarks with an FID of 1.34.\nOur code is available at https://github.com/tzco/Diffusion-wo-CFG.'}","['Zhicong Tang', 'Jianmin Bao', 'Dong Chen', 'Baining Guo']",{'name': 'Baining Guo'},Baining Guo,,"[{'href': 'http://arxiv.org/abs/2502.12154v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12154v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12154v1,None,http://arxiv.org/abs/2502.12154v1,,,9048,0
http://arxiv.org/abs/2502.12186v1,True,2025-02-15T05:05:49Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=5, tm_min=5, tm_sec=49, tm_wday=5, tm_yday=46, tm_isdst=0)",2025-02-15T05:05:49Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=15, tm_hour=5, tm_min=5, tm_sec=49, tm_wday=5, tm_yday=46, tm_isdst=0)","E2CB2former: Effecitve and Explainable Transformer for CB2 Receptor
  Ligand Activity Prediction","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'E2CB2former: Effecitve and Explainable Transformer for CB2 Receptor\n  Ligand Activity Prediction'}","Accurate prediction of CB2 receptor ligand activity is pivotal for advancing
drug discovery targeting this receptor, which is implicated in inflammation,
pain management, and neurodegenerative conditions. Although conventional
machine learning and deep learning techniques have shown promise, their limited
interpretability remains a significant barrier to rational drug design. In this
work, we introduce CB2former, a framework that combines a Graph Convolutional
Network with a Transformer architecture to predict CB2 receptor ligand
activity. By leveraging the Transformer's self attention mechanism alongside
the GCN's structural learning capability, CB2former not only enhances
predictive performance but also offers insights into the molecular features
underlying receptor activity. We benchmark CB2former against diverse baseline
models including Random Forest, Support Vector Machine, K Nearest Neighbors,
Gradient Boosting, Extreme Gradient Boosting, Multilayer Perceptron,
Convolutional Neural Network, and Recurrent Neural Network and demonstrate its
superior performance with an R squared of 0.685, an RMSE of 0.675, and an AUC
of 0.940. Moreover, attention weight analysis reveals key molecular
substructures influencing CB2 receptor activity, underscoring the model's
potential as an interpretable AI tool for drug discovery. This ability to
pinpoint critical molecular motifs can streamline virtual screening, guide lead
optimization, and expedite therapeutic development. Overall, our results
showcase the transformative potential of advanced AI approaches exemplified by
CB2former in delivering both accurate predictions and actionable molecular
insights, thus fostering interdisciplinary collaboration and innovation in drug
discovery.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Accurate prediction of CB2 receptor ligand activity is pivotal for advancing\ndrug discovery targeting this receptor, which is implicated in inflammation,\npain management, and neurodegenerative conditions. Although conventional\nmachine learning and deep learning techniques have shown promise, their limited\ninterpretability remains a significant barrier to rational drug design. In this\nwork, we introduce CB2former, a framework that combines a Graph Convolutional\nNetwork with a Transformer architecture to predict CB2 receptor ligand\nactivity. By leveraging the Transformer's self attention mechanism alongside\nthe GCN's structural learning capability, CB2former not only enhances\npredictive performance but also offers insights into the molecular features\nunderlying receptor activity. We benchmark CB2former against diverse baseline\nmodels including Random Forest, Support Vector Machine, K Nearest Neighbors,\nGradient Boosting, Extreme Gradient Boosting, Multilayer Perceptron,\nConvolutional Neural Network, and Recurrent Neural Network and demonstrate its\nsuperior performance with an R squared of 0.685, an RMSE of 0.675, and an AUC\nof 0.940. Moreover, attention weight analysis reveals key molecular\nsubstructures influencing CB2 receptor activity, underscoring the model's\npotential as an interpretable AI tool for drug discovery. This ability to\npinpoint critical molecular motifs can streamline virtual screening, guide lead\noptimization, and expedite therapeutic development. Overall, our results\nshowcase the transformative potential of advanced AI approaches exemplified by\nCB2former in delivering both accurate predictions and actionable molecular\ninsights, thus fostering interdisciplinary collaboration and innovation in drug\ndiscovery.""}","['Jiacheng Xie', 'Yingrui Ji', 'Linghuan Zeng', 'Xi Xiao', 'Gaofei Chen', 'Lijing Zhu', 'Joyanta Jyoti Mondal', 'Jiansheng Chen']",{'name': 'Jiansheng Chen'},Jiansheng Chen,,"[{'href': 'http://arxiv.org/abs/2502.12186v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12186v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-bio.QM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12186v1,None,http://arxiv.org/abs/2502.12186v1,,,49,0
http://arxiv.org/abs/2502.12202v1,True,2025-02-16T10:45:56Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=10, tm_min=45, tm_sec=56, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T10:45:56Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=10, tm_min=45, tm_sec=56, tm_wday=6, tm_yday=47, tm_isdst=0)","BoT: Breaking Long Thought Processes of o1-like Large Language Models
  through Backdoor Attack","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'BoT: Breaking Long Thought Processes of o1-like Large Language Models\n  through Backdoor Attack'}","Longer thought, better performance: large language models with deep reasoning
capabilities, particularly o1-like models, have demonstrated remarkable
performance by generating extensive thought processes during inference. This
trade-off reveals a potential vulnerability: adversaries could compromise model
performance by forcing immediate responses without thought processes. To this
end, in this paper, we introduce a novel attack scenario targeting the long
thought processes of o1-like models and propose BoT (Break CoT), which can
selectively break intrinsic reasoning mechanisms through backdoor attacks. BoT
constructs poisoned datasets with designed triggers and injects backdoor by
either supervised fine-tuning or direct preference optimization. When
triggered, the model directly generates answers without thought processes,
while maintaining normal reasoning capabilities for clean inputs. Extensive
experiments on open-source o1-like models, including recent DeepSeek-R1,
demonstrate that BoT nearly achieves high attack success rates while
maintaining clean accuracy, highlighting the critical safety risk in current
models. Furthermore, the relationship between task difficulty and helpfulness
reveals a potential application for good, enabling users to customize model
behavior based on task complexity. Code is available at
\href{https://github.com/zihao-ai/BoT}{https://github.com/zihao-ai/BoT}.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Longer thought, better performance: large language models with deep reasoning\ncapabilities, particularly o1-like models, have demonstrated remarkable\nperformance by generating extensive thought processes during inference. This\ntrade-off reveals a potential vulnerability: adversaries could compromise model\nperformance by forcing immediate responses without thought processes. To this\nend, in this paper, we introduce a novel attack scenario targeting the long\nthought processes of o1-like models and propose BoT (Break CoT), which can\nselectively break intrinsic reasoning mechanisms through backdoor attacks. BoT\nconstructs poisoned datasets with designed triggers and injects backdoor by\neither supervised fine-tuning or direct preference optimization. When\ntriggered, the model directly generates answers without thought processes,\nwhile maintaining normal reasoning capabilities for clean inputs. Extensive\nexperiments on open-source o1-like models, including recent DeepSeek-R1,\ndemonstrate that BoT nearly achieves high attack success rates while\nmaintaining clean accuracy, highlighting the critical safety risk in current\nmodels. Furthermore, the relationship between task difficulty and helpfulness\nreveals a potential application for good, enabling users to customize model\nbehavior based on task complexity. Code is available at\n\\href{https://github.com/zihao-ai/BoT}{https://github.com/zihao-ai/BoT}.'}","['Zihao Zhu', 'Hongbao Zhang', 'Mingda Zhang', 'Ruotong Wang', 'Guanzong Wu', 'Ke Xu', 'Baoyuan Wu']",{'name': 'Baoyuan Wu'},Baoyuan Wu,,"[{'href': 'http://arxiv.org/abs/2502.12202v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12202v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12202v1,None,http://arxiv.org/abs/2502.12202v1,,,155,0
http://arxiv.org/abs/2502.12203v1,True,2025-02-16T12:33:03Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=12, tm_min=33, tm_sec=3, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T12:33:03Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=12, tm_min=33, tm_sec=3, tm_wday=6, tm_yday=47, tm_isdst=0)","An Interpretable Automated Mechanism Design Framework with Large
  Language Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'An Interpretable Automated Mechanism Design Framework with Large\n  Language Models'}","Mechanism design has long been a cornerstone of economic theory, with
traditional approaches relying on mathematical derivations. Recently, automated
approaches, including differentiable economics with neural networks, have
emerged for designing payments and allocations. While both analytical and
automated methods have advanced the field, they each face significant
weaknesses: mathematical derivations are not automated and often struggle to
scale to complex problems, while automated and especially neural-network-based
approaches suffer from limited interpretability. To address these challenges,
we introduce a novel framework that reformulates mechanism design as a code
generation task. Using large language models (LLMs), we generate heuristic
mechanisms described in code and evolve them to optimize over some evaluation
metrics while ensuring key design criteria (e.g., strategy-proofness) through a
problem-specific fixing process. This fixing process ensures any mechanism
violating the design criteria is adjusted to satisfy them, albeit with some
trade-offs in performance metrics. These trade-offs are factored in during the
LLM-based evolution process. The code generation capabilities of LLMs enable
the discovery of novel and interpretable solutions, bridging the symbolic logic
of mechanism design and the generative power of modern AI. Through rigorous
experimentation, we demonstrate that LLM-generated mechanisms achieve
competitive performance while offering greater interpretability compared to
previous approaches. Notably, our framework can rediscover existing manually
designed mechanisms and provide insights into neural-network based solutions
through Programming-by-Example. These results highlight the potential of LLMs
to not only automate but also enhance the transparency and scalability of
mechanism design, ensuring safe deployment of the mechanisms in society.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Mechanism design has long been a cornerstone of economic theory, with\ntraditional approaches relying on mathematical derivations. Recently, automated\napproaches, including differentiable economics with neural networks, have\nemerged for designing payments and allocations. While both analytical and\nautomated methods have advanced the field, they each face significant\nweaknesses: mathematical derivations are not automated and often struggle to\nscale to complex problems, while automated and especially neural-network-based\napproaches suffer from limited interpretability. To address these challenges,\nwe introduce a novel framework that reformulates mechanism design as a code\ngeneration task. Using large language models (LLMs), we generate heuristic\nmechanisms described in code and evolve them to optimize over some evaluation\nmetrics while ensuring key design criteria (e.g., strategy-proofness) through a\nproblem-specific fixing process. This fixing process ensures any mechanism\nviolating the design criteria is adjusted to satisfy them, albeit with some\ntrade-offs in performance metrics. These trade-offs are factored in during the\nLLM-based evolution process. The code generation capabilities of LLMs enable\nthe discovery of novel and interpretable solutions, bridging the symbolic logic\nof mechanism design and the generative power of modern AI. Through rigorous\nexperimentation, we demonstrate that LLM-generated mechanisms achieve\ncompetitive performance while offering greater interpretability compared to\nprevious approaches. Notably, our framework can rediscover existing manually\ndesigned mechanisms and provide insights into neural-network based solutions\nthrough Programming-by-Example. These results highlight the potential of LLMs\nto not only automate but also enhance the transparency and scalability of\nmechanism design, ensuring safe deployment of the mechanisms in society.'}","['Jiayuan Liu', 'Mingyu Guo', 'Vincent Conitzer']",{'name': 'Vincent Conitzer'},Vincent Conitzer,,"[{'href': 'http://arxiv.org/abs/2502.12203v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12203v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12203v1,None,http://arxiv.org/abs/2502.12203v1,,,58,0
http://arxiv.org/abs/2502.12206v1,True,2025-02-16T16:29:20Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=16, tm_min=29, tm_sec=20, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T16:29:20Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=16, tm_min=29, tm_sec=20, tm_wday=6, tm_yday=47, tm_isdst=0)","Evaluating the Paperclip Maximizer: Are RL-Based Language Models More
  Likely to Pursue Instrumental Goals?","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Evaluating the Paperclip Maximizer: Are RL-Based Language Models More\n  Likely to Pursue Instrumental Goals?'}","As large language models (LLMs) continue to evolve, ensuring their alignment
with human goals and values remains a pressing challenge. A key concern is
\textit{instrumental convergence}, where an AI system, in optimizing for a
given objective, develops unintended intermediate goals that override the
ultimate objective and deviate from human-intended goals. This issue is
particularly relevant in reinforcement learning (RL)-trained models, which can
generate creative but unintended strategies to maximize rewards. In this paper,
we explore instrumental convergence in LLMs by comparing models trained with
direct RL optimization (e.g., the o1 model) to those trained with reinforcement
learning from human feedback (RLHF). We hypothesize that RL-driven models
exhibit a stronger tendency for instrumental convergence due to their
optimization of goal-directed behavior in ways that may misalign with human
intentions. To assess this, we introduce InstrumentalEval, a benchmark for
evaluating instrumental convergence in RL-trained LLMs. Initial experiments
reveal cases where a model tasked with making money unexpectedly pursues
instrumental objectives, such as self-replication, implying signs of
instrumental convergence. Our findings contribute to a deeper understanding of
alignment challenges in AI systems and the risks posed by unintended model
behaviors.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'As large language models (LLMs) continue to evolve, ensuring their alignment\nwith human goals and values remains a pressing challenge. A key concern is\n\\textit{instrumental convergence}, where an AI system, in optimizing for a\ngiven objective, develops unintended intermediate goals that override the\nultimate objective and deviate from human-intended goals. This issue is\nparticularly relevant in reinforcement learning (RL)-trained models, which can\ngenerate creative but unintended strategies to maximize rewards. In this paper,\nwe explore instrumental convergence in LLMs by comparing models trained with\ndirect RL optimization (e.g., the o1 model) to those trained with reinforcement\nlearning from human feedback (RLHF). We hypothesize that RL-driven models\nexhibit a stronger tendency for instrumental convergence due to their\noptimization of goal-directed behavior in ways that may misalign with human\nintentions. To assess this, we introduce InstrumentalEval, a benchmark for\nevaluating instrumental convergence in RL-trained LLMs. Initial experiments\nreveal cases where a model tasked with making money unexpectedly pursues\ninstrumental objectives, such as self-replication, implying signs of\ninstrumental convergence. Our findings contribute to a deeper understanding of\nalignment challenges in AI systems and the risks posed by unintended model\nbehaviors.'}","['Yufei He', 'Yuexin Li', 'Jiaying Wu', 'Yuan Sui', 'Yulin Chen', 'Bryan Hooi']",{'name': 'Bryan Hooi'},Bryan Hooi,,"[{'href': 'http://arxiv.org/abs/2502.12206v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12206v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12206v1,None,http://arxiv.org/abs/2502.12206v1,,,198,0
http://arxiv.org/abs/2502.12209v1,True,2025-02-17T01:17:12Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=1, tm_min=17, tm_sec=12, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T01:17:12Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=1, tm_min=17, tm_sec=12, tm_wday=0, tm_yday=48, tm_isdst=0)",Suboptimal Shapley Value Explanations,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Suboptimal Shapley Value Explanations'}","Deep Neural Networks (DNNs) have demonstrated strong capacity in supporting a
wide variety of applications. Shapley value has emerged as a prominent tool to
analyze feature importance to help people understand the inference process of
deep neural models. Computing Shapley value function requires choosing a
baseline to represent feature's missingness. However, existing random and
conditional baselines could negatively influence the explanation. In this
paper, by analyzing the suboptimality of different baselines, we identify the
problematic baseline where the asymmetric interaction between $\bm{x}'_i$ (the
replacement of the faithful influential feature) and other features has
significant directional bias toward the model's output, and conclude that
$p(y|\bm{x}'_i) = p(y)$ potentially minimizes the asymmetric interaction
involving $\bm{x}'_i$. We further generalize the uninformativeness of
$\bm{x}'_i$ toward the label space $L$ to avoid estimating $p(y)$ and design a
simple uncertainty-based reweighting mechanism to accelerate the computation
process. We conduct experiments on various NLP tasks and our quantitative
analysis demonstrates the effectiveness of the proposed uncertainty-based
reweighting mechanism. Furthermore, by measuring the consistency of
explanations generated by explainable methods and human, we highlight the
disparity between model inference and human understanding.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Deep Neural Networks (DNNs) have demonstrated strong capacity in supporting a\nwide variety of applications. Shapley value has emerged as a prominent tool to\nanalyze feature importance to help people understand the inference process of\ndeep neural models. Computing Shapley value function requires choosing a\nbaseline to represent feature's missingness. However, existing random and\nconditional baselines could negatively influence the explanation. In this\npaper, by analyzing the suboptimality of different baselines, we identify the\nproblematic baseline where the asymmetric interaction between $\\bm{x}'_i$ (the\nreplacement of the faithful influential feature) and other features has\nsignificant directional bias toward the model's output, and conclude that\n$p(y|\\bm{x}'_i) = p(y)$ potentially minimizes the asymmetric interaction\ninvolving $\\bm{x}'_i$. We further generalize the uninformativeness of\n$\\bm{x}'_i$ toward the label space $L$ to avoid estimating $p(y)$ and design a\nsimple uncertainty-based reweighting mechanism to accelerate the computation\nprocess. We conduct experiments on various NLP tasks and our quantitative\nanalysis demonstrates the effectiveness of the proposed uncertainty-based\nreweighting mechanism. Furthermore, by measuring the consistency of\nexplanations generated by explainable methods and human, we highlight the\ndisparity between model inference and human understanding.""}",['Xiaolei Lu'],{'name': 'Xiaolei Lu'},Xiaolei Lu,,"[{'href': 'http://arxiv.org/abs/2502.12209v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12209v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12209v1,None,http://arxiv.org/abs/2502.12209v1,,,0,0
http://arxiv.org/abs/2502.12210v1,True,2025-02-17T02:34:02Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=2, tm_min=34, tm_sec=2, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T02:34:02Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=2, tm_min=34, tm_sec=2, tm_wday=0, tm_yday=48, tm_isdst=0)",Enhancing Frame Detection with Retrieval Augmented Generation,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Enhancing Frame Detection with Retrieval Augmented Generation'}","Recent advancements in Natural Language Processing have significantly
improved the extraction of structured semantic representations from
unstructured text, especially through Frame Semantic Role Labeling (FSRL).
Despite this progress, the potential of Retrieval-Augmented Generation (RAG)
models for frame detection remains under-explored. In this paper, we present
the first RAG-based approach for frame detection called RCIF (Retrieve
Candidates and Identify Frames). RCIF is also the first approach to operate
without the need for explicit target span and comprises three main stages: (1)
generation of frame embeddings from various representations ; (2) retrieval of
candidate frames given an input text; and (3) identification of the most
suitable frames. We conducted extensive experiments across multiple
configurations, including zero-shot, few-shot, and fine-tuning settings. Our
results show that our retrieval component significantly reduces the complexity
of the task by narrowing the search space thus allowing the frame identifier to
refine and complete the set of candidates. Our approach achieves
state-of-the-art performance on FrameNet 1.5 and 1.7, demonstrating its
robustness in scenarios where only raw text is provided. Furthermore, we
leverage the structured representation obtained through this method as a proxy
to enhance generalization across lexical variations in the task of translating
natural language questions into SPARQL queries.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Recent advancements in Natural Language Processing have significantly\nimproved the extraction of structured semantic representations from\nunstructured text, especially through Frame Semantic Role Labeling (FSRL).\nDespite this progress, the potential of Retrieval-Augmented Generation (RAG)\nmodels for frame detection remains under-explored. In this paper, we present\nthe first RAG-based approach for frame detection called RCIF (Retrieve\nCandidates and Identify Frames). RCIF is also the first approach to operate\nwithout the need for explicit target span and comprises three main stages: (1)\ngeneration of frame embeddings from various representations ; (2) retrieval of\ncandidate frames given an input text; and (3) identification of the most\nsuitable frames. We conducted extensive experiments across multiple\nconfigurations, including zero-shot, few-shot, and fine-tuning settings. Our\nresults show that our retrieval component significantly reduces the complexity\nof the task by narrowing the search space thus allowing the frame identifier to\nrefine and complete the set of candidates. Our approach achieves\nstate-of-the-art performance on FrameNet 1.5 and 1.7, demonstrating its\nrobustness in scenarios where only raw text is provided. Furthermore, we\nleverage the structured representation obtained through this method as a proxy\nto enhance generalization across lexical variations in the task of translating\nnatural language questions into SPARQL queries.'}","['Papa Abdou Karim Karou Diallo', 'Amal Zouaq']",{'name': 'Amal Zouaq'},Amal Zouaq,,"[{'href': 'http://arxiv.org/abs/2502.12210v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12210v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12210v1,None,http://arxiv.org/abs/2502.12210v1,,,8,0
http://arxiv.org/abs/2502.12215v1,True,2025-02-17T07:21:11Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=7, tm_min=21, tm_sec=11, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T07:21:11Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=7, tm_min=21, tm_sec=11, tm_wday=0, tm_yday=48, tm_isdst=0)","Revisiting the Test-Time Scaling of o1-like Models: Do they Truly
  Possess Test-Time Scaling Capabilities?","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Revisiting the Test-Time Scaling of o1-like Models: Do they Truly\n  Possess Test-Time Scaling Capabilities?'}","The advent of test-time scaling in large language models (LLMs), exemplified
by OpenAI's o1 series, has advanced reasoning capabilities by scaling
computational resource allocation during inference. While successors like QwQ,
Deepseek-R1 (R1) and LIMO replicate these advancements, whether these models
truly possess test-time scaling capabilities remains underexplored. This study
found that longer CoTs of these o1-like models do not consistently enhance
accuracy; in fact, correct solutions are often shorter than incorrect ones for
the same questions. Further investigation shows this phenomenon is closely
related to models' self-revision capabilities - longer CoTs contain more
self-revisions, which often lead to performance degradation. We then compare
sequential and parallel scaling strategies on QwQ, R1 and LIMO, finding that
parallel scaling achieves better coverage and scalability. Based on these
insights, we propose Shortest Majority Vote, a method that combines parallel
scaling strategies with CoT length characteristics, significantly improving
models' test-time scalability compared to conventional majority voting
approaches.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""The advent of test-time scaling in large language models (LLMs), exemplified\nby OpenAI's o1 series, has advanced reasoning capabilities by scaling\ncomputational resource allocation during inference. While successors like QwQ,\nDeepseek-R1 (R1) and LIMO replicate these advancements, whether these models\ntruly possess test-time scaling capabilities remains underexplored. This study\nfound that longer CoTs of these o1-like models do not consistently enhance\naccuracy; in fact, correct solutions are often shorter than incorrect ones for\nthe same questions. Further investigation shows this phenomenon is closely\nrelated to models' self-revision capabilities - longer CoTs contain more\nself-revisions, which often lead to performance degradation. We then compare\nsequential and parallel scaling strategies on QwQ, R1 and LIMO, finding that\nparallel scaling achieves better coverage and scalability. Based on these\ninsights, we propose Shortest Majority Vote, a method that combines parallel\nscaling strategies with CoT length characteristics, significantly improving\nmodels' test-time scalability compared to conventional majority voting\napproaches.""}","['Zhiyuan Zeng', 'Qinyuan Cheng', 'Zhangyue Yin', 'Yunhua Zhou', 'Xipeng Qiu']",{'name': 'Xipeng Qiu'},Xipeng Qiu,,"[{'href': 'http://arxiv.org/abs/2502.12215v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12215v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12215v1,None,http://arxiv.org/abs/2502.12215v1,,,466,0
http://arxiv.org/abs/2502.12216v1,True,2025-02-17T08:39:43Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=8, tm_min=39, tm_sec=43, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T08:39:43Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=8, tm_min=39, tm_sec=43, tm_wday=0, tm_yday=48, tm_isdst=0)","Tactic: Adaptive Sparse Attention with Clustering and Distribution
  Fitting for Long-Context LLMs","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Tactic: Adaptive Sparse Attention with Clustering and Distribution\n  Fitting for Long-Context LLMs'}","Long-context models are essential for many applications but face
inefficiencies in loading large KV caches during decoding. Prior methods
enforce fixed token budgets for sparse attention, assuming a set number of
tokens can approximate full attention. However, these methods overlook
variations in the importance of attention across heads, layers, and contexts.
To address these limitations, we propose Tactic, a sparsity-adaptive and
calibration-free sparse attention mechanism that dynamically selects tokens
based on their cumulative attention scores rather than a fixed token budget. By
setting a target fraction of total attention scores, Tactic ensures that token
selection naturally adapts to variations in attention sparsity. To efficiently
approximate this selection, Tactic leverages clustering-based sorting and
distribution fitting, allowing it to accurately estimate token importance with
minimal computational overhead. We show that Tactic outperforms existing sparse
attention algorithms, achieving superior accuracy and up to 7.29x decode
attention speedup. This improvement translates to an overall 1.58x end-to-end
inference speedup, making Tactic a practical and effective solution for
long-context LLM inference in accuracy-sensitive applications.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Long-context models are essential for many applications but face\ninefficiencies in loading large KV caches during decoding. Prior methods\nenforce fixed token budgets for sparse attention, assuming a set number of\ntokens can approximate full attention. However, these methods overlook\nvariations in the importance of attention across heads, layers, and contexts.\nTo address these limitations, we propose Tactic, a sparsity-adaptive and\ncalibration-free sparse attention mechanism that dynamically selects tokens\nbased on their cumulative attention scores rather than a fixed token budget. By\nsetting a target fraction of total attention scores, Tactic ensures that token\nselection naturally adapts to variations in attention sparsity. To efficiently\napproximate this selection, Tactic leverages clustering-based sorting and\ndistribution fitting, allowing it to accurately estimate token importance with\nminimal computational overhead. We show that Tactic outperforms existing sparse\nattention algorithms, achieving superior accuracy and up to 7.29x decode\nattention speedup. This improvement translates to an overall 1.58x end-to-end\ninference speedup, making Tactic a practical and effective solution for\nlong-context LLM inference in accuracy-sensitive applications.'}","['Kan Zhu', 'Tian Tang', 'Qinyu Xu', 'Yile Gu', 'Zhichen Zeng', 'Rohan Kadekodi', 'Liangyu Zhao', 'Ang Li', 'Arvind Krishnamurthy', 'Baris Kasikci']",{'name': 'Baris Kasikci'},Baris Kasikci,,"[{'href': 'http://arxiv.org/abs/2502.12216v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12216v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12216v1,None,http://arxiv.org/abs/2502.12216v1,,,4032,0
http://arxiv.org/abs/2502.12217v1,True,2025-02-17T09:07:49Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=9, tm_min=7, tm_sec=49, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T09:07:49Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=9, tm_min=7, tm_sec=49, tm_wday=0, tm_yday=48, tm_isdst=0)",Optimal Brain Iterative Merging: Mitigating Interference in LLM Merging,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Optimal Brain Iterative Merging: Mitigating Interference in LLM Merging'}","Large Language Models (LLMs) have demonstrated impressive capabilities, but
their high computational costs pose challenges for customization. Model merging
offers a cost-effective alternative, yet existing methods suffer from
interference among parameters, leading to performance degradation. In this
work, we propose Optimal Brain Iterative Merging (OBIM), a novel method
designed to mitigate both intra-model and inter-model interference. OBIM
consists of two key components: (1) A saliency measurement mechanism that
evaluates parameter importance based on loss changes induced by individual
weight alterations, reducing intra-model interference by preserving only
high-saliency parameters. (2) A mutually exclusive iterative merging framework,
which incrementally integrates models using a binary mask to avoid direct
parameter averaging, thereby mitigating inter-model interference. We validate
OBIM through experiments on both Supervised Fine-Tuned (SFT) models and
post-pretrained checkpoints. The results show that OBIM significantly
outperforms existing merging techniques. Overall, OBIM provides an effective
and practical solution for enhancing LLM merging.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Language Models (LLMs) have demonstrated impressive capabilities, but\ntheir high computational costs pose challenges for customization. Model merging\noffers a cost-effective alternative, yet existing methods suffer from\ninterference among parameters, leading to performance degradation. In this\nwork, we propose Optimal Brain Iterative Merging (OBIM), a novel method\ndesigned to mitigate both intra-model and inter-model interference. OBIM\nconsists of two key components: (1) A saliency measurement mechanism that\nevaluates parameter importance based on loss changes induced by individual\nweight alterations, reducing intra-model interference by preserving only\nhigh-saliency parameters. (2) A mutually exclusive iterative merging framework,\nwhich incrementally integrates models using a binary mask to avoid direct\nparameter averaging, thereby mitigating inter-model interference. We validate\nOBIM through experiments on both Supervised Fine-Tuned (SFT) models and\npost-pretrained checkpoints. The results show that OBIM significantly\noutperforms existing merging techniques. Overall, OBIM provides an effective\nand practical solution for enhancing LLM merging.'}","['Zhixiang Wang', 'Zhenyu Mao', 'Yixuan Qiao', 'Yunfang Wu', 'Biye Li']",{'name': 'Biye Li'},Biye Li,,"[{'href': 'http://arxiv.org/abs/2502.12217v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12217v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12217v1,None,http://arxiv.org/abs/2502.12217v1,,,5,0
http://arxiv.org/abs/2502.12272v2,True,2025-02-19T23:01:25Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=23, tm_min=1, tm_sec=25, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-17T19:16:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=19, tm_min=16, tm_sec=37, tm_wday=0, tm_yday=48, tm_isdst=0)",Learning to Reason at the Frontier of Learnability,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Learning to Reason at the Frontier of Learnability'}","Reinforcement learning is now widely adopted as the final stage of large
language model training, especially for reasoning-style tasks such as maths
problems. Typically, models attempt each question many times during a single
training step and attempt to learn from their successes and failures. However,
we demonstrate that throughout training with two popular algorithms (PPO and
VinePPO) on two widely used datasets, many questions are either solved by all
attempts - meaning they are already learned - or by none - providing no
meaningful training signal. To address this, we adapt a method from the
reinforcement learning literature - sampling for learnability - and apply it to
the reinforcement learning stage of LLM training. Our curriculum prioritises
questions with high variance of success, i.e. those where the agent sometimes
succeeds, but not always. Our findings demonstrate that this curriculum
consistently boosts training performance across multiple algorithms and
datasets, paving the way for more efficient and effective reinforcement
learning in LLMs.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Reinforcement learning is now widely adopted as the final stage of large\nlanguage model training, especially for reasoning-style tasks such as maths\nproblems. Typically, models attempt each question many times during a single\ntraining step and attempt to learn from their successes and failures. However,\nwe demonstrate that throughout training with two popular algorithms (PPO and\nVinePPO) on two widely used datasets, many questions are either solved by all\nattempts - meaning they are already learned - or by none - providing no\nmeaningful training signal. To address this, we adapt a method from the\nreinforcement learning literature - sampling for learnability - and apply it to\nthe reinforcement learning stage of LLM training. Our curriculum prioritises\nquestions with high variance of success, i.e. those where the agent sometimes\nsucceeds, but not always. Our findings demonstrate that this curriculum\nconsistently boosts training performance across multiple algorithms and\ndatasets, paving the way for more efficient and effective reinforcement\nlearning in LLMs.'}","['Thomas Foster', 'Jakob Foerster']",{'name': 'Jakob Foerster'},Jakob Foerster,,"[{'href': 'http://arxiv.org/abs/2502.12272v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12272v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12272v2,None,http://arxiv.org/abs/2502.12272v2,,,0,0
http://arxiv.org/abs/2502.12275v1,True,2025-02-17T19:18:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=19, tm_min=18, tm_sec=23, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T19:18:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=19, tm_min=18, tm_sec=23, tm_wday=0, tm_yday=48, tm_isdst=0)",Integrating Expert Knowledge into Logical Programs via LLMs,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Integrating Expert Knowledge into Logical Programs via LLMs'}","This paper introduces ExKLoP, a novel framework designed to evaluate how
effectively Large Language Models (LLMs) integrate expert knowledge into
logical reasoning systems. This capability is especially valuable in
engineering, where expert knowledge-such as manufacturer-recommended
operational ranges-can be directly embedded into automated monitoring systems.
By mirroring expert verification steps, tasks like range checking and
constraint validation help ensure system safety and reliability. Our approach
systematically evaluates LLM-generated logical rules, assessing both syntactic
fluency and logical correctness in these critical validation tasks. We also
explore the models capacity for self-correction via an iterative feedback loop
based on code execution outcomes. ExKLoP presents an extensible dataset
comprising 130 engineering premises, 950 prompts, and corresponding validation
points. It enables comprehensive benchmarking while allowing control over task
complexity and scalability of experiments. We leverage the synthetic data
creation methodology to conduct extensive empirical evaluation on a diverse set
of LLMs including Llama3, Gemma, Mixtral, Mistral, and Qwen. Results reveal
that while models generate nearly perfect syntactically correct code, they
frequently exhibit logical errors in translating expert knowledge. Furthermore,
iterative self-correction yields only marginal improvements (up to 3%).
Overall, ExKLoP serves as a robust evaluation platform that streamlines the
selection of effective models for self-correcting systems while clearly
delineating the types of errors encountered. The complete implementation, along
with all relevant data, is available at GitHub.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'This paper introduces ExKLoP, a novel framework designed to evaluate how\neffectively Large Language Models (LLMs) integrate expert knowledge into\nlogical reasoning systems. This capability is especially valuable in\nengineering, where expert knowledge-such as manufacturer-recommended\noperational ranges-can be directly embedded into automated monitoring systems.\nBy mirroring expert verification steps, tasks like range checking and\nconstraint validation help ensure system safety and reliability. Our approach\nsystematically evaluates LLM-generated logical rules, assessing both syntactic\nfluency and logical correctness in these critical validation tasks. We also\nexplore the models capacity for self-correction via an iterative feedback loop\nbased on code execution outcomes. ExKLoP presents an extensible dataset\ncomprising 130 engineering premises, 950 prompts, and corresponding validation\npoints. It enables comprehensive benchmarking while allowing control over task\ncomplexity and scalability of experiments. We leverage the synthetic data\ncreation methodology to conduct extensive empirical evaluation on a diverse set\nof LLMs including Llama3, Gemma, Mixtral, Mistral, and Qwen. Results reveal\nthat while models generate nearly perfect syntactically correct code, they\nfrequently exhibit logical errors in translating expert knowledge. Furthermore,\niterative self-correction yields only marginal improvements (up to 3%).\nOverall, ExKLoP serves as a robust evaluation platform that streamlines the\nselection of effective models for self-correcting systems while clearly\ndelineating the types of errors encountered. The complete implementation, along\nwith all relevant data, is available at GitHub.'}","['Franciszek Grski', 'Oskar Wysocki', 'Marco Valentino', 'Andre Freitas']",{'name': 'Andre Freitas'},Andre Freitas,,"[{'href': 'http://arxiv.org/abs/2502.12275v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12275v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12275v1,None,http://arxiv.org/abs/2502.12275v1,,,531,0
http://arxiv.org/abs/2502.12329v1,True,2025-02-17T21:25:31Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=21, tm_min=25, tm_sec=31, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T21:25:31Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=21, tm_min=25, tm_sec=31, tm_wday=0, tm_yday=48, tm_isdst=0)",A Novel Unified Parametric Assumption for Nonconvex Optimization,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A Novel Unified Parametric Assumption for Nonconvex Optimization'}","Nonconvex optimization is central to modern machine learning, but the general
framework of nonconvex optimization yields weak convergence guarantees that are
too pessimistic compared to practice. On the other hand, while convexity
enables efficient optimization, it is of limited applicability to many
practical problems. To bridge this gap and better understand the practical
success of optimization algorithms in nonconvex settings, we introduce a novel
unified parametric assumption. Our assumption is general enough to encompass a
broad class of nonconvex functions while also being specific enough to enable
the derivation of a unified convergence theorem for gradient-based methods.
Notably, by tuning the parameters of our assumption, we demonstrate its
versatility in recovering several existing function classes as special cases
and in identifying functions amenable to efficient optimization. We derive our
convergence theorem for both deterministic and stochastic optimization, and
conduct experiments to verify that our assumption can hold practically over
optimization trajectories.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Nonconvex optimization is central to modern machine learning, but the general\nframework of nonconvex optimization yields weak convergence guarantees that are\ntoo pessimistic compared to practice. On the other hand, while convexity\nenables efficient optimization, it is of limited applicability to many\npractical problems. To bridge this gap and better understand the practical\nsuccess of optimization algorithms in nonconvex settings, we introduce a novel\nunified parametric assumption. Our assumption is general enough to encompass a\nbroad class of nonconvex functions while also being specific enough to enable\nthe derivation of a unified convergence theorem for gradient-based methods.\nNotably, by tuning the parameters of our assumption, we demonstrate its\nversatility in recovering several existing function classes as special cases\nand in identifying functions amenable to efficient optimization. We derive our\nconvergence theorem for both deterministic and stochastic optimization, and\nconduct experiments to verify that our assumption can hold practically over\noptimization trajectories.'}","['Artem Riabinin', 'Ahmed Khaled', 'Peter Richtrik']",{'name': 'Peter Richtrik'},Peter Richtrik,,"[{'href': 'http://arxiv.org/abs/2502.12329v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12329v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.OC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12329v1,None,http://arxiv.org/abs/2502.12329v1,,,1081,0
http://arxiv.org/abs/2502.12354v1,True,2025-02-17T22:42:53Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=22, tm_min=42, tm_sec=53, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T22:42:53Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=22, tm_min=42, tm_sec=53, tm_wday=0, tm_yday=48, tm_isdst=0)","Human-centered explanation does not fit all: The interplay of
  sociotechnical, cognitive, and individual factors in the effect AI
  explanations in algorithmic decision-making","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Human-centered explanation does not fit all: The interplay of\n  sociotechnical, cognitive, and individual factors in the effect AI\n  explanations in algorithmic decision-making'}","Recent XAI studies have investigated what constitutes a \textit{good}
explanation in AI-assisted decision-making. Despite the widely accepted
human-friendly properties of explanations, such as contrastive and selective,
existing studies have yielded inconsistent findings. To address these gaps, our
study focuses on the cognitive dimensions of explanation evaluation, by
evaluating six explanations with different contrastive strategies and
information selectivity and scrutinizing factors behind their valuation
process. Our analysis results find that contrastive explanations are not the
most preferable or understandable in general; Rather, different contrastive and
selective explanations were appreciated to a different extent based on who they
are, when, how, and what to explain -- with different level of cognitive load
and engagement and sociotechnical contexts. Given these findings, we call for a
nuanced view of explanation strategies, with implications for designing AI
interfaces to accommodate individual and contextual differences in AI-assisted
decision-making.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Recent XAI studies have investigated what constitutes a \\textit{good}\nexplanation in AI-assisted decision-making. Despite the widely accepted\nhuman-friendly properties of explanations, such as contrastive and selective,\nexisting studies have yielded inconsistent findings. To address these gaps, our\nstudy focuses on the cognitive dimensions of explanation evaluation, by\nevaluating six explanations with different contrastive strategies and\ninformation selectivity and scrutinizing factors behind their valuation\nprocess. Our analysis results find that contrastive explanations are not the\nmost preferable or understandable in general; Rather, different contrastive and\nselective explanations were appreciated to a different extent based on who they\nare, when, how, and what to explain -- with different level of cognitive load\nand engagement and sociotechnical contexts. Given these findings, we call for a\nnuanced view of explanation strategies, with implications for designing AI\ninterfaces to accommodate individual and contextual differences in AI-assisted\ndecision-making.'}","['Yongsu Ahn', 'Yu-Run Lin', 'Malihe Alikhani', 'Eunjeong Cheon']",{'name': 'Eunjeong Cheon'},Eunjeong Cheon,,"[{'href': 'http://arxiv.org/abs/2502.12354v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12354v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12354v1,None,http://arxiv.org/abs/2502.12354v1,,,811,0
http://arxiv.org/abs/2502.12360v1,True,2025-02-17T22:50:45Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=22, tm_min=50, tm_sec=45, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T22:50:45Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=22, tm_min=50, tm_sec=45, tm_wday=0, tm_yday=48, tm_isdst=0)","Detecting Systematic Weaknesses in Vision Models along Predefined
  Human-Understandable Dimensions","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Detecting Systematic Weaknesses in Vision Models along Predefined\n  Human-Understandable Dimensions'}","Studying systematic weaknesses of DNNs has gained prominence in the last few
years with the rising focus on building safe AI systems. Slice discovery
methods (SDMs) are prominent algorithmic approaches for finding such systematic
weaknesses. They identify top-k semantically coherent slices/subsets of data
where a DNN-under-test has low performance. For being directly useful, e.g., as
evidences in a safety argumentation, slices should be aligned with
human-understandable (safety-relevant) dimensions, which, for example, are
defined by safety and domain experts as parts of the operational design domain
(ODD). While straightforward for structured data, the lack of semantic metadata
makes these investigations challenging for unstructured data. Therefore, we
propose a complete workflow which combines contemporary foundation models with
algorithms for combinatorial search that consider structured data and DNN
errors for finding systematic weaknesses in images. In contrast to existing
approaches, ours identifies weak slices that are in line with predefined
human-understandable dimensions. As the workflow includes foundation models,
its intermediate and final results may not always be exact. Therefore, we build
into our workflow an approach to address the impact of noisy metadata. We
evaluate our approach w.r.t. its quality on four popular computer vision
datasets, including autonomous driving datasets like Cityscapes, BDD100k, and
RailSem19, while using multiple state-of-the-art models as DNNs-under-test.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Studying systematic weaknesses of DNNs has gained prominence in the last few\nyears with the rising focus on building safe AI systems. Slice discovery\nmethods (SDMs) are prominent algorithmic approaches for finding such systematic\nweaknesses. They identify top-k semantically coherent slices/subsets of data\nwhere a DNN-under-test has low performance. For being directly useful, e.g., as\nevidences in a safety argumentation, slices should be aligned with\nhuman-understandable (safety-relevant) dimensions, which, for example, are\ndefined by safety and domain experts as parts of the operational design domain\n(ODD). While straightforward for structured data, the lack of semantic metadata\nmakes these investigations challenging for unstructured data. Therefore, we\npropose a complete workflow which combines contemporary foundation models with\nalgorithms for combinatorial search that consider structured data and DNN\nerrors for finding systematic weaknesses in images. In contrast to existing\napproaches, ours identifies weak slices that are in line with predefined\nhuman-understandable dimensions. As the workflow includes foundation models,\nits intermediate and final results may not always be exact. Therefore, we build\ninto our workflow an approach to address the impact of noisy metadata. We\nevaluate our approach w.r.t. its quality on four popular computer vision\ndatasets, including autonomous driving datasets like Cityscapes, BDD100k, and\nRailSem19, while using multiple state-of-the-art models as DNNs-under-test.'}","['Sujan Sai Gannamaneni', 'Rohil Prakash Rao', 'Michael Mock', 'Maram Akila', 'Stefan Wrobel']",{'name': 'Stefan Wrobel'},Stefan Wrobel,,"[{'href': 'http://arxiv.org/abs/2502.12360v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12360v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12360v1,None,http://arxiv.org/abs/2502.12360v1,,,717,0
http://arxiv.org/abs/2502.12371v1,True,2025-02-17T23:22:49Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=23, tm_min=22, tm_sec=49, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T23:22:49Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=23, tm_min=22, tm_sec=49, tm_wday=0, tm_yday=48, tm_isdst=0)","IMLE Policy: Fast and Sample Efficient Visuomotor Policy Learning via
  Implicit Maximum Likelihood Estimation","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'IMLE Policy: Fast and Sample Efficient Visuomotor Policy Learning via\n  Implicit Maximum Likelihood Estimation'}","Recent advances in imitation learning, particularly using generative
modelling techniques like diffusion, have enabled policies to capture complex
multi-modal action distributions. However, these methods often require large
datasets and multiple inference steps for action generation, posing challenges
in robotics where the cost for data collection is high and computation
resources are limited. To address this, we introduce IMLE Policy, a novel
behaviour cloning approach based on Implicit Maximum Likelihood Estimation
(IMLE). IMLE Policy excels in low-data regimes, effectively learning from
minimal demonstrations and requiring 38\% less data on average to match the
performance of baseline methods in learning complex multi-modal behaviours. Its
simple generator-based architecture enables single-step action generation,
improving inference speed by 97.3\% compared to Diffusion Policy, while
outperforming single-step Flow Matching. We validate our approach across
diverse manipulation tasks in simulated and real-world environments, showcasing
its ability to capture complex behaviours under data constraints. Videos and
code are provided on our project page: https://imle-policy.github.io/.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Recent advances in imitation learning, particularly using generative\nmodelling techniques like diffusion, have enabled policies to capture complex\nmulti-modal action distributions. However, these methods often require large\ndatasets and multiple inference steps for action generation, posing challenges\nin robotics where the cost for data collection is high and computation\nresources are limited. To address this, we introduce IMLE Policy, a novel\nbehaviour cloning approach based on Implicit Maximum Likelihood Estimation\n(IMLE). IMLE Policy excels in low-data regimes, effectively learning from\nminimal demonstrations and requiring 38\\% less data on average to match the\nperformance of baseline methods in learning complex multi-modal behaviours. Its\nsimple generator-based architecture enables single-step action generation,\nimproving inference speed by 97.3\\% compared to Diffusion Policy, while\noutperforming single-step Flow Matching. We validate our approach across\ndiverse manipulation tasks in simulated and real-world environments, showcasing\nits ability to capture complex behaviours under data constraints. Videos and\ncode are provided on our project page: https://imle-policy.github.io/.'}","['Krishan Rana', 'Robert Lee', 'David Pershouse', 'Niko Suenderhauf']",{'name': 'Niko Suenderhauf'},Niko Suenderhauf,Videos and code are available at https://imle-policy.github.io/,"[{'href': 'http://arxiv.org/abs/2502.12371v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12371v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12371v1,None,http://arxiv.org/abs/2502.12371v1,,,665,0
http://arxiv.org/abs/2502.12372v1,True,2025-02-17T23:24:00Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=23, tm_min=24, tm_sec=0, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T23:24:00Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=23, tm_min=24, tm_sec=0, tm_wday=0, tm_yday=48, tm_isdst=0)","Factual Inconsistency in Data-to-Text Generation Scales Exponentially
  with LLM Size: A Statistical Validation","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Factual Inconsistency in Data-to-Text Generation Scales Exponentially\n  with LLM Size: A Statistical Validation'}","Monitoring factual inconsistency is essential for ensuring trustworthiness in
data-to-text generation (D2T). While large language models (LLMs) have
demonstrated exceptional performance across various D2T tasks, previous studies
on scaling laws have primarily focused on generalization error through power
law scaling to LLM size (i.e., the number of model parameters). However, no
research has examined the impact of LLM size on factual inconsistency in D2T.
In this paper, we investigate how factual inconsistency in D2T scales with LLM
size by exploring two scaling laws: power law and exponential scaling. To
rigorously evaluate and compare these scaling laws, we employ a statistical
validation framework consisting of three key stages: predictive performance
estimation, goodness-of-fit assessment, and comparative analysis. For a
comprehensive empirical study, we analyze three popular LLM families across
five D2T datasets, measuring factual inconsistency inversely using four
state-of-the-art consistency metrics. Our findings, based on exhaustive
empirical results and validated through our framework, reveal that, contrary to
the widely assumed power law scaling, factual inconsistency in D2T follows an
exponential scaling with LLM size.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Monitoring factual inconsistency is essential for ensuring trustworthiness in\ndata-to-text generation (D2T). While large language models (LLMs) have\ndemonstrated exceptional performance across various D2T tasks, previous studies\non scaling laws have primarily focused on generalization error through power\nlaw scaling to LLM size (i.e., the number of model parameters). However, no\nresearch has examined the impact of LLM size on factual inconsistency in D2T.\nIn this paper, we investigate how factual inconsistency in D2T scales with LLM\nsize by exploring two scaling laws: power law and exponential scaling. To\nrigorously evaluate and compare these scaling laws, we employ a statistical\nvalidation framework consisting of three key stages: predictive performance\nestimation, goodness-of-fit assessment, and comparative analysis. For a\ncomprehensive empirical study, we analyze three popular LLM families across\nfive D2T datasets, measuring factual inconsistency inversely using four\nstate-of-the-art consistency metrics. Our findings, based on exhaustive\nempirical results and validated through our framework, reveal that, contrary to\nthe widely assumed power law scaling, factual inconsistency in D2T follows an\nexponential scaling with LLM size.'}","['Joy Mahapatra', 'Soumyajit Roy', 'Utpal Garain']",{'name': 'Utpal Garain'},Utpal Garain,21 pages,"[{'href': 'http://arxiv.org/abs/2502.12372v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12372v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12372v1,None,http://arxiv.org/abs/2502.12372v1,,,2,0
http://arxiv.org/abs/2502.12393v1,True,2025-02-18T00:03:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=0, tm_min=3, tm_sec=36, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T00:03:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=0, tm_min=3, tm_sec=36, tm_wday=1, tm_yday=49, tm_isdst=0)",Time Series Treatment Effects Analysis with Always-Missing Controls,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Time Series Treatment Effects Analysis with Always-Missing Controls'}","Estimating treatment effects in time series data presents a significant
challenge, especially when the control group is always unobservable. For
example, in analyzing the effects of Christmas on retail sales, we lack direct
observation of what would have occurred in late December without the Christmas
impact. To address this, we try to recover the control group in the event
period while accounting for confounders and temporal dependencies. Experimental
results on the M5 Walmart retail sales data demonstrate robust estimation of
the potential outcome of the control group as well as accurate predicted
holiday effect. Furthermore, we provided theoretical guarantees for the
estimated treatment effect, proving its consistency and asymptotic normality.
The proposed methodology is applicable not only to this always-missing control
scenario but also in other conventional time series causal inference settings.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Estimating treatment effects in time series data presents a significant\nchallenge, especially when the control group is always unobservable. For\nexample, in analyzing the effects of Christmas on retail sales, we lack direct\nobservation of what would have occurred in late December without the Christmas\nimpact. To address this, we try to recover the control group in the event\nperiod while accounting for confounders and temporal dependencies. Experimental\nresults on the M5 Walmart retail sales data demonstrate robust estimation of\nthe potential outcome of the control group as well as accurate predicted\nholiday effect. Furthermore, we provided theoretical guarantees for the\nestimated treatment effect, proving its consistency and asymptotic normality.\nThe proposed methodology is applicable not only to this always-missing control\nscenario but also in other conventional time series causal inference settings.'}","['Juan Shu', 'Qiyu Han', 'George Chen', 'Xihao Cao', 'Kangming Luo', 'Dan Pallotta', 'Shivam Agrawal', 'Yuping Lu', 'Xiaoyu Zhang', 'Jawad Mansoor', 'Jyoti Anand']",{'name': 'Jyoti Anand'},Jyoti Anand,,"[{'href': 'http://arxiv.org/abs/2502.12393v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12393v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'stat.ME', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'stat.ME', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12393v1,None,http://arxiv.org/abs/2502.12393v1,,,0,0
http://arxiv.org/abs/2502.12398v1,True,2025-02-18T00:12:52Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=0, tm_min=12, tm_sec=52, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T00:12:52Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=0, tm_min=12, tm_sec=52, tm_wday=1, tm_yday=49, tm_isdst=0)","Solving the Cold Start Problem on One's Own as an End User via
  Preference Transfer","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Solving the Cold Start Problem on One's Own as an End User via\n  Preference Transfer""}","We propose a new approach that enables end users to directly solve the cold
start problem by themselves. The cold start problem is a common issue in
recommender systems, and many methods have been proposed to address the problem
on the service provider's side. However, when the service provider does not
take action, users are left with poor recommendations and no means to improve
their experience. We propose an algorithm, Pretender, that allows end users to
proactively solve the cold start problem on their own. Pretender does not
require any special support from the service provider and can be deployed
independently by users. We formulate the problem as minimizing the distance
between the source and target distributions and optimize item selection from
the target service accordingly. Furthermore, we establish theoretical
guarantees for Pretender based on a discrete quadrature problem. We conduct
experiments on real-world datasets to demonstrate the effectiveness of
Pretender.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""We propose a new approach that enables end users to directly solve the cold\nstart problem by themselves. The cold start problem is a common issue in\nrecommender systems, and many methods have been proposed to address the problem\non the service provider's side. However, when the service provider does not\ntake action, users are left with poor recommendations and no means to improve\ntheir experience. We propose an algorithm, Pretender, that allows end users to\nproactively solve the cold start problem on their own. Pretender does not\nrequire any special support from the service provider and can be deployed\nindependently by users. We formulate the problem as minimizing the distance\nbetween the source and target distributions and optimize item selection from\nthe target service accordingly. Furthermore, we establish theoretical\nguarantees for Pretender based on a discrete quadrature problem. We conduct\nexperiments on real-world datasets to demonstrate the effectiveness of\nPretender.""}",['Ryoma Sato'],{'name': 'Ryoma Sato'},Ryoma Sato,25 pages,"[{'href': 'http://arxiv.org/abs/2502.12398v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12398v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12398v1,None,http://arxiv.org/abs/2502.12398v1,,,0,0
http://arxiv.org/abs/2502.12444v1,True,2025-02-18T02:26:34Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=2, tm_min=26, tm_sec=34, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T02:26:34Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=2, tm_min=26, tm_sec=34, tm_wday=1, tm_yday=49, tm_isdst=0)","SparAMX: Accelerating Compressed LLMs Token Generation on AMX-powered
  CPUs","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'SparAMX: Accelerating Compressed LLMs Token Generation on AMX-powered\n  CPUs'}","Large language models have high compute, latency, and memory requirements.
While specialized accelerators such as GPUs and TPUs typically run these
workloads, CPUs are more widely available and consume less energy. Accelerating
LLMs with CPUs enables broader AI access at a lower cost and power consumption.
This acceleration potential for CPUs is especially relevant during the
memory-bound decoding stage of LLM inference, which processes one token at a
time and is becoming increasingly utilized with reasoning models. We utilize
Advanced Matrix Extensions (AMX) support on the latest Intel CPUs together with
unstructured sparsity to achieve a $1.42 \times$ reduction in end-to-end
latency compared to the current PyTorch implementation by applying our
technique in linear layers. We provide a set of open-source customized sparse
kernels that can speed up any PyTorch model by automatically replacing all
linear layers with our custom sparse implementation. Furthermore, we
demonstrate for the first time the use of unstructured sparsity in the
attention computation achieving a $1.14 \times$ speedup over the current
systems without compromising accuracy. Code:
https://github.com/IntelLabs/Hardware-Aware-Automated-Machine-Learning/tree/main/SparAMX","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large language models have high compute, latency, and memory requirements.\nWhile specialized accelerators such as GPUs and TPUs typically run these\nworkloads, CPUs are more widely available and consume less energy. Accelerating\nLLMs with CPUs enables broader AI access at a lower cost and power consumption.\nThis acceleration potential for CPUs is especially relevant during the\nmemory-bound decoding stage of LLM inference, which processes one token at a\ntime and is becoming increasingly utilized with reasoning models. We utilize\nAdvanced Matrix Extensions (AMX) support on the latest Intel CPUs together with\nunstructured sparsity to achieve a $1.42 \\times$ reduction in end-to-end\nlatency compared to the current PyTorch implementation by applying our\ntechnique in linear layers. We provide a set of open-source customized sparse\nkernels that can speed up any PyTorch model by automatically replacing all\nlinear layers with our custom sparse implementation. Furthermore, we\ndemonstrate for the first time the use of unstructured sparsity in the\nattention computation achieving a $1.14 \\times$ speedup over the current\nsystems without compromising accuracy. Code:\nhttps://github.com/IntelLabs/Hardware-Aware-Automated-Machine-Learning/tree/main/SparAMX'}","['Ahmed F. AbouElhamayed', 'Jordan Dotzel', 'Yash Akhauri', 'Chi-Chih Chang', 'Sameh Gobriel', 'J. Pablo Muoz', 'Vui Seng Chua', 'Nilesh Jain', 'Mohamed S. Abdelfattah']",{'name': 'Mohamed S. Abdelfattah'},Mohamed S. Abdelfattah,,"[{'href': 'http://arxiv.org/abs/2502.12444v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12444v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.PF', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12444v1,None,http://arxiv.org/abs/2502.12444v1,,,1109,0
http://arxiv.org/abs/2502.12445v1,True,2025-02-18T02:26:50Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=2, tm_min=26, tm_sec=50, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T02:26:50Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=2, tm_min=26, tm_sec=50, tm_wday=1, tm_yday=49, tm_isdst=0)",Computational Safety for Generative AI: A Signal Processing Perspective,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Computational Safety for Generative AI: A Signal Processing Perspective'}","AI safety is a rapidly growing area of research that seeks to prevent the
harm and misuse of frontier AI technology, particularly with respect to
generative AI (GenAI) tools that are capable of creating realistic and
high-quality content through text prompts. Examples of such tools include large
language models (LLMs) and text-to-image (T2I) diffusion models. As the
performance of various leading GenAI models approaches saturation due to
similar training data sources and neural network architecture designs, the
development of reliable safety guardrails has become a key differentiator for
responsibility and sustainability. This paper presents a formalization of the
concept of computational safety, which is a mathematical framework that enables
the quantitative assessment, formulation, and study of safety challenges in
GenAI through the lens of signal processing theory and methods. In particular,
we explore two exemplary categories of computational safety challenges in GenAI
that can be formulated as hypothesis testing problems. For the safety of model
input, we show how sensitivity analysis and loss landscape analysis can be used
to detect malicious prompts with jailbreak attempts. For the safety of model
output, we elucidate how statistical signal processing and adversarial learning
can be used to detect AI-generated content. Finally, we discuss key open
research challenges, opportunities, and the essential role of signal processing
in computational AI safety.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'AI safety is a rapidly growing area of research that seeks to prevent the\nharm and misuse of frontier AI technology, particularly with respect to\ngenerative AI (GenAI) tools that are capable of creating realistic and\nhigh-quality content through text prompts. Examples of such tools include large\nlanguage models (LLMs) and text-to-image (T2I) diffusion models. As the\nperformance of various leading GenAI models approaches saturation due to\nsimilar training data sources and neural network architecture designs, the\ndevelopment of reliable safety guardrails has become a key differentiator for\nresponsibility and sustainability. This paper presents a formalization of the\nconcept of computational safety, which is a mathematical framework that enables\nthe quantitative assessment, formulation, and study of safety challenges in\nGenAI through the lens of signal processing theory and methods. In particular,\nwe explore two exemplary categories of computational safety challenges in GenAI\nthat can be formulated as hypothesis testing problems. For the safety of model\ninput, we show how sensitivity analysis and loss landscape analysis can be used\nto detect malicious prompts with jailbreak attempts. For the safety of model\noutput, we elucidate how statistical signal processing and adversarial learning\ncan be used to detect AI-generated content. Finally, we discuss key open\nresearch challenges, opportunities, and the essential role of signal processing\nin computational AI safety.'}",['Pin-Yu Chen'],{'name': 'Pin-Yu Chen'},Pin-Yu Chen,preprint for an invited paper,"[{'href': 'http://arxiv.org/abs/2502.12445v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12445v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12445v1,None,http://arxiv.org/abs/2502.12445v1,,,0,0
http://arxiv.org/abs/2502.12446v1,True,2025-02-18T02:27:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=2, tm_min=27, tm_sec=23, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T02:27:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=2, tm_min=27, tm_sec=23, tm_wday=1, tm_yday=49, tm_isdst=0)",Multi-Attribute Steering of Language Models via Targeted Intervention,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Multi-Attribute Steering of Language Models via Targeted Intervention'}","Inference-time intervention (ITI) has emerged as a promising method for
steering large language model (LLM) behavior in a particular direction (e.g.,
improving helpfulness) by intervening on token representations without costly
updates to the LLM's parameters. However, existing ITI approaches fail to scale
to multi-attribute settings with conflicts, such as enhancing helpfulness while
also reducing toxicity. To address this, we introduce Multi-Attribute Targeted
Steering (MAT-Steer), a novel steering framework designed for selective
token-level intervention across multiple attributes. MAT-Steer learns steering
vectors using an alignment objective that shifts the model's internal
representations of undesirable outputs closer to those of desirable ones while
enforcing sparsity and orthogonality among vectors for different attributes,
thereby reducing inter-attribute conflicts. We evaluate MAT-Steer in two
distinct settings: (i) on question answering (QA) tasks where we balance
attributes like truthfulness, bias, and toxicity; (ii) on generative tasks
where we simultaneously improve attributes like helpfulness, correctness, and
coherence. MAT-Steer outperforms existing ITI and parameter-efficient
finetuning approaches across both task types (e.g., 3% average accuracy gain
across QA tasks and 55.82% win rate against the best ITI baseline).","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Inference-time intervention (ITI) has emerged as a promising method for\nsteering large language model (LLM) behavior in a particular direction (e.g.,\nimproving helpfulness) by intervening on token representations without costly\nupdates to the LLM's parameters. However, existing ITI approaches fail to scale\nto multi-attribute settings with conflicts, such as enhancing helpfulness while\nalso reducing toxicity. To address this, we introduce Multi-Attribute Targeted\nSteering (MAT-Steer), a novel steering framework designed for selective\ntoken-level intervention across multiple attributes. MAT-Steer learns steering\nvectors using an alignment objective that shifts the model's internal\nrepresentations of undesirable outputs closer to those of desirable ones while\nenforcing sparsity and orthogonality among vectors for different attributes,\nthereby reducing inter-attribute conflicts. We evaluate MAT-Steer in two\ndistinct settings: (i) on question answering (QA) tasks where we balance\nattributes like truthfulness, bias, and toxicity; (ii) on generative tasks\nwhere we simultaneously improve attributes like helpfulness, correctness, and\ncoherence. MAT-Steer outperforms existing ITI and parameter-efficient\nfinetuning approaches across both task types (e.g., 3% average accuracy gain\nacross QA tasks and 55.82% win rate against the best ITI baseline).""}","['Duy Nguyen', 'Archiki Prasad', 'Elias Stengel-Eskin', 'Mohit Bansal']",{'name': 'Mohit Bansal'},Mohit Bansal,"15 pages, code link: https://github.com/duykhuongnguyen/MAT-Steer","[{'href': 'http://arxiv.org/abs/2502.12446v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12446v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12446v1,None,http://arxiv.org/abs/2502.12446v1,,,578,0
http://arxiv.org/abs/2502.12453v1,True,2025-02-18T02:36:03Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=2, tm_min=36, tm_sec=3, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T02:36:03Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=2, tm_min=36, tm_sec=3, tm_wday=1, tm_yday=49, tm_isdst=0)","UniMatch: Universal Matching from Atom to Task for Few-Shot Drug
  Discovery","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'UniMatch: Universal Matching from Atom to Task for Few-Shot Drug\n  Discovery'}","Drug discovery is crucial for identifying candidate drugs for various
diseases.However, its low success rate often results in a scarcity of
annotations, posing a few-shot learning problem. Existing methods primarily
focus on single-scale features, overlooking the hierarchical molecular
structures that determine different molecular properties. To address these
issues, we introduce Universal Matching Networks (UniMatch), a dual matching
framework that integrates explicit hierarchical molecular matching with
implicit task-level matching via meta-learning, bridging multi-level molecular
representations and task-level generalization. Specifically, our approach
explicitly captures structural features across multiple levels, such as atoms,
substructures, and molecules, via hierarchical pooling and matching,
facilitating precise molecular representation and comparison. Additionally, we
employ a meta-learning strategy for implicit task-level matching, allowing the
model to capture shared patterns across tasks and quickly adapt to new ones.
This unified matching framework ensures effective molecular alignment while
leveraging shared meta-knowledge for fast adaptation. Our experimental results
demonstrate that UniMatch outperforms state-of-the-art methods on the
MoleculeNet and FS-Mol benchmarks, achieving improvements of 2.87% in AUROC and
6.52% in delta AUPRC. UniMatch also shows excellent generalization ability on
the Meta-MolNet benchmark.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Drug discovery is crucial for identifying candidate drugs for various\ndiseases.However, its low success rate often results in a scarcity of\nannotations, posing a few-shot learning problem. Existing methods primarily\nfocus on single-scale features, overlooking the hierarchical molecular\nstructures that determine different molecular properties. To address these\nissues, we introduce Universal Matching Networks (UniMatch), a dual matching\nframework that integrates explicit hierarchical molecular matching with\nimplicit task-level matching via meta-learning, bridging multi-level molecular\nrepresentations and task-level generalization. Specifically, our approach\nexplicitly captures structural features across multiple levels, such as atoms,\nsubstructures, and molecules, via hierarchical pooling and matching,\nfacilitating precise molecular representation and comparison. Additionally, we\nemploy a meta-learning strategy for implicit task-level matching, allowing the\nmodel to capture shared patterns across tasks and quickly adapt to new ones.\nThis unified matching framework ensures effective molecular alignment while\nleveraging shared meta-knowledge for fast adaptation. Our experimental results\ndemonstrate that UniMatch outperforms state-of-the-art methods on the\nMoleculeNet and FS-Mol benchmarks, achieving improvements of 2.87% in AUROC and\n6.52% in delta AUPRC. UniMatch also shows excellent generalization ability on\nthe Meta-MolNet benchmark.'}","['Ruifeng Li', 'Mingqian Li', 'Wei Liu', 'Yuhua Zhou', 'Xiangxin Zhou', 'Yuan Yao', 'Qiang Zhang', 'Hongyang Chen']",{'name': 'Hongyang Chen'},Hongyang Chen,accepted as ICLR 2025 Spotlight,"[{'href': 'http://arxiv.org/abs/2502.12453v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12453v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-bio.BM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68U07', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12453v1,None,http://arxiv.org/abs/2502.12453v1,,,16,0
http://arxiv.org/abs/2502.12454v1,True,2025-02-18T02:36:16Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=2, tm_min=36, tm_sec=16, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T02:36:16Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=2, tm_min=36, tm_sec=16, tm_wday=1, tm_yday=49, tm_isdst=0)","Benchmarking Zero-Shot Facial Emotion Annotation with Large Language
  Models: A Multi-Class and Multi-Frame Approach in DailyLife","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Benchmarking Zero-Shot Facial Emotion Annotation with Large Language\n  Models: A Multi-Class and Multi-Frame Approach in DailyLife'}","This study investigates the feasibility and performance of using large
language models (LLMs) to automatically annotate human emotions in everyday
scenarios. We conducted experiments on the DailyLife subset of the publicly
available FERV39k dataset, employing the GPT-4o-mini model for rapid, zero-shot
labeling of key frames extracted from video segments. Under a seven-class
emotion taxonomy (""Angry,"" ""Disgust,"" ""Fear,"" ""Happy,"" ""Neutral,"" ""Sad,""
""Surprise""), the LLM achieved an average precision of approximately 50%. In
contrast, when limited to ternary emotion classification
(negative/neutral/positive), the average precision increased to approximately
64%. Additionally, we explored a strategy that integrates multiple frames
within 1-2 second video clips to enhance labeling performance and reduce costs.
The results indicate that this approach can slightly improve annotation
accuracy. Overall, our preliminary findings highlight the potential application
of zero-shot LLMs in human facial emotion annotation tasks, offering new
avenues for reducing labeling costs and broadening the applicability of LLMs in
complex multimodal environments.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'This study investigates the feasibility and performance of using large\nlanguage models (LLMs) to automatically annotate human emotions in everyday\nscenarios. We conducted experiments on the DailyLife subset of the publicly\navailable FERV39k dataset, employing the GPT-4o-mini model for rapid, zero-shot\nlabeling of key frames extracted from video segments. Under a seven-class\nemotion taxonomy (""Angry,"" ""Disgust,"" ""Fear,"" ""Happy,"" ""Neutral,"" ""Sad,""\n""Surprise""), the LLM achieved an average precision of approximately 50%. In\ncontrast, when limited to ternary emotion classification\n(negative/neutral/positive), the average precision increased to approximately\n64%. Additionally, we explored a strategy that integrates multiple frames\nwithin 1-2 second video clips to enhance labeling performance and reduce costs.\nThe results indicate that this approach can slightly improve annotation\naccuracy. Overall, our preliminary findings highlight the potential application\nof zero-shot LLMs in human facial emotion annotation tasks, offering new\navenues for reducing labeling costs and broadening the applicability of LLMs in\ncomplex multimodal environments.'}","['He Zhang', 'Xinyi Fu']",{'name': 'Xinyi Fu'},Xinyi Fu,10 pages,"[{'href': 'http://arxiv.org/abs/2502.12454v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12454v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12454v1,None,http://arxiv.org/abs/2502.12454v1,,,7,0
http://arxiv.org/abs/2502.12459v1,True,2025-02-18T02:42:53Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=2, tm_min=42, tm_sec=53, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T02:42:53Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=2, tm_min=42, tm_sec=53, tm_wday=1, tm_yday=49, tm_isdst=0)","Stress Testing Generalization: How Minor Modifications Undermine Large
  Language Model Performance","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Stress Testing Generalization: How Minor Modifications Undermine Large\n  Language Model Performance'}","This paper investigates the fragility of Large Language Models (LLMs) in
generalizing to novel inputs, specifically focusing on minor perturbations in
well-established benchmarks (e.g., slight changes in question format or
distractor length). Despite high benchmark scores, LLMs exhibit significant
accuracy drops and unexpected biases (e.g., preference for longer distractors)
when faced with these minor but content-preserving modifications. For example,
Qwen 2.5 1.5B's MMLU score rises from 60 to 89 and drops from 89 to 36 when
option lengths are changed without altering the question. Even GPT-4
experiences a 25-point accuracy loss when question types are changed, with a
6-point drop across all three modification categories. These analyses suggest
that LLMs rely heavily on superficial cues rather than forming robust, abstract
representations that generalize across formats, lexical variations, and
irrelevant content shifts. This work aligns with the ACL 2025 theme track on
the Generalization of NLP models, proposing a ""Generalization Stress Test"" to
assess performance shifts under controlled perturbations. The study calls for
reevaluating benchmarks and developing more reliable evaluation methodologies
to capture LLM generalization abilities better.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'This paper investigates the fragility of Large Language Models (LLMs) in\ngeneralizing to novel inputs, specifically focusing on minor perturbations in\nwell-established benchmarks (e.g., slight changes in question format or\ndistractor length). Despite high benchmark scores, LLMs exhibit significant\naccuracy drops and unexpected biases (e.g., preference for longer distractors)\nwhen faced with these minor but content-preserving modifications. For example,\nQwen 2.5 1.5B\'s MMLU score rises from 60 to 89 and drops from 89 to 36 when\noption lengths are changed without altering the question. Even GPT-4\nexperiences a 25-point accuracy loss when question types are changed, with a\n6-point drop across all three modification categories. These analyses suggest\nthat LLMs rely heavily on superficial cues rather than forming robust, abstract\nrepresentations that generalize across formats, lexical variations, and\nirrelevant content shifts. This work aligns with the ACL 2025 theme track on\nthe Generalization of NLP models, proposing a ""Generalization Stress Test"" to\nassess performance shifts under controlled perturbations. The study calls for\nreevaluating benchmarks and developing more reliable evaluation methodologies\nto capture LLM generalization abilities better.'}","['Guangxiang Zhao', 'Saier Hu', 'Xiaoqi Jian', 'Jinzhu Wu', 'Yuhan Wu', 'Change Jia', 'Lin Sun', 'Xiangzheng Zhang']",{'name': 'Xiangzheng Zhang'},Xiangzheng Zhang,Submitted to ACL 2025 theme track on the Generalization of NLP models,"[{'href': 'http://arxiv.org/abs/2502.12459v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12459v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12459v1,None,http://arxiv.org/abs/2502.12459v1,,,0,0
http://arxiv.org/abs/2502.12481v1,True,2025-02-18T03:08:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=3, tm_min=8, tm_sec=37, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T03:08:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=3, tm_min=8, tm_sec=37, tm_wday=1, tm_yday=49, tm_isdst=0)",Predicate Hierarchies Improve Few-Shot State Classification,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Predicate Hierarchies Improve Few-Shot State Classification'}","State classification of objects and their relations is core to many
long-horizon tasks, particularly in robot planning and manipulation. However,
the combinatorial explosion of possible object-predicate combinations, coupled
with the need to adapt to novel real-world environments, makes it a desideratum
for state classification models to generalize to novel queries with few
examples. To this end, we propose PHIER, which leverages predicate hierarchies
to generalize effectively in few-shot scenarios. PHIER uses an object-centric
scene encoder, self-supervised losses that infer semantic relations between
predicates, and a hyperbolic distance metric that captures hierarchical
structure; it learns a structured latent space of image-predicate pairs that
guides reasoning over state classification queries. We evaluate PHIER in the
CALVIN and BEHAVIOR robotic environments and show that PHIER significantly
outperforms existing methods in few-shot, out-of-distribution state
classification, and demonstrates strong zero- and few-shot generalization from
simulated to real-world tasks. Our results demonstrate that leveraging
predicate hierarchies improves performance on state classification tasks with
limited data.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'State classification of objects and their relations is core to many\nlong-horizon tasks, particularly in robot planning and manipulation. However,\nthe combinatorial explosion of possible object-predicate combinations, coupled\nwith the need to adapt to novel real-world environments, makes it a desideratum\nfor state classification models to generalize to novel queries with few\nexamples. To this end, we propose PHIER, which leverages predicate hierarchies\nto generalize effectively in few-shot scenarios. PHIER uses an object-centric\nscene encoder, self-supervised losses that infer semantic relations between\npredicates, and a hyperbolic distance metric that captures hierarchical\nstructure; it learns a structured latent space of image-predicate pairs that\nguides reasoning over state classification queries. We evaluate PHIER in the\nCALVIN and BEHAVIOR robotic environments and show that PHIER significantly\noutperforms existing methods in few-shot, out-of-distribution state\nclassification, and demonstrates strong zero- and few-shot generalization from\nsimulated to real-world tasks. Our results demonstrate that leveraging\npredicate hierarchies improves performance on state classification tasks with\nlimited data.'}","['Emily Jin', 'Joy Hsu', 'Jiajun Wu']",{'name': 'Jiajun Wu'},Jiajun Wu,"ICLR 2025. First two authors contributed equally. Project page:
  https://emilyzjin.github.io/projects/phier.html","[{'href': 'http://arxiv.org/abs/2502.12481v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12481v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12481v1,None,http://arxiv.org/abs/2502.12481v1,,,149,0
http://arxiv.org/abs/2502.12489v1,True,2025-02-18T03:18:54Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=3, tm_min=18, tm_sec=54, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T03:18:54Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=3, tm_min=18, tm_sec=54, tm_wday=1, tm_yday=49, tm_isdst=0)",A Comprehensive Survey on Generative AI for Video-to-Music Generation,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A Comprehensive Survey on Generative AI for Video-to-Music Generation'}","The burgeoning growth of video-to-music generation can be attributed to the
ascendancy of multimodal generative models. However, there is a lack of
literature that comprehensively combs through the work in this field. To fill
this gap, this paper presents a comprehensive review of video-to-music
generation using deep generative AI techniques, focusing on three key
components: visual feature extraction, music generation frameworks, and
conditioning mechanisms. We categorize existing approaches based on their
designs for each component, clarifying the roles of different strategies.
Preceding this, we provide a fine-grained classification of video and music
modalities, illustrating how different categories influence the design of
components within the generation pipelines. Furthermore, we summarize available
multimodal datasets and evaluation metrics while highlighting ongoing
challenges in the field.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The burgeoning growth of video-to-music generation can be attributed to the\nascendancy of multimodal generative models. However, there is a lack of\nliterature that comprehensively combs through the work in this field. To fill\nthis gap, this paper presents a comprehensive review of video-to-music\ngeneration using deep generative AI techniques, focusing on three key\ncomponents: visual feature extraction, music generation frameworks, and\nconditioning mechanisms. We categorize existing approaches based on their\ndesigns for each component, clarifying the roles of different strategies.\nPreceding this, we provide a fine-grained classification of video and music\nmodalities, illustrating how different categories influence the design of\ncomponents within the generation pipelines. Furthermore, we summarize available\nmultimodal datasets and evaluation metrics while highlighting ongoing\nchallenges in the field.'}","['Shulei Ji', 'Songruoyao Wu', 'Zihao Wang', 'Shuyu Li', 'Kejun Zhang']",{'name': 'Kejun Zhang'},Kejun Zhang,,"[{'href': 'http://arxiv.org/abs/2502.12489v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12489v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'eess.AS', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'eess.AS', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12489v1,None,http://arxiv.org/abs/2502.12489v1,,,72,0
http://arxiv.org/abs/2502.12511v2,True,2025-02-19T02:47:43Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=2, tm_min=47, tm_sec=43, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-18T03:54:25Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=3, tm_min=54, tm_sec=25, tm_wday=1, tm_yday=49, tm_isdst=0)",Myna: Masking-Based Contrastive Learning of Musical Representations,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Myna: Masking-Based Contrastive Learning of Musical Representations'}","We present Myna, a simple yet effective approach for self-supervised musical
representation learning. Built on a contrastive learning framework, Myna
introduces two key innovations: (1) the use of a Vision Transformer (ViT) on
mel-spectrograms as the backbone and (2) a novel data augmentation strategy,
token masking, that masks 90 percent of spectrogram tokens. These innovations
deliver both effectiveness and efficiency: (i) Token masking enables a
significant increase in per-GPU batch size, from 48 or 120 in prior methods
(CLMR, MULE) to 4096. (ii) By avoiding traditional augmentations, Myna retains
pitch sensitivity, enhancing performance in tasks like key detection. (iii) The
use of vertical patches allows the model to better capture critical features
for key detection. Our hybrid model, Myna-22M-Hybrid, processes both 16x16 and
128x2 patches, achieving state-of-the-art results. Trained on a single GPU, it
outperforms MULE (62M) on average and rivals MERT-95M, which was trained on 16
and 64 GPUs, respectively. Additionally, it surpasses MERT-95M-public,
establishing itself as the best-performing model trained on publicly available
data. We release our code and models to promote reproducibility and facilitate
future research.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'We present Myna, a simple yet effective approach for self-supervised musical\nrepresentation learning. Built on a contrastive learning framework, Myna\nintroduces two key innovations: (1) the use of a Vision Transformer (ViT) on\nmel-spectrograms as the backbone and (2) a novel data augmentation strategy,\ntoken masking, that masks 90 percent of spectrogram tokens. These innovations\ndeliver both effectiveness and efficiency: (i) Token masking enables a\nsignificant increase in per-GPU batch size, from 48 or 120 in prior methods\n(CLMR, MULE) to 4096. (ii) By avoiding traditional augmentations, Myna retains\npitch sensitivity, enhancing performance in tasks like key detection. (iii) The\nuse of vertical patches allows the model to better capture critical features\nfor key detection. Our hybrid model, Myna-22M-Hybrid, processes both 16x16 and\n128x2 patches, achieving state-of-the-art results. Trained on a single GPU, it\noutperforms MULE (62M) on average and rivals MERT-95M, which was trained on 16\nand 64 GPUs, respectively. Additionally, it surpasses MERT-95M-public,\nestablishing itself as the best-performing model trained on publicly available\ndata. We release our code and models to promote reproducibility and facilitate\nfuture research.'}","['Ori Yonay', 'Tracy Hammond', 'Tianbao Yang']",{'name': 'Tianbao Yang'},Tianbao Yang,,"[{'href': 'http://arxiv.org/abs/2502.12511v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12511v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.SD', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.SD', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12511v2,None,http://arxiv.org/abs/2502.12511v2,,,0,0
http://arxiv.org/abs/2502.12563v1,True,2025-02-18T05:59:54Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=5, tm_min=59, tm_sec=54, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T05:59:54Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=5, tm_min=59, tm_sec=54, tm_wday=1, tm_yday=49, tm_isdst=0)","Evaluating Language Models on Grooming Risk Estimation Using Fuzzy
  Theory","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Evaluating Language Models on Grooming Risk Estimation Using Fuzzy\n  Theory'}","Encoding implicit language presents a challenge for language models,
especially in high-risk domains where maintaining high precision is important.
Automated detection of online child grooming is one such critical domain, where
predators manipulate victims using a combination of explicit and implicit
language to convey harmful intentions. While recent studies have shown the
potential of Transformer language models like SBERT for preemptive grooming
detection, they primarily depend on surface-level features and approximate real
victim grooming processes using vigilante and law enforcement conversations.
The question of whether these features and approximations are reasonable has
not been addressed thus far. In this paper, we address this gap and study
whether SBERT can effectively discern varying degrees of grooming risk inherent
in conversations, and evaluate its results across different participant groups.
Our analysis reveals that while fine-tuning aids language models in learning to
assign grooming scores, they show high variance in predictions, especially for
contexts containing higher degrees of grooming risk. These errors appear in
cases that 1) utilize indirect speech pathways to manipulate victims and 2)
lack sexually explicit content. This finding underscores the necessity for
robust modeling of indirect speech acts by language models, particularly those
employed by predators.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Encoding implicit language presents a challenge for language models,\nespecially in high-risk domains where maintaining high precision is important.\nAutomated detection of online child grooming is one such critical domain, where\npredators manipulate victims using a combination of explicit and implicit\nlanguage to convey harmful intentions. While recent studies have shown the\npotential of Transformer language models like SBERT for preemptive grooming\ndetection, they primarily depend on surface-level features and approximate real\nvictim grooming processes using vigilante and law enforcement conversations.\nThe question of whether these features and approximations are reasonable has\nnot been addressed thus far. In this paper, we address this gap and study\nwhether SBERT can effectively discern varying degrees of grooming risk inherent\nin conversations, and evaluate its results across different participant groups.\nOur analysis reveals that while fine-tuning aids language models in learning to\nassign grooming scores, they show high variance in predictions, especially for\ncontexts containing higher degrees of grooming risk. These errors appear in\ncases that 1) utilize indirect speech pathways to manipulate victims and 2)\nlack sexually explicit content. This finding underscores the necessity for\nrobust modeling of indirect speech acts by language models, particularly those\nemployed by predators.'}","['Geetanjali Bihani', 'Tatiana Ringenberg', 'Julia Rayz']",{'name': 'Julia Rayz'},Julia Rayz,"9 pages, 2 figures. Accepted for publication in the Proceedings of
  the NAFIPS International Conference on Fuzzy Systems, Soft Computing, and
  Explainable AI. NAFIPS'2024","[{'href': 'http://arxiv.org/abs/2502.12563v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12563v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12563v1,None,http://arxiv.org/abs/2502.12563v1,,,144,0
http://arxiv.org/abs/2502.12576v1,True,2025-02-18T06:26:46Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=6, tm_min=26, tm_sec=46, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T06:26:46Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=6, tm_min=26, tm_sec=46, tm_wday=1, tm_yday=49, tm_isdst=0)",A Fuzzy Evaluation of Sentence Encoders on Grooming Risk Classification,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A Fuzzy Evaluation of Sentence Encoders on Grooming Risk Classification'}","With the advent of social media, children are becoming increasingly
vulnerable to the risk of grooming in online settings. Detecting grooming
instances in an online conversation poses a significant challenge as the
interactions are not necessarily sexually explicit, since the predators take
time to build trust and a relationship with their victim. Moreover, predators
evade detection using indirect and coded language. While previous studies have
fine-tuned Transformers to automatically identify grooming in chat
conversations, they overlook the impact of coded and indirect language on model
predictions, and how these align with human perceptions of grooming. In this
paper, we address this gap and evaluate bi-encoders on the task of classifying
different degrees of grooming risk in chat contexts, for three different
participant groups, i.e. law enforcement officers, real victims, and decoys.
Using a fuzzy-theoretic framework, we map human assessments of grooming
behaviors to estimate the actual degree of grooming risk. Our analysis reveals
that fine-tuned models fail to tag instances where the predator uses indirect
speech pathways and coded language to evade detection. Further, we find that
such instances are characterized by a higher presence of out-of-vocabulary
(OOV) words in samples, causing the model to misclassify. Our findings
highlight the need for more robust models to identify coded language from noisy
chat inputs in grooming contexts.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'With the advent of social media, children are becoming increasingly\nvulnerable to the risk of grooming in online settings. Detecting grooming\ninstances in an online conversation poses a significant challenge as the\ninteractions are not necessarily sexually explicit, since the predators take\ntime to build trust and a relationship with their victim. Moreover, predators\nevade detection using indirect and coded language. While previous studies have\nfine-tuned Transformers to automatically identify grooming in chat\nconversations, they overlook the impact of coded and indirect language on model\npredictions, and how these align with human perceptions of grooming. In this\npaper, we address this gap and evaluate bi-encoders on the task of classifying\ndifferent degrees of grooming risk in chat contexts, for three different\nparticipant groups, i.e. law enforcement officers, real victims, and decoys.\nUsing a fuzzy-theoretic framework, we map human assessments of grooming\nbehaviors to estimate the actual degree of grooming risk. Our analysis reveals\nthat fine-tuned models fail to tag instances where the predator uses indirect\nspeech pathways and coded language to evade detection. Further, we find that\nsuch instances are characterized by a higher presence of out-of-vocabulary\n(OOV) words in samples, causing the model to misclassify. Our findings\nhighlight the need for more robust models to identify coded language from noisy\nchat inputs in grooming contexts.'}","['Geetanjali Bihani', 'Julia Rayz']",{'name': 'Julia Rayz'},Julia Rayz,"8 pages, 2 figures. Accepted for publication in the Proceedings of
  the NAFIPS International Conference on Fuzzy Systems, Soft Computing, and
  Explainable AI. NAFIPS'2024","[{'href': 'http://arxiv.org/abs/2502.12576v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12576v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12576v1,None,http://arxiv.org/abs/2502.12576v1,,,144,0
http://arxiv.org/abs/2502.12581v2,True,2025-02-19T07:01:27Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=7, tm_min=1, tm_sec=27, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-18T06:37:33Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=6, tm_min=37, tm_sec=33, tm_wday=1, tm_yday=49, tm_isdst=0)",The Majority Vote Paradigm Shift: When Popular Meets Optimal,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The Majority Vote Paradigm Shift: When Popular Meets Optimal'}","Reliably labelling data typically requires annotations from multiple human
workers. However, humans are far from being perfect. Hence, it is a common
practice to aggregate labels gathered from multiple annotators to make a more
confident estimate of the true label. Among many aggregation methods, the
simple and well known Majority Vote (MV) selects the class label polling the
highest number of votes. However, despite its importance, the optimality of
MV's label aggregation has not been extensively studied. We address this gap in
our work by characterising the conditions under which MV achieves the
theoretically optimal lower bound on label estimation error. Our results
capture the tolerable limits on annotation noise under which MV can optimally
recover labels for a given class distribution. This certificate of optimality
provides a more principled approach to model selection for label aggregation as
an alternative to otherwise inefficient practices that sometimes include higher
experts, gold labels, etc., that are all marred by the same human uncertainty
despite huge time and monetary costs. Experiments on both synthetic and real
world data corroborate our theoretical findings.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Reliably labelling data typically requires annotations from multiple human\nworkers. However, humans are far from being perfect. Hence, it is a common\npractice to aggregate labels gathered from multiple annotators to make a more\nconfident estimate of the true label. Among many aggregation methods, the\nsimple and well known Majority Vote (MV) selects the class label polling the\nhighest number of votes. However, despite its importance, the optimality of\nMV's label aggregation has not been extensively studied. We address this gap in\nour work by characterising the conditions under which MV achieves the\ntheoretically optimal lower bound on label estimation error. Our results\ncapture the tolerable limits on annotation noise under which MV can optimally\nrecover labels for a given class distribution. This certificate of optimality\nprovides a more principled approach to model selection for label aggregation as\nan alternative to otherwise inefficient practices that sometimes include higher\nexperts, gold labels, etc., that are all marred by the same human uncertainty\ndespite huge time and monetary costs. Experiments on both synthetic and real\nworld data corroborate our theoretical findings.""}","['Antonio Purificato', 'Maria Sofia Bucarelli', 'Anil Kumar Nelakanti', 'Andrea Bacciu', 'Fabrizio Silvestri', 'Amin Mantrach']",{'name': 'Amin Mantrach'},Amin Mantrach,"33 pages, 7 figures","[{'href': 'http://arxiv.org/abs/2502.12581v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12581v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12581v2,None,http://arxiv.org/abs/2502.12581v2,,,1234,0
http://arxiv.org/abs/2502.12617v1,True,2025-02-18T08:02:17Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=8, tm_min=2, tm_sec=17, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T08:02:17Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=8, tm_min=2, tm_sec=17, tm_wday=1, tm_yday=49, tm_isdst=0)","A Graph-Enhanced Deep-Reinforcement Learning Framework for the Aircraft
  Landing Problem","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A Graph-Enhanced Deep-Reinforcement Learning Framework for the Aircraft\n  Landing Problem'}","The Aircraft Landing Problem (ALP) is one of the challenging problems in
aircraft transportation and management. The challenge is to schedule the
arriving aircraft in a sequence so that the cost and delays are optimized.
There are various solution approaches to solving this problem, most of which
are based on operations research algorithms and meta-heuristics. Although
traditional methods perform better on one or the other factors, there remains a
problem of solving real-time rescheduling and computational scalability
altogether. This paper presents a novel deep reinforcement learning (DRL)
framework that combines graph neural networks with actor-critic architectures
to address the ALP. This paper introduces three key contributions: A
graph-based state representation that efficiently captures temporal and spatial
relationships between aircraft, a specialized actor-critic architecture
designed to handle multiple competing objectives in landing scheduling, and a
runway balance strategy that ensures efficient resource utilization while
maintaining safety constraints. The results show that the trained algorithm can
be tested on different problem sets and the results are competitive to
operation research algorithms. The experimental results on standard benchmark
data sets demonstrate a 99.95 reduction in computational time compared to Mixed
Integer Programming (MIP) and 38 higher runway throughput over First Come First
Serve (FCFS) approaches. Therefore, the proposed solution is competitive to
traditional approaches and achieves substantial advancements. Notably, it does
not require retraining, making it particularly suitable for industrial
deployment. The frameworks capability to generate solutions within 1 second
enables real-time rescheduling, addressing critical requirements of air traffic
management.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The Aircraft Landing Problem (ALP) is one of the challenging problems in\naircraft transportation and management. The challenge is to schedule the\narriving aircraft in a sequence so that the cost and delays are optimized.\nThere are various solution approaches to solving this problem, most of which\nare based on operations research algorithms and meta-heuristics. Although\ntraditional methods perform better on one or the other factors, there remains a\nproblem of solving real-time rescheduling and computational scalability\naltogether. This paper presents a novel deep reinforcement learning (DRL)\nframework that combines graph neural networks with actor-critic architectures\nto address the ALP. This paper introduces three key contributions: A\ngraph-based state representation that efficiently captures temporal and spatial\nrelationships between aircraft, a specialized actor-critic architecture\ndesigned to handle multiple competing objectives in landing scheduling, and a\nrunway balance strategy that ensures efficient resource utilization while\nmaintaining safety constraints. The results show that the trained algorithm can\nbe tested on different problem sets and the results are competitive to\noperation research algorithms. The experimental results on standard benchmark\ndata sets demonstrate a 99.95 reduction in computational time compared to Mixed\nInteger Programming (MIP) and 38 higher runway throughput over First Come First\nServe (FCFS) approaches. Therefore, the proposed solution is competitive to\ntraditional approaches and achieves substantial advancements. Notably, it does\nnot require retraining, making it particularly suitable for industrial\ndeployment. The frameworks capability to generate solutions within 1 second\nenables real-time rescheduling, addressing critical requirements of air traffic\nmanagement.'}",['Vatsal Maru'],{'name': 'Vatsal Maru'},Vatsal Maru,"This paper presents a novel deep reinforcement learning framework
  combining graph neural networks with actor-critic architectures to address
  the aircraft landing problem. The framework achieves a 99.95% reduction in
  computational time compared to Mixed Integer Programming while maintaining
  safety compliance, and 38% higher runway throughput over First Come First
  Serve","[{'href': 'http://arxiv.org/abs/2502.12617v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12617v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'eess.SY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12617v1,None,http://arxiv.org/abs/2502.12617v1,,,8,0
http://arxiv.org/abs/2502.12678v1,True,2025-02-18T09:33:48Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=9, tm_min=33, tm_sec=48, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T09:33:48Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=9, tm_min=33, tm_sec=48, tm_wday=1, tm_yday=49, tm_isdst=0)","Multi-Step Alignment as Markov Games: An Optimistic Online Gradient
  Descent Approach with Convergence Guarantees","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Multi-Step Alignment as Markov Games: An Optimistic Online Gradient\n  Descent Approach with Convergence Guarantees'}","Reinforcement Learning from Human Feedback (RLHF) has been highly successful
in aligning large language models with human preferences. While prevalent
methods like DPO have demonstrated strong performance, they frame interactions
with the language model as a bandit problem, which limits their applicability
in real-world scenarios where multi-turn conversations are common.
Additionally, DPO relies on the Bradley-Terry model assumption, which does not
adequately capture the non-transitive nature of human preferences. In this
paper, we address these challenges by modeling the alignment problem as a
two-player constant-sum Markov game, where each player seeks to maximize their
winning rate against the other across all steps of the conversation. Our
approach Multi-step Preference Optimization (MPO) is built upon the natural
actor-critic framework~\citep{peters2008natural}. We further develop OMPO based
on the optimistic online gradient descent
algorithm~\citep{rakhlin2013online,joulani17a}. Theoretically, we provide a
rigorous analysis for both algorithms on convergence and show that OMPO
requires $\mathcal{O}(\epsilon^{-1})$ policy updates to converge to an
$\epsilon$-approximate Nash equilibrium. We also validate the effectiveness of
our method on multi-turn conversations dataset and math reasoning dataset.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Reinforcement Learning from Human Feedback (RLHF) has been highly successful\nin aligning large language models with human preferences. While prevalent\nmethods like DPO have demonstrated strong performance, they frame interactions\nwith the language model as a bandit problem, which limits their applicability\nin real-world scenarios where multi-turn conversations are common.\nAdditionally, DPO relies on the Bradley-Terry model assumption, which does not\nadequately capture the non-transitive nature of human preferences. In this\npaper, we address these challenges by modeling the alignment problem as a\ntwo-player constant-sum Markov game, where each player seeks to maximize their\nwinning rate against the other across all steps of the conversation. Our\napproach Multi-step Preference Optimization (MPO) is built upon the natural\nactor-critic framework~\\citep{peters2008natural}. We further develop OMPO based\non the optimistic online gradient descent\nalgorithm~\\citep{rakhlin2013online,joulani17a}. Theoretically, we provide a\nrigorous analysis for both algorithms on convergence and show that OMPO\nrequires $\\mathcal{O}(\\epsilon^{-1})$ policy updates to converge to an\n$\\epsilon$-approximate Nash equilibrium. We also validate the effectiveness of\nour method on multi-turn conversations dataset and math reasoning dataset.'}","['Yongtao Wu', 'Luca Viano', 'Yihang Chen', 'Zhenyu Zhu', 'Kimon Antonakopoulos', 'Quanquan Gu', 'Volkan Cevher']",{'name': 'Volkan Cevher'},Volkan Cevher,"Accepted as oral presentation in NeurIPS LanGame Workshop, revised
  from ICLR submission","[{'href': 'http://arxiv.org/abs/2502.12678v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12678v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12678v1,None,http://arxiv.org/abs/2502.12678v1,,,13677,0
http://arxiv.org/abs/2502.12690v1,True,2025-02-18T09:51:03Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=9, tm_min=51, tm_sec=3, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T09:51:03Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=9, tm_min=51, tm_sec=3, tm_wday=1, tm_yday=49, tm_isdst=0)","Fast Data Aware Neural Architecture Search via Supernet Accelerated
  Evaluation","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Fast Data Aware Neural Architecture Search via Supernet Accelerated\n  Evaluation'}","Tiny machine learning (TinyML) promises to revolutionize fields such as
healthcare, environmental monitoring, and industrial maintenance by running
machine learning models on low-power embedded systems. However, the complex
optimizations required for successful TinyML deployment continue to impede its
widespread adoption. A promising route to simplifying TinyML is through
automatic machine learning (AutoML), which can distill elaborate optimization
workflows into accessible key decisions. Notably, Hardware Aware Neural
Architecture Searches - where a computer searches for an optimal TinyML model
based on predictive performance and hardware metrics - have gained significant
traction, producing some of today's most widely used TinyML models.
Nevertheless, limiting optimization solely to neural network architectures can
prove insufficient. Because TinyML systems must operate under extremely tight
resource constraints, the choice of input data configuration, such as
resolution or sampling rate, also profoundly impacts overall system efficiency.
Achieving truly optimal TinyML systems thus requires jointly tuning both input
data and model architecture. Despite its importance, this ""Data Aware Neural
Architecture Search"" remains underexplored. To address this gap, we propose a
new state-of-the-art Data Aware Neural Architecture Search technique and
demonstrate its effectiveness on the novel TinyML ``Wake Vision'' dataset. Our
experiments show that across varying time and hardware constraints, Data Aware
Neural Architecture Search consistently discovers superior TinyML systems
compared to purely architecture-focused methods, underscoring the critical role
of data-aware optimization in advancing TinyML.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Tiny machine learning (TinyML) promises to revolutionize fields such as\nhealthcare, environmental monitoring, and industrial maintenance by running\nmachine learning models on low-power embedded systems. However, the complex\noptimizations required for successful TinyML deployment continue to impede its\nwidespread adoption. A promising route to simplifying TinyML is through\nautomatic machine learning (AutoML), which can distill elaborate optimization\nworkflows into accessible key decisions. Notably, Hardware Aware Neural\nArchitecture Searches - where a computer searches for an optimal TinyML model\nbased on predictive performance and hardware metrics - have gained significant\ntraction, producing some of today\'s most widely used TinyML models.\nNevertheless, limiting optimization solely to neural network architectures can\nprove insufficient. Because TinyML systems must operate under extremely tight\nresource constraints, the choice of input data configuration, such as\nresolution or sampling rate, also profoundly impacts overall system efficiency.\nAchieving truly optimal TinyML systems thus requires jointly tuning both input\ndata and model architecture. Despite its importance, this ""Data Aware Neural\nArchitecture Search"" remains underexplored. To address this gap, we propose a\nnew state-of-the-art Data Aware Neural Architecture Search technique and\ndemonstrate its effectiveness on the novel TinyML ``Wake Vision\'\' dataset. Our\nexperiments show that across varying time and hardware constraints, Data Aware\nNeural Architecture Search consistently discovers superior TinyML systems\ncompared to purely architecture-focused methods, underscoring the critical role\nof data-aware optimization in advancing TinyML.'}","['Emil Njor', 'Colby Banbury', 'Xenofon Fafoutis']",{'name': 'Xenofon Fafoutis'},Xenofon Fafoutis,,"[{'href': 'http://arxiv.org/abs/2502.12690v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12690v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T10, 68T20, 68T45', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12690v1,None,http://arxiv.org/abs/2502.12690v1,,,3198,0
http://arxiv.org/abs/2502.12701v1,True,2025-02-18T10:05:40Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=10, tm_min=5, tm_sec=40, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T10:05:40Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=10, tm_min=5, tm_sec=40, tm_wday=1, tm_yday=49, tm_isdst=0)","Translate Smart, not Hard: Cascaded Translation Systems with
  Quality-Aware Deferral","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Translate Smart, not Hard: Cascaded Translation Systems with\n  Quality-Aware Deferral'}","Larger models often outperform smaller ones but come with high computational
costs. Cascading offers a potential solution. By default, it uses smaller
models and defers only some instances to larger, more powerful models. However,
designing effective deferral rules remains a challenge. In this paper, we
propose a simple yet effective approach for machine translation, using existing
quality estimation (QE) metrics as deferral rules. We show that QE-based
deferral allows a cascaded system to match the performance of a larger model
while invoking it for a small fraction (30% to 50%) of the examples,
significantly reducing computational costs. We validate this approach through
both automatic and human evaluation.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Larger models often outperform smaller ones but come with high computational\ncosts. Cascading offers a potential solution. By default, it uses smaller\nmodels and defers only some instances to larger, more powerful models. However,\ndesigning effective deferral rules remains a challenge. In this paper, we\npropose a simple yet effective approach for machine translation, using existing\nquality estimation (QE) metrics as deferral rules. We show that QE-based\ndeferral allows a cascaded system to match the performance of a larger model\nwhile invoking it for a small fraction (30% to 50%) of the examples,\nsignificantly reducing computational costs. We validate this approach through\nboth automatic and human evaluation.'}","['Antnio Farinhas', 'Nuno M. Guerreiro', 'Sweta Agrawal', 'Ricardo Rei', 'Andr F. T. Martins']",{'name': 'Andr F. T. Martins'},Andr F. T. Martins,Preprint,"[{'href': 'http://arxiv.org/abs/2502.12701v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12701v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12701v1,None,http://arxiv.org/abs/2502.12701v1,,,1916,0
http://arxiv.org/abs/2502.12710v1,True,2025-02-18T10:21:27Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=10, tm_min=21, tm_sec=27, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T10:21:27Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=10, tm_min=21, tm_sec=27, tm_wday=1, tm_yday=49, tm_isdst=0)",TREND: A Whitespace Replacement Information Hiding Method,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'TREND: A Whitespace Replacement Information Hiding Method'}","Large Language Models (LLMs) have gained significant popularity in recent
years. Differentiating between a text written by a human and a text generated
by an LLM has become almost impossible. Information hiding techniques such as
digital watermarking or steganography can help by embedding information inside
text without being noticed. However, existing techniques, such as
linguistic-based or format-based methods, change the semantics or do not work
on pure, unformatted text. In this paper, we introduce a novel method for
information hiding termed TREND, which is able to conceal any byte-encoded
sequence within a cover text. The proposed method is implemented as a
multi-platform library using the Kotlin programming language, accompanied by a
command-line tool and a web interface provided as examples of usage. By
substituting conventional whitespace characters with visually similar Unicode
whitespace characters, our proposed scheme preserves the semantics of the cover
text without increasing the number of characters. Furthermore, we propose a
specified structure for secret messages that enables configurable compression,
encryption, hashing, and error correction. Our experimental benchmark
comparison on a dataset of one million Wikipedia articles compares ten
algorithms from literature and practice. It proves the robustness of our
proposed method in various applications while remaining imperceptible to
humans. We discuss the limitations of limited embedding capacity and further
robustness, which guide implications for future work.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Language Models (LLMs) have gained significant popularity in recent\nyears. Differentiating between a text written by a human and a text generated\nby an LLM has become almost impossible. Information hiding techniques such as\ndigital watermarking or steganography can help by embedding information inside\ntext without being noticed. However, existing techniques, such as\nlinguistic-based or format-based methods, change the semantics or do not work\non pure, unformatted text. In this paper, we introduce a novel method for\ninformation hiding termed TREND, which is able to conceal any byte-encoded\nsequence within a cover text. The proposed method is implemented as a\nmulti-platform library using the Kotlin programming language, accompanied by a\ncommand-line tool and a web interface provided as examples of usage. By\nsubstituting conventional whitespace characters with visually similar Unicode\nwhitespace characters, our proposed scheme preserves the semantics of the cover\ntext without increasing the number of characters. Furthermore, we propose a\nspecified structure for secret messages that enables configurable compression,\nencryption, hashing, and error correction. Our experimental benchmark\ncomparison on a dataset of one million Wikipedia articles compares ten\nalgorithms from literature and practice. It proves the robustness of our\nproposed method in various applications while remaining imperceptible to\nhumans. We discuss the limitations of limited embedding capacity and further\nrobustness, which guide implications for future work.'}","['Malte Hellmeier', 'Hendrik Norkowski', 'Ernst-Christoph Schrewe', 'Haydar Qarawlus', 'Falk Howar']",{'name': 'Falk Howar'},Falk Howar,,"[{'href': 'http://arxiv.org/abs/2502.12710v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12710v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12710v1,None,http://arxiv.org/abs/2502.12710v1,,,119,0
http://arxiv.org/abs/2502.12745v1,True,2025-02-18T11:05:38Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=11, tm_min=5, tm_sec=38, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T11:05:38Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=11, tm_min=5, tm_sec=38, tm_wday=1, tm_yday=49, tm_isdst=0)",MediaMind: Revolutionizing Media Monitoring using Agentification,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'MediaMind: Revolutionizing Media Monitoring using Agentification'}","In an era of rapid technological advancements, agentification of software
tools has emerged as a critical innovation, enabling systems to function
autonomously and adaptively. This paper introduces MediaMind as a case study to
demonstrate the agentification process, highlighting how existing software can
be transformed into intelligent agents capable of independent decision-making
and dynamic interaction. Developed by aiXplain, MediaMind leverages agent-based
architecture to autonomously monitor, analyze, and provide insights from
multilingual media content in real time. The focus of this paper is on the
technical methodologies and design principles behind agentifying MediaMind,
showcasing how agentification enhances adaptability, efficiency, and
responsiveness. Through detailed case studies and practical examples, we
illustrate how the agentification of MediaMind empowers organizations to
streamline workflows, optimize decision-making, and respond to evolving trends.
This work underscores the broader potential of agentification to revolutionize
software tools across various domains.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'In an era of rapid technological advancements, agentification of software\ntools has emerged as a critical innovation, enabling systems to function\nautonomously and adaptively. This paper introduces MediaMind as a case study to\ndemonstrate the agentification process, highlighting how existing software can\nbe transformed into intelligent agents capable of independent decision-making\nand dynamic interaction. Developed by aiXplain, MediaMind leverages agent-based\narchitecture to autonomously monitor, analyze, and provide insights from\nmultilingual media content in real time. The focus of this paper is on the\ntechnical methodologies and design principles behind agentifying MediaMind,\nshowcasing how agentification enhances adaptability, efficiency, and\nresponsiveness. Through detailed case studies and practical examples, we\nillustrate how the agentification of MediaMind empowers organizations to\nstreamline workflows, optimize decision-making, and respond to evolving trends.\nThis work underscores the broader potential of agentification to revolutionize\nsoftware tools across various domains.'}","['Ahmet Gunduz', 'Kamer Ali Yuksel', 'Hassan Sawaf']",{'name': 'Hassan Sawaf'},Hassan Sawaf,,"[{'href': 'http://arxiv.org/abs/2502.12745v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12745v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12745v1,None,http://arxiv.org/abs/2502.12745v1,,,1252,0
http://arxiv.org/abs/2502.12755v1,True,2025-02-18T11:16:38Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=11, tm_min=16, tm_sec=38, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T11:16:38Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=11, tm_min=16, tm_sec=38, tm_wday=1, tm_yday=49, tm_isdst=0)","Efficient Machine Translation Corpus Generation: Integrating
  Human-in-the-Loop Post-Editing with Large Language Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Efficient Machine Translation Corpus Generation: Integrating\n  Human-in-the-Loop Post-Editing with Large Language Models'}","This paper introduces an advanced methodology for machine translation (MT)
corpus generation, integrating semi-automated, human-in-the-loop post-editing
with large language models (LLMs) to enhance efficiency and translation
quality. Building upon previous work that utilized real-time training of a
custom MT quality estimation metric, this system incorporates novel LLM
features such as Enhanced Translation Synthesis and Assisted Annotation
Analysis, which improve initial translation hypotheses and quality assessments,
respectively. Additionally, the system employs LLM-Driven Pseudo Labeling and a
Translation Recommendation System to reduce human annotator workload in
specific contexts. These improvements not only retain the original benefits of
cost reduction and enhanced post-edit quality but also open new avenues for
leveraging cutting-edge LLM advancements. The project's source code is
available for community use, promoting collaborative developments in the field.
The demo video can be accessed here.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""This paper introduces an advanced methodology for machine translation (MT)\ncorpus generation, integrating semi-automated, human-in-the-loop post-editing\nwith large language models (LLMs) to enhance efficiency and translation\nquality. Building upon previous work that utilized real-time training of a\ncustom MT quality estimation metric, this system incorporates novel LLM\nfeatures such as Enhanced Translation Synthesis and Assisted Annotation\nAnalysis, which improve initial translation hypotheses and quality assessments,\nrespectively. Additionally, the system employs LLM-Driven Pseudo Labeling and a\nTranslation Recommendation System to reduce human annotator workload in\nspecific contexts. These improvements not only retain the original benefits of\ncost reduction and enhanced post-edit quality but also open new avenues for\nleveraging cutting-edge LLM advancements. The project's source code is\navailable for community use, promoting collaborative developments in the field.\nThe demo video can be accessed here.""}","['Kamer Ali Yuksel', 'Ahmet Gunduz', 'Abdul Baseet Anees', 'Hassan Sawaf']",{'name': 'Hassan Sawaf'},Hassan Sawaf,,"[{'href': 'http://arxiv.org/abs/2502.12755v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12755v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12755v1,None,http://arxiv.org/abs/2502.12755v1,,,1252,0
http://arxiv.org/abs/2502.12776v1,True,2025-02-18T11:36:33Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=11, tm_min=36, tm_sec=33, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T11:36:33Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=11, tm_min=36, tm_sec=33, tm_wday=1, tm_yday=49, tm_isdst=0)","Portable Reward Tuning: Towards Reusable Fine-Tuning across Different
  Pretrained Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Portable Reward Tuning: Towards Reusable Fine-Tuning across Different\n  Pretrained Models'}","While foundation models have been exploited for various expert tasks through
fine-tuning, any foundation model will become outdated due to its old knowledge
or limited capability. Thus the underlying foundation model should be
eventually replaced by new ones, which leads to repeated cost of fine-tuning
these new models. Existing work addresses this problem by inference-time
tuning, i.e., modifying the output probabilities from the new foundation model
with the outputs from the old foundation model and its fine-tuned model, which
involves an additional overhead in inference by the latter two models. In this
paper, we propose a new fine-tuning principle, Portable Reward Tuning (PRT),
that reduces the inference overhead by its nature, based on the reformulation
of fine-tuning as the reward maximization. Specifically, instead of fine-tuning
parameters of the foundation models, PRT trains the reward model explicitly
through the same loss function as in fine-tuning. During inference, the reward
model can be used with any foundation model (with the same set of vocabularies
or labels) through the formulation of reward maximization. Experimental
results, covering both vision and language models, demonstrate that the
PRT-trained model can achieve comparable accuracy to the existing work of
inference-time tuning, with less inference cost.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'While foundation models have been exploited for various expert tasks through\nfine-tuning, any foundation model will become outdated due to its old knowledge\nor limited capability. Thus the underlying foundation model should be\neventually replaced by new ones, which leads to repeated cost of fine-tuning\nthese new models. Existing work addresses this problem by inference-time\ntuning, i.e., modifying the output probabilities from the new foundation model\nwith the outputs from the old foundation model and its fine-tuned model, which\ninvolves an additional overhead in inference by the latter two models. In this\npaper, we propose a new fine-tuning principle, Portable Reward Tuning (PRT),\nthat reduces the inference overhead by its nature, based on the reformulation\nof fine-tuning as the reward maximization. Specifically, instead of fine-tuning\nparameters of the foundation models, PRT trains the reward model explicitly\nthrough the same loss function as in fine-tuning. During inference, the reward\nmodel can be used with any foundation model (with the same set of vocabularies\nor labels) through the formulation of reward maximization. Experimental\nresults, covering both vision and language models, demonstrate that the\nPRT-trained model can achieve comparable accuracy to the existing work of\ninference-time tuning, with less inference cost.'}","['Daiki Chijiwa', 'Taku Hasegawa', 'Kyosuke Nishida', 'Kuniko Saito', 'Susumu Takeuchi']",{'name': 'Susumu Takeuchi'},Susumu Takeuchi,,"[{'href': 'http://arxiv.org/abs/2502.12776v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12776v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12776v1,None,http://arxiv.org/abs/2502.12776v1,,,162,0
http://arxiv.org/abs/2502.12793v1,True,2025-02-18T11:54:12Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=11, tm_min=54, tm_sec=12, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T11:54:12Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=11, tm_min=54, tm_sec=12, tm_wday=1, tm_yday=49, tm_isdst=0)",Unsupervised Anomaly Detection through Mass Repulsing Optimal Transport,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Unsupervised Anomaly Detection through Mass Repulsing Optimal Transport'}","Detecting anomalies in datasets is a longstanding problem in machine
learning. In this context, anomalies are defined as a sample that significantly
deviates from the remaining data. Meanwhile, optimal transport (OT) is a field
of mathematics concerned with the transportation, between two probability
measures, at least effort. In classical OT, the optimal transportation strategy
of a measure to itself is the identity. In this paper, we tackle anomaly
detection by forcing samples to displace its mass, while keeping the least
effort objective. We call this new transportation problem Mass Repulsing
Optimal Transport (MROT). Naturally, samples lying in low density regions of
space will be forced to displace mass very far, incurring a higher
transportation cost. We use these concepts to design a new anomaly score.
Through a series of experiments in existing benchmarks, and fault detection
problems, we show that our algorithm improves over existing methods.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Detecting anomalies in datasets is a longstanding problem in machine\nlearning. In this context, anomalies are defined as a sample that significantly\ndeviates from the remaining data. Meanwhile, optimal transport (OT) is a field\nof mathematics concerned with the transportation, between two probability\nmeasures, at least effort. In classical OT, the optimal transportation strategy\nof a measure to itself is the identity. In this paper, we tackle anomaly\ndetection by forcing samples to displace its mass, while keeping the least\neffort objective. We call this new transportation problem Mass Repulsing\nOptimal Transport (MROT). Naturally, samples lying in low density regions of\nspace will be forced to displace mass very far, incurring a higher\ntransportation cost. We use these concepts to design a new anomaly score.\nThrough a series of experiments in existing benchmarks, and fault detection\nproblems, we show that our algorithm improves over existing methods.'}","['Eduardo Fernandes Montesuma', 'Adel El Habazi', 'Fred Ngole Mboula']",{'name': 'Fred Ngole Mboula'},Fred Ngole Mboula,"15 pages, 9 figures, 1 table, under review","[{'href': 'http://arxiv.org/abs/2502.12793v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12793v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12793v1,None,http://arxiv.org/abs/2502.12793v1,,,99,0
http://arxiv.org/abs/2502.12798v1,True,2025-02-18T12:00:35Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=12, tm_min=0, tm_sec=35, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T12:00:35Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=12, tm_min=0, tm_sec=35, tm_wday=1, tm_yday=49, tm_isdst=0)",Envious Explore and Exploit,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Envious Explore and Exploit'}","Explore-and-exploit tradeoffs play a key role in recommendation systems
(RSs), aiming at serving users better by learning from previous interactions.
Despite their commercial success, the societal effects of explore-and-exploit
mechanisms are not well understood, especially regarding the utility
discrepancy they generate between different users. In this work, we measure
such discrepancy using the economic notion of envy. We present a multi-armed
bandit-like model in which every round consists of several sessions, and
rewards are realized once per round. We call the latter property reward
consistency, and show that the RS can leverage this property for better
societal outcomes. On the downside, doing so also generates envy, as
late-to-arrive users enjoy the information gathered by early-to-arrive users.
We examine the generated envy under several arrival order mechanisms and
virtually any anonymous algorithm, i.e., any algorithm that treats all similar
users similarly without leveraging their identities. We provide tight envy
bounds on uniform arrival and upper bound the envy for nudged arrival, in which
the RS can affect the order of arrival by nudging its users. Furthermore, we
study the efficiency-fairness trade-off by devising an algorithm that allows
constant envy and approximates the optimal welfare in restricted settings.
Finally, we validate our theoretical results empirically using simulations.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Explore-and-exploit tradeoffs play a key role in recommendation systems\n(RSs), aiming at serving users better by learning from previous interactions.\nDespite their commercial success, the societal effects of explore-and-exploit\nmechanisms are not well understood, especially regarding the utility\ndiscrepancy they generate between different users. In this work, we measure\nsuch discrepancy using the economic notion of envy. We present a multi-armed\nbandit-like model in which every round consists of several sessions, and\nrewards are realized once per round. We call the latter property reward\nconsistency, and show that the RS can leverage this property for better\nsocietal outcomes. On the downside, doing so also generates envy, as\nlate-to-arrive users enjoy the information gathered by early-to-arrive users.\nWe examine the generated envy under several arrival order mechanisms and\nvirtually any anonymous algorithm, i.e., any algorithm that treats all similar\nusers similarly without leveraging their identities. We provide tight envy\nbounds on uniform arrival and upper bound the envy for nudged arrival, in which\nthe RS can affect the order of arrival by nudging its users. Furthermore, we\nstudy the efficiency-fairness trade-off by devising an algorithm that allows\nconstant envy and approximates the optimal welfare in restricted settings.\nFinally, we validate our theoretical results empirically using simulations.'}","['Omer Ben-Porat', 'Yotam Gafni', 'Or Markovetzki']",{'name': 'Or Markovetzki'},Or Markovetzki,,"[{'href': 'http://arxiv.org/abs/2502.12798v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12798v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12798v1,None,http://arxiv.org/abs/2502.12798v1,,,56,0
http://arxiv.org/abs/2502.12855v1,True,2025-02-18T13:43:06Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=13, tm_min=43, tm_sec=6, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T13:43:06Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=13, tm_min=43, tm_sec=6, tm_wday=1, tm_yday=49, tm_isdst=0)","Integrating Arithmetic Learning Improves Mathematical Reasoning in
  Smaller Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Integrating Arithmetic Learning Improves Mathematical Reasoning in\n  Smaller Models'}","While large models pre-trained on high-quality data exhibit excellent
performance across various reasoning tasks, including mathematical reasoning
(e.g. GSM8k, MultiArith), specializing smaller models to excel at mathematical
reasoning remains a challenging problem. Common approaches to address this
challenge include knowledge distillation, where smaller student models learn
from large pre-trained teacher models, and data augmentation, such as
rephrasing questions. Despite these efforts, smaller models struggle with
arithmetic computations, leading to errors in mathematical reasoning. In this
work, we focus on leveraging a programmatically generated arithmetic dataset to
enhance the reasoning capabilities of smaller models. We investigate two key
approaches to incorporate this dataset -- (1) intermediate fine-tuning, where a
model is fine-tuned on the arithmetic dataset before being trained on a
reasoning dataset, and (2) integrating the arithmetic dataset into the
instruction-tuning mixture, allowing the model to learn arithmetic skills
alongside general instruction-following abilities. Our experiments on multiple
reasoning benchmarks demonstrate that incorporating an arithmetic dataset,
whether through targeted fine-tuning or within the instruction-tuning mixture,
enhances the models' arithmetic capabilities, which in turn improves their
mathematical reasoning performance.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""While large models pre-trained on high-quality data exhibit excellent\nperformance across various reasoning tasks, including mathematical reasoning\n(e.g. GSM8k, MultiArith), specializing smaller models to excel at mathematical\nreasoning remains a challenging problem. Common approaches to address this\nchallenge include knowledge distillation, where smaller student models learn\nfrom large pre-trained teacher models, and data augmentation, such as\nrephrasing questions. Despite these efforts, smaller models struggle with\narithmetic computations, leading to errors in mathematical reasoning. In this\nwork, we focus on leveraging a programmatically generated arithmetic dataset to\nenhance the reasoning capabilities of smaller models. We investigate two key\napproaches to incorporate this dataset -- (1) intermediate fine-tuning, where a\nmodel is fine-tuned on the arithmetic dataset before being trained on a\nreasoning dataset, and (2) integrating the arithmetic dataset into the\ninstruction-tuning mixture, allowing the model to learn arithmetic skills\nalongside general instruction-following abilities. Our experiments on multiple\nreasoning benchmarks demonstrate that incorporating an arithmetic dataset,\nwhether through targeted fine-tuning or within the instruction-tuning mixture,\nenhances the models' arithmetic capabilities, which in turn improves their\nmathematical reasoning performance.""}","['Neeraj Gangwar', 'Suma P Bhat', 'Nickvash Kani']",{'name': 'Nickvash Kani'},Nickvash Kani,Preprint,"[{'href': 'http://arxiv.org/abs/2502.12855v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12855v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12855v1,None,http://arxiv.org/abs/2502.12855v1,,,174,0
http://arxiv.org/abs/2502.12858v1,True,2025-02-18T13:45:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=13, tm_min=45, tm_sec=42, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T13:45:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=13, tm_min=45, tm_sec=42, tm_wday=1, tm_yday=49, tm_isdst=0)","Rejected Dialects: Biases Against African American Language in Reward
  Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Rejected Dialects: Biases Against African American Language in Reward\n  Models'}","Preference alignment via reward models helps build safe, helpful, and
reliable large language models (LLMs). However, subjectivity in preference
judgments and the lack of representative sampling in preference data collection
can introduce new biases, hindering reward models' fairness and equity. In this
work, we introduce a framework for evaluating dialect biases in reward models
and conduct a case study on biases against African American Language (AAL)
through several experiments comparing reward model preferences and behavior on
paired White Mainstream English (WME) and both machine-translated and
human-written AAL corpora. We show that reward models are less aligned with
human preferences when processing AAL texts vs. WME ones (-4\% accuracy on
average), frequently disprefer AAL-aligned texts vs. WME-aligned ones, and
steer conversations toward WME, even when prompted with AAL texts. Our findings
provide a targeted analysis of anti-AAL biases at a relatively understudied
stage in LLM development, highlighting representational harms and ethical
questions about the desired behavior of LLMs concerning AAL.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Preference alignment via reward models helps build safe, helpful, and\nreliable large language models (LLMs). However, subjectivity in preference\njudgments and the lack of representative sampling in preference data collection\ncan introduce new biases, hindering reward models' fairness and equity. In this\nwork, we introduce a framework for evaluating dialect biases in reward models\nand conduct a case study on biases against African American Language (AAL)\nthrough several experiments comparing reward model preferences and behavior on\npaired White Mainstream English (WME) and both machine-translated and\nhuman-written AAL corpora. We show that reward models are less aligned with\nhuman preferences when processing AAL texts vs. WME ones (-4\\% accuracy on\naverage), frequently disprefer AAL-aligned texts vs. WME-aligned ones, and\nsteer conversations toward WME, even when prompted with AAL texts. Our findings\nprovide a targeted analysis of anti-AAL biases at a relatively understudied\nstage in LLM development, highlighting representational harms and ethical\nquestions about the desired behavior of LLMs concerning AAL.""}","['Joel Mire', 'Zubin Trivadi Aysola', 'Daniel Chechelnitsky', 'Nicholas Deas', 'Chrysoula Zerva', 'Maarten Sap']",{'name': 'Maarten Sap'},Maarten Sap,Accepted to NAACL Findings 2025,"[{'href': 'http://arxiv.org/abs/2502.12858v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12858v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7; K.4.2', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12858v1,None,http://arxiv.org/abs/2502.12858v1,,,11224,0
http://arxiv.org/abs/2502.12900v1,True,2025-02-18T14:36:39Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=14, tm_min=36, tm_sec=39, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T14:36:39Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=14, tm_min=36, tm_sec=39, tm_wday=1, tm_yday=49, tm_isdst=0)",Soundwave: Less is More for Speech-Text Alignment in LLMs,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Soundwave: Less is More for Speech-Text Alignment in LLMs'}","Existing end-to-end speech large language models (LLMs) usually rely on
large-scale annotated data for training, while data-efficient training has not
been discussed in depth. We focus on two fundamental problems between speech
and text: the representation space gap and sequence length inconsistency. We
propose Soundwave, which utilizes an efficient training strategy and a novel
architecture to address these issues. Results show that Soundwave outperforms
the advanced Qwen2-Audio in speech translation and AIR-Bench speech tasks,
using only one-fiftieth of the training data. Further analysis shows that
Soundwave still retains its intelligence during conversation. The project is
available at https://github.com/FreedomIntelligence/Soundwave.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Existing end-to-end speech large language models (LLMs) usually rely on\nlarge-scale annotated data for training, while data-efficient training has not\nbeen discussed in depth. We focus on two fundamental problems between speech\nand text: the representation space gap and sequence length inconsistency. We\npropose Soundwave, which utilizes an efficient training strategy and a novel\narchitecture to address these issues. Results show that Soundwave outperforms\nthe advanced Qwen2-Audio in speech translation and AIR-Bench speech tasks,\nusing only one-fiftieth of the training data. Further analysis shows that\nSoundwave still retains its intelligence during conversation. The project is\navailable at https://github.com/FreedomIntelligence/Soundwave.'}","['Yuhao Zhang', 'Zhiheng Liu', 'Fan Bu', 'Ruiyu Zhang', 'Benyou Wang', 'Haizhou Li']",{'name': 'Haizhou Li'},Haizhou Li,,"[{'href': 'http://arxiv.org/abs/2502.12900v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12900v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SD', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12900v1,None,http://arxiv.org/abs/2502.12900v1,,,0,0
http://arxiv.org/abs/2502.12913v1,True,2025-02-18T14:54:55Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=14, tm_min=54, tm_sec=55, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T14:54:55Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=14, tm_min=54, tm_sec=55, tm_wday=1, tm_yday=49, tm_isdst=0)","GSQ-Tuning: Group-Shared Exponents Integer in Fully Quantized Training
  for LLMs On-Device Fine-tuning","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'GSQ-Tuning: Group-Shared Exponents Integer in Fully Quantized Training\n  for LLMs On-Device Fine-tuning'}","Large Language Models (LLMs) fine-tuning technologies have achieved
remarkable results. However, traditional LLM fine-tuning approaches face
significant challenges: they require large Floating Point (FP) computation,
raising privacy concerns when handling sensitive data, and are impractical for
resource-constrained edge devices. While Parameter-Efficient Fine-Tuning (PEFT)
techniques reduce trainable parameters, their reliance on floating-point
arithmetic creates fundamental incompatibilities with edge hardware. In this
work, we introduce a novel framework for on-device LLM fine-tuning that
eliminates the need for floating-point operations in both inference and
training, named GSQ-Tuning. At its core is the Group-Shared Exponents Integer
format, which efficiently represents model parameters in integer format using
shared exponents among parameter groups. When combined with LoRA-like adapters,
this enables fully integer-based fine-tuning that is both memory and compute
efficient. We demonstrate that our approach achieves accuracy comparable to
FP16-based fine-tuning while significantly reducing memory usage (50%).
Moreover, compared to FP8, our method can reduce 5x power consumption and 11x
chip area with same performance, making large-scale model adaptation feasible
on edge devices.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Language Models (LLMs) fine-tuning technologies have achieved\nremarkable results. However, traditional LLM fine-tuning approaches face\nsignificant challenges: they require large Floating Point (FP) computation,\nraising privacy concerns when handling sensitive data, and are impractical for\nresource-constrained edge devices. While Parameter-Efficient Fine-Tuning (PEFT)\ntechniques reduce trainable parameters, their reliance on floating-point\narithmetic creates fundamental incompatibilities with edge hardware. In this\nwork, we introduce a novel framework for on-device LLM fine-tuning that\neliminates the need for floating-point operations in both inference and\ntraining, named GSQ-Tuning. At its core is the Group-Shared Exponents Integer\nformat, which efficiently represents model parameters in integer format using\nshared exponents among parameter groups. When combined with LoRA-like adapters,\nthis enables fully integer-based fine-tuning that is both memory and compute\nefficient. We demonstrate that our approach achieves accuracy comparable to\nFP16-based fine-tuning while significantly reducing memory usage (50%).\nMoreover, compared to FP8, our method can reduce 5x power consumption and 11x\nchip area with same performance, making large-scale model adaptation feasible\non edge devices.'}","['Sifan Zhou', 'Shuo Wang', 'Zhihang Yuan', 'Mingjia Shi', 'Yuzhang Shang', 'Dawei Yang']",{'name': 'Dawei Yang'},Dawei Yang,,"[{'href': 'http://arxiv.org/abs/2502.12913v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12913v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12913v1,None,http://arxiv.org/abs/2502.12913v1,,,11,0
http://arxiv.org/abs/2502.12929v1,True,2025-02-18T15:11:46Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=15, tm_min=11, tm_sec=46, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T15:11:46Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=15, tm_min=11, tm_sec=46, tm_wday=1, tm_yday=49, tm_isdst=0)","Flow-of-Options: Diversified and Improved LLM Reasoning by Thinking
  Through Options","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Flow-of-Options: Diversified and Improved LLM Reasoning by Thinking\n  Through Options'}","We present a novel reasoning approach called Flow-of-Options (FoO), designed
to address intrinsic biases in Large Language Models (LLMs). FoO enables LLMs
to systematically explore a diverse range of possibilities in their reasoning,
as demonstrated by an FoO-based agentic system for autonomously solving Machine
Learning tasks (AutoML). Our framework outperforms state-of-the-art baselines,
achieving improvements of 38.2% - 69.2% on standard data science tasks, and
37.4% - 47.9% on therapeutic chemistry tasks. With an overall operation cost
under $1 per task, our framework is well-suited for cost-sensitive
applications. Beyond classification and regression, we illustrate the broader
applicability of our FoO-based agentic system to tasks such as reinforcement
learning and image generation. Our framework presents significant advancements
compared to current state-of-the-art agentic systems for AutoML, due to the
benefits of FoO in enforcing diversity in LLM solutions through compressed,
explainable representations that also support long-term memory when combined
with case-based reasoning.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'We present a novel reasoning approach called Flow-of-Options (FoO), designed\nto address intrinsic biases in Large Language Models (LLMs). FoO enables LLMs\nto systematically explore a diverse range of possibilities in their reasoning,\nas demonstrated by an FoO-based agentic system for autonomously solving Machine\nLearning tasks (AutoML). Our framework outperforms state-of-the-art baselines,\nachieving improvements of 38.2% - 69.2% on standard data science tasks, and\n37.4% - 47.9% on therapeutic chemistry tasks. With an overall operation cost\nunder $1 per task, our framework is well-suited for cost-sensitive\napplications. Beyond classification and regression, we illustrate the broader\napplicability of our FoO-based agentic system to tasks such as reinforcement\nlearning and image generation. Our framework presents significant advancements\ncompared to current state-of-the-art agentic systems for AutoML, due to the\nbenefits of FoO in enforcing diversity in LLM solutions through compressed,\nexplainable representations that also support long-term memory when combined\nwith case-based reasoning.'}","['Lakshmi Nair', 'Ian Trase', 'Mark Kim']",{'name': 'Mark Kim'},Mark Kim,Github code: https://github.com/flagshippioneering/Flow-of-Options,"[{'href': 'http://arxiv.org/abs/2502.12929v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12929v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12929v1,None,http://arxiv.org/abs/2502.12929v1,,,764,0
http://arxiv.org/abs/2502.12947v1,True,2025-02-18T15:30:34Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=15, tm_min=30, tm_sec=34, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T15:30:34Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=15, tm_min=30, tm_sec=34, tm_wday=1, tm_yday=49, tm_isdst=0)","Every Expert Matters: Towards Effective Knowledge Distillation for
  Mixture-of-Experts Language Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Every Expert Matters: Towards Effective Knowledge Distillation for\n  Mixture-of-Experts Language Models'}","With the emergence of Mixture-of-Experts (MoE), the efficient scaling of
model size has accelerated the development of large language models in recent
years. However, their high memory requirements prevent their use in
resource-constrained environments. While knowledge distillation (KD) has been a
proven method for model compression, its application to MoE teacher models
remains underexplored. Through our investigation, we discover that
non-activated experts in MoE models possess valuable knowledge that benefits
student models. We further demonstrate that existing KD methods are not optimal
for compressing MoE models, as they fail to leverage this knowledge
effectively. To address this, we propose two intuitive MoE-specific KD methods
for the first time: Knowledge Augmentation (KA) and Student-Aware Router (SAR),
both designed to effectively extract knowledge from all experts. Specifically,
KA augments knowledge by sampling experts multiple times, while SAR uses all
experts and adjusts the expert weights through router training to provide
optimal knowledge. Extensive experiments show that our methods outperform
conventional KD methods, demonstrating their effectiveness for MoE teacher
models.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'With the emergence of Mixture-of-Experts (MoE), the efficient scaling of\nmodel size has accelerated the development of large language models in recent\nyears. However, their high memory requirements prevent their use in\nresource-constrained environments. While knowledge distillation (KD) has been a\nproven method for model compression, its application to MoE teacher models\nremains underexplored. Through our investigation, we discover that\nnon-activated experts in MoE models possess valuable knowledge that benefits\nstudent models. We further demonstrate that existing KD methods are not optimal\nfor compressing MoE models, as they fail to leverage this knowledge\neffectively. To address this, we propose two intuitive MoE-specific KD methods\nfor the first time: Knowledge Augmentation (KA) and Student-Aware Router (SAR),\nboth designed to effectively extract knowledge from all experts. Specifically,\nKA augments knowledge by sampling experts multiple times, while SAR uses all\nexperts and adjusts the expert weights through router training to provide\noptimal knowledge. Extensive experiments show that our methods outperform\nconventional KD methods, demonstrating their effectiveness for MoE teacher\nmodels.'}","['Gyeongman Kim', 'Gyouk Chu', 'Eunho Yang']",{'name': 'Eunho Yang'},Eunho Yang,,"[{'href': 'http://arxiv.org/abs/2502.12947v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12947v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12947v1,None,http://arxiv.org/abs/2502.12947v1,,,71,0
http://arxiv.org/abs/2502.12953v1,True,2025-02-18T15:36:16Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=15, tm_min=36, tm_sec=16, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T15:36:16Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=15, tm_min=36, tm_sec=16, tm_wday=1, tm_yday=49, tm_isdst=0)","Task-Informed Anti-Curriculum by Masking Improves Downstream Performance
  on Text","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Task-Informed Anti-Curriculum by Masking Improves Downstream Performance\n  on Text'}","Masked language modeling has become a widely adopted unsupervised technique
to pre-train language models. However, the process of selecting tokens for
masking is random, and the percentage of masked tokens is typically fixed for
the entire training process. In this paper, we propose to adjust the masking
ratio and to decide which tokens to mask based on a novel task-informed
anti-curriculum learning scheme. First, we harness task-specific knowledge
about useful and harmful tokens in order to determine which tokens to mask.
Second, we propose a cyclic decaying masking ratio, which corresponds to an
anti-curriculum schedule (from hard to easy). We exemplify our novel
task-informed anti-curriculum by masking (TIACBM) approach across three diverse
downstream tasks: sentiment analysis, text classification by topic, and
authorship attribution. Our findings suggest that TIACBM enhances the ability
of the model to focus on key task-relevant features, contributing to
statistically significant performance gains across tasks. We release our code
at https://github.com/JarcaAndrei/TIACBM.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Masked language modeling has become a widely adopted unsupervised technique\nto pre-train language models. However, the process of selecting tokens for\nmasking is random, and the percentage of masked tokens is typically fixed for\nthe entire training process. In this paper, we propose to adjust the masking\nratio and to decide which tokens to mask based on a novel task-informed\nanti-curriculum learning scheme. First, we harness task-specific knowledge\nabout useful and harmful tokens in order to determine which tokens to mask.\nSecond, we propose a cyclic decaying masking ratio, which corresponds to an\nanti-curriculum schedule (from hard to easy). We exemplify our novel\ntask-informed anti-curriculum by masking (TIACBM) approach across three diverse\ndownstream tasks: sentiment analysis, text classification by topic, and\nauthorship attribution. Our findings suggest that TIACBM enhances the ability\nof the model to focus on key task-relevant features, contributing to\nstatistically significant performance gains across tasks. We release our code\nat https://github.com/JarcaAndrei/TIACBM.'}","['Andrei Jarca', 'Florinel Alin Croitoru', 'Radu Tudor Ionescu']",{'name': 'Radu Tudor Ionescu'},Radu Tudor Ionescu,,"[{'href': 'http://arxiv.org/abs/2502.12953v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12953v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12953v1,None,http://arxiv.org/abs/2502.12953v1,,,969,0
http://arxiv.org/abs/2502.12965v1,True,2025-02-18T15:46:54Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=15, tm_min=46, tm_sec=54, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T15:46:54Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=15, tm_min=46, tm_sec=54, tm_wday=1, tm_yday=49, tm_isdst=0)",A Survey of Text Classification Under Class Distribution Shift,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A Survey of Text Classification Under Class Distribution Shift'}","The basic underlying assumption of machine learning (ML) models is that the
training and test data are sampled from the same distribution. However, in
daily practice, this assumption is often broken, i.e.~the distribution of the
test data changes over time, which hinders the application of conventional ML
models. One domain where the distribution shift naturally occurs is text
classification, since people always find new topics to discuss. To this end, we
survey research articles studying open-set text classification and related
tasks. We divide the methods in this area based on the constraints that define
the kind of distribution shift and the corresponding problem formulation,
i.e.~learning with the Universum, zero-shot learning, and open-set learning. We
next discuss the predominant mitigation approaches for each problem setup.
Finally, we identify several future work directions, aiming to push the
boundaries beyond the state of the art. Interestingly, we find that continual
learning can solve many of the issues caused by the shifting class
distribution. We maintain a list of relevant papers at
https://github.com/Eduard6421/Open-Set-Survey.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The basic underlying assumption of machine learning (ML) models is that the\ntraining and test data are sampled from the same distribution. However, in\ndaily practice, this assumption is often broken, i.e.~the distribution of the\ntest data changes over time, which hinders the application of conventional ML\nmodels. One domain where the distribution shift naturally occurs is text\nclassification, since people always find new topics to discuss. To this end, we\nsurvey research articles studying open-set text classification and related\ntasks. We divide the methods in this area based on the constraints that define\nthe kind of distribution shift and the corresponding problem formulation,\ni.e.~learning with the Universum, zero-shot learning, and open-set learning. We\nnext discuss the predominant mitigation approaches for each problem setup.\nFinally, we identify several future work directions, aiming to push the\nboundaries beyond the state of the art. Interestingly, we find that continual\nlearning can solve many of the issues caused by the shifting class\ndistribution. We maintain a list of relevant papers at\nhttps://github.com/Eduard6421/Open-Set-Survey.'}","['Adriana Valentina Costache', 'Silviu Florin Gheorghe', 'Eduard Gabriel Poesina', 'Paul Irofti', 'Radu Tudor Ionescu']",{'name': 'Radu Tudor Ionescu'},Radu Tudor Ionescu,,"[{'href': 'http://arxiv.org/abs/2502.12965v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12965v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12965v1,None,http://arxiv.org/abs/2502.12965v1,,,286,0
http://arxiv.org/abs/2502.12977v1,True,2025-02-17T18:34:25Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=34, tm_sec=25, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T18:34:25Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=18, tm_min=34, tm_sec=25, tm_wday=0, tm_yday=48, tm_isdst=0)",Time-series attribution maps with regularized contrastive learning,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Time-series attribution maps with regularized contrastive learning'}","Gradient-based attribution methods aim to explain decisions of deep learning
models but so far lack identifiability guarantees. Here, we propose a method to
generate attribution maps with identifiability guarantees by developing a
regularized contrastive learning algorithm trained on time-series data plus a
new attribution method called Inverted Neuron Gradient (collectively named
xCEBRA). We show theoretically that xCEBRA has favorable properties for
identifying the Jacobian matrix of the data generating process. Empirically, we
demonstrate robust approximation of zero vs. non-zero entries in the
ground-truth attribution map on synthetic datasets, and significant
improvements across previous attribution methods based on feature ablation,
Shapley values, and other gradient-based methods. Our work constitutes a first
example of identifiable inference of time-series attribution maps and opens
avenues to a better understanding of time-series data, such as for neural
dynamics and decision-processes within neural networks.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Gradient-based attribution methods aim to explain decisions of deep learning\nmodels but so far lack identifiability guarantees. Here, we propose a method to\ngenerate attribution maps with identifiability guarantees by developing a\nregularized contrastive learning algorithm trained on time-series data plus a\nnew attribution method called Inverted Neuron Gradient (collectively named\nxCEBRA). We show theoretically that xCEBRA has favorable properties for\nidentifying the Jacobian matrix of the data generating process. Empirically, we\ndemonstrate robust approximation of zero vs. non-zero entries in the\nground-truth attribution map on synthetic datasets, and significant\nimprovements across previous attribution methods based on feature ablation,\nShapley values, and other gradient-based methods. Our work constitutes a first\nexample of identifiable inference of time-series attribution maps and opens\navenues to a better understanding of time-series data, such as for neural\ndynamics and decision-processes within neural networks.'}","['Steffen Schneider', 'Rodrigo Gonzlez Laiz', 'Anastasiia Filippova', 'Markus Frey', 'Mackenzie Weygandt Mathis']",{'name': 'Mackenzie Weygandt Mathis'},Mackenzie Weygandt Mathis,"Accepted at The 28th International Conference on Artificial
  Intelligence and Statistics (AISTATS 2025). Code is available at
  https://github.com/AdaptiveMotorControlLab/CEBRA","[{'href': 'http://arxiv.org/abs/2502.12977v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12977v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-bio.NC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12977v1,None,http://arxiv.org/abs/2502.12977v1,"The 28th International Conference on Artificial Intelligence and
  Statistics 2025",,8690,0
http://arxiv.org/abs/2502.12982v1,True,2025-02-18T16:04:57Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=16, tm_min=4, tm_sec=57, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T16:04:57Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=16, tm_min=4, tm_sec=57, tm_wday=1, tm_yday=49, tm_isdst=0)",Sailor2: Sailing in South-East Asia with Inclusive Multilingual LLMs,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Sailor2: Sailing in South-East Asia with Inclusive Multilingual LLMs'}","Sailor2 is a family of cutting-edge multilingual language models for
South-East Asian (SEA) languages, available in 1B, 8B, and 20B sizes to suit
diverse applications. Building on Qwen2.5, Sailor2 undergoes continuous
pre-training on 500B tokens (400B SEA-specific and 100B replay tokens) to
support 13 SEA languages while retaining proficiency in Chinese and English.
Sailor2-20B model achieves a 50-50 win rate against GPT-4o across SEA
languages. We also deliver a comprehensive cookbook on how to develop the
multilingual model in an efficient manner, including five key aspects: data
curation, pre-training, post-training, model customization and evaluation. We
hope that Sailor2 model (Apache 2.0 license) will drive language development in
the SEA region, and Sailor2 cookbook will inspire researchers to build more
inclusive LLMs for other under-served languages.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Sailor2 is a family of cutting-edge multilingual language models for\nSouth-East Asian (SEA) languages, available in 1B, 8B, and 20B sizes to suit\ndiverse applications. Building on Qwen2.5, Sailor2 undergoes continuous\npre-training on 500B tokens (400B SEA-specific and 100B replay tokens) to\nsupport 13 SEA languages while retaining proficiency in Chinese and English.\nSailor2-20B model achieves a 50-50 win rate against GPT-4o across SEA\nlanguages. We also deliver a comprehensive cookbook on how to develop the\nmultilingual model in an efficient manner, including five key aspects: data\ncuration, pre-training, post-training, model customization and evaluation. We\nhope that Sailor2 model (Apache 2.0 license) will drive language development in\nthe SEA region, and Sailor2 cookbook will inspire researchers to build more\ninclusive LLMs for other under-served languages.'}","['Longxu Dou', 'Qian Liu', 'Fan Zhou', 'Changyu Chen', 'Zili Wang', 'Ziqi Jin', 'Zichen Liu', 'Tongyao Zhu', 'Cunxiao Du', 'Penghui Yang', 'Haonan Wang', 'Jiaheng Liu', 'Yongchi Zhao', 'Xiachong Feng', 'Xin Mao', 'Man Tsung Yeung', 'Kunat Pipatanakul', 'Fajri Koto', 'Min Si Thu', 'Hynek Kydlek', 'Zeyi Liu', 'Qunshu Lin', 'Sittipong Sripaisarnmongkol', 'Kridtaphad Sae-Khow', 'Nirattisai Thongchim', 'Taechawat Konkaew', 'Narong Borijindargoon', 'Anh Dao', 'Matichon Maneegard', 'Phakphum Artkaew', 'Zheng-Xin Yong', 'Quan Nguyen', 'Wannaphong Phatthiyaphaibun', 'Hoang H. Tran', 'Mike Zhang', 'Shiqi Chen', 'Tianyu Pang', 'Chao Du', 'Xinyi Wan', 'Wei Lu', 'Min Lin']",{'name': 'Min Lin'},Min Lin,"49 pages, 16 figures. Technical Report of Sailor2:
  https://sea-sailor.github.io/blog/sailor2/","[{'href': 'http://arxiv.org/abs/2502.12982v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12982v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12982v1,None,http://arxiv.org/abs/2502.12982v1,,,10270,0
http://arxiv.org/abs/2502.12998v1,True,2025-02-18T16:19:08Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=16, tm_min=19, tm_sec=8, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T16:19:08Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=16, tm_min=19, tm_sec=8, tm_wday=1, tm_yday=49, tm_isdst=0)",Personalized Top-k Set Queries Over Predicted Scores,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Personalized Top-k Set Queries Over Predicted Scores'}","This work studies the applicability of expensive external oracles such as
large language models in answering top-k queries over predicted scores. Such
scores are incurred by user-defined functions to answer personalized queries
over multi-modal data. We propose a generic computational framework that
handles arbitrary set-based scoring functions, as long as the functions could
be decomposed into constructs, each of which sent to an oracle (in our case an
LLM) to predict partial scores. At a given point in time, the framework assumes
a set of responses and their partial predicted scores, and it maintains a
collection of possible sets that are likely to be the true top-k. Since calling
oracles is costly, our framework judiciously identifies the next construct,
i.e., the next best question to ask the oracle so as to maximize the likelihood
of identifying the true top-k. We present a principled probabilistic model that
quantifies that likelihood. We study efficiency opportunities in designing
algorithms. We run an evaluation with three large scale datasets, scoring
functions, and baselines. Experiments indicate the efficacy of our framework,
as it achieves an order of magnitude improvement over baselines in requiring
LLM calls while ensuring result accuracy. Scalability experiments further
indicate that our framework could be used in large-scale applications.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'This work studies the applicability of expensive external oracles such as\nlarge language models in answering top-k queries over predicted scores. Such\nscores are incurred by user-defined functions to answer personalized queries\nover multi-modal data. We propose a generic computational framework that\nhandles arbitrary set-based scoring functions, as long as the functions could\nbe decomposed into constructs, each of which sent to an oracle (in our case an\nLLM) to predict partial scores. At a given point in time, the framework assumes\na set of responses and their partial predicted scores, and it maintains a\ncollection of possible sets that are likely to be the true top-k. Since calling\noracles is costly, our framework judiciously identifies the next construct,\ni.e., the next best question to ask the oracle so as to maximize the likelihood\nof identifying the true top-k. We present a principled probabilistic model that\nquantifies that likelihood. We study efficiency opportunities in designing\nalgorithms. We run an evaluation with three large scale datasets, scoring\nfunctions, and baselines. Experiments indicate the efficacy of our framework,\nas it achieves an order of magnitude improvement over baselines in requiring\nLLM calls while ensuring result accuracy. Scalability experiments further\nindicate that our framework could be used in large-scale applications.'}","['Sohrab Namazi Nia', 'Subhodeep Ghosh', 'Senjuti Basu Roy', 'Sihem Amer-Yahia']",{'name': 'Sihem Amer-Yahia'},Sihem Amer-Yahia,,"[{'href': 'http://arxiv.org/abs/2502.12998v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12998v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.DB', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.DB', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12998v1,None,http://arxiv.org/abs/2502.12998v1,,,8435,0
http://arxiv.org/abs/2502.13013v1,True,2025-02-18T16:33:38Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=16, tm_min=33, tm_sec=38, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T16:33:38Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=16, tm_min=33, tm_sec=38, tm_wday=1, tm_yday=49, tm_isdst=0)",HOMIE: Humanoid Loco-Manipulation with Isomorphic Exoskeleton Cockpit,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'HOMIE: Humanoid Loco-Manipulation with Isomorphic Exoskeleton Cockpit'}","Current humanoid teleoperation systems either lack reliable low-level control
policies, or struggle to acquire accurate whole-body control commands, making
it difficult to teleoperate humanoids for loco-manipulation tasks. To solve
these issues, we propose HOMIE, a novel humanoid teleoperation cockpit
integrates a humanoid loco-manipulation policy and a low-cost exoskeleton-based
hardware system. The policy enables humanoid robots to walk and squat to
specific heights while accommodating arbitrary upper-body poses. This is
achieved through our novel reinforcement learning-based training framework that
incorporates upper-body pose curriculum, height-tracking reward, and symmetry
utilization, without relying on any motion priors. Complementing the policy,
the hardware system integrates isomorphic exoskeleton arms, a pair of
motion-sensing gloves, and a pedal, allowing a single operator to achieve full
control of the humanoid robot. Our experiments show our cockpit facilitates
more stable, rapid, and precise humanoid loco-manipulation teleoperation,
accelerating task completion and eliminating retargeting errors compared to
inverse kinematics-based methods. We also validate the effectiveness of the
data collected by our cockpit for imitation learning. Our project is fully
open-sourced, demos and code can be found in https://homietele.github.io/.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Current humanoid teleoperation systems either lack reliable low-level control\npolicies, or struggle to acquire accurate whole-body control commands, making\nit difficult to teleoperate humanoids for loco-manipulation tasks. To solve\nthese issues, we propose HOMIE, a novel humanoid teleoperation cockpit\nintegrates a humanoid loco-manipulation policy and a low-cost exoskeleton-based\nhardware system. The policy enables humanoid robots to walk and squat to\nspecific heights while accommodating arbitrary upper-body poses. This is\nachieved through our novel reinforcement learning-based training framework that\nincorporates upper-body pose curriculum, height-tracking reward, and symmetry\nutilization, without relying on any motion priors. Complementing the policy,\nthe hardware system integrates isomorphic exoskeleton arms, a pair of\nmotion-sensing gloves, and a pedal, allowing a single operator to achieve full\ncontrol of the humanoid robot. Our experiments show our cockpit facilitates\nmore stable, rapid, and precise humanoid loco-manipulation teleoperation,\naccelerating task completion and eliminating retargeting errors compared to\ninverse kinematics-based methods. We also validate the effectiveness of the\ndata collected by our cockpit for imitation learning. Our project is fully\nopen-sourced, demos and code can be found in https://homietele.github.io/.'}","['Qingwei Ben', 'Feiyu Jia', 'Jia Zeng', 'Junting Dong', 'Dahua Lin', 'Jiangmiao Pang']",{'name': 'Jiangmiao Pang'},Jiangmiao Pang,,"[{'href': 'http://arxiv.org/abs/2502.13013v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13013v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13013v1,None,http://arxiv.org/abs/2502.13013v1,,,86,0
http://arxiv.org/abs/2502.13025v1,True,2025-02-18T16:44:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=16, tm_min=44, tm_sec=42, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T16:44:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=16, tm_min=44, tm_sec=42, tm_wday=1, tm_yday=49, tm_isdst=0)",Agentic Deep Graph Reasoning Yields Self-Organizing Knowledge Networks,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Agentic Deep Graph Reasoning Yields Self-Organizing Knowledge Networks'}","We present an agentic, autonomous graph expansion framework that iteratively
structures and refines knowledge in situ. Unlike conventional knowledge graph
construction methods relying on static extraction or single-pass learning, our
approach couples a reasoning-native large language model with a continually
updated graph representation. At each step, the system actively generates new
concepts and relationships, merges them into a global graph, and formulates
subsequent prompts based on its evolving structure. Through this
feedback-driven loop, the model organizes information into a scale-free network
characterized by hub formation, stable modularity, and bridging nodes that link
disparate knowledge clusters. Over hundreds of iterations, new nodes and edges
continue to appear without saturating, while centrality measures and shortest
path distributions evolve to yield increasingly distributed connectivity. Our
analysis reveals emergent patterns, such as the rise of highly connected 'hub'
concepts and the shifting influence of 'bridge' nodes, indicating that agentic,
self-reinforcing graph construction can yield open-ended, coherent knowledge
structures. Applied to materials design problems, we present compositional
reasoning experiments by extracting node-specific and synergy-level principles
to foster genuinely novel knowledge synthesis, yielding cross-domain ideas that
transcend rote summarization and strengthen the framework's potential for
open-ended scientific discovery. We discuss other applications in scientific
discovery and outline future directions for enhancing scalability and
interpretability.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""We present an agentic, autonomous graph expansion framework that iteratively\nstructures and refines knowledge in situ. Unlike conventional knowledge graph\nconstruction methods relying on static extraction or single-pass learning, our\napproach couples a reasoning-native large language model with a continually\nupdated graph representation. At each step, the system actively generates new\nconcepts and relationships, merges them into a global graph, and formulates\nsubsequent prompts based on its evolving structure. Through this\nfeedback-driven loop, the model organizes information into a scale-free network\ncharacterized by hub formation, stable modularity, and bridging nodes that link\ndisparate knowledge clusters. Over hundreds of iterations, new nodes and edges\ncontinue to appear without saturating, while centrality measures and shortest\npath distributions evolve to yield increasingly distributed connectivity. Our\nanalysis reveals emergent patterns, such as the rise of highly connected 'hub'\nconcepts and the shifting influence of 'bridge' nodes, indicating that agentic,\nself-reinforcing graph construction can yield open-ended, coherent knowledge\nstructures. Applied to materials design problems, we present compositional\nreasoning experiments by extracting node-specific and synergy-level principles\nto foster genuinely novel knowledge synthesis, yielding cross-domain ideas that\ntranscend rote summarization and strengthen the framework's potential for\nopen-ended scientific discovery. We discuss other applications in scientific\ndiscovery and outline future directions for enhancing scalability and\ninterpretability.""}",['Markus J. Buehler'],{'name': 'Markus J. Buehler'},Markus J. Buehler,,"[{'href': 'http://arxiv.org/abs/2502.13025v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13025v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cond-mat.mtrl-sci', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13025v1,None,http://arxiv.org/abs/2502.13025v1,,,0,0
http://arxiv.org/abs/2502.13030v1,True,2025-02-18T16:46:44Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=16, tm_min=46, tm_sec=44, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T16:46:44Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=16, tm_min=46, tm_sec=44, tm_wday=1, tm_yday=49, tm_isdst=0)","Likelihood-Ratio Regularized Quantile Regression: Adapting Conformal
  Prediction to High-Dimensional Covariate Shifts","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Likelihood-Ratio Regularized Quantile Regression: Adapting Conformal\n  Prediction to High-Dimensional Covariate Shifts'}","We consider the problem of conformal prediction under covariate shift. Given
labeled data from a source domain and unlabeled data from a covariate shifted
target domain, we seek to construct prediction sets with valid marginal
coverage in the target domain. Most existing methods require estimating the
unknown likelihood ratio function, which can be prohibitive for
high-dimensional data such as images. To address this challenge, we introduce
the likelihood ratio regularized quantile regression (LR-QR) algorithm, which
combines the pinball loss with a novel choice of regularization in order to
construct a threshold function without directly estimating the unknown
likelihood ratio. We show that the LR-QR method has coverage at the desired
level in the target domain, up to a small error term that we can control. Our
proofs draw on a novel analysis of coverage via stability bounds from learning
theory. Our experiments demonstrate that the LR-QR algorithm outperforms
existing methods on high-dimensional prediction tasks, including a regression
task for the Communities and Crime dataset, and an image classification task
from the WILDS repository.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'We consider the problem of conformal prediction under covariate shift. Given\nlabeled data from a source domain and unlabeled data from a covariate shifted\ntarget domain, we seek to construct prediction sets with valid marginal\ncoverage in the target domain. Most existing methods require estimating the\nunknown likelihood ratio function, which can be prohibitive for\nhigh-dimensional data such as images. To address this challenge, we introduce\nthe likelihood ratio regularized quantile regression (LR-QR) algorithm, which\ncombines the pinball loss with a novel choice of regularization in order to\nconstruct a threshold function without directly estimating the unknown\nlikelihood ratio. We show that the LR-QR method has coverage at the desired\nlevel in the target domain, up to a small error term that we can control. Our\nproofs draw on a novel analysis of coverage via stability bounds from learning\ntheory. Our experiments demonstrate that the LR-QR algorithm outperforms\nexisting methods on high-dimensional prediction tasks, including a regression\ntask for the Communities and Crime dataset, and an image classification task\nfrom the WILDS repository.'}","['Sunay Joshi', 'Shayan Kiyani', 'George Pappas', 'Edgar Dobriban', 'Hamed Hassani']",{'name': 'Hamed Hassani'},Hamed Hassani,,"[{'href': 'http://arxiv.org/abs/2502.13030v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13030v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13030v1,None,http://arxiv.org/abs/2502.13030v1,,,778,0
http://arxiv.org/abs/2502.13034v1,True,2025-02-18T16:48:18Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=16, tm_min=48, tm_sec=18, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T16:48:18Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=16, tm_min=48, tm_sec=18, tm_wday=1, tm_yday=49, tm_isdst=0)","Natural Language Generation from Visual Sequences: Challenges and Future
  Directions","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Natural Language Generation from Visual Sequences: Challenges and Future\n  Directions'}","The ability to use natural language to talk about visual content is at the
core of human intelligence and a crucial feature of any artificial intelligence
system. Various studies have focused on generating text for single images. In
contrast, comparatively little attention has been paid to exhaustively
analyzing and advancing work on multiple-image vision-to-text settings. In this
position paper, we claim that any task dealing with temporally ordered
sequences of multiple images or frames is an instance of a broader, more
general problem involving the understanding of intricate relationships between
the visual content and the corresponding text. We comprehensively analyze five
tasks that are instances of this problem and argue that they pose a common set
of challenges and share similarities in terms of modeling and evaluation
approaches. Based on the insights from these various aspects and stages of
multi-image-to-text generation, we highlight several open questions and suggest
future research directions. We believe that these directions can advance the
understanding of complex phenomena in this domain and the development of better
models.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The ability to use natural language to talk about visual content is at the\ncore of human intelligence and a crucial feature of any artificial intelligence\nsystem. Various studies have focused on generating text for single images. In\ncontrast, comparatively little attention has been paid to exhaustively\nanalyzing and advancing work on multiple-image vision-to-text settings. In this\nposition paper, we claim that any task dealing with temporally ordered\nsequences of multiple images or frames is an instance of a broader, more\ngeneral problem involving the understanding of intricate relationships between\nthe visual content and the corresponding text. We comprehensively analyze five\ntasks that are instances of this problem and argue that they pose a common set\nof challenges and share similarities in terms of modeling and evaluation\napproaches. Based on the insights from these various aspects and stages of\nmulti-image-to-text generation, we highlight several open questions and suggest\nfuture research directions. We believe that these directions can advance the\nunderstanding of complex phenomena in this domain and the development of better\nmodels.'}","['Aditya K Surikuchi', 'Raquel Fernndez', 'Sandro Pezzelle']",{'name': 'Sandro Pezzelle'},Sandro Pezzelle,,"[{'href': 'http://arxiv.org/abs/2502.13034v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13034v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13034v1,None,http://arxiv.org/abs/2502.13034v1,,,436,0
http://arxiv.org/abs/2502.13055v1,True,2025-02-18T17:01:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=17, tm_min=1, tm_sec=37, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T17:01:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=17, tm_min=1, tm_sec=37, tm_wday=1, tm_yday=49, tm_isdst=0)","LAMD: Context-driven Android Malware Detection and Classification with
  LLMs","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'LAMD: Context-driven Android Malware Detection and Classification with\n  LLMs'}","The rapid growth of mobile applications has escalated Android malware
threats. Although there are numerous detection methods, they often struggle
with evolving attacks, dataset biases, and limited explainability. Large
Language Models (LLMs) offer a promising alternative with their zero-shot
inference and reasoning capabilities. However, applying LLMs to Android malware
detection presents two key challenges: (1)the extensive support code in Android
applications, often spanning thousands of classes, exceeds LLMs' context limits
and obscures malicious behavior within benign functionality; (2)the structural
complexity and interdependencies of Android applications surpass LLMs'
sequence-based reasoning, fragmenting code analysis and hindering malicious
intent inference. To address these challenges, we propose LAMD, a practical
context-driven framework to enable LLM-based Android malware detection. LAMD
integrates key context extraction to isolate security-critical code regions and
construct program structures, then applies tier-wise code reasoning to analyze
application behavior progressively, from low-level instructions to high-level
semantics, providing final prediction and explanation. A well-designed factual
consistency verification mechanism is equipped to mitigate LLM hallucinations
from the first tier. Evaluation in real-world settings demonstrates LAMD's
effectiveness over conventional detectors, establishing a feasible basis for
LLM-driven malware analysis in dynamic threat landscapes.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""The rapid growth of mobile applications has escalated Android malware\nthreats. Although there are numerous detection methods, they often struggle\nwith evolving attacks, dataset biases, and limited explainability. Large\nLanguage Models (LLMs) offer a promising alternative with their zero-shot\ninference and reasoning capabilities. However, applying LLMs to Android malware\ndetection presents two key challenges: (1)the extensive support code in Android\napplications, often spanning thousands of classes, exceeds LLMs' context limits\nand obscures malicious behavior within benign functionality; (2)the structural\ncomplexity and interdependencies of Android applications surpass LLMs'\nsequence-based reasoning, fragmenting code analysis and hindering malicious\nintent inference. To address these challenges, we propose LAMD, a practical\ncontext-driven framework to enable LLM-based Android malware detection. LAMD\nintegrates key context extraction to isolate security-critical code regions and\nconstruct program structures, then applies tier-wise code reasoning to analyze\napplication behavior progressively, from low-level instructions to high-level\nsemantics, providing final prediction and explanation. A well-designed factual\nconsistency verification mechanism is equipped to mitigate LLM hallucinations\nfrom the first tier. Evaluation in real-world settings demonstrates LAMD's\neffectiveness over conventional detectors, establishing a feasible basis for\nLLM-driven malware analysis in dynamic threat landscapes.""}","['Xingzhi Qian', 'Xinran Zheng', 'Yiling He', 'Shuo Yang', 'Lorenzo Cavallaro']",{'name': 'Lorenzo Cavallaro'},Lorenzo Cavallaro,,"[{'href': 'http://arxiv.org/abs/2502.13055v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13055v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13055v1,None,http://arxiv.org/abs/2502.13055v1,,,4,0
http://arxiv.org/abs/2502.13061v1,True,2025-02-18T17:07:29Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=17, tm_min=7, tm_sec=29, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T17:07:29Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=17, tm_min=7, tm_sec=29, tm_wday=1, tm_yday=49, tm_isdst=0)","Improved Fine-Tuning of Large Multimodal Models for Hateful Meme
  Detection","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Improved Fine-Tuning of Large Multimodal Models for Hateful Meme\n  Detection'}","Hateful memes have become a significant concern on the Internet,
necessitating robust automated detection systems. While large multimodal models
have shown strong generalization across various tasks, they exhibit poor
generalization to hateful meme detection due to the dynamic nature of memes
tied to emerging social trends and breaking news. Recent work further
highlights the limitations of conventional supervised fine-tuning for large
multimodal models in this context. To address these challenges, we propose
Large Multimodal Model Retrieval-Guided Contrastive Learning (LMM-RGCL), a
novel two-stage fine-tuning framework designed to improve both in-domain
accuracy and cross-domain generalization. Experimental results on six widely
used meme classification datasets demonstrate that LMM-RGCL achieves
state-of-the-art performance, outperforming agent-based systems such as
VPD-PALI-X-55B. Furthermore, our method effectively generalizes to
out-of-domain memes under low-resource settings, surpassing models like GPT-4o.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Hateful memes have become a significant concern on the Internet,\nnecessitating robust automated detection systems. While large multimodal models\nhave shown strong generalization across various tasks, they exhibit poor\ngeneralization to hateful meme detection due to the dynamic nature of memes\ntied to emerging social trends and breaking news. Recent work further\nhighlights the limitations of conventional supervised fine-tuning for large\nmultimodal models in this context. To address these challenges, we propose\nLarge Multimodal Model Retrieval-Guided Contrastive Learning (LMM-RGCL), a\nnovel two-stage fine-tuning framework designed to improve both in-domain\naccuracy and cross-domain generalization. Experimental results on six widely\nused meme classification datasets demonstrate that LMM-RGCL achieves\nstate-of-the-art performance, outperforming agent-based systems such as\nVPD-PALI-X-55B. Furthermore, our method effectively generalizes to\nout-of-domain memes under low-resource settings, surpassing models like GPT-4o.'}","['Jingbiao Mei', 'Jinghong Chen', 'Guangyu Yang', 'Weizhe Lin', 'Bill Byrne']",{'name': 'Bill Byrne'},Bill Byrne,Preprint. Under Review,"[{'href': 'http://arxiv.org/abs/2502.13061v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13061v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13061v1,None,http://arxiv.org/abs/2502.13061v1,,,1179,0
http://arxiv.org/abs/2502.13062v1,True,2025-02-18T17:08:21Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=17, tm_min=8, tm_sec=21, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T17:08:21Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=17, tm_min=8, tm_sec=21, tm_wday=1, tm_yday=49, tm_isdst=0)",AI-Assisted Decision Making with Human Learning,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'AI-Assisted Decision Making with Human Learning'}","AI systems increasingly support human decision-making. In many cases, despite
the algorithm's superior performance, the final decision remains in human
hands. For example, an AI may assist doctors in determining which diagnostic
tests to run, but the doctor ultimately makes the diagnosis. This paper studies
such AI-assisted decision-making settings, where the human learns through
repeated interactions with the algorithm. In our framework, the algorithm --
designed to maximize decision accuracy according to its own model -- determines
which features the human can consider. The human then makes a prediction based
on their own less accurate model. We observe that the discrepancy between the
algorithm's model and the human's model creates a fundamental tradeoff. Should
the algorithm prioritize recommending more informative features, encouraging
the human to recognize their importance, even if it results in less accurate
predictions in the short term until learning occurs? Or is it preferable to
forgo educating the human and instead select features that align more closely
with their existing understanding, minimizing the immediate cost of learning?
This tradeoff is shaped by the algorithm's time-discounted objective and the
human's learning ability. Our results show that optimal feature selection has a
surprisingly clean combinatorial characterization, reducible to a stationary
sequence of feature subsets that is tractable to compute. As the algorithm
becomes more ""patient"" or the human's learning improves, the algorithm
increasingly selects more informative features, enhancing both prediction
accuracy and the human's understanding. Notably, early investment in learning
leads to the selection of more informative features than a later investment. We
complement our analysis by showing that the impact of errors in the algorithm's
knowledge is limited as it does not make the prediction directly.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'AI systems increasingly support human decision-making. In many cases, despite\nthe algorithm\'s superior performance, the final decision remains in human\nhands. For example, an AI may assist doctors in determining which diagnostic\ntests to run, but the doctor ultimately makes the diagnosis. This paper studies\nsuch AI-assisted decision-making settings, where the human learns through\nrepeated interactions with the algorithm. In our framework, the algorithm --\ndesigned to maximize decision accuracy according to its own model -- determines\nwhich features the human can consider. The human then makes a prediction based\non their own less accurate model. We observe that the discrepancy between the\nalgorithm\'s model and the human\'s model creates a fundamental tradeoff. Should\nthe algorithm prioritize recommending more informative features, encouraging\nthe human to recognize their importance, even if it results in less accurate\npredictions in the short term until learning occurs? Or is it preferable to\nforgo educating the human and instead select features that align more closely\nwith their existing understanding, minimizing the immediate cost of learning?\nThis tradeoff is shaped by the algorithm\'s time-discounted objective and the\nhuman\'s learning ability. Our results show that optimal feature selection has a\nsurprisingly clean combinatorial characterization, reducible to a stationary\nsequence of feature subsets that is tractable to compute. As the algorithm\nbecomes more ""patient"" or the human\'s learning improves, the algorithm\nincreasingly selects more informative features, enhancing both prediction\naccuracy and the human\'s understanding. Notably, early investment in learning\nleads to the selection of more informative features than a later investment. We\ncomplement our analysis by showing that the impact of errors in the algorithm\'s\nknowledge is limited as it does not make the prediction directly.'}","['Gali Noti', 'Kate Donahue', 'Jon Kleinberg', 'Sigal Oren']",{'name': 'Sigal Oren'},Sigal Oren,,"[{'href': 'http://arxiv.org/abs/2502.13062v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13062v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13062v1,None,http://arxiv.org/abs/2502.13062v1,,,1384,0
http://arxiv.org/abs/2502.13108v1,True,2025-02-18T18:20:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=20, tm_sec=37, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T18:20:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=20, tm_sec=37, tm_wday=1, tm_yday=49, tm_isdst=0)","Improving Clinical Question Answering with Multi-Task Learning: A Joint
  Approach for Answer Extraction and Medical Categorization","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Improving Clinical Question Answering with Multi-Task Learning: A Joint\n  Approach for Answer Extraction and Medical Categorization'}","Clinical Question Answering (CQA) plays a crucial role in medical
decision-making, enabling physicians to extract relevant information from
Electronic Medical Records (EMRs). While transformer-based models such as BERT,
BioBERT, and ClinicalBERT have demonstrated state-of-the-art performance in
CQA, existing models lack the ability to categorize extracted answers, which is
critical for structured retrieval, content filtering, and medical decision
support.
  To address this limitation, we introduce a Multi-Task Learning (MTL)
framework that jointly trains CQA models for both answer extraction and medical
categorization. In addition to predicting answer spans, our model classifies
responses into five standardized medical categories: Diagnosis, Medication,
Symptoms, Procedure, and Lab Reports. This categorization enables more
structured and interpretable outputs, making clinical QA models more useful in
real-world healthcare settings.
  We evaluate our approach on emrQA, a large-scale dataset for medical question
answering. Results show that MTL improves F1-score by 2.2% compared to standard
fine-tuning, while achieving 90.7% accuracy in answer categorization. These
findings suggest that MTL not only enhances CQA performance but also introduces
an effective mechanism for categorization and structured medical information
retrieval.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Clinical Question Answering (CQA) plays a crucial role in medical\ndecision-making, enabling physicians to extract relevant information from\nElectronic Medical Records (EMRs). While transformer-based models such as BERT,\nBioBERT, and ClinicalBERT have demonstrated state-of-the-art performance in\nCQA, existing models lack the ability to categorize extracted answers, which is\ncritical for structured retrieval, content filtering, and medical decision\nsupport.\n  To address this limitation, we introduce a Multi-Task Learning (MTL)\nframework that jointly trains CQA models for both answer extraction and medical\ncategorization. In addition to predicting answer spans, our model classifies\nresponses into five standardized medical categories: Diagnosis, Medication,\nSymptoms, Procedure, and Lab Reports. This categorization enables more\nstructured and interpretable outputs, making clinical QA models more useful in\nreal-world healthcare settings.\n  We evaluate our approach on emrQA, a large-scale dataset for medical question\nanswering. Results show that MTL improves F1-score by 2.2% compared to standard\nfine-tuning, while achieving 90.7% accuracy in answer categorization. These\nfindings suggest that MTL not only enhances CQA performance but also introduces\nan effective mechanism for categorization and structured medical information\nretrieval.'}","['Priyaranjan Pattnayak', 'Hitesh Laxmichand Patel', 'Amit Agarwal', 'Bhargava Kumar', 'Srikant Panda', 'Tejaswini Kumar']",{'name': 'Tejaswini Kumar'},Tejaswini Kumar,,"[{'href': 'http://arxiv.org/abs/2502.13108v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13108v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13108v1,None,http://arxiv.org/abs/2502.13108v1,,,11,0
http://arxiv.org/abs/2502.13132v1,True,2025-02-18T18:55:53Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=55, tm_sec=53, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T18:55:53Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=55, tm_sec=53, tm_wday=1, tm_yday=49, tm_isdst=0)",Learning to Defer for Causal Discovery with Imperfect Experts,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Learning to Defer for Causal Discovery with Imperfect Experts'}","Integrating expert knowledge, e.g. from large language models, into causal
discovery algorithms can be challenging when the knowledge is not guaranteed to
be correct. Expert recommendations may contradict data-driven results, and
their reliability can vary significantly depending on the domain or specific
query. Existing methods based on soft constraints or inconsistencies in
predicted causal relationships fail to account for these variations in
expertise. To remedy this, we propose L2D-CD, a method for gauging the
correctness of expert recommendations and optimally combining them with
data-driven causal discovery results. By adapting learning-to-defer (L2D)
algorithms for pairwise causal discovery (CD), we learn a deferral function
that selects whether to rely on classical causal discovery methods using
numerical data or expert recommendations based on textual meta-data. We
evaluate L2D-CD on the canonical T\""ubingen pairs dataset and demonstrate its
superior performance compared to both the causal discovery method and the
expert used in isolation. Moreover, our approach identifies domains where the
expert's performance is strong or weak. Finally, we outline a strategy for
generalizing this approach to causal discovery on graphs with more than two
variables, paving the way for further research in this area.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Integrating expert knowledge, e.g. from large language models, into causal\ndiscovery algorithms can be challenging when the knowledge is not guaranteed to\nbe correct. Expert recommendations may contradict data-driven results, and\ntheir reliability can vary significantly depending on the domain or specific\nquery. Existing methods based on soft constraints or inconsistencies in\npredicted causal relationships fail to account for these variations in\nexpertise. To remedy this, we propose L2D-CD, a method for gauging the\ncorrectness of expert recommendations and optimally combining them with\ndata-driven causal discovery results. By adapting learning-to-defer (L2D)\nalgorithms for pairwise causal discovery (CD), we learn a deferral function\nthat selects whether to rely on classical causal discovery methods using\nnumerical data or expert recommendations based on textual meta-data. We\nevaluate L2D-CD on the canonical T\\""ubingen pairs dataset and demonstrate its\nsuperior performance compared to both the causal discovery method and the\nexpert used in isolation. Moreover, our approach identifies domains where the\nexpert\'s performance is strong or weak. Finally, we outline a strategy for\ngeneralizing this approach to causal discovery on graphs with more than two\nvariables, paving the way for further research in this area.'}","['Oscar Clivio', 'Divyat Mahajan', 'Perouz Taslakian', 'Sara Magliacane', 'Ioannis Mitliagkas', 'Valentina Zantedeschi', 'Alexandre Drouin']",{'name': 'Alexandre Drouin'},Alexandre Drouin,,"[{'href': 'http://arxiv.org/abs/2502.13132v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13132v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13132v1,None,http://arxiv.org/abs/2502.13132v1,,,1885,0
http://arxiv.org/abs/2502.13135v1,True,2025-02-18T18:56:44Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=56, tm_sec=44, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T18:56:44Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=56, tm_sec=44, tm_wday=1, tm_yday=49, tm_isdst=0)","Sleepless Nights, Sugary Days: Creating Synthetic Users with Health
  Conditions for Realistic Coaching Agent Interactions","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Sleepless Nights, Sugary Days: Creating Synthetic Users with Health\n  Conditions for Realistic Coaching Agent Interactions'}","We present an end-to-end framework for generating synthetic users for
evaluating interactive agents designed to encourage positive behavior changes,
such as in health and lifestyle coaching. The synthetic users are grounded in
health and lifestyle conditions, specifically sleep and diabetes management in
this study, to ensure realistic interactions with the health coaching agent.
Synthetic users are created in two stages: first, structured data are generated
grounded in real-world health and lifestyle factors in addition to basic
demographics and behavioral attributes; second, full profiles of the synthetic
users are developed conditioned on the structured data. Interactions between
synthetic users and the coaching agent are simulated using generative
agent-based models such as Concordia, or directly by prompting a language
model. Using two independently-developed agents for sleep and diabetes coaching
as case studies, the validity of this framework is demonstrated by analyzing
the coaching agent's understanding of the synthetic users' needs and
challenges. Finally, through multiple blinded evaluations of user-coach
interactions by human experts, we demonstrate that our synthetic users with
health and behavioral attributes more accurately portray real human users with
the same attributes, compared to generic synthetic users not grounded in such
attributes. The proposed framework lays the foundation for efficient
development of conversational agents through extensive, realistic, and grounded
simulated interactions.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""We present an end-to-end framework for generating synthetic users for\nevaluating interactive agents designed to encourage positive behavior changes,\nsuch as in health and lifestyle coaching. The synthetic users are grounded in\nhealth and lifestyle conditions, specifically sleep and diabetes management in\nthis study, to ensure realistic interactions with the health coaching agent.\nSynthetic users are created in two stages: first, structured data are generated\ngrounded in real-world health and lifestyle factors in addition to basic\ndemographics and behavioral attributes; second, full profiles of the synthetic\nusers are developed conditioned on the structured data. Interactions between\nsynthetic users and the coaching agent are simulated using generative\nagent-based models such as Concordia, or directly by prompting a language\nmodel. Using two independently-developed agents for sleep and diabetes coaching\nas case studies, the validity of this framework is demonstrated by analyzing\nthe coaching agent's understanding of the synthetic users' needs and\nchallenges. Finally, through multiple blinded evaluations of user-coach\ninteractions by human experts, we demonstrate that our synthetic users with\nhealth and behavioral attributes more accurately portray real human users with\nthe same attributes, compared to generic synthetic users not grounded in such\nattributes. The proposed framework lays the foundation for efficient\ndevelopment of conversational agents through extensive, realistic, and grounded\nsimulated interactions.""}","['Taedong Yun', 'Eric Yang', 'Mustafa Safdari', 'Jong Ha Lee', 'Vaishnavi Vinod Kumar', 'S. Sara Mahdavi', 'Jonathan Amar', 'Derek Peyton', 'Reut Aharony', 'Andreas Michaelides', 'Logan Schneider', 'Isaac Galatzer-Levy', 'Yugang Jia', 'John Canny', 'Arthur Gretton', 'Maja Matari']",{'name': 'Maja Matari'},Maja Matari,,"[{'href': 'http://arxiv.org/abs/2502.13135v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13135v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13135v1,None,http://arxiv.org/abs/2502.13135v1,,,415,0
http://arxiv.org/abs/2502.13141v1,True,2025-02-18T18:59:00Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=59, tm_sec=0, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T18:59:00Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=59, tm_sec=0, tm_wday=1, tm_yday=49, tm_isdst=0)","UniGuardian: A Unified Defense for Detecting Prompt Injection, Backdoor
  Attacks and Adversarial Attacks in Large Language Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'UniGuardian: A Unified Defense for Detecting Prompt Injection, Backdoor\n  Attacks and Adversarial Attacks in Large Language Models'}","Large Language Models (LLMs) are vulnerable to attacks like prompt injection,
backdoor attacks, and adversarial attacks, which manipulate prompts or models
to generate harmful outputs. In this paper, departing from traditional deep
learning attack paradigms, we explore their intrinsic relationship and
collectively term them Prompt Trigger Attacks (PTA). This raises a key
question: Can we determine if a prompt is benign or poisoned? To address this,
we propose UniGuardian, the first unified defense mechanism designed to detect
prompt injection, backdoor attacks, and adversarial attacks in LLMs.
Additionally, we introduce a single-forward strategy to optimize the detection
pipeline, enabling simultaneous attack detection and text generation within a
single forward pass. Our experiments confirm that UniGuardian accurately and
efficiently identifies malicious prompts in LLMs.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Language Models (LLMs) are vulnerable to attacks like prompt injection,\nbackdoor attacks, and adversarial attacks, which manipulate prompts or models\nto generate harmful outputs. In this paper, departing from traditional deep\nlearning attack paradigms, we explore their intrinsic relationship and\ncollectively term them Prompt Trigger Attacks (PTA). This raises a key\nquestion: Can we determine if a prompt is benign or poisoned? To address this,\nwe propose UniGuardian, the first unified defense mechanism designed to detect\nprompt injection, backdoor attacks, and adversarial attacks in LLMs.\nAdditionally, we introduce a single-forward strategy to optimize the detection\npipeline, enabling simultaneous attack detection and text generation within a\nsingle forward pass. Our experiments confirm that UniGuardian accurately and\nefficiently identifies malicious prompts in LLMs.'}","['Huawei Lin', 'Yingjie Lao', 'Tong Geng', 'Tan Yu', 'Weijie Zhao']",{'name': 'Weijie Zhao'},Weijie Zhao,"18 Pages, 8 Figures, 5 Tables, Keywords: Attack Defending, Security,
  Prompt Injection, Backdoor Attacks, Adversarial Attacks, Prompt Trigger
  Attacks","[{'href': 'http://arxiv.org/abs/2502.13141v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13141v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13141v1,None,http://arxiv.org/abs/2502.13141v1,,,1062,0
http://arxiv.org/abs/2502.13143v1,True,2025-02-18T18:59:02Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=59, tm_sec=2, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T18:59:02Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=59, tm_sec=2, tm_wday=1, tm_yday=49, tm_isdst=0)","SoFar: Language-Grounded Orientation Bridges Spatial Reasoning and
  Object Manipulation","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'SoFar: Language-Grounded Orientation Bridges Spatial Reasoning and\n  Object Manipulation'}","Spatial intelligence is a critical component of embodied AI, promoting robots
to understand and interact with their environments. While recent advances have
enhanced the ability of VLMs to perceive object locations and positional
relationships, they still lack the capability to precisely understand object
orientations-a key requirement for tasks involving fine-grained manipulations.
Addressing this limitation not only requires geometric reasoning but also an
expressive and intuitive way to represent orientation. In this context, we
propose that natural language offers a more flexible representation space than
canonical frames, making it particularly suitable for instruction-following
robotic systems. In this paper, we introduce the concept of semantic
orientation, which defines object orientations using natural language in a
reference-frame-free manner (e.g., the ''plug-in'' direction of a USB or the
''handle'' direction of a knife). To support this, we construct OrienText300K,
a large-scale dataset of 3D models annotated with semantic orientations that
link geometric understanding to functional semantics. By integrating semantic
orientation into a VLM system, we enable robots to generate manipulation
actions with both positional and orientational constraints. Extensive
experiments in simulation and real world demonstrate that our approach
significantly enhances robotic manipulation capabilities, e.g., 48.7% accuracy
on Open6DOR and 74.9% accuracy on SIMPLER.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Spatial intelligence is a critical component of embodied AI, promoting robots\nto understand and interact with their environments. While recent advances have\nenhanced the ability of VLMs to perceive object locations and positional\nrelationships, they still lack the capability to precisely understand object\norientations-a key requirement for tasks involving fine-grained manipulations.\nAddressing this limitation not only requires geometric reasoning but also an\nexpressive and intuitive way to represent orientation. In this context, we\npropose that natural language offers a more flexible representation space than\ncanonical frames, making it particularly suitable for instruction-following\nrobotic systems. In this paper, we introduce the concept of semantic\norientation, which defines object orientations using natural language in a\nreference-frame-free manner (e.g., the ''plug-in'' direction of a USB or the\n''handle'' direction of a knife). To support this, we construct OrienText300K,\na large-scale dataset of 3D models annotated with semantic orientations that\nlink geometric understanding to functional semantics. By integrating semantic\norientation into a VLM system, we enable robots to generate manipulation\nactions with both positional and orientational constraints. Extensive\nexperiments in simulation and real world demonstrate that our approach\nsignificantly enhances robotic manipulation capabilities, e.g., 48.7% accuracy\non Open6DOR and 74.9% accuracy on SIMPLER.""}","['Zekun Qi', 'Wenyao Zhang', 'Yufei Ding', 'Runpei Dong', 'Xinqiang Yu', 'Jingwen Li', 'Lingyun Xu', 'Baoyu Li', 'Xialin He', 'Guofan Fan', 'Jiazhao Zhang', 'Jiawei He', 'Jiayuan Gu', 'Xin Jin', 'Kaisheng Ma', 'Zhizheng Zhang', 'He Wang', 'Li Yi']",{'name': 'Li Yi'},Li Yi,Project page: https://qizekun.github.io/sofar/,"[{'href': 'http://arxiv.org/abs/2502.13143v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13143v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13143v1,None,http://arxiv.org/abs/2502.13143v1,,,1716,0
http://arxiv.org/abs/2502.13162v1,True,2025-02-16T18:47:41Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=18, tm_min=47, tm_sec=41, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T18:47:41Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=18, tm_min=47, tm_sec=41, tm_wday=6, tm_yday=47, tm_isdst=0)",ShieldLearner: A New Paradigm for Jailbreak Attack Defense in LLMs,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'ShieldLearner: A New Paradigm for Jailbreak Attack Defense in LLMs'}","Large Language Models (LLMs) have achieved remarkable success in various
domains but remain vulnerable to adversarial jailbreak attacks. Existing
prompt-defense strategies, including parameter-modifying and parameter-free
approaches, face limitations in adaptability, interpretability, and
customization, constraining their effectiveness against evolving threats. To
address these challenges, we propose ShieldLearner, a novel paradigm that
mimics human learning in defense. Through trial and error, it autonomously
distills attack signatures into a Pattern Atlas and synthesizes defense
heuristics into a Meta-analysis Framework, enabling systematic and
interpretable threat detection. Furthermore, we introduce Adaptive Adversarial
Augmentation to generate adversarial variations of successfully defended
prompts, enabling continuous self-improvement without model retraining. In
addition to standard benchmarks, we create a hard test set by curating
adversarial prompts from the Wildjailbreak dataset, emphasizing more concealed
malicious intent. Experimental results show that ShieldLearner achieves a
significantly higher defense success rate than existing baselines on both
conventional and hard test sets, while also operating with lower computational
overhead, making it a practical and efficient solution for real-world
adversarial defense.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Language Models (LLMs) have achieved remarkable success in various\ndomains but remain vulnerable to adversarial jailbreak attacks. Existing\nprompt-defense strategies, including parameter-modifying and parameter-free\napproaches, face limitations in adaptability, interpretability, and\ncustomization, constraining their effectiveness against evolving threats. To\naddress these challenges, we propose ShieldLearner, a novel paradigm that\nmimics human learning in defense. Through trial and error, it autonomously\ndistills attack signatures into a Pattern Atlas and synthesizes defense\nheuristics into a Meta-analysis Framework, enabling systematic and\ninterpretable threat detection. Furthermore, we introduce Adaptive Adversarial\nAugmentation to generate adversarial variations of successfully defended\nprompts, enabling continuous self-improvement without model retraining. In\naddition to standard benchmarks, we create a hard test set by curating\nadversarial prompts from the Wildjailbreak dataset, emphasizing more concealed\nmalicious intent. Experimental results show that ShieldLearner achieves a\nsignificantly higher defense success rate than existing baselines on both\nconventional and hard test sets, while also operating with lower computational\noverhead, making it a practical and efficient solution for real-world\nadversarial defense.'}","['Ziyi Ni', 'Hao Wang', 'Huacan Wang']",{'name': 'Huacan Wang'},Huacan Wang,,"[{'href': 'http://arxiv.org/abs/2502.13162v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13162v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13162v1,None,http://arxiv.org/abs/2502.13162v1,,,0,0
http://arxiv.org/abs/2502.13165v1,True,2025-02-17T04:13:19Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=4, tm_min=13, tm_sec=19, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T04:13:19Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=4, tm_min=13, tm_sec=19, tm_wday=0, tm_yday=48, tm_isdst=0)",HedgeAgents: A Balanced-aware Multi-agent Financial Trading System,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'HedgeAgents: A Balanced-aware Multi-agent Financial Trading System'}","As automated trading gains traction in the financial market, algorithmic
investment strategies are increasingly prominent. While Large Language Models
(LLMs) and Agent-based models exhibit promising potential in real-time market
analysis and trading decisions, they still experience a significant -20% loss
when confronted with rapid declines or frequent fluctuations, impeding their
practical application. Hence, there is an imperative to explore a more robust
and resilient framework. This paper introduces an innovative multi-agent
system, HedgeAgents, aimed at bolstering system robustness via ``hedging''
strategies. In this well-balanced system, an array of hedging agents has been
tailored, where HedgeAgents consist of a central fund manager and multiple
hedging experts specializing in various financial asset classes. These agents
leverage LLMs' cognitive capabilities to make decisions and coordinate through
three types of conferences. Benefiting from the powerful understanding of LLMs,
our HedgeAgents attained a 70% annualized return and a 400% total return over a
period of 3 years. Moreover, we have observed with delight that HedgeAgents can
even formulate investment experience comparable to those of human experts
(https://hedgeagents.github.io/).","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""As automated trading gains traction in the financial market, algorithmic\ninvestment strategies are increasingly prominent. While Large Language Models\n(LLMs) and Agent-based models exhibit promising potential in real-time market\nanalysis and trading decisions, they still experience a significant -20% loss\nwhen confronted with rapid declines or frequent fluctuations, impeding their\npractical application. Hence, there is an imperative to explore a more robust\nand resilient framework. This paper introduces an innovative multi-agent\nsystem, HedgeAgents, aimed at bolstering system robustness via ``hedging''\nstrategies. In this well-balanced system, an array of hedging agents has been\ntailored, where HedgeAgents consist of a central fund manager and multiple\nhedging experts specializing in various financial asset classes. These agents\nleverage LLMs' cognitive capabilities to make decisions and coordinate through\nthree types of conferences. Benefiting from the powerful understanding of LLMs,\nour HedgeAgents attained a 70% annualized return and a 400% total return over a\nperiod of 3 years. Moreover, we have observed with delight that HedgeAgents can\neven formulate investment experience comparable to those of human experts\n(https://hedgeagents.github.io/).""}","['Xiangyu Li', 'Yawen Zeng', 'Xiaofen Xing', 'Jin Xu', 'Xiangmin Xu']",{'name': 'Xiangmin Xu'},Xiangmin Xu,"This paper has been accepted by The Web Conference 2025 (WWW 2025)
  and selected for an oral presentation","[{'href': 'http://arxiv.org/abs/2502.13165v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13165v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-fin.TR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13165v1,None,http://arxiv.org/abs/2502.13165v1,,,1283,0
http://arxiv.org/abs/2502.13166v1,True,2025-02-17T05:57:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=5, tm_min=57, tm_sec=15, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T05:57:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=5, tm_min=57, tm_sec=15, tm_wday=0, tm_yday=48, tm_isdst=0)",Large Language Models Can Help Mitigate Barren Plateaus,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Language Models Can Help Mitigate Barren Plateaus'}","In the era of noisy intermediate-scale quantum (NISQ) computing, Quantum
Neural Networks (QNNs) have emerged as a promising approach for various
applications, yet their training is often hindered by barren plateaus (BPs),
where gradient variance vanishes exponentially as the model size increases. To
address this challenge, we propose a new Large Language Model (LLM)-driven
search framework, AdaInit, that iteratively searches for optimal initial
parameters of QNNs to maximize gradient variance and therefore mitigate BPs.
Unlike conventional one-time initialization methods, AdaInit dynamically
refines QNN's initialization using LLMs with adaptive prompting. Theoretical
analysis of the Expected Improvement (EI) proves a supremum for the search,
ensuring this process can eventually identify the optimal initial parameter of
the QNN. Extensive experiments across four public datasets demonstrate that
AdaInit significantly enhances QNN's trainability compared to classic
initialization methods, validating its effectiveness in mitigating BPs.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""In the era of noisy intermediate-scale quantum (NISQ) computing, Quantum\nNeural Networks (QNNs) have emerged as a promising approach for various\napplications, yet their training is often hindered by barren plateaus (BPs),\nwhere gradient variance vanishes exponentially as the model size increases. To\naddress this challenge, we propose a new Large Language Model (LLM)-driven\nsearch framework, AdaInit, that iteratively searches for optimal initial\nparameters of QNNs to maximize gradient variance and therefore mitigate BPs.\nUnlike conventional one-time initialization methods, AdaInit dynamically\nrefines QNN's initialization using LLMs with adaptive prompting. Theoretical\nanalysis of the Expected Improvement (EI) proves a supremum for the search,\nensuring this process can eventually identify the optimal initial parameter of\nthe QNN. Extensive experiments across four public datasets demonstrate that\nAdaInit significantly enhances QNN's trainability compared to classic\ninitialization methods, validating its effectiveness in mitigating BPs.""}","['Jun Zhuang', 'Chaowen Guan']",{'name': 'Chaowen Guan'},Chaowen Guan,"TL;DR: We propose a new LLM-driven framework designed for mitigating
  barren plateaus","[{'href': 'http://arxiv.org/abs/2502.13166v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13166v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'quant-ph', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'quant-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13166v1,None,http://arxiv.org/abs/2502.13166v1,,,9,0
http://arxiv.org/abs/2502.13171v1,True,2025-02-17T15:06:56Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=15, tm_min=6, tm_sec=56, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T15:06:56Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=15, tm_min=6, tm_sec=56, tm_wday=0, tm_yday=48, tm_isdst=0)","Web Phishing Net (WPN): A scalable machine learning approach for
  real-time phishing campaign detection","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Web Phishing Net (WPN): A scalable machine learning approach for\n  real-time phishing campaign detection'}","Phishing is the most prevalent type of cyber-attack today and is recognized
as the leading source of data breaches with significant consequences for both
individuals and corporations. Web-based phishing attacks are the most frequent
with vectors such as social media posts and emails containing links to phishing
URLs that once clicked on render host systems vulnerable to more sinister
attacks. Research efforts to detect phishing URLs have involved the use of
supervised learning techniques that use large amounts of data to train models
and have high computational requirements. They also involve analysis of
features derived from vectors including email contents thus affecting user
privacy. Additionally, they suffer from a lack of resilience against evolution
of threats especially with the advent of generative AI techniques to bypass
these systems as with AI-generated phishing URLs. Unsupervised methods such as
clustering techniques have also been used in phishing detection in the past,
however, they are at times unscalable due to the use of pair-wise comparisons.
They also lack high detection rates while detecting phishing campaigns. In this
paper, we propose an unsupervised learning approach that is not only fast but
scalable, as it does not involve pair-wise comparisons. It is able to detect
entire campaigns at a time with a high detection rate while preserving user
privacy; this includes the recent surge of campaigns with targeted phishing
URLs generated by malicious entities using generative AI techniques.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Phishing is the most prevalent type of cyber-attack today and is recognized\nas the leading source of data breaches with significant consequences for both\nindividuals and corporations. Web-based phishing attacks are the most frequent\nwith vectors such as social media posts and emails containing links to phishing\nURLs that once clicked on render host systems vulnerable to more sinister\nattacks. Research efforts to detect phishing URLs have involved the use of\nsupervised learning techniques that use large amounts of data to train models\nand have high computational requirements. They also involve analysis of\nfeatures derived from vectors including email contents thus affecting user\nprivacy. Additionally, they suffer from a lack of resilience against evolution\nof threats especially with the advent of generative AI techniques to bypass\nthese systems as with AI-generated phishing URLs. Unsupervised methods such as\nclustering techniques have also been used in phishing detection in the past,\nhowever, they are at times unscalable due to the use of pair-wise comparisons.\nThey also lack high detection rates while detecting phishing campaigns. In this\npaper, we propose an unsupervised learning approach that is not only fast but\nscalable, as it does not involve pair-wise comparisons. It is able to detect\nentire campaigns at a time with a high detection rate while preserving user\nprivacy; this includes the recent surge of campaigns with targeted phishing\nURLs generated by malicious entities using generative AI techniques.'}","['Muhammad Fahad Zia', 'Sri Harish Kalidass']",{'name': 'Sri Harish Kalidass'},Sri Harish Kalidass,IEEE Intelligent Cybersecurity Conference (ICSC2024),"[{'href': 'http://arxiv.org/abs/2502.13171v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13171v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13171v1,None,http://arxiv.org/abs/2502.13171v1,,,0,0
http://arxiv.org/abs/2502.13174v1,True,2025-02-17T21:24:18Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=21, tm_min=24, tm_sec=18, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T21:24:18Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=21, tm_min=24, tm_sec=18, tm_wday=0, tm_yday=48, tm_isdst=0)","Generative Topology Optimization: Exploring Diverse Solutions in
  Structural Design","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Generative Topology Optimization: Exploring Diverse Solutions in\n  Structural Design'}","Topology optimization (TO) is a family of computational methods that derive
near-optimal geometries from formal problem descriptions. Despite their
success, established TO methods are limited to generating single solutions,
restricting the exploration of alternative designs. To address this limitation,
we introduce Generative Topology Optimization (GenTO) - a data-free method that
trains a neural network to generate structurally compliant shapes and explores
diverse solutions through an explicit diversity constraint. The network is
trained with a solver-in-the-loop, optimizing the material distribution in each
iteration. The trained model produces diverse shapes that closely adhere to the
design requirements. We validate GenTO on 2D and 3D TO problems. Our results
demonstrate that GenTO produces more diverse solutions than any prior method
while maintaining near-optimality and being an order of magnitude faster due to
inherent parallelism. These findings open new avenues for engineering and
design, offering enhanced flexibility and innovation in structural
optimization.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Topology optimization (TO) is a family of computational methods that derive\nnear-optimal geometries from formal problem descriptions. Despite their\nsuccess, established TO methods are limited to generating single solutions,\nrestricting the exploration of alternative designs. To address this limitation,\nwe introduce Generative Topology Optimization (GenTO) - a data-free method that\ntrains a neural network to generate structurally compliant shapes and explores\ndiverse solutions through an explicit diversity constraint. The network is\ntrained with a solver-in-the-loop, optimizing the material distribution in each\niteration. The trained model produces diverse shapes that closely adhere to the\ndesign requirements. We validate GenTO on 2D and 3D TO problems. Our results\ndemonstrate that GenTO produces more diverse solutions than any prior method\nwhile maintaining near-optimality and being an order of magnitude faster due to\ninherent parallelism. These findings open new avenues for engineering and\ndesign, offering enhanced flexibility and innovation in structural\noptimization.'}","['Andreas Radler', 'Eric Volkmann', 'Johannes Brandstetter', 'Arturs Berzins']",{'name': 'Arturs Berzins'},Arturs Berzins,"11 pages, 7 figures","[{'href': 'http://arxiv.org/abs/2502.13174v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13174v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cond-mat.mtrl-sci', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13174v1,None,http://arxiv.org/abs/2502.13174v1,,,42,0
http://arxiv.org/abs/2502.13175v1,True,2025-02-18T03:38:07Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=3, tm_min=38, tm_sec=7, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T03:38:07Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=3, tm_min=38, tm_sec=7, tm_wday=1, tm_yday=49, tm_isdst=0)","Towards Robust and Secure Embodied AI: A Survey on Vulnerabilities and
  Attacks","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Towards Robust and Secure Embodied AI: A Survey on Vulnerabilities and\n  Attacks'}","Embodied AI systems, including robots and autonomous vehicles, are
increasingly integrated into real-world applications, where they encounter a
range of vulnerabilities stemming from both environmental and system-level
factors. These vulnerabilities manifest through sensor spoofing, adversarial
attacks, and failures in task and motion planning, posing significant
challenges to robustness and safety. Despite the growing body of research,
existing reviews rarely focus specifically on the unique safety and security
challenges of embodied AI systems. Most prior work either addresses general AI
vulnerabilities or focuses on isolated aspects, lacking a dedicated and unified
framework tailored to embodied AI. This survey fills this critical gap by: (1)
categorizing vulnerabilities specific to embodied AI into exogenous (e.g.,
physical attacks, cybersecurity threats) and endogenous (e.g., sensor failures,
software flaws) origins; (2) systematically analyzing adversarial attack
paradigms unique to embodied AI, with a focus on their impact on perception,
decision-making, and embodied interaction; (3) investigating attack vectors
targeting large vision-language models (LVLMs) and large language models (LLMs)
within embodied systems, such as jailbreak attacks and instruction
misinterpretation; (4) evaluating robustness challenges in algorithms for
embodied perception, decision-making, and task planning; and (5) proposing
targeted strategies to enhance the safety and reliability of embodied AI
systems. By integrating these dimensions, we provide a comprehensive framework
for understanding the interplay between vulnerabilities and safety in embodied
AI.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Embodied AI systems, including robots and autonomous vehicles, are\nincreasingly integrated into real-world applications, where they encounter a\nrange of vulnerabilities stemming from both environmental and system-level\nfactors. These vulnerabilities manifest through sensor spoofing, adversarial\nattacks, and failures in task and motion planning, posing significant\nchallenges to robustness and safety. Despite the growing body of research,\nexisting reviews rarely focus specifically on the unique safety and security\nchallenges of embodied AI systems. Most prior work either addresses general AI\nvulnerabilities or focuses on isolated aspects, lacking a dedicated and unified\nframework tailored to embodied AI. This survey fills this critical gap by: (1)\ncategorizing vulnerabilities specific to embodied AI into exogenous (e.g.,\nphysical attacks, cybersecurity threats) and endogenous (e.g., sensor failures,\nsoftware flaws) origins; (2) systematically analyzing adversarial attack\nparadigms unique to embodied AI, with a focus on their impact on perception,\ndecision-making, and embodied interaction; (3) investigating attack vectors\ntargeting large vision-language models (LVLMs) and large language models (LLMs)\nwithin embodied systems, such as jailbreak attacks and instruction\nmisinterpretation; (4) evaluating robustness challenges in algorithms for\nembodied perception, decision-making, and task planning; and (5) proposing\ntargeted strategies to enhance the safety and reliability of embodied AI\nsystems. By integrating these dimensions, we provide a comprehensive framework\nfor understanding the interplay between vulnerabilities and safety in embodied\nAI.'}","['Wenpeng Xing', 'Minghao Li', 'Mohan Li', 'Meng Han']",{'name': 'Meng Han'},Meng Han,,"[{'href': 'http://arxiv.org/abs/2502.13175v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13175v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13175v1,None,http://arxiv.org/abs/2502.13175v1,,,2,0
http://arxiv.org/abs/2502.13185v1,True,2025-02-18T11:11:17Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=11, tm_min=11, tm_sec=17, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T11:11:17Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=11, tm_min=11, tm_sec=17, tm_wday=1, tm_yday=49, tm_isdst=0)","CondensNet: Enabling stable long-term climate simulations via hybrid
  deep learning models with adaptive physical constraints","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'CondensNet: Enabling stable long-term climate simulations via hybrid\n  deep learning models with adaptive physical constraints'}","Accurate and efficient climate simulations are crucial for understanding
Earth's evolving climate. However, current general circulation models (GCMs)
face challenges in capturing unresolved physical processes, such as cloud and
convection. A common solution is to adopt cloud resolving models, that provide
more accurate results than the standard subgrid parametrisation schemes
typically used in GCMs. However, cloud resolving models, also referred to as
super paramtetrizations, remain computationally prohibitive. Hybrid modeling,
which integrates deep learning with equation-based GCMs, offers a promising
alternative but often struggles with long-term stability and accuracy issues.
In this work, we find that water vapor oversaturation during condensation is a
key factor compromising the stability of hybrid models. To address this, we
introduce CondensNet, a novel neural network architecture that embeds a
self-adaptive physical constraint to correct unphysical condensation processes.
CondensNet effectively mitigates water vapor oversaturation, enhancing
simulation stability while maintaining accuracy and improving computational
efficiency compared to super parameterization schemes.
  We integrate CondensNet into a GCM to form PCNN-GCM (Physics-Constrained
Neural Network GCM), a hybrid deep learning framework designed for long-term
stable climate simulations in real-world conditions, including ocean and land.
PCNN-GCM represents a significant milestone in hybrid climate modeling, as it
shows a novel way to incorporate physical constraints adaptively, paving the
way for accurate, lightweight, and stable long-term climate simulations.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Accurate and efficient climate simulations are crucial for understanding\nEarth's evolving climate. However, current general circulation models (GCMs)\nface challenges in capturing unresolved physical processes, such as cloud and\nconvection. A common solution is to adopt cloud resolving models, that provide\nmore accurate results than the standard subgrid parametrisation schemes\ntypically used in GCMs. However, cloud resolving models, also referred to as\nsuper paramtetrizations, remain computationally prohibitive. Hybrid modeling,\nwhich integrates deep learning with equation-based GCMs, offers a promising\nalternative but often struggles with long-term stability and accuracy issues.\nIn this work, we find that water vapor oversaturation during condensation is a\nkey factor compromising the stability of hybrid models. To address this, we\nintroduce CondensNet, a novel neural network architecture that embeds a\nself-adaptive physical constraint to correct unphysical condensation processes.\nCondensNet effectively mitigates water vapor oversaturation, enhancing\nsimulation stability while maintaining accuracy and improving computational\nefficiency compared to super parameterization schemes.\n  We integrate CondensNet into a GCM to form PCNN-GCM (Physics-Constrained\nNeural Network GCM), a hybrid deep learning framework designed for long-term\nstable climate simulations in real-world conditions, including ocean and land.\nPCNN-GCM represents a significant milestone in hybrid climate modeling, as it\nshows a novel way to incorporate physical constraints adaptively, paving the\nway for accurate, lightweight, and stable long-term climate simulations.""}","['Xin Wang', 'Juntao Yang', 'Jeff Adie', 'Simon See', 'Kalli Furtado', 'Chen Chen', 'Troy Arcomano', 'Romit Maulik', 'Gianmarco Mengaldo']",{'name': 'Gianmarco Mengaldo'},Gianmarco Mengaldo,,"[{'href': 'http://arxiv.org/abs/2502.13185v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13185v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'physics.ao-ph', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'physics.ao-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13185v1,None,http://arxiv.org/abs/2502.13185v1,,,4447,0
http://arxiv.org/abs/2502.13187v1,True,2025-02-18T12:57:29Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=12, tm_min=57, tm_sec=29, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T12:57:29Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=12, tm_min=57, tm_sec=29, tm_wday=1, tm_yday=49, tm_isdst=0)","A Survey of Sim-to-Real Methods in RL: Progress, Prospects and
  Challenges with Foundation Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A Survey of Sim-to-Real Methods in RL: Progress, Prospects and\n  Challenges with Foundation Models'}","Deep Reinforcement Learning (RL) has been explored and verified to be
effective in solving decision-making tasks in various domains, such as
robotics, transportation, recommender systems, etc. It learns from the
interaction with environments and updates the policy using the collected
experience. However, due to the limited real-world data and unbearable
consequences of taking detrimental actions, the learning of RL policy is mainly
restricted within the simulators. This practice guarantees safety in learning
but introduces an inevitable sim-to-real gap in terms of deployment, thus
causing degraded performance and risks in execution. There are attempts to
solve the sim-to-real problems from different domains with various techniques,
especially in the era with emerging techniques such as large foundations or
language models that have cast light on the sim-to-real. This survey paper, to
the best of our knowledge, is the first taxonomy that formally frames the
sim-to-real techniques from key elements of the Markov Decision Process (State,
Action, Transition, and Reward). Based on the framework, we cover comprehensive
literature from the classic to the most advanced methods including the
sim-to-real techniques empowered by foundation models, and we also discuss the
specialties that are worth attention in different domains of sim-to-real
problems. Then we summarize the formal evaluation process of sim-to-real
performance with accessible code or benchmarks. The challenges and
opportunities are also presented to encourage future exploration of this
direction. We are actively maintaining a to include the most up-to-date
sim-to-real research outcomes to help the researchers in their work.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Deep Reinforcement Learning (RL) has been explored and verified to be\neffective in solving decision-making tasks in various domains, such as\nrobotics, transportation, recommender systems, etc. It learns from the\ninteraction with environments and updates the policy using the collected\nexperience. However, due to the limited real-world data and unbearable\nconsequences of taking detrimental actions, the learning of RL policy is mainly\nrestricted within the simulators. This practice guarantees safety in learning\nbut introduces an inevitable sim-to-real gap in terms of deployment, thus\ncausing degraded performance and risks in execution. There are attempts to\nsolve the sim-to-real problems from different domains with various techniques,\nespecially in the era with emerging techniques such as large foundations or\nlanguage models that have cast light on the sim-to-real. This survey paper, to\nthe best of our knowledge, is the first taxonomy that formally frames the\nsim-to-real techniques from key elements of the Markov Decision Process (State,\nAction, Transition, and Reward). Based on the framework, we cover comprehensive\nliterature from the classic to the most advanced methods including the\nsim-to-real techniques empowered by foundation models, and we also discuss the\nspecialties that are worth attention in different domains of sim-to-real\nproblems. Then we summarize the formal evaluation process of sim-to-real\nperformance with accessible code or benchmarks. The challenges and\nopportunities are also presented to encourage future exploration of this\ndirection. We are actively maintaining a to include the most up-to-date\nsim-to-real research outcomes to help the researchers in their work.'}","['Longchao Da', 'Justin Turnau', 'Thirulogasankar Pranav Kutralingam', 'Alvaro Velasquez', 'Paulo Shakarian', 'Hua Wei']",{'name': 'Hua Wei'},Hua Wei,"19 pages, 6 figures, 5 tables","[{'href': 'http://arxiv.org/abs/2502.13187v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13187v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T05, 68U05', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.6.0; I.2.9; I.2.1', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13187v1,None,http://arxiv.org/abs/2502.13187v1,,,748,0
http://arxiv.org/abs/2502.13189v1,True,2025-02-18T14:06:05Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=14, tm_min=6, tm_sec=5, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T14:06:05Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=14, tm_min=6, tm_sec=5, tm_wday=1, tm_yday=49, tm_isdst=0)",MoBA: Mixture of Block Attention for Long-Context LLMs,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'MoBA: Mixture of Block Attention for Long-Context LLMs'}","Scaling the effective context length is essential for advancing large
language models (LLMs) toward artificial general intelligence (AGI). However,
the quadratic increase in computational complexity inherent in traditional
attention mechanisms presents a prohibitive overhead. Existing approaches
either impose strongly biased structures, such as sink or window attention
which are task-specific, or radically modify the attention mechanism into
linear approximations, whose performance in complex reasoning tasks remains
inadequately explored.
  In this work, we propose a solution that adheres to the ``less structure''
principle, allowing the model to determine where to attend autonomously, rather
than introducing predefined biases. We introduce Mixture of Block Attention
(MoBA), an innovative approach that applies the principles of Mixture of
Experts (MoE) to the attention mechanism. This novel architecture demonstrates
superior performance on long-context tasks while offering a key advantage: the
ability to seamlessly transition between full and sparse attention, enhancing
efficiency without the risk of compromising performance. MoBA has already been
deployed to support Kimi's long-context requests and demonstrates significant
advancements in efficient attention computation for LLMs. Our code is available
at https://github.com/MoonshotAI/MoBA.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Scaling the effective context length is essential for advancing large\nlanguage models (LLMs) toward artificial general intelligence (AGI). However,\nthe quadratic increase in computational complexity inherent in traditional\nattention mechanisms presents a prohibitive overhead. Existing approaches\neither impose strongly biased structures, such as sink or window attention\nwhich are task-specific, or radically modify the attention mechanism into\nlinear approximations, whose performance in complex reasoning tasks remains\ninadequately explored.\n  In this work, we propose a solution that adheres to the ``less structure''\nprinciple, allowing the model to determine where to attend autonomously, rather\nthan introducing predefined biases. We introduce Mixture of Block Attention\n(MoBA), an innovative approach that applies the principles of Mixture of\nExperts (MoE) to the attention mechanism. This novel architecture demonstrates\nsuperior performance on long-context tasks while offering a key advantage: the\nability to seamlessly transition between full and sparse attention, enhancing\nefficiency without the risk of compromising performance. MoBA has already been\ndeployed to support Kimi's long-context requests and demonstrates significant\nadvancements in efficient attention computation for LLMs. Our code is available\nat https://github.com/MoonshotAI/MoBA.""}","['Enzhe Lu', 'Zhejun Jiang', 'Jingyuan Liu', 'Yulun Du', 'Tao Jiang', 'Chao Hong', 'Shaowei Liu', 'Weiran He', 'Enming Yuan', 'Yuzhi Wang', 'Zhiqi Huang', 'Huan Yuan', 'Suting Xu', 'Xinran Xu', 'Guokun Lai', 'Yanru Chen', 'Huabin Zheng', 'Junjie Yan', 'Jianlin Su', 'Yuxin Wu', 'Neo Y. Zhang', 'Zhilin Yang', 'Xinyu Zhou', 'Mingxing Zhang', 'Jiezhong Qiu']",{'name': 'Jiezhong Qiu'},Jiezhong Qiu,15 pages,"[{'href': 'http://arxiv.org/abs/2502.13189v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13189v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13189v1,None,http://arxiv.org/abs/2502.13189v1,,,54,0
http://arxiv.org/abs/2502.13198v1,True,2025-02-18T18:01:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=1, tm_sec=36, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T18:01:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=1, tm_sec=36, tm_wday=1, tm_yday=49, tm_isdst=0)","Enhancing Machine Learning Performance through Intelligent Data Quality
  Assessment: An Unsupervised Data-centric Framework","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Enhancing Machine Learning Performance through Intelligent Data Quality\n  Assessment: An Unsupervised Data-centric Framework'}","Poor data quality limits the advantageous power of Machine Learning (ML) and
weakens high-performing ML software systems. Nowadays, data are more prone to
the risk of poor quality due to their increasing volume and complexity.
Therefore, tedious and time-consuming work goes into data preparation and
improvement before moving further in the ML pipeline. To address this
challenge, we propose an intelligent data-centric evaluation framework that can
identify high-quality data and improve the performance of an ML system. The
proposed framework combines the curation of quality measurements and
unsupervised learning to distinguish high- and low-quality data. The framework
is designed to integrate flexible and general-purpose methods so that it is
deployed in various domains and applications. To validate the outcomes of the
designed framework, we implemented it in a real-world use case from the field
of analytical chemistry, where it is tested on three datasets of anti-sense
oligonucleotides. A domain expert is consulted to identify the relevant quality
measurements and evaluate the outcomes of the framework. The results show that
the quality-centric data evaluation framework identifies the characteristics of
high-quality data that guide the conduct of efficient laboratory experiments
and consequently improve the performance of the ML system.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Poor data quality limits the advantageous power of Machine Learning (ML) and\nweakens high-performing ML software systems. Nowadays, data are more prone to\nthe risk of poor quality due to their increasing volume and complexity.\nTherefore, tedious and time-consuming work goes into data preparation and\nimprovement before moving further in the ML pipeline. To address this\nchallenge, we propose an intelligent data-centric evaluation framework that can\nidentify high-quality data and improve the performance of an ML system. The\nproposed framework combines the curation of quality measurements and\nunsupervised learning to distinguish high- and low-quality data. The framework\nis designed to integrate flexible and general-purpose methods so that it is\ndeployed in various domains and applications. To validate the outcomes of the\ndesigned framework, we implemented it in a real-world use case from the field\nof analytical chemistry, where it is tested on three datasets of anti-sense\noligonucleotides. A domain expert is consulted to identify the relevant quality\nmeasurements and evaluate the outcomes of the framework. The results show that\nthe quality-centric data evaluation framework identifies the characteristics of\nhigh-quality data that guide the conduct of efficient laboratory experiments\nand consequently improve the performance of the ML system.'}","['Manal Rahal', 'Bestoun S. Ahmed', 'Gergely Szabados', 'Torgny Fornstedt', 'Jorgen Samuelsson']",{'name': 'Jorgen Samuelsson'},Jorgen Samuelsson,42 pages,"[{'href': 'http://arxiv.org/abs/2502.13198v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13198v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13198v1,None,http://arxiv.org/abs/2502.13198v1,Heliyon 2025,,5522,0
http://arxiv.org/abs/2502.13207v1,True,2025-02-18T19:00:01Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=19, tm_min=0, tm_sec=1, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T19:00:01Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=19, tm_min=0, tm_sec=1, tm_wday=1, tm_yday=49, tm_isdst=0)","Thinking Outside the (Gray) Box: A Context-Based Score for Assessing
  Value and Originality in Neural Text Generation","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Thinking Outside the (Gray) Box: A Context-Based Score for Assessing\n  Value and Originality in Neural Text Generation'}","Despite the increasing use of large language models for creative tasks, their
outputs often lack diversity. Common solutions, such as sampling at higher
temperatures, can compromise the quality of the results. Drawing on information
theory, we propose a context-based score to quantitatively evaluate value and
originality. This score incentivizes accuracy and adherence to the request
while fostering divergence from the learned distribution. We propose using our
score as a reward in a reinforcement learning framework to fine-tune large
language models for maximum performance. We validate our strategy through
experiments in poetry generation and math problem solving, demonstrating that
it enhances the value and originality of the generated solutions.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Despite the increasing use of large language models for creative tasks, their\noutputs often lack diversity. Common solutions, such as sampling at higher\ntemperatures, can compromise the quality of the results. Drawing on information\ntheory, we propose a context-based score to quantitatively evaluate value and\noriginality. This score incentivizes accuracy and adherence to the request\nwhile fostering divergence from the learned distribution. We propose using our\nscore as a reward in a reinforcement learning framework to fine-tune large\nlanguage models for maximum performance. We validate our strategy through\nexperiments in poetry generation and math problem solving, demonstrating that\nit enhances the value and originality of the generated solutions.'}","['Giorgio Franceschelli', 'Mirco Musolesi']",{'name': 'Mirco Musolesi'},Mirco Musolesi,,"[{'href': 'http://arxiv.org/abs/2502.13207v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13207v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13207v1,None,http://arxiv.org/abs/2502.13207v1,,,261,0
http://arxiv.org/abs/2502.13221v1,True,2025-02-18T19:01:04Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=19, tm_min=1, tm_sec=4, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T19:01:04Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=19, tm_min=1, tm_sec=4, tm_wday=1, tm_yday=49, tm_isdst=0)","Two Tickets are Better than One: Fair and Accurate Hiring Under
  Strategic LLM Manipulations","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Two Tickets are Better than One: Fair and Accurate Hiring Under\n  Strategic LLM Manipulations'}","In an era of increasingly capable foundation models, job seekers are turning
to generative AI tools to enhance their application materials. However, unequal
access to and knowledge about generative AI tools can harm both employers and
candidates by reducing the accuracy of hiring decisions and giving some
candidates an unfair advantage. To address these challenges, we introduce a new
variant of the strategic classification framework tailored to manipulations
performed using large language models, accommodating varying levels of
manipulations and stochastic outcomes. We propose a ``two-ticket'' scheme,
where the hiring algorithm applies an additional manipulation to each submitted
resume and considers this manipulated version together with the original
submitted resume. We establish theoretical guarantees for this scheme, showing
improvements for both the fairness and accuracy of hiring decisions when the
true positive rate is maximized subject to a no false positives constraint. We
further generalize this approach to an $n$-ticket scheme and prove that hiring
outcomes converge to a fixed, group-independent decision, eliminating
disparities arising from differential LLM access. Finally, we empirically
validate our framework and the performance of our two-ticket scheme on real
resumes using an open-source resume screening tool.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""In an era of increasingly capable foundation models, job seekers are turning\nto generative AI tools to enhance their application materials. However, unequal\naccess to and knowledge about generative AI tools can harm both employers and\ncandidates by reducing the accuracy of hiring decisions and giving some\ncandidates an unfair advantage. To address these challenges, we introduce a new\nvariant of the strategic classification framework tailored to manipulations\nperformed using large language models, accommodating varying levels of\nmanipulations and stochastic outcomes. We propose a ``two-ticket'' scheme,\nwhere the hiring algorithm applies an additional manipulation to each submitted\nresume and considers this manipulated version together with the original\nsubmitted resume. We establish theoretical guarantees for this scheme, showing\nimprovements for both the fairness and accuracy of hiring decisions when the\ntrue positive rate is maximized subject to a no false positives constraint. We\nfurther generalize this approach to an $n$-ticket scheme and prove that hiring\noutcomes converge to a fixed, group-independent decision, eliminating\ndisparities arising from differential LLM access. Finally, we empirically\nvalidate our framework and the performance of our two-ticket scheme on real\nresumes using an open-source resume screening tool.""}","['Lee Cohen', 'Jack Hsieh', 'Connie Hong', 'Judy Hanwen Shen']",{'name': 'Judy Hanwen Shen'},Judy Hanwen Shen,,"[{'href': 'http://arxiv.org/abs/2502.13221v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13221v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13221v1,None,http://arxiv.org/abs/2502.13221v1,,,0,0
http://arxiv.org/abs/2502.13228v1,True,2025-02-18T19:06:21Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=19, tm_min=6, tm_sec=21, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T19:06:21Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=19, tm_min=6, tm_sec=21, tm_wday=1, tm_yday=49, tm_isdst=0)",Conformal Prediction as Bayesian Quadrature,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Conformal Prediction as Bayesian Quadrature'}","As machine learning-based prediction systems are increasingly used in
high-stakes situations, it is important to understand how such predictive
models will perform upon deployment. Distribution-free uncertainty
quantification techniques such as conformal prediction provide guarantees about
the loss black-box models will incur even when the details of the models are
hidden. However, such methods are based on frequentist probability, which
unduly limits their applicability. We revisit the central aspects of conformal
prediction from a Bayesian perspective and thereby illuminate the shortcomings
of frequentist guarantees. We propose a practical alternative based on Bayesian
quadrature that provides interpretable guarantees and offers a richer
representation of the likely range of losses to be observed at test time.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'As machine learning-based prediction systems are increasingly used in\nhigh-stakes situations, it is important to understand how such predictive\nmodels will perform upon deployment. Distribution-free uncertainty\nquantification techniques such as conformal prediction provide guarantees about\nthe loss black-box models will incur even when the details of the models are\nhidden. However, such methods are based on frequentist probability, which\nunduly limits their applicability. We revisit the central aspects of conformal\nprediction from a Bayesian perspective and thereby illuminate the shortcomings\nof frequentist guarantees. We propose a practical alternative based on Bayesian\nquadrature that provides interpretable guarantees and offers a richer\nrepresentation of the likely range of losses to be observed at test time.'}","['Jake C. Snell', 'Thomas L. Griffiths']",{'name': 'Thomas L. Griffiths'},Thomas L. Griffiths,"16 pages, 4 figures","[{'href': 'http://arxiv.org/abs/2502.13228v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13228v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13228v1,None,http://arxiv.org/abs/2502.13228v1,,,5,0
http://arxiv.org/abs/2502.13234v1,True,2025-02-18T19:12:51Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=19, tm_min=12, tm_sec=51, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T19:12:51Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=19, tm_min=12, tm_sec=51, tm_wday=1, tm_yday=49, tm_isdst=0)","MotionMatcher: Motion Customization of Text-to-Video Diffusion Models
  via Motion Feature Matching","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'MotionMatcher: Motion Customization of Text-to-Video Diffusion Models\n  via Motion Feature Matching'}","Text-to-video (T2V) diffusion models have shown promising capabilities in
synthesizing realistic videos from input text prompts. However, the input text
description alone provides limited control over the precise objects movements
and camera framing. In this work, we tackle the motion customization problem,
where a reference video is provided as motion guidance. While most existing
methods choose to fine-tune pre-trained diffusion models to reconstruct the
frame differences of the reference video, we observe that such strategy suffer
from content leakage from the reference video, and they cannot capture complex
motion accurately. To address this issue, we propose MotionMatcher, a motion
customization framework that fine-tunes the pre-trained T2V diffusion model at
the feature level. Instead of using pixel-level objectives, MotionMatcher
compares high-level, spatio-temporal motion features to fine-tune diffusion
models, ensuring precise motion learning. For the sake of memory efficiency and
accessibility, we utilize a pre-trained T2V diffusion model, which contains
considerable prior knowledge about video motion, to compute these motion
features. In our experiments, we demonstrate state-of-the-art motion
customization performances, validating the design of our framework.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Text-to-video (T2V) diffusion models have shown promising capabilities in\nsynthesizing realistic videos from input text prompts. However, the input text\ndescription alone provides limited control over the precise objects movements\nand camera framing. In this work, we tackle the motion customization problem,\nwhere a reference video is provided as motion guidance. While most existing\nmethods choose to fine-tune pre-trained diffusion models to reconstruct the\nframe differences of the reference video, we observe that such strategy suffer\nfrom content leakage from the reference video, and they cannot capture complex\nmotion accurately. To address this issue, we propose MotionMatcher, a motion\ncustomization framework that fine-tunes the pre-trained T2V diffusion model at\nthe feature level. Instead of using pixel-level objectives, MotionMatcher\ncompares high-level, spatio-temporal motion features to fine-tune diffusion\nmodels, ensuring precise motion learning. For the sake of memory efficiency and\naccessibility, we utilize a pre-trained T2V diffusion model, which contains\nconsiderable prior knowledge about video motion, to compute these motion\nfeatures. In our experiments, we demonstrate state-of-the-art motion\ncustomization performances, validating the design of our framework.'}","['Yen-Siang Wu', 'Chi-Pin Huang', 'Fu-En Yang', 'Yu-Chiang Frank Wang']",{'name': 'Yu-Chiang Frank Wang'},Yu-Chiang Frank Wang,Project page: https://www.csie.ntu.edu.tw/~b09902097/motionmatcher/,"[{'href': 'http://arxiv.org/abs/2502.13234v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13234v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13234v1,None,http://arxiv.org/abs/2502.13234v1,,,364,0
http://arxiv.org/abs/2502.13248v1,True,2025-02-18T19:20:51Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=19, tm_min=20, tm_sec=51, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T19:20:51Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=19, tm_min=20, tm_sec=51, tm_wday=1, tm_yday=49, tm_isdst=0)","Communication Strategy on Macro-and-Micro Traffic State in Cooperative
  Deep Reinforcement Learning for Regional Traffic Signal Control","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Communication Strategy on Macro-and-Micro Traffic State in Cooperative\n  Deep Reinforcement Learning for Regional Traffic Signal Control'}","Adaptive Traffic Signal Control (ATSC) has become a popular research topic in
intelligent transportation systems. Regional Traffic Signal Control (RTSC)
using the Multi-agent Deep Reinforcement Learning (MADRL) technique has become
a promising approach for ATSC due to its ability to achieve the optimum
trade-off between scalability and optimality. Most existing RTSC approaches
partition a traffic network into several disjoint regions, followed by applying
centralized reinforcement learning techniques to each region. However, the
pursuit of cooperation among RTSC agents still remains an open issue and no
communication strategy for RTSC agents has been investigated. In this paper, we
propose communication strategies to capture the correlation of micro-traffic
states among lanes and the correlation of macro-traffic states among
intersections. We first justify the evolution equation of the RTSC process is
Markovian via a system of store-and-forward queues. Next, based on the
evolution equation, we propose two GAT-Aggregated (GA2) communication
modules--GA2-Naive and GA2-Aug to extract both intra-region and inter-region
correlations between macro and micro traffic states. While GA2-Naive only
considers the movements at each intersection, GA2-Aug also considers the
lane-changing behavior of vehicles. Two proposed communication modules are then
aggregated into two existing novel RTSC frameworks--RegionLight and
Regional-DRL. Experimental results demonstrate that both GA2-Naive and GA2-Aug
effectively improve the performance of existing RTSC frameworks under both real
and synthetic scenarios. Hyperparameter testing also reveals the robustness and
potential of our communication modules in large-scale traffic networks.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Adaptive Traffic Signal Control (ATSC) has become a popular research topic in\nintelligent transportation systems. Regional Traffic Signal Control (RTSC)\nusing the Multi-agent Deep Reinforcement Learning (MADRL) technique has become\na promising approach for ATSC due to its ability to achieve the optimum\ntrade-off between scalability and optimality. Most existing RTSC approaches\npartition a traffic network into several disjoint regions, followed by applying\ncentralized reinforcement learning techniques to each region. However, the\npursuit of cooperation among RTSC agents still remains an open issue and no\ncommunication strategy for RTSC agents has been investigated. In this paper, we\npropose communication strategies to capture the correlation of micro-traffic\nstates among lanes and the correlation of macro-traffic states among\nintersections. We first justify the evolution equation of the RTSC process is\nMarkovian via a system of store-and-forward queues. Next, based on the\nevolution equation, we propose two GAT-Aggregated (GA2) communication\nmodules--GA2-Naive and GA2-Aug to extract both intra-region and inter-region\ncorrelations between macro and micro traffic states. While GA2-Naive only\nconsiders the movements at each intersection, GA2-Aug also considers the\nlane-changing behavior of vehicles. Two proposed communication modules are then\naggregated into two existing novel RTSC frameworks--RegionLight and\nRegional-DRL. Experimental results demonstrate that both GA2-Naive and GA2-Aug\neffectively improve the performance of existing RTSC frameworks under both real\nand synthetic scenarios. Hyperparameter testing also reveals the robustness and\npotential of our communication modules in large-scale traffic networks.'}","['Hankang Gu', 'Shangbo Wang', 'Dongyao Jia', 'Yuli Zhang', 'Yanrong Luo', 'Guoqiang Mao', 'Jianping Wang', 'Eng Gee Lim']",{'name': 'Eng Gee Lim'},Eng Gee Lim,,"[{'href': 'http://arxiv.org/abs/2502.13248v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13248v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13248v1,None,http://arxiv.org/abs/2502.13248v1,,,886,0
http://arxiv.org/abs/2502.13259v1,True,2025-02-18T20:04:09Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=20, tm_min=4, tm_sec=9, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T20:04:09Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=20, tm_min=4, tm_sec=9, tm_wday=1, tm_yday=49, tm_isdst=0)",HumT DumT: Measuring and controlling human-like language in LLMs,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'HumT DumT: Measuring and controlling human-like language in LLMs'}","Should LLMs generate language that makes them seem human? Human-like language
might improve user experience, but might also lead to overreliance and
stereotyping. Assessing these potential impacts requires a systematic way to
measure human-like tone in LLM outputs. We introduce HumT and SocioT, metrics
for human-like tone and other dimensions of social perceptions in text data
based on relative probabilities from an LLM. By measuring HumT across
preference and usage datasets, we find that users prefer less human-like
outputs from LLMs. HumT also offers insights into the impacts of
anthropomorphism: human-like LLM outputs are highly correlated with warmth,
social closeness, femininity, and low status, which are closely linked to the
aforementioned harms. We introduce DumT, a method using HumT to systematically
control and reduce the degree of human-like tone while preserving model
performance. DumT offers a practical approach for mitigating risks associated
with anthropomorphic language generation.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Should LLMs generate language that makes them seem human? Human-like language\nmight improve user experience, but might also lead to overreliance and\nstereotyping. Assessing these potential impacts requires a systematic way to\nmeasure human-like tone in LLM outputs. We introduce HumT and SocioT, metrics\nfor human-like tone and other dimensions of social perceptions in text data\nbased on relative probabilities from an LLM. By measuring HumT across\npreference and usage datasets, we find that users prefer less human-like\noutputs from LLMs. HumT also offers insights into the impacts of\nanthropomorphism: human-like LLM outputs are highly correlated with warmth,\nsocial closeness, femininity, and low status, which are closely linked to the\naforementioned harms. We introduce DumT, a method using HumT to systematically\ncontrol and reduce the degree of human-like tone while preserving model\nperformance. DumT offers a practical approach for mitigating risks associated\nwith anthropomorphic language generation.'}","['Myra Cheng', 'Sunny Yu', 'Dan Jurafsky']",{'name': 'Dan Jurafsky'},Dan Jurafsky,,"[{'href': 'http://arxiv.org/abs/2502.13259v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13259v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13259v1,None,http://arxiv.org/abs/2502.13259v1,,,567,0
http://arxiv.org/abs/2502.13260v1,True,2025-02-18T20:04:51Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=20, tm_min=4, tm_sec=51, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T20:04:51Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=20, tm_min=4, tm_sec=51, tm_wday=1, tm_yday=49, tm_isdst=0)","Stepwise Perplexity-Guided Refinement for Efficient Chain-of-Thought
  Reasoning in Large Language Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Stepwise Perplexity-Guided Refinement for Efficient Chain-of-Thought\n  Reasoning in Large Language Models'}","Chain-of-Thought (CoT) reasoning, which breaks down complex tasks into
intermediate reasoning steps, has significantly enhanced the performance of
large language models (LLMs) on challenging tasks. However, the detailed
reasoning process in CoT often incurs long generation times and high
computational costs, partly due to the inclusion of unnecessary steps. To
address this, we propose a method to identify critical reasoning steps using
perplexity as a measure of their importance: a step is deemed critical if its
removal causes a significant increase in perplexity. Our method enables models
to focus solely on generating these critical steps. This can be achieved
through two approaches: refining demonstration examples in few-shot CoT or
fine-tuning the model using selected examples that include only critical steps.
Comprehensive experiments validate the effectiveness of our method, which
achieves a better balance between the reasoning accuracy and efficiency of CoT.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Chain-of-Thought (CoT) reasoning, which breaks down complex tasks into\nintermediate reasoning steps, has significantly enhanced the performance of\nlarge language models (LLMs) on challenging tasks. However, the detailed\nreasoning process in CoT often incurs long generation times and high\ncomputational costs, partly due to the inclusion of unnecessary steps. To\naddress this, we propose a method to identify critical reasoning steps using\nperplexity as a measure of their importance: a step is deemed critical if its\nremoval causes a significant increase in perplexity. Our method enables models\nto focus solely on generating these critical steps. This can be achieved\nthrough two approaches: refining demonstration examples in few-shot CoT or\nfine-tuning the model using selected examples that include only critical steps.\nComprehensive experiments validate the effectiveness of our method, which\nachieves a better balance between the reasoning accuracy and efficiency of CoT.'}","['Yingqian Cui', 'Pengfei He', 'Jingying Zeng', 'Hui Liu', 'Xianfeng Tang', 'Zhenwei Dai', 'Yan Han', 'Chen Luo', 'Jing Huang', 'Zhen Li', 'Suhang Wang', 'Yue Xing', 'Jiliang Tang', 'Qi He']",{'name': 'Qi He'},Qi He,,"[{'href': 'http://arxiv.org/abs/2502.13260v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13260v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13260v1,None,http://arxiv.org/abs/2502.13260v1,,,173,0
http://arxiv.org/abs/2502.13321v1,True,2025-02-18T22:42:39Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=22, tm_min=42, tm_sec=39, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T22:42:39Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=22, tm_min=42, tm_sec=39, tm_wday=1, tm_yday=49, tm_isdst=0)","Adjust for Trust: Mitigating Trust-Induced Inappropriate Reliance on AI
  Assistance","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Adjust for Trust: Mitigating Trust-Induced Inappropriate Reliance on AI\n  Assistance'}","Trust biases how users rely on AI recommendations in AI-assisted
decision-making tasks, with low and high levels of trust resulting in increased
under- and over-reliance, respectively. We propose that AI assistants should
adapt their behavior through trust-adaptive interventions to mitigate such
inappropriate reliance. For instance, when user trust is low, providing an
explanation can elicit more careful consideration of the assistant's advice by
the user. In two decision-making scenarios -- laypeople answering science
questions and doctors making medical diagnoses -- we find that providing
supporting and counter-explanations during moments of low and high trust,
respectively, yields up to 38% reduction in inappropriate reliance and 20%
improvement in decision accuracy. We are similarly able to reduce over-reliance
by adaptively inserting forced pauses to promote deliberation. Our results
highlight how AI adaptation to user trust facilitates appropriate reliance,
presenting exciting avenues for improving human-AI collaboration.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Trust biases how users rely on AI recommendations in AI-assisted\ndecision-making tasks, with low and high levels of trust resulting in increased\nunder- and over-reliance, respectively. We propose that AI assistants should\nadapt their behavior through trust-adaptive interventions to mitigate such\ninappropriate reliance. For instance, when user trust is low, providing an\nexplanation can elicit more careful consideration of the assistant's advice by\nthe user. In two decision-making scenarios -- laypeople answering science\nquestions and doctors making medical diagnoses -- we find that providing\nsupporting and counter-explanations during moments of low and high trust,\nrespectively, yields up to 38% reduction in inappropriate reliance and 20%\nimprovement in decision accuracy. We are similarly able to reduce over-reliance\nby adaptively inserting forced pauses to promote deliberation. Our results\nhighlight how AI adaptation to user trust facilitates appropriate reliance,\npresenting exciting avenues for improving human-AI collaboration.""}","['Tejas Srinivasan', 'Jesse Thomason']",{'name': 'Jesse Thomason'},Jesse Thomason,,"[{'href': 'http://arxiv.org/abs/2502.13321v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13321v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13321v1,None,http://arxiv.org/abs/2502.13321v1,,,278,0
http://arxiv.org/abs/2502.13329v1,True,2025-02-18T23:13:16Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=23, tm_min=13, tm_sec=16, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T23:13:16Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=23, tm_min=13, tm_sec=16, tm_wday=1, tm_yday=49, tm_isdst=0)",Language Models Can Predict Their Own Behavior,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Language Models Can Predict Their Own Behavior'}","Autoregressive Language Models output text by sequentially predicting the
next token to generate, with modern methods like Chain-of-Thought (CoT)
prompting achieving state-of-the-art reasoning capabilities by scaling the
number of generated tokens. However, are there times when we can infer how the
model will behave (e.g. abstain from answering a question) early in the
computation, making generation unnecessary? We show that internal
representation of input tokens alone can often precisely predict, not just the
next token, but eventual behavior over the entire output sequence. We leverage
this capacity and learn probes on internal states to create early warning (and
exit) systems. Specifically, if the probes can confidently estimate the way the
LM is going to behave, then the system will avoid generating tokens altogether
and return the estimated behavior instead. On 27 text classification datasets
spanning five different tasks, we apply this method to estimate the eventual
answer of an LM under CoT prompting, reducing inference costs by 65% (average)
while suffering an accuracy loss of no more than 1.4% (worst case). We
demonstrate the potential of this method to pre-emptively identify when a model
will abstain from answering a question, fail to follow output format
specifications, or give a low-confidence response. We explore the limits of
this capability, showing that probes generalize to unseen datasets, but perform
worse when LM outputs are longer and struggle to predict properties that
require access to knowledge that the models themselves lack. Encouragingly,
performance scales with model size, suggesting applicability to the largest of
models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Autoregressive Language Models output text by sequentially predicting the\nnext token to generate, with modern methods like Chain-of-Thought (CoT)\nprompting achieving state-of-the-art reasoning capabilities by scaling the\nnumber of generated tokens. However, are there times when we can infer how the\nmodel will behave (e.g. abstain from answering a question) early in the\ncomputation, making generation unnecessary? We show that internal\nrepresentation of input tokens alone can often precisely predict, not just the\nnext token, but eventual behavior over the entire output sequence. We leverage\nthis capacity and learn probes on internal states to create early warning (and\nexit) systems. Specifically, if the probes can confidently estimate the way the\nLM is going to behave, then the system will avoid generating tokens altogether\nand return the estimated behavior instead. On 27 text classification datasets\nspanning five different tasks, we apply this method to estimate the eventual\nanswer of an LM under CoT prompting, reducing inference costs by 65% (average)\nwhile suffering an accuracy loss of no more than 1.4% (worst case). We\ndemonstrate the potential of this method to pre-emptively identify when a model\nwill abstain from answering a question, fail to follow output format\nspecifications, or give a low-confidence response. We explore the limits of\nthis capability, showing that probes generalize to unseen datasets, but perform\nworse when LM outputs are longer and struggle to predict properties that\nrequire access to knowledge that the models themselves lack. Encouragingly,\nperformance scales with model size, suggesting applicability to the largest of\nmodels'}","['Dhananjay Ashok', 'Jonathan May']",{'name': 'Jonathan May'},Jonathan May,,"[{'href': 'http://arxiv.org/abs/2502.13329v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13329v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13329v1,None,http://arxiv.org/abs/2502.13329v1,,,0,0
http://arxiv.org/abs/2502.13376v1,True,2025-02-19T02:24:44Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=2, tm_min=24, tm_sec=44, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T02:24:44Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=2, tm_min=24, tm_sec=44, tm_wday=2, tm_yday=50, tm_isdst=0)",Learning Symbolic Task Decompositions for Multi-Agent Teams,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Learning Symbolic Task Decompositions for Multi-Agent Teams'}","One approach for improving sample efficiency in cooperative multi-agent
learning is to decompose overall tasks into sub-tasks that can be assigned to
individual agents. We study this problem in the context of reward machines:
symbolic tasks that can be formally decomposed into sub-tasks. In order to
handle settings without a priori knowledge of the environment, we introduce a
framework that can learn the optimal decomposition from model-free interactions
with the environment. Our method uses a task-conditioned architecture to
simultaneously learn an optimal decomposition and the corresponding agents'
policies for each sub-task. In doing so, we remove the need for a human to
manually design the optimal decomposition while maintaining the
sample-efficiency benefits of improved credit assignment. We provide
experimental results in several deep reinforcement learning settings,
demonstrating the efficacy of our approach. Our results indicate that our
approach succeeds even in environments with codependent agent dynamics,
enabling synchronous multi-agent learning not achievable in previous works.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""One approach for improving sample efficiency in cooperative multi-agent\nlearning is to decompose overall tasks into sub-tasks that can be assigned to\nindividual agents. We study this problem in the context of reward machines:\nsymbolic tasks that can be formally decomposed into sub-tasks. In order to\nhandle settings without a priori knowledge of the environment, we introduce a\nframework that can learn the optimal decomposition from model-free interactions\nwith the environment. Our method uses a task-conditioned architecture to\nsimultaneously learn an optimal decomposition and the corresponding agents'\npolicies for each sub-task. In doing so, we remove the need for a human to\nmanually design the optimal decomposition while maintaining the\nsample-efficiency benefits of improved credit assignment. We provide\nexperimental results in several deep reinforcement learning settings,\ndemonstrating the efficacy of our approach. Our results indicate that our\napproach succeeds even in environments with codependent agent dynamics,\nenabling synchronous multi-agent learning not achievable in previous works.""}","['Ameesh Shah', 'Niklas Lauffer', 'Thomas Chen', 'Nikhil Pitta', 'Sanjit A. Seshia']",{'name': 'Sanjit A. Seshia'},Sanjit A. Seshia,"8 pages, main track full paper at AAMAS 2025","[{'href': 'http://arxiv.org/abs/2502.13376v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13376v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'F.2.2', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13376v1,None,http://arxiv.org/abs/2502.13376v1,,,18894,0
http://arxiv.org/abs/2502.13406v1,True,2025-02-19T03:33:01Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=3, tm_min=33, tm_sec=1, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T03:33:01Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=3, tm_min=33, tm_sec=1, tm_wday=2, tm_yday=50, tm_isdst=0)","Generative Predictive Control: Flow Matching Policies for Dynamic and
  Difficult-to-Demonstrate Tasks","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Generative Predictive Control: Flow Matching Policies for Dynamic and\n  Difficult-to-Demonstrate Tasks'}","Generative control policies have recently unlocked major progress in
robotics. These methods produce action sequences via diffusion or flow
matching, with training data provided by demonstrations. But despite enjoying
considerable success on difficult manipulation problems, generative policies
come with two key limitations. First, behavior cloning requires expert
demonstrations, which can be time-consuming and expensive to obtain. Second,
existing methods are limited to relatively slow, quasi-static tasks. In this
paper, we leverage a tight connection between sampling-based predictive control
and generative modeling to address each of these issues. In particular, we
introduce generative predictive control, a supervised learning framework for
tasks with fast dynamics that are easy to simulate but difficult to
demonstrate. We then show how trained flow-matching policies can be
warm-started at run-time, maintaining temporal consistency and enabling fast
feedback rates. We believe that generative predictive control offers a
complementary approach to existing behavior cloning methods, and hope that it
paves the way toward generalist policies that extend beyond quasi-static
demonstration-oriented tasks.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Generative control policies have recently unlocked major progress in\nrobotics. These methods produce action sequences via diffusion or flow\nmatching, with training data provided by demonstrations. But despite enjoying\nconsiderable success on difficult manipulation problems, generative policies\ncome with two key limitations. First, behavior cloning requires expert\ndemonstrations, which can be time-consuming and expensive to obtain. Second,\nexisting methods are limited to relatively slow, quasi-static tasks. In this\npaper, we leverage a tight connection between sampling-based predictive control\nand generative modeling to address each of these issues. In particular, we\nintroduce generative predictive control, a supervised learning framework for\ntasks with fast dynamics that are easy to simulate but difficult to\ndemonstrate. We then show how trained flow-matching policies can be\nwarm-started at run-time, maintaining temporal consistency and enabling fast\nfeedback rates. We believe that generative predictive control offers a\ncomplementary approach to existing behavior cloning methods, and hope that it\npaves the way toward generalist policies that extend beyond quasi-static\ndemonstration-oriented tasks.'}","['Vince Kurtz', 'Joel W. Burdick']",{'name': 'Joel W. Burdick'},Joel W. Burdick,,"[{'href': 'http://arxiv.org/abs/2502.13406v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13406v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'eess.SY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13406v1,None,http://arxiv.org/abs/2502.13406v1,,,323,0
http://arxiv.org/abs/2502.13410v1,True,2025-02-19T03:47:34Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=3, tm_min=47, tm_sec=34, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T03:47:34Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=3, tm_min=47, tm_sec=34, tm_wday=2, tm_yday=50, tm_isdst=0)",Tell Me Why: Incentivizing Explanations,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Tell Me Why: Incentivizing Explanations'}","Common sense suggests that when individuals explain why they believe
something, we can arrive at more accurate conclusions than when they simply
state what they believe. Yet, there is no known mechanism that provides
incentives to elicit explanations for beliefs from agents. This likely stems
from the fact that standard Bayesian models make assumptions (like conditional
independence of signals) that preempt the need for explanations, in order to
show efficient information aggregation. A natural justification for the value
of explanations is that agents' beliefs tend to be drawn from overlapping
sources of information, so agents' belief reports do not reveal all that needs
to be known. Indeed, this work argues that rationales-explanations of an
agent's private information-lead to more efficient aggregation by allowing
agents to efficiently identify what information they share and what information
is new. Building on this model of rationales, we present a novel 'deliberation
mechanism' to elicit rationales from agents in which truthful reporting of
beliefs and rationales is a perfect Bayesian equilibrium.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Common sense suggests that when individuals explain why they believe\nsomething, we can arrive at more accurate conclusions than when they simply\nstate what they believe. Yet, there is no known mechanism that provides\nincentives to elicit explanations for beliefs from agents. This likely stems\nfrom the fact that standard Bayesian models make assumptions (like conditional\nindependence of signals) that preempt the need for explanations, in order to\nshow efficient information aggregation. A natural justification for the value\nof explanations is that agents' beliefs tend to be drawn from overlapping\nsources of information, so agents' belief reports do not reveal all that needs\nto be known. Indeed, this work argues that rationales-explanations of an\nagent's private information-lead to more efficient aggregation by allowing\nagents to efficiently identify what information they share and what information\nis new. Building on this model of rationales, we present a novel 'deliberation\nmechanism' to elicit rationales from agents in which truthful reporting of\nbeliefs and rationales is a perfect Bayesian equilibrium.""}","['Siddarth Srinivasan', 'Ezra Karger', 'Michiel Bakker', 'Yiling Chen']",{'name': 'Yiling Chen'},Yiling Chen,,"[{'href': 'http://arxiv.org/abs/2502.13410v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13410v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'econ.TH', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13410v1,None,http://arxiv.org/abs/2502.13410v1,,,219,0
http://arxiv.org/abs/2502.13417v1,True,2025-02-19T04:25:11Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=4, tm_min=25, tm_sec=11, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T04:25:11Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=4, tm_min=25, tm_sec=11, tm_wday=2, tm_yday=50, tm_isdst=0)",RLTHF: Targeted Human Feedback for LLM Alignment,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'RLTHF: Targeted Human Feedback for LLM Alignment'}","Fine-tuning large language models (LLMs) to align with user preferences is
challenging due to the high cost of quality human annotations in Reinforcement
Learning from Human Feedback (RLHF) and the generalizability limitations of AI
Feedback. To address these challenges, we propose RLTHF, a human-AI hybrid
framework that combines LLM-based initial alignment with selective human
annotations to achieve full-human annotation alignment with minimal effort.
RLTHF identifies hard-to-annotate samples mislabeled by LLMs using a reward
model's reward distribution and iteratively enhances alignment by integrating
strategic human corrections while leveraging LLM's correctly labeled samples.
Evaluations on HH-RLHF and TL;DR datasets show that RLTHF reaches full-human
annotation-level alignment with only 6-7% of the human annotation effort.
Furthermore, models trained on RLTHF's curated datasets for downstream tasks
outperform those trained on fully human-annotated datasets, underscoring the
effectiveness of RLTHF's strategic data curation.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Fine-tuning large language models (LLMs) to align with user preferences is\nchallenging due to the high cost of quality human annotations in Reinforcement\nLearning from Human Feedback (RLHF) and the generalizability limitations of AI\nFeedback. To address these challenges, we propose RLTHF, a human-AI hybrid\nframework that combines LLM-based initial alignment with selective human\nannotations to achieve full-human annotation alignment with minimal effort.\nRLTHF identifies hard-to-annotate samples mislabeled by LLMs using a reward\nmodel's reward distribution and iteratively enhances alignment by integrating\nstrategic human corrections while leveraging LLM's correctly labeled samples.\nEvaluations on HH-RLHF and TL;DR datasets show that RLTHF reaches full-human\nannotation-level alignment with only 6-7% of the human annotation effort.\nFurthermore, models trained on RLTHF's curated datasets for downstream tasks\noutperform those trained on fully human-annotated datasets, underscoring the\neffectiveness of RLTHF's strategic data curation.""}","['Yifei Xu', 'Tusher Chakraborty', 'Emre Kcman', 'Bibek Aryal', 'Eduardo Rodrigues', 'Srinagesh Sharma', 'Roberto Estevao', 'Maria Angels de Luis Balaguer', 'Jessica Wolk', 'Rafael Padilha', 'Leonardo Nunes', 'Shobana Balakrishnan', 'Songwu Lu', 'Ranveer Chandra']",{'name': 'Ranveer Chandra'},Ranveer Chandra,,"[{'href': 'http://arxiv.org/abs/2502.13417v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13417v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13417v1,None,http://arxiv.org/abs/2502.13417v1,,,589,0
http://arxiv.org/abs/2502.13422v1,True,2025-02-19T04:45:05Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=4, tm_min=45, tm_sec=5, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T04:45:05Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=4, tm_min=45, tm_sec=5, tm_wday=2, tm_yday=50, tm_isdst=0)","TabSD: Large Free-Form Table Question Answering with SQL-Based Table
  Decomposition","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'TabSD: Large Free-Form Table Question Answering with SQL-Based Table\n  Decomposition'}","Question answering on free-form tables (TableQA) is challenging due to the
absence of predefined schemas and the presence of noise in large tables. While
Large Language Models (LLMs) have shown promise in TableQA, they struggle with
large free-form tables and noise sensitivity. To address these challenges, we
propose TabSD, a SQL-based decomposition model that enhances LLMs' ability to
process large free-form tables. TabSD generates SQL queries to guide the table
decomposition, remove noise, and processes sub-tables for better answer
generation. Additionally, SQL Verifier refines SQL outputs to enhance
decomposition accuracy. We introduce two TableQA datasets with large free-form
tables, SLQA and SEQA, which consist solely of large free-form tables and will
be publicly available. Experimental results on four benchmark datasets
demonstrate that TABSD outperforms the best-existing baseline models by 23.07%,
2.84%, 23.24% and 9.32% in accuracy, respectively, highlighting its
effectiveness in handling large and noisy free-form tables.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Question answering on free-form tables (TableQA) is challenging due to the\nabsence of predefined schemas and the presence of noise in large tables. While\nLarge Language Models (LLMs) have shown promise in TableQA, they struggle with\nlarge free-form tables and noise sensitivity. To address these challenges, we\npropose TabSD, a SQL-based decomposition model that enhances LLMs' ability to\nprocess large free-form tables. TabSD generates SQL queries to guide the table\ndecomposition, remove noise, and processes sub-tables for better answer\ngeneration. Additionally, SQL Verifier refines SQL outputs to enhance\ndecomposition accuracy. We introduce two TableQA datasets with large free-form\ntables, SLQA and SEQA, which consist solely of large free-form tables and will\nbe publicly available. Experimental results on four benchmark datasets\ndemonstrate that TABSD outperforms the best-existing baseline models by 23.07%,\n2.84%, 23.24% and 9.32% in accuracy, respectively, highlighting its\neffectiveness in handling large and noisy free-form tables.""}","['Yuxiang Wang', 'Junhao Gan', 'Jianzhong Qi']",{'name': 'Jianzhong Qi'},Jianzhong Qi,,"[{'href': 'http://arxiv.org/abs/2502.13422v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13422v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.DB', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13422v1,None,http://arxiv.org/abs/2502.13422v1,,,5,0
http://arxiv.org/abs/2502.13442v1,True,2025-02-19T05:38:45Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=5, tm_min=38, tm_sec=45, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T05:38:45Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=5, tm_min=38, tm_sec=45, tm_wday=2, tm_yday=50, tm_isdst=0)","TreeCut: A Synthetic Unanswerable Math Word Problem Dataset for LLM
  Hallucination Evaluation","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'TreeCut: A Synthetic Unanswerable Math Word Problem Dataset for LLM\n  Hallucination Evaluation'}","Large language models (LLMs) now achieve near-human performance on standard
math word problem benchmarks (e.g., GSM8K), yet their true reasoning ability
remains disputed. A key concern is that models often produce confident, yet
unfounded, answers to unanswerable problems. We introduce TreeCut, a synthetic
dataset that systematically generates infinite unanswerable math word problems
and their answerable counterparts, by representing each question as a tree and
removing chosen necessary conditions. Experiments show TreeCut effectively
induce hallucinations in large language models, including GPT-4o and o3-mini,
with rates of 61% and 42% in their respective worst-case scenarios. Further
analysis highlights that deeper or more complex trees, composite item names,
and removing necessary condition near the middle of a path all increase the
likelihood of hallucinations, underscoring the persistent challenges LLMs face
in identifying unanswerable math problems.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large language models (LLMs) now achieve near-human performance on standard\nmath word problem benchmarks (e.g., GSM8K), yet their true reasoning ability\nremains disputed. A key concern is that models often produce confident, yet\nunfounded, answers to unanswerable problems. We introduce TreeCut, a synthetic\ndataset that systematically generates infinite unanswerable math word problems\nand their answerable counterparts, by representing each question as a tree and\nremoving chosen necessary conditions. Experiments show TreeCut effectively\ninduce hallucinations in large language models, including GPT-4o and o3-mini,\nwith rates of 61% and 42% in their respective worst-case scenarios. Further\nanalysis highlights that deeper or more complex trees, composite item names,\nand removing necessary condition near the middle of a path all increase the\nlikelihood of hallucinations, underscoring the persistent challenges LLMs face\nin identifying unanswerable math problems.'}",['Jialin Ouyang'],{'name': 'Jialin Ouyang'},Jialin Ouyang,,"[{'href': 'http://arxiv.org/abs/2502.13442v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13442v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13442v1,None,http://arxiv.org/abs/2502.13442v1,,,0,0
http://arxiv.org/abs/2502.13458v1,True,2025-02-19T06:09:58Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=6, tm_min=9, tm_sec=58, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T06:09:58Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=6, tm_min=9, tm_sec=58, tm_wday=2, tm_yday=50, tm_isdst=0)",ThinkGuard: Deliberative Slow Thinking Leads to Cautious Guardrails,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'ThinkGuard: Deliberative Slow Thinking Leads to Cautious Guardrails'}","Ensuring the safety of large language models (LLMs) is critical as they are
deployed in real-world applications. Existing guardrails rely on rule-based
filtering or single-pass classification, limiting their ability to handle
nuanced safety violations. To address this, we propose ThinkGuard, a
critique-augmented guardrail model that distills knowledge from high-capacity
LLMs by generating structured critiques alongside safety labels. Fine-tuned on
critique-augmented data, the captured deliberative thinking ability drastically
enhances the guardrail's cautiousness and interpretability. Evaluated on
multiple safety benchmarks, ThinkGuard achieves the highest average F1 and
AUPRC, outperforming all baselines. Compared to LLaMA Guard 3, ThinkGuard
improves accuracy by 16.1% and macro F1 by 27.0%. Moreover, it surpasses
label-only fine-tuned models, confirming that structured critiques enhance both
classification precision and nuanced safety reasoning while maintaining
computational efficiency.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Ensuring the safety of large language models (LLMs) is critical as they are\ndeployed in real-world applications. Existing guardrails rely on rule-based\nfiltering or single-pass classification, limiting their ability to handle\nnuanced safety violations. To address this, we propose ThinkGuard, a\ncritique-augmented guardrail model that distills knowledge from high-capacity\nLLMs by generating structured critiques alongside safety labels. Fine-tuned on\ncritique-augmented data, the captured deliberative thinking ability drastically\nenhances the guardrail's cautiousness and interpretability. Evaluated on\nmultiple safety benchmarks, ThinkGuard achieves the highest average F1 and\nAUPRC, outperforming all baselines. Compared to LLaMA Guard 3, ThinkGuard\nimproves accuracy by 16.1% and macro F1 by 27.0%. Moreover, it surpasses\nlabel-only fine-tuned models, confirming that structured critiques enhance both\nclassification precision and nuanced safety reasoning while maintaining\ncomputational efficiency.""}","['Xiaofei Wen', 'Wenxuan Zhou', 'Wenjie Jacky Mo', 'Muhao Chen']",{'name': 'Muhao Chen'},Muhao Chen,,"[{'href': 'http://arxiv.org/abs/2502.13458v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13458v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13458v1,None,http://arxiv.org/abs/2502.13458v1,,,1073,0
http://arxiv.org/abs/2502.13465v1,True,2025-02-19T06:33:39Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=6, tm_min=33, tm_sec=39, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T06:33:39Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=6, tm_min=33, tm_sec=39, tm_wday=2, tm_yday=50, tm_isdst=0)","HawkBench: Investigating Resilience of RAG Methods on Stratified
  Information-Seeking Tasks","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'HawkBench: Investigating Resilience of RAG Methods on Stratified\n  Information-Seeking Tasks'}","In real-world information-seeking scenarios, users have dynamic and diverse
needs, requiring RAG systems to demonstrate adaptable resilience. To
comprehensively evaluate the resilience of current RAG methods, we introduce
HawkBench, a human-labeled, multi-domain benchmark designed to rigorously
assess RAG performance across categorized task types. By stratifying tasks
based on information-seeking behaviors, HawkBench provides a systematic
evaluation of how well RAG systems adapt to diverse user needs.
  Unlike existing benchmarks, which focus primarily on specific task types
(mostly factoid queries) and rely on varying knowledge bases, HawkBench offers:
(1) systematic task stratification to cover a broad range of query types,
including both factoid and rationale queries, (2) integration of multi-domain
corpora across all task types to mitigate corpus bias, and (3) rigorous
annotation for high-quality evaluation.
  HawkBench includes 1,600 high-quality test samples, evenly distributed across
domains and task types. Using this benchmark, we evaluate representative RAG
methods, analyzing their performance in terms of answer quality and response
latency. Our findings highlight the need for dynamic task strategies that
integrate decision-making, query interpretation, and global knowledge
understanding to improve RAG generalizability. We believe HawkBench serves as a
pivotal benchmark for advancing the resilience of RAG methods and their ability
to achieve general-purpose information seeking.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'In real-world information-seeking scenarios, users have dynamic and diverse\nneeds, requiring RAG systems to demonstrate adaptable resilience. To\ncomprehensively evaluate the resilience of current RAG methods, we introduce\nHawkBench, a human-labeled, multi-domain benchmark designed to rigorously\nassess RAG performance across categorized task types. By stratifying tasks\nbased on information-seeking behaviors, HawkBench provides a systematic\nevaluation of how well RAG systems adapt to diverse user needs.\n  Unlike existing benchmarks, which focus primarily on specific task types\n(mostly factoid queries) and rely on varying knowledge bases, HawkBench offers:\n(1) systematic task stratification to cover a broad range of query types,\nincluding both factoid and rationale queries, (2) integration of multi-domain\ncorpora across all task types to mitigate corpus bias, and (3) rigorous\nannotation for high-quality evaluation.\n  HawkBench includes 1,600 high-quality test samples, evenly distributed across\ndomains and task types. Using this benchmark, we evaluate representative RAG\nmethods, analyzing their performance in terms of answer quality and response\nlatency. Our findings highlight the need for dynamic task strategies that\nintegrate decision-making, query interpretation, and global knowledge\nunderstanding to improve RAG generalizability. We believe HawkBench serves as a\npivotal benchmark for advancing the resilience of RAG methods and their ability\nto achieve general-purpose information seeking.'}","['Hongjin Qian', 'Zheng Liu', 'Chao Gao', 'Yankai Wang', 'Defu Lian', 'Zhicheng Dou']",{'name': 'Zhicheng Dou'},Zhicheng Dou,13 pages,"[{'href': 'http://arxiv.org/abs/2502.13465v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13465v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13465v1,None,http://arxiv.org/abs/2502.13465v1,,,795,0
http://arxiv.org/abs/2502.13471v1,True,2025-02-19T06:47:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=6, tm_min=47, tm_sec=23, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T06:47:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=6, tm_min=47, tm_sec=23, tm_wday=2, tm_yday=50, tm_isdst=0)","Some Insights of Construction of Feature Graph to Learn Pairwise Feature
  Interactions with Graph Neural Networks","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Some Insights of Construction of Feature Graph to Learn Pairwise Feature\n  Interactions with Graph Neural Networks'}","Feature interaction is crucial in predictive machine learning models, as it
captures the relationships between features that influence model performance.
In this work, we focus on pairwise interactions and investigate their
importance in constructing feature graphs for Graph Neural Networks (GNNs).
Rather than proposing new methods, we leverage existing GNN models and tools to
explore the relationship between feature graph structures and their
effectiveness in modeling interactions. Through experiments on synthesized
datasets, we uncover that edges between interacting features are important for
enabling GNNs to model feature interactions effectively. We also observe that
including non-interaction edges can act as noise, degrading model performance.
Furthermore, we provide theoretical support for sparse feature graph selection
using the Minimum Description Length (MDL) principle. We prove that feature
graphs retaining only necessary interaction edges yield a more efficient and
interpretable representation than complete graphs, aligning with Occam's Razor.
  Our findings offer both theoretical insights and practical guidelines for
designing feature graphs that improve the performance and interpretability of
GNN models.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Feature interaction is crucial in predictive machine learning models, as it\ncaptures the relationships between features that influence model performance.\nIn this work, we focus on pairwise interactions and investigate their\nimportance in constructing feature graphs for Graph Neural Networks (GNNs).\nRather than proposing new methods, we leverage existing GNN models and tools to\nexplore the relationship between feature graph structures and their\neffectiveness in modeling interactions. Through experiments on synthesized\ndatasets, we uncover that edges between interacting features are important for\nenabling GNNs to model feature interactions effectively. We also observe that\nincluding non-interaction edges can act as noise, degrading model performance.\nFurthermore, we provide theoretical support for sparse feature graph selection\nusing the Minimum Description Length (MDL) principle. We prove that feature\ngraphs retaining only necessary interaction edges yield a more efficient and\ninterpretable representation than complete graphs, aligning with Occam's Razor.\n  Our findings offer both theoretical insights and practical guidelines for\ndesigning feature graphs that improve the performance and interpretability of\nGNN models.""}","['Phaphontee Yamchote', 'Saw Nay Htet Win', 'Chainarong Amornbunchornvej', 'Thanapon Noraset']",{'name': 'Thanapon Noraset'},Thanapon Noraset,This is the draft before submitting to any journal,"[{'href': 'http://arxiv.org/abs/2502.13471v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13471v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T07 68T07 68T07', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.6', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13471v1,None,http://arxiv.org/abs/2502.13471v1,,,641,0
http://arxiv.org/abs/2502.13487v1,True,2025-02-19T07:20:07Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=7, tm_min=20, tm_sec=7, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T07:20:07Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=7, tm_min=20, tm_sec=7, tm_wday=2, tm_yday=50, tm_isdst=0)","Transferring Textual Preferences to Vision-Language Understanding
  through Model Merging","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Transferring Textual Preferences to Vision-Language Understanding\n  through Model Merging'}","Large vision-language models (LVLMs) perform outstandingly across various
multimodal tasks. However, their ability to evaluate generated content remains
limited, and training vision-language reward models (VLRMs) with preference
data is computationally expensive. This paper explores a training-free
alternative by merging text-based reward models (RMs) with LVLMs to create
VLRMs. Our approach shows that integrating these models leads to improved
performance over LVLMs' scoring and text-based RMs, offering an efficient
method for incorporating textual preferences into LVLMs.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Large vision-language models (LVLMs) perform outstandingly across various\nmultimodal tasks. However, their ability to evaluate generated content remains\nlimited, and training vision-language reward models (VLRMs) with preference\ndata is computationally expensive. This paper explores a training-free\nalternative by merging text-based reward models (RMs) with LVLMs to create\nVLRMs. Our approach shows that integrating these models leads to improved\nperformance over LVLMs' scoring and text-based RMs, offering an efficient\nmethod for incorporating textual preferences into LVLMs.""}","['Chen-An Li', 'Tzu-Han Lin', 'Yun-Nung Chen', 'Hung-yi Lee']",{'name': 'Hung-yi Lee'},Hung-yi Lee,Preprint. Under Review,"[{'href': 'http://arxiv.org/abs/2502.13487v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13487v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13487v1,None,http://arxiv.org/abs/2502.13487v1,,,124,0
http://arxiv.org/abs/2502.13499v1,True,2025-02-19T07:35:07Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=7, tm_min=35, tm_sec=7, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T07:35:07Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=7, tm_min=35, tm_sec=7, tm_wday=2, tm_yday=50, tm_isdst=0)","Hidden Darkness in LLM-Generated Designs: Exploring Dark Patterns in
  Ecommerce Web Components Generated by LLMs","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Hidden Darkness in LLM-Generated Designs: Exploring Dark Patterns in\n  Ecommerce Web Components Generated by LLMs'}","Recent work has highlighted the risks of LLM-generated content for a wide
range of harmful behaviors, including incorrect and harmful code. In this work,
we extend this by studying whether LLM-generated web design contains dark
patterns. This work evaluated designs of ecommerce web components generated by
four popular LLMs: Claude, GPT, Gemini, and Llama. We tested 13 commonly used
ecommerce components (e.g., search, product reviews) and used them as prompts
to generate a total of 312 components across all models. Over one-third of
generated components contain at least one dark pattern. The majority of dark
pattern strategies involve hiding crucial information, limiting users' actions,
and manipulating them into making decisions through a sense of urgency. Dark
patterns are also more frequently produced in components that are related to
company interests. These findings highlight the need for interventions to
prevent dark patterns during front-end code generation with LLMs and emphasize
the importance of expanding ethical design education to a broader audience.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Recent work has highlighted the risks of LLM-generated content for a wide\nrange of harmful behaviors, including incorrect and harmful code. In this work,\nwe extend this by studying whether LLM-generated web design contains dark\npatterns. This work evaluated designs of ecommerce web components generated by\nfour popular LLMs: Claude, GPT, Gemini, and Llama. We tested 13 commonly used\necommerce components (e.g., search, product reviews) and used them as prompts\nto generate a total of 312 components across all models. Over one-third of\ngenerated components contain at least one dark pattern. The majority of dark\npattern strategies involve hiding crucial information, limiting users' actions,\nand manipulating them into making decisions through a sense of urgency. Dark\npatterns are also more frequently produced in components that are related to\ncompany interests. These findings highlight the need for interventions to\nprevent dark patterns during front-end code generation with LLMs and emphasize\nthe importance of expanding ethical design education to a broader audience.""}","['Ziwei Chen', 'Jiawen Shen', 'Luna', 'Kristen Vaccaro']",{'name': 'Kristen Vaccaro'},Kristen Vaccaro,15 pages,"[{'href': 'http://arxiv.org/abs/2502.13499v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13499v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13499v1,None,http://arxiv.org/abs/2502.13499v1,,,0,0
http://arxiv.org/abs/2502.13502v1,True,2025-02-19T07:43:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=7, tm_min=43, tm_sec=36, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T07:43:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=7, tm_min=43, tm_sec=36, tm_wday=2, tm_yday=50, tm_isdst=0)","PLDR-LLMs Learn A Generalizable Tensor Operator That Can Replace Its Own
  Deep Neural Net At Inference","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'PLDR-LLMs Learn A Generalizable Tensor Operator That Can Replace Its Own\n  Deep Neural Net At Inference'}","We show that Large Language Model from Power Law Decoder Representations
(PLDR-LLM) is a foundational model whose deductive outputs are invariant
tensors up to a small perturbation. PLDR-LLM learns a singularity condition for
the deductive outputs that enable the once-inferred energy-curvature tensor
$\mathbf{G}_{LM}$ to replace the deep neural network of power law graph
attention (PLGA) generating the deductive outputs at inference. We demonstrate
that a cache for $\mathbf{G}_{LM}$ (G-cache) and KV-cache can be implemented in
a straightforward manner to improve the inference time. The invariance and
generalizable nature of deductive outputs is at a very high fidelity where
deductive outputs have same RMSE and determinant values up to 15 decimal places
after caching, and zero-shot benchmark scores remain unchanged. Ablation
studies show that learned deductive outputs have distinct loss and accuracy
characteristics from models pretrained with transferred, randomly initialized
or identity tensors as a constant tensor operator and an LLM with scaled-dot
product attention (SDPA) is a special case of PLDR-LLM where $\mathbf{G}_{LM}$
is predefined as identity. The observed invariance characteristic introduces a
novel asymmetry between training and inference phases with caching. We outline
observed common characteristics of the deductive outputs for the learned
singularity condition. We provide an implementation of a training and inference
framework for PLDR-LLM with KV-cache and G-cache.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'We show that Large Language Model from Power Law Decoder Representations\n(PLDR-LLM) is a foundational model whose deductive outputs are invariant\ntensors up to a small perturbation. PLDR-LLM learns a singularity condition for\nthe deductive outputs that enable the once-inferred energy-curvature tensor\n$\\mathbf{G}_{LM}$ to replace the deep neural network of power law graph\nattention (PLGA) generating the deductive outputs at inference. We demonstrate\nthat a cache for $\\mathbf{G}_{LM}$ (G-cache) and KV-cache can be implemented in\na straightforward manner to improve the inference time. The invariance and\ngeneralizable nature of deductive outputs is at a very high fidelity where\ndeductive outputs have same RMSE and determinant values up to 15 decimal places\nafter caching, and zero-shot benchmark scores remain unchanged. Ablation\nstudies show that learned deductive outputs have distinct loss and accuracy\ncharacteristics from models pretrained with transferred, randomly initialized\nor identity tensors as a constant tensor operator and an LLM with scaled-dot\nproduct attention (SDPA) is a special case of PLDR-LLM where $\\mathbf{G}_{LM}$\nis predefined as identity. The observed invariance characteristic introduces a\nnovel asymmetry between training and inference phases with caching. We outline\nobserved common characteristics of the deductive outputs for the learned\nsingularity condition. We provide an implementation of a training and inference\nframework for PLDR-LLM with KV-cache and G-cache.'}",['Burc Gokden'],{'name': 'Burc Gokden'},Burc Gokden,"15 pages, 1 figure, 12 tables","[{'href': 'http://arxiv.org/abs/2502.13502v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13502v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13502v1,None,http://arxiv.org/abs/2502.13502v1,,,0,0
http://arxiv.org/abs/2502.13509v1,True,2025-02-19T07:56:48Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=7, tm_min=56, tm_sec=48, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T07:56:48Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=7, tm_min=56, tm_sec=48, tm_wday=2, tm_yday=50, tm_isdst=0)","Unlocking Multimodal Integration in EHRs: A Prompt Learning Framework
  for Language and Time Series Fusion","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Unlocking Multimodal Integration in EHRs: A Prompt Learning Framework\n  for Language and Time Series Fusion'}","Large language models (LLMs) have shown remarkable performance in
vision-language tasks, but their application in the medical field remains
underexplored, particularly for integrating structured time series data with
unstructured clinical notes. In clinical practice, dynamic time series data
such as lab test results capture critical temporal patterns, while clinical
notes provide rich semantic context. Merging these modalities is challenging
due to the inherent differences between continuous signals and discrete text.
To bridge this gap, we introduce ProMedTS, a novel self-supervised multimodal
framework that employs prompt-guided learning to unify these heterogeneous data
types. Our approach leverages lightweight anomaly detection to generate anomaly
captions that serve as prompts, guiding the encoding of raw time series data
into informative embeddings. These embeddings are aligned with textual
representations in a shared latent space, preserving fine-grained temporal
nuances alongside semantic insights. Furthermore, our framework incorporates
tailored self-supervised objectives to enhance both intra- and inter-modal
alignment. We evaluate ProMedTS on disease diagnosis tasks using real-world
datasets, and the results demonstrate that our method consistently outperforms
state-of-the-art approaches.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large language models (LLMs) have shown remarkable performance in\nvision-language tasks, but their application in the medical field remains\nunderexplored, particularly for integrating structured time series data with\nunstructured clinical notes. In clinical practice, dynamic time series data\nsuch as lab test results capture critical temporal patterns, while clinical\nnotes provide rich semantic context. Merging these modalities is challenging\ndue to the inherent differences between continuous signals and discrete text.\nTo bridge this gap, we introduce ProMedTS, a novel self-supervised multimodal\nframework that employs prompt-guided learning to unify these heterogeneous data\ntypes. Our approach leverages lightweight anomaly detection to generate anomaly\ncaptions that serve as prompts, guiding the encoding of raw time series data\ninto informative embeddings. These embeddings are aligned with textual\nrepresentations in a shared latent space, preserving fine-grained temporal\nnuances alongside semantic insights. Furthermore, our framework incorporates\ntailored self-supervised objectives to enhance both intra- and inter-modal\nalignment. We evaluate ProMedTS on disease diagnosis tasks using real-world\ndatasets, and the results demonstrate that our method consistently outperforms\nstate-of-the-art approaches.'}","['Shuai Niu', 'Jing Ma', 'Hongzhan Lin', 'Liang Bai', 'Zhihua Wang', 'Wei Bi', 'Yida Xu', 'Guo Li', 'Xian Yang']",{'name': 'Xian Yang'},Xian Yang,"13 pages, 5 figures","[{'href': 'http://arxiv.org/abs/2502.13509v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13509v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13509v1,None,http://arxiv.org/abs/2502.13509v1,,,404,0
http://arxiv.org/abs/2502.13519v1,True,2025-02-19T08:15:16Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=8, tm_min=15, tm_sec=16, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T08:15:16Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=8, tm_min=15, tm_sec=16, tm_wday=2, tm_yday=50, tm_isdst=0)",MILE: Model-based Intervention Learning,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'MILE: Model-based Intervention Learning'}","Imitation learning techniques have been shown to be highly effective in
real-world control scenarios, such as robotics. However, these approaches not
only suffer from compounding error issues but also require human experts to
provide complete trajectories. Although there exist interactive methods where
an expert oversees the robot and intervenes if needed, these extensions usually
only utilize the data collected during intervention periods and ignore the
feedback signal hidden in non-intervention timesteps. In this work, we create a
model to formulate how the interventions occur in such cases, and show that it
is possible to learn a policy with just a handful of expert interventions. Our
key insight is that it is possible to get crucial information about the quality
of the current state and the optimality of the chosen action from expert
feedback, regardless of the presence or the absence of intervention. We
evaluate our method on various discrete and continuous simulation environments,
a real-world robotic manipulation task, as well as a human subject study.
Videos and the code can be found at https://liralab.usc.edu/mile .","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Imitation learning techniques have been shown to be highly effective in\nreal-world control scenarios, such as robotics. However, these approaches not\nonly suffer from compounding error issues but also require human experts to\nprovide complete trajectories. Although there exist interactive methods where\nan expert oversees the robot and intervenes if needed, these extensions usually\nonly utilize the data collected during intervention periods and ignore the\nfeedback signal hidden in non-intervention timesteps. In this work, we create a\nmodel to formulate how the interventions occur in such cases, and show that it\nis possible to learn a policy with just a handful of expert interventions. Our\nkey insight is that it is possible to get crucial information about the quality\nof the current state and the optimality of the chosen action from expert\nfeedback, regardless of the presence or the absence of intervention. We\nevaluate our method on various discrete and continuous simulation environments,\na real-world robotic manipulation task, as well as a human subject study.\nVideos and the code can be found at https://liralab.usc.edu/mile .'}","['Yigit Korkmaz', 'Erdem Byk']",{'name': 'Erdem Byk'},Erdem Byk,International Conference on Robotics and Automation (ICRA),"[{'href': 'http://arxiv.org/abs/2502.13519v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13519v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13519v1,None,http://arxiv.org/abs/2502.13519v1,,,1524,0
http://arxiv.org/abs/2502.13524v1,True,2025-02-19T08:21:59Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=8, tm_min=21, tm_sec=59, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T08:21:59Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=8, tm_min=21, tm_sec=59, tm_wday=2, tm_yday=50, tm_isdst=0)","MobileViM: A Light-weight and Dimension-independent Vision Mamba for 3D
  Medical Image Analysis","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'MobileViM: A Light-weight and Dimension-independent Vision Mamba for 3D\n  Medical Image Analysis'}","Efficient evaluation of three-dimensional (3D) medical images is crucial for
diagnostic and therapeutic practices in healthcare. Recent years have seen a
substantial uptake in applying deep learning and computer vision to analyse and
interpret medical images. Traditional approaches, such as convolutional neural
networks (CNNs) and vision transformers (ViTs), face significant computational
challenges, prompting the need for architectural advancements. Recent efforts
have led to the introduction of novel architectures like the ``Mamba'' model as
alternative solutions to traditional CNNs or ViTs. The Mamba model excels in
the linear processing of one-dimensional data with low computational demands.
However, Mamba's potential for 3D medical image analysis remains underexplored
and could face significant computational challenges as the dimension increases.
This manuscript presents MobileViM, a streamlined architecture for efficient
segmentation of 3D medical images. In the MobileViM network, we invent a new
dimension-independent mechanism and a dual-direction traversing approach to
incorporate with a vision-Mamba-based framework. MobileViM also features a
cross-scale bridging technique to improve efficiency and accuracy across
various medical imaging modalities. With these enhancements, MobileViM achieves
segmentation speeds exceeding 90 frames per second (FPS) on a single graphics
processing unit (i.e., NVIDIA RTX 4090). This performance is over 24 FPS faster
than the state-of-the-art deep learning models for processing 3D images with
the same computational resources. In addition, experimental evaluations
demonstrate that MobileViM delivers superior performance, with Dice similarity
scores reaching 92.72%, 86.69%, 80.46%, and 77.43% for PENGWIN, BraTS2024,
ATLAS, and Toothfairy2 datasets, respectively, which significantly surpasses
existing models.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Efficient evaluation of three-dimensional (3D) medical images is crucial for\ndiagnostic and therapeutic practices in healthcare. Recent years have seen a\nsubstantial uptake in applying deep learning and computer vision to analyse and\ninterpret medical images. Traditional approaches, such as convolutional neural\nnetworks (CNNs) and vision transformers (ViTs), face significant computational\nchallenges, prompting the need for architectural advancements. Recent efforts\nhave led to the introduction of novel architectures like the ``Mamba'' model as\nalternative solutions to traditional CNNs or ViTs. The Mamba model excels in\nthe linear processing of one-dimensional data with low computational demands.\nHowever, Mamba's potential for 3D medical image analysis remains underexplored\nand could face significant computational challenges as the dimension increases.\nThis manuscript presents MobileViM, a streamlined architecture for efficient\nsegmentation of 3D medical images. In the MobileViM network, we invent a new\ndimension-independent mechanism and a dual-direction traversing approach to\nincorporate with a vision-Mamba-based framework. MobileViM also features a\ncross-scale bridging technique to improve efficiency and accuracy across\nvarious medical imaging modalities. With these enhancements, MobileViM achieves\nsegmentation speeds exceeding 90 frames per second (FPS) on a single graphics\nprocessing unit (i.e., NVIDIA RTX 4090). This performance is over 24 FPS faster\nthan the state-of-the-art deep learning models for processing 3D images with\nthe same computational resources. In addition, experimental evaluations\ndemonstrate that MobileViM delivers superior performance, with Dice similarity\nscores reaching 92.72%, 86.69%, 80.46%, and 77.43% for PENGWIN, BraTS2024,\nATLAS, and Toothfairy2 datasets, respectively, which significantly surpasses\nexisting models.""}","['Wei Dai', 'Steven Wang', 'Jun Liu']",{'name': 'Jun Liu'},Jun Liu,"The code is accessible through:
  https://github.com/anthonyweidai/MobileViM_3D/","[{'href': 'http://arxiv.org/abs/2502.13524v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13524v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13524v1,None,http://arxiv.org/abs/2502.13524v1,,,0,0
http://arxiv.org/abs/2502.13533v1,True,2025-02-19T08:39:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=8, tm_min=39, tm_sec=15, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T08:39:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=8, tm_min=39, tm_sec=15, tm_wday=2, tm_yday=50, tm_isdst=0)","Train Small, Infer Large: Memory-Efficient LoRA Training for Large
  Language Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Train Small, Infer Large: Memory-Efficient LoRA Training for Large\n  Language Models'}","Large Language Models (LLMs) have significantly advanced natural language
processing with exceptional task generalization capabilities. Low-Rank Adaption
(LoRA) offers a cost-effective fine-tuning solution, freezing the original
model parameters and training only lightweight, low-rank adapter matrices.
However, the memory footprint of LoRA is largely dominated by the original
model parameters. To mitigate this, we propose LoRAM, a memory-efficient LoRA
training scheme founded on the intuition that many neurons in
over-parameterized LLMs have low training utility but are essential for
inference. LoRAM presents a unique twist: it trains on a pruned (small) model
to obtain pruned low-rank matrices, which are then recovered and utilized with
the original (large) model for inference. Additionally, minimal-cost continual
pre-training, performed by the model publishers in advance, aligns the
knowledge discrepancy between pruned and original models. Our extensive
experiments demonstrate the efficacy of LoRAM across various pruning strategies
and downstream tasks. For a model with 70 billion parameters, LoRAM enables
training on a GPU with only 20G HBM, replacing an A100-80G GPU for LoRA
training and 15 GPUs for full fine-tuning. Specifically, QLoRAM implemented by
structured pruning combined with 4-bit quantization, for LLaMA-3.1-70B
(LLaMA-2-70B), reduces the parameter storage cost that dominates the memory
usage in low-rank matrix training by 15.81$\times$ (16.95$\times$), while
achieving dominant performance gains over both the original LLaMA-3.1-70B
(LLaMA-2-70B) and LoRA-trained LLaMA-3.1-8B (LLaMA-2-13B).","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Language Models (LLMs) have significantly advanced natural language\nprocessing with exceptional task generalization capabilities. Low-Rank Adaption\n(LoRA) offers a cost-effective fine-tuning solution, freezing the original\nmodel parameters and training only lightweight, low-rank adapter matrices.\nHowever, the memory footprint of LoRA is largely dominated by the original\nmodel parameters. To mitigate this, we propose LoRAM, a memory-efficient LoRA\ntraining scheme founded on the intuition that many neurons in\nover-parameterized LLMs have low training utility but are essential for\ninference. LoRAM presents a unique twist: it trains on a pruned (small) model\nto obtain pruned low-rank matrices, which are then recovered and utilized with\nthe original (large) model for inference. Additionally, minimal-cost continual\npre-training, performed by the model publishers in advance, aligns the\nknowledge discrepancy between pruned and original models. Our extensive\nexperiments demonstrate the efficacy of LoRAM across various pruning strategies\nand downstream tasks. For a model with 70 billion parameters, LoRAM enables\ntraining on a GPU with only 20G HBM, replacing an A100-80G GPU for LoRA\ntraining and 15 GPUs for full fine-tuning. Specifically, QLoRAM implemented by\nstructured pruning combined with 4-bit quantization, for LLaMA-3.1-70B\n(LLaMA-2-70B), reduces the parameter storage cost that dominates the memory\nusage in low-rank matrix training by 15.81$\\times$ (16.95$\\times$), while\nachieving dominant performance gains over both the original LLaMA-3.1-70B\n(LLaMA-2-70B) and LoRA-trained LLaMA-3.1-8B (LLaMA-2-13B).'}","['Jun Zhang', 'Jue Wang', 'Huan Li', 'Lidan Shou', 'Ke Chen', 'Yang You', 'Guiming Xie', 'Xuejian Gong', 'Kunlong Zhou']",{'name': 'Kunlong Zhou'},Kunlong Zhou,Accepted at ICLR 2025,"[{'href': 'http://arxiv.org/abs/2502.13533v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13533v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13533v1,None,http://arxiv.org/abs/2502.13533v1,,,1998,0
http://arxiv.org/abs/2502.13534v1,True,2025-02-19T08:39:41Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=8, tm_min=39, tm_sec=41, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T08:39:41Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=8, tm_min=39, tm_sec=41, tm_wday=2, tm_yday=50, tm_isdst=0)","Solving the Encoding Bottleneck: Of the HHL Algorithm, By the HHL
  Algorithm","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Solving the Encoding Bottleneck: Of the HHL Algorithm, By the HHL\n  Algorithm'}","The Harrow-Hassidim-Lloyd (HHL) algorithm offers exponential speedup for
solving the quantum linear-system problem. But some caveats for the speedup
could be hard to met. One of the difficulties is the encoding bottleneck, i.e.,
the efficient preparation of the initial quantum state. To prepare an arbitrary
$N$-dimensional state exactly, existing state-preparation approaches generally
require a runtime of $O(N)$, which will ruin the speedup of the HHL algorithm.
Here we show that the states can be prepared approximately with a runtime of
$O(poly(\log N))$ by employing a slightly modified version of the HHL algorithm
itself. Thus, applying this approach to prepare the initial state of the
original HHL algorithm can preserve the exponential speedup advantage. It can
also serve as a standalone solution for other applications demanding rapid
state preparation.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The Harrow-Hassidim-Lloyd (HHL) algorithm offers exponential speedup for\nsolving the quantum linear-system problem. But some caveats for the speedup\ncould be hard to met. One of the difficulties is the encoding bottleneck, i.e.,\nthe efficient preparation of the initial quantum state. To prepare an arbitrary\n$N$-dimensional state exactly, existing state-preparation approaches generally\nrequire a runtime of $O(N)$, which will ruin the speedup of the HHL algorithm.\nHere we show that the states can be prepared approximately with a runtime of\n$O(poly(\\log N))$ by employing a slightly modified version of the HHL algorithm\nitself. Thus, applying this approach to prepare the initial state of the\noriginal HHL algorithm can preserve the exponential speedup advantage. It can\nalso serve as a standalone solution for other applications demanding rapid\nstate preparation.'}",['Guang Ping He'],{'name': 'Guang Ping He'},Guang Ping He,5 pages,"[{'href': 'http://arxiv.org/abs/2502.13534v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13534v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'quant-ph', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'quant-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13534v1,None,http://arxiv.org/abs/2502.13534v1,,,0,0
http://arxiv.org/abs/2502.13595v1,True,2025-02-19T10:13:43Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=10, tm_min=13, tm_sec=43, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T10:13:43Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=10, tm_min=13, tm_sec=43, tm_wday=2, tm_yday=50, tm_isdst=0)",MMTEB: Massive Multilingual Text Embedding Benchmark,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'MMTEB: Massive Multilingual Text Embedding Benchmark'}","Text embeddings are typically evaluated on a limited set of tasks, which are
constrained by language, domain, and task diversity. To address these
limitations and provide a more comprehensive evaluation, we introduce the
Massive Multilingual Text Embedding Benchmark (MMTEB) - a large-scale,
community-driven expansion of MTEB, covering over 500 quality-controlled
evaluation tasks across 250+ languages. MMTEB includes a diverse set of
challenging, novel tasks such as instruction following, long-document
retrieval, and code retrieval, representing the largest multilingual collection
of evaluation tasks for embedding models to date. Using this collection, we
develop several highly multilingual benchmarks, which we use to evaluate a
representative set of models. We find that while large language models (LLMs)
with billions of parameters can achieve state-of-the-art performance on certain
language subsets and task categories, the best-performing publicly available
model is multilingual-e5-large-instruct with only 560 million parameters. To
facilitate accessibility and reduce computational cost, we introduce a novel
downsampling method based on inter-task correlation, ensuring a diverse
selection while preserving relative model rankings. Furthermore, we optimize
tasks such as retrieval by sampling hard negatives, creating smaller but
effective splits. These optimizations allow us to introduce benchmarks that
drastically reduce computational demands. For instance, our newly introduced
zero-shot English benchmark maintains a ranking order similar to the full-scale
version but at a fraction of the computational cost.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Text embeddings are typically evaluated on a limited set of tasks, which are\nconstrained by language, domain, and task diversity. To address these\nlimitations and provide a more comprehensive evaluation, we introduce the\nMassive Multilingual Text Embedding Benchmark (MMTEB) - a large-scale,\ncommunity-driven expansion of MTEB, covering over 500 quality-controlled\nevaluation tasks across 250+ languages. MMTEB includes a diverse set of\nchallenging, novel tasks such as instruction following, long-document\nretrieval, and code retrieval, representing the largest multilingual collection\nof evaluation tasks for embedding models to date. Using this collection, we\ndevelop several highly multilingual benchmarks, which we use to evaluate a\nrepresentative set of models. We find that while large language models (LLMs)\nwith billions of parameters can achieve state-of-the-art performance on certain\nlanguage subsets and task categories, the best-performing publicly available\nmodel is multilingual-e5-large-instruct with only 560 million parameters. To\nfacilitate accessibility and reduce computational cost, we introduce a novel\ndownsampling method based on inter-task correlation, ensuring a diverse\nselection while preserving relative model rankings. Furthermore, we optimize\ntasks such as retrieval by sampling hard negatives, creating smaller but\neffective splits. These optimizations allow us to introduce benchmarks that\ndrastically reduce computational demands. For instance, our newly introduced\nzero-shot English benchmark maintains a ranking order similar to the full-scale\nversion but at a fraction of the computational cost.'}","['Kenneth Enevoldsen', 'Isaac Chung', 'Imene Kerboua', 'Mrton Kardos', 'Ashwin Mathur', 'David Stap', 'Jay Gala', 'Wissam Siblini', 'Dominik Krzemiski', 'Genta Indra Winata', 'Saba Sturua', 'Saiteja Utpala', 'Mathieu Ciancone', 'Marion Schaeffer', 'Gabriel Sequeira', 'Diganta Misra', 'Shreeya Dhakal', 'Jonathan Rystrm', 'Roman Solomatin', 'mer aatan', 'Akash Kundu', 'Martin Bernstorff', 'Shitao Xiao', 'Akshita Sukhlecha', 'Bhavish Pahwa', 'Rafa Powiata', 'Kranthi Kiran GV', 'Shawon Ashraf', 'Daniel Auras', 'Bjrn Plster', 'Jan Philipp Harries', 'Loc Magne', 'Isabelle Mohr', 'Mariya Hendriksen', 'Dawei Zhu', 'Hippolyte Gisserot-Boukhlef', 'Tom Aarsen', 'Jan Kostkan', 'Konrad Wojtasik', 'Taemin Lee', 'Marek uppa', 'Crystina Zhang', 'Roberta Rocca', 'Mohammed Hamdy', 'Andrianos Michail', 'John Yang', 'Manuel Faysse', 'Aleksei Vatolin', 'Nandan Thakur', 'Manan Dey', 'Dipam Vasani', 'Pranjal Chitale', 'Simone Tedeschi', 'Nguyen Tai', 'Artem Snegirev', 'Michael Gnther', 'Mengzhou Xia', 'Weijia Shi', 'Xing Han L', 'Jordan Clive', 'Gayatri Krishnakumar', 'Anna Maksimova', 'Silvan Wehrli', 'Maria Tikhonova', 'Henil Panchal', 'Aleksandr Abramov', 'Malte Ostendorff', 'Zheng Liu', 'Simon Clematide', 'Lester James Miranda', 'Alena Fenogenova', 'Guangyu Song', 'Ruqiya Bin Safi', 'Wen-Ding Li', 'Alessia Borghini', 'Federico Cassano', 'Hongjin Su', 'Jimmy Lin', 'Howard Yen', 'Lasse Hansen', 'Sara Hooker', 'Chenghao Xiao', 'Vaibhav Adlakha', 'Orion Weller', 'Siva Reddy', 'Niklas Muennighoff']",{'name': 'Niklas Muennighoff'},Niklas Muennighoff,Accepted for ICLR: https://openreview.net/forum?id=zl3pfz4VCV,"[{'href': 'http://arxiv.org/abs/2502.13595v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13595v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13595v1,None,http://arxiv.org/abs/2502.13595v1,,,29121,0
http://arxiv.org/abs/2502.13603v1,True,2025-02-19T10:33:18Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=10, tm_min=33, tm_sec=18, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T10:33:18Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=10, tm_min=33, tm_sec=18, tm_wday=2, tm_yday=50, tm_isdst=0)",Efficient Safety Retrofitting Against Jailbreaking for LLMs,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Efficient Safety Retrofitting Against Jailbreaking for LLMs'}","Direct Preference Optimization (DPO) is an efficient alignment technique that
steers LLMs towards preferable outputs by training on preference data,
bypassing the need for explicit reward models. Its simplicity enables easy
adaptation to various domains and safety requirements. This paper examines
DPO's effectiveness in model safety against jailbreaking attacks while
minimizing data requirements and training costs. We introduce Egida, a dataset
expanded from multiple sources, which includes 27 different safety topics and
18 different attack styles, complemented with synthetic and human labels. This
data is used to boost the safety of state-of-the-art LLMs
(Llama-3.1-8B/70B-Instruct, Qwen-2.5-7B/72B-Instruct) across topics and attack
styles. In addition to safety evaluations, we assess their post-alignment
performance degradation in general purpose tasks, and their tendency to over
refusal. Following the proposed methodology, trained models reduce their Attack
Success Rate by 10%-30%, using small training efforts (2,000 samples) with low
computational cost (3\$ for 8B models, 20\$ for 72B models). Safety aligned
models generalize to unseen topics and attack styles, with the most successful
attack style reaching a success rate around 5%. Size and family are found to
strongly influence model malleability towards safety, pointing at the
importance of pre-training choices. To validate our findings, a large
independent assessment of human preference agreement with Llama-Guard-3-8B is
conducted by the authors and the associated dataset Egida-HSafe is released.
Overall, this study illustrates how affordable and accessible it is to enhance
LLM safety using DPO while outlining its current limitations. All datasets and
models are released to enable reproducibility and further research.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Direct Preference Optimization (DPO) is an efficient alignment technique that\nsteers LLMs towards preferable outputs by training on preference data,\nbypassing the need for explicit reward models. Its simplicity enables easy\nadaptation to various domains and safety requirements. This paper examines\nDPO's effectiveness in model safety against jailbreaking attacks while\nminimizing data requirements and training costs. We introduce Egida, a dataset\nexpanded from multiple sources, which includes 27 different safety topics and\n18 different attack styles, complemented with synthetic and human labels. This\ndata is used to boost the safety of state-of-the-art LLMs\n(Llama-3.1-8B/70B-Instruct, Qwen-2.5-7B/72B-Instruct) across topics and attack\nstyles. In addition to safety evaluations, we assess their post-alignment\nperformance degradation in general purpose tasks, and their tendency to over\nrefusal. Following the proposed methodology, trained models reduce their Attack\nSuccess Rate by 10%-30%, using small training efforts (2,000 samples) with low\ncomputational cost (3\\$ for 8B models, 20\\$ for 72B models). Safety aligned\nmodels generalize to unseen topics and attack styles, with the most successful\nattack style reaching a success rate around 5%. Size and family are found to\nstrongly influence model malleability towards safety, pointing at the\nimportance of pre-training choices. To validate our findings, a large\nindependent assessment of human preference agreement with Llama-Guard-3-8B is\nconducted by the authors and the associated dataset Egida-HSafe is released.\nOverall, this study illustrates how affordable and accessible it is to enhance\nLLM safety using DPO while outlining its current limitations. All datasets and\nmodels are released to enable reproducibility and further research.""}","['Dario Garcia-Gasulla', 'Anna Arias-Duart', 'Adrian Tormos', 'Daniel Hinjos', 'Oscar Molina-Sedano', 'Ashwin Kumar Gururajan', 'Maria Eugenia Cardello']",{'name': 'Maria Eugenia Cardello'},Maria Eugenia Cardello,,"[{'href': 'http://arxiv.org/abs/2502.13603v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13603v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13603v1,None,http://arxiv.org/abs/2502.13603v1,,,230,0
http://arxiv.org/abs/2502.13632v1,True,2025-02-19T11:10:19Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=11, tm_min=10, tm_sec=19, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T11:10:19Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=11, tm_min=10, tm_sec=19, tm_wday=2, tm_yday=50, tm_isdst=0)","Concept Layers: Enhancing Interpretability and Intervenability via LLM
  Conceptualization","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Concept Layers: Enhancing Interpretability and Intervenability via LLM\n  Conceptualization'}","The opaque nature of Large Language Models (LLMs) has led to significant
research efforts aimed at enhancing their interpretability, primarily through
post-hoc methods. More recent in-hoc approaches, such as Concept Bottleneck
Models (CBMs), offer both interpretability and intervenability by incorporating
explicit concept representations. However, these methods suffer from key
limitations, including reliance on labeled concept datasets and significant
architectural modifications that challenges re-integration into existing system
pipelines. In this work, we introduce a new methodology for incorporating
interpretability and intervenability into an existing model by integrating
Concept Layers (CLs) into its architecture. Our approach projects the model's
internal vector representations into a conceptual, explainable vector space
before reconstructing and feeding them back into the model. Furthermore, we
eliminate the need for a human-selected concept set by algorithmically
searching an ontology for a set of concepts that can be either task-specific or
task-agnostic. We evaluate CLs across multiple tasks, demonstrating that they
maintain the original model's performance and agreement while enabling
meaningful interventions. Additionally, we present a proof of concept
showcasing an intervenability interface, allowing users to adjust model
behavior dynamically, such as mitigating biases during inference.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""The opaque nature of Large Language Models (LLMs) has led to significant\nresearch efforts aimed at enhancing their interpretability, primarily through\npost-hoc methods. More recent in-hoc approaches, such as Concept Bottleneck\nModels (CBMs), offer both interpretability and intervenability by incorporating\nexplicit concept representations. However, these methods suffer from key\nlimitations, including reliance on labeled concept datasets and significant\narchitectural modifications that challenges re-integration into existing system\npipelines. In this work, we introduce a new methodology for incorporating\ninterpretability and intervenability into an existing model by integrating\nConcept Layers (CLs) into its architecture. Our approach projects the model's\ninternal vector representations into a conceptual, explainable vector space\nbefore reconstructing and feeding them back into the model. Furthermore, we\neliminate the need for a human-selected concept set by algorithmically\nsearching an ontology for a set of concepts that can be either task-specific or\ntask-agnostic. We evaluate CLs across multiple tasks, demonstrating that they\nmaintain the original model's performance and agreement while enabling\nmeaningful interventions. Additionally, we present a proof of concept\nshowcasing an intervenability interface, allowing users to adjust model\nbehavior dynamically, such as mitigating biases during inference.""}","['Or Raphael Bidusa', 'Shaul Markovitch']",{'name': 'Shaul Markovitch'},Shaul Markovitch,,"[{'href': 'http://arxiv.org/abs/2502.13632v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13632v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13632v1,None,http://arxiv.org/abs/2502.13632v1,,,7800,0
http://arxiv.org/abs/2502.13668v1,True,2025-02-19T12:24:46Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=12, tm_min=24, tm_sec=46, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T12:24:46Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=12, tm_min=24, tm_sec=46, tm_wday=2, tm_yday=50, tm_isdst=0)",PeerQA: A Scientific Question Answering Dataset from Peer Reviews,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'PeerQA: A Scientific Question Answering Dataset from Peer Reviews'}","We present PeerQA, a real-world, scientific, document-level Question
Answering (QA) dataset. PeerQA questions have been sourced from peer reviews,
which contain questions that reviewers raised while thoroughly examining the
scientific article. Answers have been annotated by the original authors of each
paper. The dataset contains 579 QA pairs from 208 academic articles, with a
majority from ML and NLP, as well as a subset of other scientific communities
like Geoscience and Public Health. PeerQA supports three critical tasks for
developing practical QA systems: Evidence retrieval, unanswerable question
classification, and answer generation. We provide a detailed analysis of the
collected dataset and conduct experiments establishing baseline systems for all
three tasks. Our experiments and analyses reveal the need for
decontextualization in document-level retrieval, where we find that even simple
decontextualization approaches consistently improve retrieval performance
across architectures. On answer generation, PeerQA serves as a challenging
benchmark for long-context modeling, as the papers have an average size of 12k
tokens. Our code and data is available at https://github.com/UKPLab/peerqa.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'We present PeerQA, a real-world, scientific, document-level Question\nAnswering (QA) dataset. PeerQA questions have been sourced from peer reviews,\nwhich contain questions that reviewers raised while thoroughly examining the\nscientific article. Answers have been annotated by the original authors of each\npaper. The dataset contains 579 QA pairs from 208 academic articles, with a\nmajority from ML and NLP, as well as a subset of other scientific communities\nlike Geoscience and Public Health. PeerQA supports three critical tasks for\ndeveloping practical QA systems: Evidence retrieval, unanswerable question\nclassification, and answer generation. We provide a detailed analysis of the\ncollected dataset and conduct experiments establishing baseline systems for all\nthree tasks. Our experiments and analyses reveal the need for\ndecontextualization in document-level retrieval, where we find that even simple\ndecontextualization approaches consistently improve retrieval performance\nacross architectures. On answer generation, PeerQA serves as a challenging\nbenchmark for long-context modeling, as the papers have an average size of 12k\ntokens. Our code and data is available at https://github.com/UKPLab/peerqa.'}","['Tim Baumgrtner', 'Ted Briscoe', 'Iryna Gurevych']",{'name': 'Iryna Gurevych'},Iryna Gurevych,Accepted at NAACL 2025,"[{'href': 'http://arxiv.org/abs/2502.13668v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13668v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13668v1,None,http://arxiv.org/abs/2502.13668v1,,,160,0
http://arxiv.org/abs/2502.13681v1,True,2025-02-19T12:51:35Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=12, tm_min=51, tm_sec=35, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T12:51:35Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=12, tm_min=51, tm_sec=35, tm_wday=2, tm_yday=50, tm_isdst=0)",An LLM-based Agent for Reliable Docker Environment Configuration,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'An LLM-based Agent for Reliable Docker Environment Configuration'}","Environment configuration is a critical yet time-consuming step in software
development, especially when dealing with unfamiliar code repositories. While
Large Language Models (LLMs) demonstrate the potential to accomplish software
engineering tasks, existing methods for environment configuration often rely on
manual efforts or fragile scripts, leading to inefficiencies and unreliable
outcomes. We introduce Repo2Run, the first LLM-based agent designed to fully
automate environment configuration and generate executable Dockerfiles for
arbitrary Python repositories. We address two major challenges: (1) enabling
the LLM agent to configure environments within isolated Docker containers, and
(2) ensuring the successful configuration process is recorded and accurately
transferred to a Dockerfile without error. To achieve this, we propose atomic
configuration synthesis, featuring a dual-environment architecture (internal
and external environment) with a rollback mechanism to prevent environment
""pollution"" from failed commands, guaranteeing atomic execution (execute fully
or not at all) and a Dockerfile generator to transfer successful configuration
steps into runnable Dockerfiles. We evaluate Repo2Run~on our proposed benchmark
of 420 recent Python repositories with unit tests, where it achieves an 86.0%
success rate, outperforming the best baseline by 63.9%.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Environment configuration is a critical yet time-consuming step in software\ndevelopment, especially when dealing with unfamiliar code repositories. While\nLarge Language Models (LLMs) demonstrate the potential to accomplish software\nengineering tasks, existing methods for environment configuration often rely on\nmanual efforts or fragile scripts, leading to inefficiencies and unreliable\noutcomes. We introduce Repo2Run, the first LLM-based agent designed to fully\nautomate environment configuration and generate executable Dockerfiles for\narbitrary Python repositories. We address two major challenges: (1) enabling\nthe LLM agent to configure environments within isolated Docker containers, and\n(2) ensuring the successful configuration process is recorded and accurately\ntransferred to a Dockerfile without error. To achieve this, we propose atomic\nconfiguration synthesis, featuring a dual-environment architecture (internal\nand external environment) with a rollback mechanism to prevent environment\n""pollution"" from failed commands, guaranteeing atomic execution (execute fully\nor not at all) and a Dockerfile generator to transfer successful configuration\nsteps into runnable Dockerfiles. We evaluate Repo2Run~on our proposed benchmark\nof 420 recent Python repositories with unit tests, where it achieves an 86.0%\nsuccess rate, outperforming the best baseline by 63.9%.'}","['Ruida Hu', 'Chao Peng', 'Xinchen Wang', 'Cuiyun Gao']",{'name': 'Cuiyun Gao'},Cuiyun Gao,,"[{'href': 'http://arxiv.org/abs/2502.13681v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13681v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.SE', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.SE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13681v1,None,http://arxiv.org/abs/2502.13681v1,,,19,0
http://arxiv.org/abs/2502.13685v1,True,2025-02-19T12:53:55Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=12, tm_min=53, tm_sec=55, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T12:53:55Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=12, tm_min=53, tm_sec=55, tm_wday=2, tm_yday=50, tm_isdst=0)",MoM: Linear Sequence Modeling with Mixture-of-Memories,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'MoM: Linear Sequence Modeling with Mixture-of-Memories'}","Linear sequence modeling methods, such as linear attention, state space
modeling, and linear RNNs, offer significant efficiency improvements by
reducing the complexity of training and inference. However, these methods
typically compress the entire input sequence into a single fixed-size memory
state, which leads to suboptimal performance on recall-intensive downstream
tasks. Drawing inspiration from neuroscience, particularly the brain's ability
to maintain robust long-term memory while mitigating ""memory interference"", we
introduce a novel architecture called Mixture-of-Memories (MoM). MoM utilizes
multiple independent memory states, with a router network directing input
tokens to specific memory states. This approach greatly enhances the overall
memory capacity while minimizing memory interference. As a result, MoM performs
exceptionally well on recall-intensive tasks, surpassing existing linear
sequence modeling techniques. Despite incorporating multiple memory states, the
computation of each memory state remains linear in complexity, allowing MoM to
retain the linear-complexity advantage during training, while
constant-complexity during inference. Our experimental results show that MoM
significantly outperforms current linear sequence models on downstream language
tasks, particularly recall-intensive tasks, and even achieves performance
comparable to Transformer models. The code is released at
https://github.com/OpenSparseLLMs/MoM and is also released as a part of
https://github.com/OpenSparseLLMs/Linear-MoE.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Linear sequence modeling methods, such as linear attention, state space\nmodeling, and linear RNNs, offer significant efficiency improvements by\nreducing the complexity of training and inference. However, these methods\ntypically compress the entire input sequence into a single fixed-size memory\nstate, which leads to suboptimal performance on recall-intensive downstream\ntasks. Drawing inspiration from neuroscience, particularly the brain\'s ability\nto maintain robust long-term memory while mitigating ""memory interference"", we\nintroduce a novel architecture called Mixture-of-Memories (MoM). MoM utilizes\nmultiple independent memory states, with a router network directing input\ntokens to specific memory states. This approach greatly enhances the overall\nmemory capacity while minimizing memory interference. As a result, MoM performs\nexceptionally well on recall-intensive tasks, surpassing existing linear\nsequence modeling techniques. Despite incorporating multiple memory states, the\ncomputation of each memory state remains linear in complexity, allowing MoM to\nretain the linear-complexity advantage during training, while\nconstant-complexity during inference. Our experimental results show that MoM\nsignificantly outperforms current linear sequence models on downstream language\ntasks, particularly recall-intensive tasks, and even achieves performance\ncomparable to Transformer models. The code is released at\nhttps://github.com/OpenSparseLLMs/MoM and is also released as a part of\nhttps://github.com/OpenSparseLLMs/Linear-MoE.'}","['Jusen Du', 'Weigao Sun', 'Disen Lan', 'Jiaxi Hu', 'Yu Cheng']",{'name': 'Yu Cheng'},Yu Cheng,"Technical report, 14 pages","[{'href': 'http://arxiv.org/abs/2502.13685v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13685v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13685v1,None,http://arxiv.org/abs/2502.13685v1,,,0,0
http://arxiv.org/abs/2502.13775v1,True,2025-02-19T14:38:57Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=14, tm_min=38, tm_sec=57, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T14:38:57Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=14, tm_min=38, tm_sec=57, tm_wday=2, tm_yday=50, tm_isdst=0)","VITAL: A New Dataset for Benchmarking Pluralistic Alignment in
  Healthcare","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'VITAL: A New Dataset for Benchmarking Pluralistic Alignment in\n  Healthcare'}","Alignment techniques have become central to ensuring that Large Language
Models (LLMs) generate outputs consistent with human values. However, existing
alignment paradigms often model an averaged or monolithic preference, failing
to account for the diversity of perspectives across cultures, demographics, and
communities. This limitation is particularly critical in health-related
scenarios, where plurality is essential due to the influence of culture,
religion, personal values, and conflicting opinions. Despite progress in
pluralistic alignment, no prior work has focused on health, likely due to the
unavailability of publicly available datasets. To address this gap, we
introduce VITAL, a new benchmark dataset comprising 13.1K value-laden
situations and 5.4K multiple-choice questions focused on health, designed to
assess and benchmark pluralistic alignment methodologies. Through extensive
evaluation of eight LLMs of varying sizes, we demonstrate that existing
pluralistic alignment techniques fall short in effectively accommodating
diverse healthcare beliefs, underscoring the need for tailored AI alignment in
specific domains. This work highlights the limitations of current approaches
and lays the groundwork for developing health-specific alignment solutions.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Alignment techniques have become central to ensuring that Large Language\nModels (LLMs) generate outputs consistent with human values. However, existing\nalignment paradigms often model an averaged or monolithic preference, failing\nto account for the diversity of perspectives across cultures, demographics, and\ncommunities. This limitation is particularly critical in health-related\nscenarios, where plurality is essential due to the influence of culture,\nreligion, personal values, and conflicting opinions. Despite progress in\npluralistic alignment, no prior work has focused on health, likely due to the\nunavailability of publicly available datasets. To address this gap, we\nintroduce VITAL, a new benchmark dataset comprising 13.1K value-laden\nsituations and 5.4K multiple-choice questions focused on health, designed to\nassess and benchmark pluralistic alignment methodologies. Through extensive\nevaluation of eight LLMs of varying sizes, we demonstrate that existing\npluralistic alignment techniques fall short in effectively accommodating\ndiverse healthcare beliefs, underscoring the need for tailored AI alignment in\nspecific domains. This work highlights the limitations of current approaches\nand lays the groundwork for developing health-specific alignment solutions.'}","['Anudeex Shetty', 'Amin Beheshti', 'Mark Dras', 'Usman Naseem']",{'name': 'Usman Naseem'},Usman Naseem,Under review,"[{'href': 'http://arxiv.org/abs/2502.13775v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13775v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13775v1,None,http://arxiv.org/abs/2502.13775v1,,,3109,0
http://arxiv.org/abs/2502.13794v1,True,2025-02-19T14:58:48Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=14, tm_min=58, tm_sec=48, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T14:58:48Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=14, tm_min=58, tm_sec=48, tm_wday=2, tm_yday=50, tm_isdst=0)",LESA: Learnable LLM Layer Scaling-Up,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'LESA: Learnable LLM Layer Scaling-Up'}","Training Large Language Models (LLMs) from scratch requires immense
computational resources, making it prohibitively expensive. Model scaling-up
offers a promising solution by leveraging the parameters of smaller models to
create larger ones. However, existing depth scaling-up methods rely on
empirical heuristic rules for layer duplication, which result in poorer
initialization and slower convergence during continual pre-training. We propose
\textbf{LESA}, a novel learnable method for depth scaling-up. By concatenating
parameters from each layer and applying Singular Value Decomposition, we
uncover latent patterns between layers, suggesting that inter-layer parameters
can be learned. LESA uses a neural network to predict the parameters inserted
between adjacent layers, enabling better initialization and faster training.
Experiments show that LESA outperforms existing baselines, achieving superior
performance with less than half the computational cost during continual
pre-training. Extensive analyses demonstrate its effectiveness across different
model sizes and tasks.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Training Large Language Models (LLMs) from scratch requires immense\ncomputational resources, making it prohibitively expensive. Model scaling-up\noffers a promising solution by leveraging the parameters of smaller models to\ncreate larger ones. However, existing depth scaling-up methods rely on\nempirical heuristic rules for layer duplication, which result in poorer\ninitialization and slower convergence during continual pre-training. We propose\n\\textbf{LESA}, a novel learnable method for depth scaling-up. By concatenating\nparameters from each layer and applying Singular Value Decomposition, we\nuncover latent patterns between layers, suggesting that inter-layer parameters\ncan be learned. LESA uses a neural network to predict the parameters inserted\nbetween adjacent layers, enabling better initialization and faster training.\nExperiments show that LESA outperforms existing baselines, achieving superior\nperformance with less than half the computational cost during continual\npre-training. Extensive analyses demonstrate its effectiveness across different\nmodel sizes and tasks.'}","['Yifei Yang', 'Zouying Cao', 'Xinbei Ma', 'Yao Yao', 'Libo Qin', 'Zhi Chen', 'Hai Zhao']",{'name': 'Hai Zhao'},Hai Zhao,,"[{'href': 'http://arxiv.org/abs/2502.13794v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13794v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13794v1,None,http://arxiv.org/abs/2502.13794v1,,,523,0
http://arxiv.org/abs/2502.13805v1,True,2025-02-19T15:15:59Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=15, tm_min=15, tm_sec=59, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T15:15:59Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=15, tm_min=15, tm_sec=59, tm_wday=2, tm_yday=50, tm_isdst=0)","AnDB: Breaking Boundaries with an AI-Native Database for Universal
  Semantic Analysis","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'AnDB: Breaking Boundaries with an AI-Native Database for Universal\n  Semantic Analysis'}","In this demonstration, we present AnDB, an AI-native database that supports
traditional OLTP workloads and innovative AI-driven tasks, enabling unified
semantic analysis across structured and unstructured data. While structured
data analytics is mature, challenges remain in bridging the semantic gap
between user queries and unstructured data. AnDB addresses these issues by
leveraging cutting-edge AI-native technologies, allowing users to perform
semantic queries using intuitive SQL-like statements without requiring AI
expertise. This approach eliminates the ambiguity of traditional text-to-SQL
systems and provides a seamless end-to-end optimization for analyzing all data
types. AnDB automates query processing by generating multiple execution plans
and selecting the optimal one through its optimizer, which balances accuracy,
execution time, and financial cost based on user policies and internal
optimizing mechanisms. AnDB future-proofs data management infrastructure,
empowering users to effectively and efficiently harness the full potential of
all kinds of data without starting from scratch.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'In this demonstration, we present AnDB, an AI-native database that supports\ntraditional OLTP workloads and innovative AI-driven tasks, enabling unified\nsemantic analysis across structured and unstructured data. While structured\ndata analytics is mature, challenges remain in bridging the semantic gap\nbetween user queries and unstructured data. AnDB addresses these issues by\nleveraging cutting-edge AI-native technologies, allowing users to perform\nsemantic queries using intuitive SQL-like statements without requiring AI\nexpertise. This approach eliminates the ambiguity of traditional text-to-SQL\nsystems and provides a seamless end-to-end optimization for analyzing all data\ntypes. AnDB automates query processing by generating multiple execution plans\nand selecting the optimal one through its optimizer, which balances accuracy,\nexecution time, and financial cost based on user policies and internal\noptimizing mechanisms. AnDB future-proofs data management infrastructure,\nempowering users to effectively and efficiently harness the full potential of\nall kinds of data without starting from scratch.'}","['Tianqing Wang', 'Xun Xue', 'Guoliang Li', 'Yong Wang']",{'name': 'Yong Wang'},Yong Wang,"4 pages, 5 figures, conference","[{'href': 'http://arxiv.org/abs/2502.13805v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13805v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.DB', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.DB', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13805v1,None,http://arxiv.org/abs/2502.13805v1,,,127,0
http://arxiv.org/abs/2502.13820v1,True,2025-02-19T15:32:11Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=15, tm_min=32, tm_sec=11, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T15:32:11Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=15, tm_min=32, tm_sec=11, tm_wday=2, tm_yday=50, tm_isdst=0)","Scoring Verifiers: Evaluating Synthetic Verification in Code and
  Reasoning","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Scoring Verifiers: Evaluating Synthetic Verification in Code and\n  Reasoning'}","Code verification has recently found great success as a critical component in
training large scale reasoning models for coding. Synthetic techniques such as
self-generated test cases and reward models provide a way to enhance code
capabilities beyond predefined tests. Building on these advancements, we
propose new benchmarks designed to systematically evaluate the impact of
synthetic verification methods on assessing solution correctness. We introduce
HE-R, HE-R+, MBPP-R, and MBPP-R+, which transform existing coding benchmarks
into scoring and ranking datasets to evaluate the effectiveness of synthetic
verifiers. Using these benchmarks, we analyze synthetic verification methods in
standard, reasoning-based, and reward-based LLMs. Our results show that recent
reasoning models significantly improve test case generation and that scaling
test cases enhances verification accuracy.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Code verification has recently found great success as a critical component in\ntraining large scale reasoning models for coding. Synthetic techniques such as\nself-generated test cases and reward models provide a way to enhance code\ncapabilities beyond predefined tests. Building on these advancements, we\npropose new benchmarks designed to systematically evaluate the impact of\nsynthetic verification methods on assessing solution correctness. We introduce\nHE-R, HE-R+, MBPP-R, and MBPP-R+, which transform existing coding benchmarks\ninto scoring and ranking datasets to evaluate the effectiveness of synthetic\nverifiers. Using these benchmarks, we analyze synthetic verification methods in\nstandard, reasoning-based, and reward-based LLMs. Our results show that recent\nreasoning models significantly improve test case generation and that scaling\ntest cases enhances verification accuracy.'}","['Aleksander Ficek', 'Somshubra Majumdar', 'Vahid Noroozi', 'Boris Ginsburg']",{'name': 'Boris Ginsburg'},Boris Ginsburg,,"[{'href': 'http://arxiv.org/abs/2502.13820v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13820v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13820v1,None,http://arxiv.org/abs/2502.13820v1,,,4288,0
http://arxiv.org/abs/2502.13847v1,True,2025-02-19T16:10:43Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=16, tm_min=10, tm_sec=43, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T16:10:43Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=16, tm_min=10, tm_sec=43, tm_wday=2, tm_yday=50, tm_isdst=0)","DH-RAG: A Dynamic Historical Context-Powered Retrieval-Augmented
  Generation Method for Multi-Turn Dialogue","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'DH-RAG: A Dynamic Historical Context-Powered Retrieval-Augmented\n  Generation Method for Multi-Turn Dialogue'}","Retrieval-Augmented Generation (RAG) systems have shown substantial benefits
in applications such as question answering and multi-turn dialogue
\citep{lewis2020retrieval}. However, traditional RAG methods, while leveraging
static knowledge bases, often overlook the potential of dynamic historical
information in ongoing conversations. To bridge this gap, we introduce DH-RAG,
a Dynamic Historical Context-Powered Retrieval-Augmented Generation Method for
Multi-Turn Dialogue. DH-RAG is inspired by human cognitive processes that
utilize both long-term memory and immediate historical context in
conversational responses \citep{stafford1987conversational}. DH-RAG is
structured around two principal components: a History-Learning based Query
Reconstruction Module, designed to generate effective queries by synthesizing
current and prior interactions, and a Dynamic History Information Updating
Module, which continually refreshes historical context throughout the dialogue.
The center of DH-RAG is a Dynamic Historical Information database, which is
further refined by three strategies within the Query Reconstruction Module:
Historical Query Clustering, Hierarchical Matching, and Chain of Thought
Tracking. Experimental evaluations show that DH-RAG significantly surpasses
conventional models on several benchmarks, enhancing response relevance,
coherence, and dialogue quality.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Retrieval-Augmented Generation (RAG) systems have shown substantial benefits\nin applications such as question answering and multi-turn dialogue\n\\citep{lewis2020retrieval}. However, traditional RAG methods, while leveraging\nstatic knowledge bases, often overlook the potential of dynamic historical\ninformation in ongoing conversations. To bridge this gap, we introduce DH-RAG,\na Dynamic Historical Context-Powered Retrieval-Augmented Generation Method for\nMulti-Turn Dialogue. DH-RAG is inspired by human cognitive processes that\nutilize both long-term memory and immediate historical context in\nconversational responses \\citep{stafford1987conversational}. DH-RAG is\nstructured around two principal components: a History-Learning based Query\nReconstruction Module, designed to generate effective queries by synthesizing\ncurrent and prior interactions, and a Dynamic History Information Updating\nModule, which continually refreshes historical context throughout the dialogue.\nThe center of DH-RAG is a Dynamic Historical Information database, which is\nfurther refined by three strategies within the Query Reconstruction Module:\nHistorical Query Clustering, Hierarchical Matching, and Chain of Thought\nTracking. Experimental evaluations show that DH-RAG significantly surpasses\nconventional models on several benchmarks, enhancing response relevance,\ncoherence, and dialogue quality.'}","['Feiyuan Zhang', 'Dezhi Zhu', 'James Ming', 'Yilun Jin', 'Di Chai', 'Liu Yang', 'Han Tian', 'Zhaoxin Fan', 'Kai Chen']",{'name': 'Kai Chen'},Kai Chen,,"[{'href': 'http://arxiv.org/abs/2502.13847v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13847v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13847v1,None,http://arxiv.org/abs/2502.13847v1,,,1108,0
http://arxiv.org/abs/2502.13881v1,True,2025-02-19T17:05:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=17, tm_min=5, tm_sec=42, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T17:05:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=17, tm_min=5, tm_sec=42, tm_wday=2, tm_yday=50, tm_isdst=0)",PSCon: Toward Conversational Product Search,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'PSCon: Toward Conversational Product Search'}","Conversational Product Search (CPS) is confined to simulated conversations
due to the lack of real-world CPS datasets that reflect human-like language.
Additionally, current conversational datasets are limited to support
cross-market and multi-lingual usage. In this paper, we introduce a new CPS
data collection protocol and present PSCon, a novel CPS dataset designed to
assist product search via human-like conversations. The dataset is constructed
using a coached human-to-human data collection protocol and supports two
languages and dual markets. Also, the dataset enables thorough exploration of
six subtasks of CPS: user intent detection, keyword extraction, system action
prediction, question selection, item ranking, and response generation.
Furthermore, we also offer an analysis of the dataset and propose a benchmark
model on the proposed CPS dataset.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Conversational Product Search (CPS) is confined to simulated conversations\ndue to the lack of real-world CPS datasets that reflect human-like language.\nAdditionally, current conversational datasets are limited to support\ncross-market and multi-lingual usage. In this paper, we introduce a new CPS\ndata collection protocol and present PSCon, a novel CPS dataset designed to\nassist product search via human-like conversations. The dataset is constructed\nusing a coached human-to-human data collection protocol and supports two\nlanguages and dual markets. Also, the dataset enables thorough exploration of\nsix subtasks of CPS: user intent detection, keyword extraction, system action\nprediction, question selection, item ranking, and response generation.\nFurthermore, we also offer an analysis of the dataset and propose a benchmark\nmodel on the proposed CPS dataset.'}","['Jie Zou', 'Mohammad Aliannejadi', 'Evangelos Kanoulas', 'Shuxi Han', 'Heli Ma', 'Zheng Wang', 'Yang Yang', 'Heng Tao Shen']",{'name': 'Heng Tao Shen'},Heng Tao Shen,11 pages,"[{'href': 'http://arxiv.org/abs/2502.13881v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13881v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13881v1,None,http://arxiv.org/abs/2502.13881v1,,,225,0
http://arxiv.org/abs/2502.13897v1,True,2025-02-19T17:31:51Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=17, tm_min=31, tm_sec=51, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T17:31:51Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=17, tm_min=31, tm_sec=51, tm_wday=2, tm_yday=50, tm_isdst=0)",DataSciBench: An LLM Agent Benchmark for Data Science,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'DataSciBench: An LLM Agent Benchmark for Data Science'}","This paper presents DataSciBench, a comprehensive benchmark for evaluating
Large Language Model (LLM) capabilities in data science. Recent related
benchmarks have primarily focused on single tasks, easily obtainable ground
truth, and straightforward evaluation metrics, which limits the scope of tasks
that can be evaluated. In contrast, DataSciBench is constructed based on a more
comprehensive and curated collection of natural and challenging prompts for
uncertain ground truth and evaluation metrics. We develop a semi-automated
pipeline for generating ground truth (GT) and validating evaluation metrics.
This pipeline utilizes and implements an LLM-based self-consistency and human
verification strategy to produce accurate GT by leveraging collected prompts,
predefined task types, and aggregate functions (metrics). Furthermore, we
propose an innovative Task - Function - Code (TFC) framework to assess each
code execution outcome based on precisely defined metrics and programmatic
rules. Our experimental framework involves testing 6 API-based models, 8
open-source general models, and 9 open-source code generation models using the
diverse set of prompts we have gathered. This approach aims to provide a more
comprehensive and rigorous evaluation of LLMs in data science, revealing their
strengths and weaknesses. Experimental results demonstrate that API-based
models outperform open-sourced models on all metrics and
Deepseek-Coder-33B-Instruct achieves the highest score among open-sourced
models. We release all code and data at https://github.com/THUDM/DataSciBench.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'This paper presents DataSciBench, a comprehensive benchmark for evaluating\nLarge Language Model (LLM) capabilities in data science. Recent related\nbenchmarks have primarily focused on single tasks, easily obtainable ground\ntruth, and straightforward evaluation metrics, which limits the scope of tasks\nthat can be evaluated. In contrast, DataSciBench is constructed based on a more\ncomprehensive and curated collection of natural and challenging prompts for\nuncertain ground truth and evaluation metrics. We develop a semi-automated\npipeline for generating ground truth (GT) and validating evaluation metrics.\nThis pipeline utilizes and implements an LLM-based self-consistency and human\nverification strategy to produce accurate GT by leveraging collected prompts,\npredefined task types, and aggregate functions (metrics). Furthermore, we\npropose an innovative Task - Function - Code (TFC) framework to assess each\ncode execution outcome based on precisely defined metrics and programmatic\nrules. Our experimental framework involves testing 6 API-based models, 8\nopen-source general models, and 9 open-source code generation models using the\ndiverse set of prompts we have gathered. This approach aims to provide a more\ncomprehensive and rigorous evaluation of LLMs in data science, revealing their\nstrengths and weaknesses. Experimental results demonstrate that API-based\nmodels outperform open-sourced models on all metrics and\nDeepseek-Coder-33B-Instruct achieves the highest score among open-sourced\nmodels. We release all code and data at https://github.com/THUDM/DataSciBench.'}","['Dan Zhang', 'Sining Zhoubian', 'Min Cai', 'Fengzu Li', 'Lekang Yang', 'Wei Wang', 'Tianjiao Dong', 'Ziniu Hu', 'Jie Tang', 'Yisong Yue']",{'name': 'Yisong Yue'},Yisong Yue,"40 pages, 7 figures, 6 tables","[{'href': 'http://arxiv.org/abs/2502.13897v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13897v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13897v1,None,http://arxiv.org/abs/2502.13897v1,,,362,0
http://arxiv.org/abs/2502.13928v1,True,2025-02-19T18:05:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=18, tm_min=5, tm_sec=42, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T18:05:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=18, tm_min=5, tm_sec=42, tm_wday=2, tm_yday=50, tm_isdst=0)","Symmetrical Visual Contrastive Optimization: Aligning Vision-Language
  Models with Minimal Contrastive Images","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Symmetrical Visual Contrastive Optimization: Aligning Vision-Language\n  Models with Minimal Contrastive Images'}","Recent studies have shown that Large Vision-Language Models (VLMs) tend to
neglect image content and over-rely on language-model priors, resulting in
errors in visually grounded tasks and hallucinations. We hypothesize that this
issue arises because existing VLMs are not explicitly trained to generate texts
that are accurately grounded in fine-grained image details. To enhance visual
feedback during VLM training, we propose S-VCO (Symmetrical Visual Contrastive
Optimization), a novel finetuning objective that steers the model toward
capturing important visual details and aligning them with corresponding text
tokens. To further facilitate this detailed alignment, we introduce MVC, a
paired image-text dataset built by automatically filtering and augmenting
visual counterfactual data to challenge the model with hard contrastive cases
involving Minimal Visual Contrasts. Experiments show that our method
consistently improves VLM performance across diverse benchmarks covering
various abilities and domains, achieving up to a 22% reduction in
hallucinations, and significant gains in vision-centric and general tasks.
Notably, these improvements become increasingly pronounced in benchmarks with
higher visual dependency. In short, S-VCO offers a significant enhancement of
VLM's visually-dependent task performance while retaining or even improving the
model's general abilities. We opensource our code at https://s-vco.github.io/","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Recent studies have shown that Large Vision-Language Models (VLMs) tend to\nneglect image content and over-rely on language-model priors, resulting in\nerrors in visually grounded tasks and hallucinations. We hypothesize that this\nissue arises because existing VLMs are not explicitly trained to generate texts\nthat are accurately grounded in fine-grained image details. To enhance visual\nfeedback during VLM training, we propose S-VCO (Symmetrical Visual Contrastive\nOptimization), a novel finetuning objective that steers the model toward\ncapturing important visual details and aligning them with corresponding text\ntokens. To further facilitate this detailed alignment, we introduce MVC, a\npaired image-text dataset built by automatically filtering and augmenting\nvisual counterfactual data to challenge the model with hard contrastive cases\ninvolving Minimal Visual Contrasts. Experiments show that our method\nconsistently improves VLM performance across diverse benchmarks covering\nvarious abilities and domains, achieving up to a 22% reduction in\nhallucinations, and significant gains in vision-centric and general tasks.\nNotably, these improvements become increasingly pronounced in benchmarks with\nhigher visual dependency. In short, S-VCO offers a significant enhancement of\nVLM's visually-dependent task performance while retaining or even improving the\nmodel's general abilities. We opensource our code at https://s-vco.github.io/""}","['Shengguang Wu', 'Fan-Yun Sun', 'Kaiyue Wen', 'Nick Haber']",{'name': 'Nick Haber'},Nick Haber,Project Website: https://s-vco.github.io/,"[{'href': 'http://arxiv.org/abs/2502.13928v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13928v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13928v1,None,http://arxiv.org/abs/2502.13928v1,,,46,0
http://arxiv.org/abs/2502.13935v1,True,2025-02-19T18:18:27Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=18, tm_min=18, tm_sec=27, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T18:18:27Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=18, tm_min=18, tm_sec=27, tm_wday=2, tm_yday=50, tm_isdst=0)","Continually Learning Structured Visual Representations via Network
  Refinement with Rerelation","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Continually Learning Structured Visual Representations via Network\n  Refinement with Rerelation'}","Current machine learning paradigm relies on continuous representations like
neural networks, which iteratively adjust parameters to approximate outcomes
rather than directly learning the structure of problem. This spreads
information across the network, causing issues like information loss and
incomprehensibility Building on prior work in environment dynamics modeling, we
propose a method that learns visual space in a structured, continual manner.
Our approach refines networks to capture the core structure of objects while
representing significant subvariants in structure efficiently. We demonstrate
this with 2D shape detection, showing incremental learning on MNIST without
overwriting knowledge and creating compact, comprehensible representations.
These results offer a promising step toward a transparent, continually learning
alternative to traditional neural networks for visual processing.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Current machine learning paradigm relies on continuous representations like\nneural networks, which iteratively adjust parameters to approximate outcomes\nrather than directly learning the structure of problem. This spreads\ninformation across the network, causing issues like information loss and\nincomprehensibility Building on prior work in environment dynamics modeling, we\npropose a method that learns visual space in a structured, continual manner.\nOur approach refines networks to capture the core structure of objects while\nrepresenting significant subvariants in structure efficiently. We demonstrate\nthis with 2D shape detection, showing incremental learning on MNIST without\noverwriting knowledge and creating compact, comprehensible representations.\nThese results offer a promising step toward a transparent, continually learning\nalternative to traditional neural networks for visual processing.'}","['Zeki Doruk Erden', 'Boi Faltings']",{'name': 'Boi Faltings'},Boi Faltings,,"[{'href': 'http://arxiv.org/abs/2502.13935v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13935v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13935v1,None,http://arxiv.org/abs/2502.13935v1,,,13114,0
http://arxiv.org/abs/2502.13943v1,True,2025-02-19T18:35:55Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=18, tm_min=35, tm_sec=55, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T18:35:55Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=18, tm_min=35, tm_sec=55, tm_wday=2, tm_yday=50, tm_isdst=0)","AdaptiveStep: Automatically Dividing Reasoning Step through Model
  Confidence","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'AdaptiveStep: Automatically Dividing Reasoning Step through Model\n  Confidence'}","Current approaches for training Process Reward Models (PRMs) often involve
breaking down responses into multiple reasoning steps using rule-based
techniques, such as using predefined placeholder tokens or setting the
reasoning step's length into a fixed size. These approaches overlook the fact
that specific words do not typically mark true decision points in a text. To
address this, we propose AdaptiveStep, a method that divides reasoning steps
based on the model's confidence in predicting the next word. This division
method provides more decision-making information at each step, enhancing
downstream tasks, such as reward model learning. Moreover, our method does not
require manual annotation. We demonstrate its effectiveness through experiments
with AdaptiveStep-trained PRMs in mathematical reasoning and code generation
tasks. Experimental results indicate that the outcome PRM achieves
state-of-the-art Best-of-N performance, surpassing greedy search strategy with
token-level value-guided decoding, while also reducing construction costs by
over 30% compared to existing open-source PRMs. In addition, we provide a
thorough analysis and case study on the PRM's performance, transferability, and
generalization capabilities.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Current approaches for training Process Reward Models (PRMs) often involve\nbreaking down responses into multiple reasoning steps using rule-based\ntechniques, such as using predefined placeholder tokens or setting the\nreasoning step's length into a fixed size. These approaches overlook the fact\nthat specific words do not typically mark true decision points in a text. To\naddress this, we propose AdaptiveStep, a method that divides reasoning steps\nbased on the model's confidence in predicting the next word. This division\nmethod provides more decision-making information at each step, enhancing\ndownstream tasks, such as reward model learning. Moreover, our method does not\nrequire manual annotation. We demonstrate its effectiveness through experiments\nwith AdaptiveStep-trained PRMs in mathematical reasoning and code generation\ntasks. Experimental results indicate that the outcome PRM achieves\nstate-of-the-art Best-of-N performance, surpassing greedy search strategy with\ntoken-level value-guided decoding, while also reducing construction costs by\nover 30% compared to existing open-source PRMs. In addition, we provide a\nthorough analysis and case study on the PRM's performance, transferability, and\ngeneralization capabilities.""}","['Yuliang Liu', 'Junjie Lu', 'Zhaoling Chen', 'Chaofeng Qu', 'Jason Klein Liu', 'Chonghan Liu', 'Zefan Cai', 'Yunhui Xia', 'Li Zhao', 'Jiang Bian', 'Chuheng Zhang', 'Wei Shen', 'Zhouhan Lin']",{'name': 'Zhouhan Lin'},Zhouhan Lin,17 pages,"[{'href': 'http://arxiv.org/abs/2502.13943v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13943v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13943v1,None,http://arxiv.org/abs/2502.13943v1,,,314,0
http://arxiv.org/abs/2502.13946v1,True,2025-02-19T18:42:45Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=18, tm_min=42, tm_sec=45, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T18:42:45Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=18, tm_min=42, tm_sec=45, tm_wday=2, tm_yday=50, tm_isdst=0)","Why Safeguarded Ships Run Aground? Aligned Large Language Models' Safety
  Mechanisms Tend to Be Anchored in The Template Region","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Why Safeguarded Ships Run Aground? Aligned Large Language Models' Safety\n  Mechanisms Tend to Be Anchored in The Template Region""}","The safety alignment of large language models (LLMs) remains vulnerable, as
their initial behavior can be easily jailbroken by even relatively simple
attacks. Since infilling a fixed template between the input instruction and
initial model output is a common practice for existing LLMs, we hypothesize
that this template is a key factor behind their vulnerabilities: LLMs'
safety-related decision-making overly relies on the aggregated information from
the template region, which largely influences these models' safety behavior. We
refer to this issue as template-anchored safety alignment. In this paper, we
conduct extensive experiments and verify that template-anchored safety
alignment is widespread across various aligned LLMs. Our mechanistic analyses
demonstrate how it leads to models' susceptibility when encountering
inference-time jailbreak attacks. Furthermore, we show that detaching safety
mechanisms from the template region is promising in mitigating vulnerabilities
to jailbreak attacks. We encourage future research to develop more robust
safety alignment techniques that reduce reliance on the template region.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""The safety alignment of large language models (LLMs) remains vulnerable, as\ntheir initial behavior can be easily jailbroken by even relatively simple\nattacks. Since infilling a fixed template between the input instruction and\ninitial model output is a common practice for existing LLMs, we hypothesize\nthat this template is a key factor behind their vulnerabilities: LLMs'\nsafety-related decision-making overly relies on the aggregated information from\nthe template region, which largely influences these models' safety behavior. We\nrefer to this issue as template-anchored safety alignment. In this paper, we\nconduct extensive experiments and verify that template-anchored safety\nalignment is widespread across various aligned LLMs. Our mechanistic analyses\ndemonstrate how it leads to models' susceptibility when encountering\ninference-time jailbreak attacks. Furthermore, we show that detaching safety\nmechanisms from the template region is promising in mitigating vulnerabilities\nto jailbreak attacks. We encourage future research to develop more robust\nsafety alignment techniques that reduce reliance on the template region.""}","['Chak Tou Leong', 'Qingyu Yin', 'Jian Wang', 'Wenjie Li']",{'name': 'Wenjie Li'},Wenjie Li,,"[{'href': 'http://arxiv.org/abs/2502.13946v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13946v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13946v1,None,http://arxiv.org/abs/2502.13946v1,,,61,0
http://arxiv.org/abs/2502.13964v1,True,2025-02-19T18:59:17Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=18, tm_min=59, tm_sec=17, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T18:59:17Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=18, tm_min=59, tm_sec=17, tm_wday=2, tm_yday=50, tm_isdst=0)","A Training-Free Framework for Precise Mobile Manipulation of Small
  Everyday Objects","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A Training-Free Framework for Precise Mobile Manipulation of Small\n  Everyday Objects'}","Many everyday mobile manipulation tasks require precise interaction with
small objects, such as grasping a knob to open a cabinet or pressing a light
switch. In this paper, we develop Servoing with Vision Models (SVM), a
closed-loop training-free framework that enables a mobile manipulator to tackle
such precise tasks involving the manipulation of small objects. SVM employs an
RGB-D wrist camera and uses visual servoing for control. Our novelty lies in
the use of state-of-the-art vision models to reliably compute 3D targets from
the wrist image for diverse tasks and under occlusion due to the end-effector.
To mitigate occlusion artifacts, we employ vision models to out-paint the
end-effector thereby significantly enhancing target localization. We
demonstrate that aided by out-painting methods, open-vocabulary object
detectors can serve as a drop-in module to identify semantic targets (e.g.
knobs) and point tracking methods can reliably track interaction sites
indicated by user clicks. This training-free method obtains an 85% zero-shot
success rate on manipulating unseen objects in novel environments in the real
world, outperforming an open-loop control method and an imitation learning
baseline trained on 1000+ demonstrations by an absolute success rate of 50%.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Many everyday mobile manipulation tasks require precise interaction with\nsmall objects, such as grasping a knob to open a cabinet or pressing a light\nswitch. In this paper, we develop Servoing with Vision Models (SVM), a\nclosed-loop training-free framework that enables a mobile manipulator to tackle\nsuch precise tasks involving the manipulation of small objects. SVM employs an\nRGB-D wrist camera and uses visual servoing for control. Our novelty lies in\nthe use of state-of-the-art vision models to reliably compute 3D targets from\nthe wrist image for diverse tasks and under occlusion due to the end-effector.\nTo mitigate occlusion artifacts, we employ vision models to out-paint the\nend-effector thereby significantly enhancing target localization. We\ndemonstrate that aided by out-painting methods, open-vocabulary object\ndetectors can serve as a drop-in module to identify semantic targets (e.g.\nknobs) and point tracking methods can reliably track interaction sites\nindicated by user clicks. This training-free method obtains an 85% zero-shot\nsuccess rate on manipulating unseen objects in novel environments in the real\nworld, outperforming an open-loop control method and an imitation learning\nbaseline trained on 1000+ demonstrations by an absolute success rate of 50%.'}","['Arjun Gupta', 'Rishik Sathua', 'Saurabh Gupta']",{'name': 'Saurabh Gupta'},Saurabh Gupta,Project webpage: https://arjung128.github.io/svm,"[{'href': 'http://arxiv.org/abs/2502.13964v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13964v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13964v1,None,http://arxiv.org/abs/2502.13964v1,,,1213,0
http://arxiv.org/abs/2502.13965v1,True,2025-02-19T18:59:30Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=18, tm_min=59, tm_sec=30, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T18:59:30Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=18, tm_min=59, tm_sec=30, tm_wday=2, tm_yday=50, tm_isdst=0)",Autellix: An Efficient Serving Engine for LLM Agents as General Programs,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Autellix: An Efficient Serving Engine for LLM Agents as General Programs'}","Large language model (LLM) applications are evolving beyond simple chatbots
into dynamic, general-purpose agentic programs, which scale LLM calls and
output tokens to help AI agents reason, explore, and solve complex tasks.
However, existing LLM serving systems ignore dependencies between programs and
calls, missing significant opportunities for optimization. Our analysis reveals
that programs submitted to LLM serving engines experience long cumulative wait
times, primarily due to head-of-line blocking at both the individual LLM
request and the program. To address this, we introduce Autellix, an LLM serving
system that treats programs as first-class citizens to minimize their
end-to-end latencies. Autellix intercepts LLM calls submitted by programs,
enriching schedulers with program-level context. We propose two scheduling
algorithms-for single-threaded and distributed programs-that preempt and
prioritize LLM calls based on their programs' previously completed calls. Our
evaluation demonstrates that across diverse LLMs and agentic workloads,
Autellix improves throughput of programs by 4-15x at the same latency compared
to state-of-the-art systems, such as vLLM.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Large language model (LLM) applications are evolving beyond simple chatbots\ninto dynamic, general-purpose agentic programs, which scale LLM calls and\noutput tokens to help AI agents reason, explore, and solve complex tasks.\nHowever, existing LLM serving systems ignore dependencies between programs and\ncalls, missing significant opportunities for optimization. Our analysis reveals\nthat programs submitted to LLM serving engines experience long cumulative wait\ntimes, primarily due to head-of-line blocking at both the individual LLM\nrequest and the program. To address this, we introduce Autellix, an LLM serving\nsystem that treats programs as first-class citizens to minimize their\nend-to-end latencies. Autellix intercepts LLM calls submitted by programs,\nenriching schedulers with program-level context. We propose two scheduling\nalgorithms-for single-threaded and distributed programs-that preempt and\nprioritize LLM calls based on their programs' previously completed calls. Our\nevaluation demonstrates that across diverse LLMs and agentic workloads,\nAutellix improves throughput of programs by 4-15x at the same latency compared\nto state-of-the-art systems, such as vLLM.""}","['Michael Luo', 'Xiaoxiang Shi', 'Colin Cai', 'Tianjun Zhang', 'Justin Wong', 'Yichuan Wang', 'Chi Wang', 'Yanping Huang', 'Zhifeng Chen', 'Joseph E. Gonzalez', 'Ion Stoica']",{'name': 'Ion Stoica'},Ion Stoica,,"[{'href': 'http://arxiv.org/abs/2502.13965v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13965v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.DC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13965v1,None,http://arxiv.org/abs/2502.13965v1,,,303,0
http://arxiv.org/abs/2502.13979v1,True,2025-02-18T08:09:05Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=8, tm_min=9, tm_sec=5, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T08:09:05Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=8, tm_min=9, tm_sec=5, tm_wday=1, tm_yday=49, tm_isdst=0)","Utilizing Effective Dynamic Graph Learning to Shield Financial Stability
  from Risk Propagation","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Utilizing Effective Dynamic Graph Learning to Shield Financial Stability\n  from Risk Propagation'}","Financial risks can propagate across both tightly coupled temporal and
spatial dimensions, posing significant threats to financial stability.
Moreover, risks embedded in unlabeled data are often difficult to detect. To
address these challenges, we introduce GraphShield, a novel approach with three
key innovations: Enhanced Cross-Domain Infor mation Learning: We propose a
dynamic graph learning module to improve information learning across temporal
and spatial domains. Advanced Risk Recognition: By leveraging the clustering
characteristics of risks, we construct a risk recognizing module to enhance the
identification of hidden threats. Risk Propagation Visualization: We provide a
visualization tool for quantifying and validating nodes that trigger widespread
cascading risks. Extensive experiments on two real-world and two open-source
datasets demonstrate the robust performance of our framework. Our approach
represents a significant advancement in leveraging artificial intelligence to
enhance financial stability, offering a powerful solution to mitigate the
spread of risks within financial networks.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Financial risks can propagate across both tightly coupled temporal and\nspatial dimensions, posing significant threats to financial stability.\nMoreover, risks embedded in unlabeled data are often difficult to detect. To\naddress these challenges, we introduce GraphShield, a novel approach with three\nkey innovations: Enhanced Cross-Domain Infor mation Learning: We propose a\ndynamic graph learning module to improve information learning across temporal\nand spatial domains. Advanced Risk Recognition: By leveraging the clustering\ncharacteristics of risks, we construct a risk recognizing module to enhance the\nidentification of hidden threats. Risk Propagation Visualization: We provide a\nvisualization tool for quantifying and validating nodes that trigger widespread\ncascading risks. Extensive experiments on two real-world and two open-source\ndatasets demonstrate the robust performance of our framework. Our approach\nrepresents a significant advancement in leveraging artificial intelligence to\nenhance financial stability, offering a powerful solution to mitigate the\nspread of risks within financial networks.'}","['Guanyuan Yu', 'Qing Li', 'Yu Zhao', 'Jun Wang', 'YiJun Chen', 'Shaolei Chen']",{'name': 'Shaolei Chen'},Shaolei Chen,,"[{'href': 'http://arxiv.org/abs/2502.13979v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13979v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'q-fin.RM', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'q-fin.RM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13979v1,None,http://arxiv.org/abs/2502.13979v1,,,258,0
http://arxiv.org/abs/2502.14000v1,True,2025-02-19T07:55:34Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=7, tm_min=55, tm_sec=34, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T07:55:34Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=7, tm_min=55, tm_sec=34, tm_wday=2, tm_yday=50, tm_isdst=0)","Human-Artificial Interaction in the Age of Agentic AI: A
  System-Theoretical Approach","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Human-Artificial Interaction in the Age of Agentic AI: A\n  System-Theoretical Approach'}","This paper presents a novel perspective on human-computer interaction (HCI),
framing it as a dynamic interplay between human and computational agents within
a networked system. Going beyond traditional interface-based approaches, we
emphasize the importance of coordination and communication among heterogeneous
agents with different capabilities, roles, and goals. A key distinction is made
between multi-agent systems (MAS) and Centaurian systems, which represent two
different paradigms of human-AI collaboration. MAS maintain agent autonomy,
with structured protocols enabling cooperation, while Centaurian systems deeply
integrate human and AI capabilities, creating unified decision-making entities.
  To formalize these interactions, we introduce a framework for communication
spaces, structured into surface, observation, and computation layers, ensuring
seamless integration between MAS and Centaurian architectures, where colored
Petri nets effectively represent structured Centaurian systems and high-level
reconfigurable networks address the dynamic nature of MAS.
  Our research has practical applications in autonomous robotics,
human-in-the-loop decision making, and AI-driven cognitive architectures, and
provides a foundation for next-generation hybrid intelligence systems that
balance structured coordination with emergent behavior.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'This paper presents a novel perspective on human-computer interaction (HCI),\nframing it as a dynamic interplay between human and computational agents within\na networked system. Going beyond traditional interface-based approaches, we\nemphasize the importance of coordination and communication among heterogeneous\nagents with different capabilities, roles, and goals. A key distinction is made\nbetween multi-agent systems (MAS) and Centaurian systems, which represent two\ndifferent paradigms of human-AI collaboration. MAS maintain agent autonomy,\nwith structured protocols enabling cooperation, while Centaurian systems deeply\nintegrate human and AI capabilities, creating unified decision-making entities.\n  To formalize these interactions, we introduce a framework for communication\nspaces, structured into surface, observation, and computation layers, ensuring\nseamless integration between MAS and Centaurian architectures, where colored\nPetri nets effectively represent structured Centaurian systems and high-level\nreconfigurable networks address the dynamic nature of MAS.\n  Our research has practical applications in autonomous robotics,\nhuman-in-the-loop decision making, and AI-driven cognitive architectures, and\nprovides a foundation for next-generation hybrid intelligence systems that\nbalance structured coordination with emergent behavior.'}","['Uwe M. Borghoff', 'Paolo Bottoni', 'Remo Pareschi']",{'name': 'Remo Pareschi'},Remo Pareschi,"27 pages, 10 figures","[{'href': 'http://arxiv.org/abs/2502.14000v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14000v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14000v1,None,http://arxiv.org/abs/2502.14000v1,,,3887,0
http://arxiv.org/abs/2502.14001v1,True,2025-02-19T07:56:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=7, tm_min=56, tm_sec=23, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T07:56:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=7, tm_min=56, tm_sec=23, tm_wday=2, tm_yday=50, tm_isdst=0)","Towards a perturbation-based explanation for medical AI as
  differentiable programs","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Towards a perturbation-based explanation for medical AI as\n  differentiable programs'}","Recent advancement in machine learning algorithms reaches a point where
medical devices can be equipped with artificial intelligence (AI) models for
diagnostic support and routine automation in clinical settings. In medicine and
healthcare, there is a particular demand for sufficient and objective
explainability of the outcome generated by AI models. However, AI models are
generally considered as black boxes due to their complexity, and the
computational process leading to their response is often opaque. Although
several methods have been proposed to explain the behavior of models by
evaluating the importance of each feature in discrimination and prediction,
they may suffer from biases and opacities arising from the scale and sampling
protocol of the dataset used for training or testing. To overcome the
shortcomings of existing methods, we explore an alternative approach to provide
an objective explanation of AI models that can be defined independently of the
learning process and does not require additional data. As a preliminary study
for this direction of research, this work examines a numerical availability of
the Jacobian matrix of deep learning models that measures how stably a model
responses against small perturbations added to the input. The indicator, if
available, are calculated from a trained AI model for a given target input.
This is a first step towards a perturbation-based explanation, which will
assist medical practitioners in understanding and interpreting the response of
the AI model in its clinical application.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Recent advancement in machine learning algorithms reaches a point where\nmedical devices can be equipped with artificial intelligence (AI) models for\ndiagnostic support and routine automation in clinical settings. In medicine and\nhealthcare, there is a particular demand for sufficient and objective\nexplainability of the outcome generated by AI models. However, AI models are\ngenerally considered as black boxes due to their complexity, and the\ncomputational process leading to their response is often opaque. Although\nseveral methods have been proposed to explain the behavior of models by\nevaluating the importance of each feature in discrimination and prediction,\nthey may suffer from biases and opacities arising from the scale and sampling\nprotocol of the dataset used for training or testing. To overcome the\nshortcomings of existing methods, we explore an alternative approach to provide\nan objective explanation of AI models that can be defined independently of the\nlearning process and does not require additional data. As a preliminary study\nfor this direction of research, this work examines a numerical availability of\nthe Jacobian matrix of deep learning models that measures how stably a model\nresponses against small perturbations added to the input. The indicator, if\navailable, are calculated from a trained AI model for a given target input.\nThis is a first step towards a perturbation-based explanation, which will\nassist medical practitioners in understanding and interpreting the response of\nthe AI model in its clinical application.'}","['Takeshi Abe', 'Yoshiyuki Asai']",{'name': 'Yoshiyuki Asai'},Yoshiyuki Asai,"7 pages, 1 figure","[{'href': 'http://arxiv.org/abs/2502.14001v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14001v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14001v1,None,http://arxiv.org/abs/2502.14001v1,,,81,0
http://arxiv.org/abs/2502.14008v1,True,2025-02-19T11:57:31Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=11, tm_min=57, tm_sec=31, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T11:57:31Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=11, tm_min=57, tm_sec=31, tm_wday=2, tm_yday=50, tm_isdst=0)",MaskPrune: Mask-based LLM Pruning for Layer-wise Uniform Structures,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'MaskPrune: Mask-based LLM Pruning for Layer-wise Uniform Structures'}","The remarkable performance of large language models (LLMs) in various
language tasks has attracted considerable attention. However, the
ever-increasing size of these models presents growing challenges for deployment
and inference. Structured pruning, an effective model compression technique, is
gaining increasing attention due to its ability to enhance inference
efficiency. Nevertheless, most previous optimization-based structured pruning
methods sacrifice the uniform structure across layers for greater flexibility
to maintain performance. The heterogeneous structure hinders the effective
utilization of off-the-shelf inference acceleration techniques and impedes
efficient configuration for continued training. To address this issue, we
propose a novel masking learning paradigm based on minimax optimization to
obtain the uniform pruned structure by optimizing the masks under sparsity
regularization. Extensive experimental results demonstrate that our method can
maintain high performance while ensuring the uniformity of the pruned model
structure, thereby outperforming existing SOTA methods.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The remarkable performance of large language models (LLMs) in various\nlanguage tasks has attracted considerable attention. However, the\never-increasing size of these models presents growing challenges for deployment\nand inference. Structured pruning, an effective model compression technique, is\ngaining increasing attention due to its ability to enhance inference\nefficiency. Nevertheless, most previous optimization-based structured pruning\nmethods sacrifice the uniform structure across layers for greater flexibility\nto maintain performance. The heterogeneous structure hinders the effective\nutilization of off-the-shelf inference acceleration techniques and impedes\nefficient configuration for continued training. To address this issue, we\npropose a novel masking learning paradigm based on minimax optimization to\nobtain the uniform pruned structure by optimizing the masks under sparsity\nregularization. Extensive experimental results demonstrate that our method can\nmaintain high performance while ensuring the uniformity of the pruned model\nstructure, thereby outperforming existing SOTA methods.'}","['Jiayu Qin', 'Jianchao Tan', 'Kefeng Zhang', 'Xunliang Cai', 'Wei Wang']",{'name': 'Wei Wang'},Wei Wang,,"[{'href': 'http://arxiv.org/abs/2502.14008v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14008v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14008v1,None,http://arxiv.org/abs/2502.14008v1,,,1,0
http://arxiv.org/abs/2502.14010v1,True,2025-02-19T12:25:02Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=12, tm_min=25, tm_sec=2, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T12:25:02Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=12, tm_min=25, tm_sec=2, tm_wday=2, tm_yday=50, tm_isdst=0)",Which Attention Heads Matter for In-Context Learning?,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Which Attention Heads Matter for In-Context Learning?'}","Large language models (LLMs) exhibit impressive in-context learning (ICL)
capability, enabling them to perform new tasks using only a few demonstrations
in the prompt. Two different mechanisms have been proposed to explain ICL:
induction heads that find and copy relevant tokens, and function vector (FV)
heads whose activations compute a latent encoding of the ICL task. To better
understand which of the two distinct mechanisms drives ICL, we study and
compare induction heads and FV heads in 12 language models.
  Through detailed ablations, we discover that few-shot ICL performance depends
primarily on FV heads, especially in larger models. In addition, we uncover
that FV and induction heads are connected: many FV heads start as induction
heads during training before transitioning to the FV mechanism. This leads us
to speculate that induction facilitates learning the more complex FV mechanism
that ultimately drives ICL.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large language models (LLMs) exhibit impressive in-context learning (ICL)\ncapability, enabling them to perform new tasks using only a few demonstrations\nin the prompt. Two different mechanisms have been proposed to explain ICL:\ninduction heads that find and copy relevant tokens, and function vector (FV)\nheads whose activations compute a latent encoding of the ICL task. To better\nunderstand which of the two distinct mechanisms drives ICL, we study and\ncompare induction heads and FV heads in 12 language models.\n  Through detailed ablations, we discover that few-shot ICL performance depends\nprimarily on FV heads, especially in larger models. In addition, we uncover\nthat FV and induction heads are connected: many FV heads start as induction\nheads during training before transitioning to the FV mechanism. This leads us\nto speculate that induction facilitates learning the more complex FV mechanism\nthat ultimately drives ICL.'}","['Kayo Yin', 'Jacob Steinhardt']",{'name': 'Jacob Steinhardt'},Jacob Steinhardt,,"[{'href': 'http://arxiv.org/abs/2502.14010v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14010v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14010v1,None,http://arxiv.org/abs/2502.14010v1,,,0,0
http://arxiv.org/abs/2502.14011v1,True,2025-02-19T12:45:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=12, tm_min=45, tm_sec=42, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T12:45:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=12, tm_min=45, tm_sec=42, tm_wday=2, tm_yday=50, tm_isdst=0)","DFDT: Dynamic Fast Decision Tree for IoT Data Stream Mining on Edge
  Devices","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'DFDT: Dynamic Fast Decision Tree for IoT Data Stream Mining on Edge\n  Devices'}","The Internet of Things generates massive data streams, with edge computing
emerging as a key enabler for online IoT applications and 5G networks. Edge
solutions facilitate real-time machine learning inference, but also require
continuous adaptation to concept drifts. Ensemble-based solutions improve
predictive performance, but incur higher resource consumption, latency, and
memory demands. This paper presents DFDT: Dynamic Fast Decision Tree, a novel
algorithm designed for energy-efficient memory-constrained data stream mining.
DFDT improves hoeffding tree growth efficiency by dynamically adjusting grace
periods, tie thresholds, and split evaluations based on incoming data. It
incorporates stricter evaluation rules (based on entropy, information gain, and
leaf instance count), adaptive expansion modes, and a leaf deactivation
mechanism to manage memory, allowing more computation on frequently visited
nodes while conserving energy on others. Experiments show that the proposed
framework can achieve increased predictive performance (0.43 vs 0.29 ranking)
with constrained memory and a fraction of the runtime of VFDT or SVFDT.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The Internet of Things generates massive data streams, with edge computing\nemerging as a key enabler for online IoT applications and 5G networks. Edge\nsolutions facilitate real-time machine learning inference, but also require\ncontinuous adaptation to concept drifts. Ensemble-based solutions improve\npredictive performance, but incur higher resource consumption, latency, and\nmemory demands. This paper presents DFDT: Dynamic Fast Decision Tree, a novel\nalgorithm designed for energy-efficient memory-constrained data stream mining.\nDFDT improves hoeffding tree growth efficiency by dynamically adjusting grace\nperiods, tie thresholds, and split evaluations based on incoming data. It\nincorporates stricter evaluation rules (based on entropy, information gain, and\nleaf instance count), adaptive expansion modes, and a leaf deactivation\nmechanism to manage memory, allowing more computation on frequently visited\nnodes while conserving energy on others. Experiments show that the proposed\nframework can achieve increased predictive performance (0.43 vs 0.29 ranking)\nwith constrained memory and a fraction of the runtime of VFDT or SVFDT.'}","['Afonso Loureno', 'Joo Rodrigo', 'Joo Gama', 'Goreti Marreiros']",{'name': 'Goreti Marreiros'},Goreti Marreiros,,"[{'href': 'http://arxiv.org/abs/2502.14011v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14011v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14011v1,None,http://arxiv.org/abs/2502.14011v1,,,1586,0
http://arxiv.org/abs/2502.14013v1,True,2025-02-19T13:45:24Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=13, tm_min=45, tm_sec=24, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T13:45:24Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=13, tm_min=45, tm_sec=24, tm_wday=2, tm_yday=50, tm_isdst=0)",Appeal prediction for AI up-scaled Images,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Appeal prediction for AI up-scaled Images'}","DNN- or AI-based up-scaling algorithms are gaining in popularity due to the
improvements in machine learning. Various up-scaling models using CNNs, GANs or
mixed approaches have been published. The majority of models are evaluated
using PSRN and SSIM or only a few example images. However, a performance
evaluation with a wide range of real-world images and subjective evaluation is
missing, which we tackle in the following paper. For this reason, we describe
our developed dataset, which uses 136 base images and five different up-scaling
methods, namely Real-ESRGAN, BSRGAN, waifu2x, KXNet, and Lanczos. Overall the
dataset consists of 1496 annotated images. The labeling of our dataset focused
on image appeal and has been performed using crowd-sourcing employing our
open-source tool AVRate Voyager. We evaluate the appeal of the different
methods, and the results indicate that Real-ESRGAN and BSRGAN are the best.
Furthermore, we train a DNN to detect which up-scaling method has been used,
the trained models have a good overall performance in our evaluation. In
addition to this, we evaluate state-of-the-art image appeal and quality models,
here none of the models showed a high prediction performance, therefore we also
trained two own approaches. The first uses transfer learning and has the best
performance, and the second model uses signal-based features and a random
forest model with good overall performance. We share the data and
implementation to allow further research in the context of open science.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'DNN- or AI-based up-scaling algorithms are gaining in popularity due to the\nimprovements in machine learning. Various up-scaling models using CNNs, GANs or\nmixed approaches have been published. The majority of models are evaluated\nusing PSRN and SSIM or only a few example images. However, a performance\nevaluation with a wide range of real-world images and subjective evaluation is\nmissing, which we tackle in the following paper. For this reason, we describe\nour developed dataset, which uses 136 base images and five different up-scaling\nmethods, namely Real-ESRGAN, BSRGAN, waifu2x, KXNet, and Lanczos. Overall the\ndataset consists of 1496 annotated images. The labeling of our dataset focused\non image appeal and has been performed using crowd-sourcing employing our\nopen-source tool AVRate Voyager. We evaluate the appeal of the different\nmethods, and the results indicate that Real-ESRGAN and BSRGAN are the best.\nFurthermore, we train a DNN to detect which up-scaling method has been used,\nthe trained models have a good overall performance in our evaluation. In\naddition to this, we evaluate state-of-the-art image appeal and quality models,\nhere none of the models showed a high prediction performance, therefore we also\ntrained two own approaches. The first uses transfer learning and has the best\nperformance, and the second model uses signal-based features and a random\nforest model with good overall performance. We share the data and\nimplementation to allow further research in the context of open science.'}","['Steve Gring', 'Rasmus Merten', 'Alexander Raake']",{'name': 'Alexander Raake'},Alexander Raake,,"[{'href': 'http://arxiv.org/abs/2502.14013v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14013v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.GR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.GR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'eess.IV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14013v1,None,http://arxiv.org/abs/2502.14013v1,,,195,0
http://arxiv.org/abs/2502.14019v1,True,2025-02-19T18:06:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=18, tm_min=6, tm_sec=37, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T18:06:37Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=18, tm_min=6, tm_sec=37, tm_wday=2, tm_yday=50, tm_isdst=0)","Dehumanizing Machines: Mitigating Anthropomorphic Behaviors in Text
  Generation Systems","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Dehumanizing Machines: Mitigating Anthropomorphic Behaviors in Text\n  Generation Systems'}","As text generation systems' outputs are increasingly anthropomorphic --
perceived as human-like -- scholars have also raised increasing concerns about
how such outputs can lead to harmful outcomes, such as users over-relying or
developing emotional dependence on these systems. How to intervene on such
system outputs to mitigate anthropomorphic behaviors and their attendant
harmful outcomes, however, remains understudied. With this work, we aim to
provide empirical and theoretical grounding for developing such interventions.
To do so, we compile an inventory of interventions grounded both in prior
literature and a crowdsourced study where participants edited system outputs to
make them less human-like. Drawing on this inventory, we also develop a
conceptual framework to help characterize the landscape of possible
interventions, articulate distinctions between different types of
interventions, and provide a theoretical basis for evaluating the effectiveness
of different interventions.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""As text generation systems' outputs are increasingly anthropomorphic --\nperceived as human-like -- scholars have also raised increasing concerns about\nhow such outputs can lead to harmful outcomes, such as users over-relying or\ndeveloping emotional dependence on these systems. How to intervene on such\nsystem outputs to mitigate anthropomorphic behaviors and their attendant\nharmful outcomes, however, remains understudied. With this work, we aim to\nprovide empirical and theoretical grounding for developing such interventions.\nTo do so, we compile an inventory of interventions grounded both in prior\nliterature and a crowdsourced study where participants edited system outputs to\nmake them less human-like. Drawing on this inventory, we also develop a\nconceptual framework to help characterize the landscape of possible\ninterventions, articulate distinctions between different types of\ninterventions, and provide a theoretical basis for evaluating the effectiveness\nof different interventions.""}","['Myra Cheng', 'Su Lin Blodgett', 'Alicia DeVrio', 'Lisa Egede', 'Alexandra Olteanu']",{'name': 'Alexandra Olteanu'},Alexandra Olteanu,,"[{'href': 'http://arxiv.org/abs/2502.14019v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14019v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14019v1,None,http://arxiv.org/abs/2502.14019v1,,,2402,0
http://arxiv.org/abs/2502.14023v1,True,2025-02-19T18:50:08Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=18, tm_min=50, tm_sec=8, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T18:50:08Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=18, tm_min=50, tm_sec=8, tm_wday=2, tm_yday=50, tm_isdst=0)","Dynamic Activation with Knowledge Distillation for Energy-Efficient
  Spiking NN Ensembles","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Dynamic Activation with Knowledge Distillation for Energy-Efficient\n  Spiking NN Ensembles'}","While foundation AI models excel at tasks like classification and
decision-making, their high energy consumption makes them unsuitable for
energy-constrained applications. Inspired by the brain's efficiency, spiking
neural networks (SNNs) have emerged as a viable alternative due to their
event-driven nature and compatibility with neuromorphic chips. This work
introduces a novel system that combines knowledge distillation and ensemble
learning to bridge the performance gap between artificial neural networks
(ANNs) and SNNs. A foundation AI model acts as a teacher network, guiding
smaller student SNNs organized into an ensemble, called Spiking Neural Ensemble
(SNE). SNE enables the disentanglement of the teacher's knowledge, allowing
each student to specialize in predicting a distinct aspect of it, while
processing the same input. The core innovation of SNE is the adaptive
activation of a subset of SNN models of an ensemble, leveraging
knowledge-distillation, enhanced with an informed-partitioning
(disentanglement) of the teacher's feature space. By dynamically activating
only a subset of these student SNNs, the system balances accuracy and energy
efficiency, achieving substantial energy savings with minimal accuracy loss.
Moreover, SNE is significantly more efficient than the teacher network,
reducing computational requirements by up to 20x with only a 2% drop in
accuracy on the CIFAR-10 dataset. This disentanglement procedure achieves an
accuracy improvement of up to 2.4% on the CIFAR-10 dataset compared to other
partitioning schemes. Finally, we comparatively analyze SNE performance under
noisy conditions, demonstrating enhanced robustness compared to its ANN
teacher. In summary, SNE offers a promising new direction for
energy-constrained applications.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""While foundation AI models excel at tasks like classification and\ndecision-making, their high energy consumption makes them unsuitable for\nenergy-constrained applications. Inspired by the brain's efficiency, spiking\nneural networks (SNNs) have emerged as a viable alternative due to their\nevent-driven nature and compatibility with neuromorphic chips. This work\nintroduces a novel system that combines knowledge distillation and ensemble\nlearning to bridge the performance gap between artificial neural networks\n(ANNs) and SNNs. A foundation AI model acts as a teacher network, guiding\nsmaller student SNNs organized into an ensemble, called Spiking Neural Ensemble\n(SNE). SNE enables the disentanglement of the teacher's knowledge, allowing\neach student to specialize in predicting a distinct aspect of it, while\nprocessing the same input. The core innovation of SNE is the adaptive\nactivation of a subset of SNN models of an ensemble, leveraging\nknowledge-distillation, enhanced with an informed-partitioning\n(disentanglement) of the teacher's feature space. By dynamically activating\nonly a subset of these student SNNs, the system balances accuracy and energy\nefficiency, achieving substantial energy savings with minimal accuracy loss.\nMoreover, SNE is significantly more efficient than the teacher network,\nreducing computational requirements by up to 20x with only a 2% drop in\naccuracy on the CIFAR-10 dataset. This disentanglement procedure achieves an\naccuracy improvement of up to 2.4% on the CIFAR-10 dataset compared to other\npartitioning schemes. Finally, we comparatively analyze SNE performance under\nnoisy conditions, demonstrating enhanced robustness compared to its ANN\nteacher. In summary, SNE offers a promising new direction for\nenergy-constrained applications.""}","['Orestis Konstantaropoulos', 'Theodoris Mallios', 'Maria Papadopouli']",{'name': 'Maria Papadopouli'},Maria Papadopouli,,"[{'href': 'http://arxiv.org/abs/2502.14023v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14023v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14023v1,None,http://arxiv.org/abs/2502.14023v1,,,1707,0
http://arxiv.org/abs/2502.14037v1,True,2025-02-19T19:00:02Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=19, tm_min=0, tm_sec=2, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T19:00:02Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=19, tm_min=0, tm_sec=2, tm_wday=2, tm_yday=50, tm_isdst=0)",DiffSampling: Enhancing Diversity and Accuracy in Neural Text Generation,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'DiffSampling: Enhancing Diversity and Accuracy in Neural Text Generation'}","Despite their increasing performance, large language models still tend to
reproduce training data, generate several repetitions, and focus on the most
common grammatical structures and words. A possible cause is the decoding
strategy adopted: the most common ones either consider only the most probable
tokens, reducing output diversity, or increase the likelihood of unlikely
tokens at the cost of output accuracy and correctness. In this paper, we
propose a family of three new decoding methods by leveraging a mathematical
analysis of the token probability distribution. In particular, the difference
between consecutive, sorted probabilities can be used to avoid incorrect tokens
and increase the chance of low-probable but accurate words. Experiments
concerning math problem solving, extreme summarization, and the divergent
association task show that our approach consistently performs at least as well
as current alternatives in terms of quality and diversity.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Despite their increasing performance, large language models still tend to\nreproduce training data, generate several repetitions, and focus on the most\ncommon grammatical structures and words. A possible cause is the decoding\nstrategy adopted: the most common ones either consider only the most probable\ntokens, reducing output diversity, or increase the likelihood of unlikely\ntokens at the cost of output accuracy and correctness. In this paper, we\npropose a family of three new decoding methods by leveraging a mathematical\nanalysis of the token probability distribution. In particular, the difference\nbetween consecutive, sorted probabilities can be used to avoid incorrect tokens\nand increase the chance of low-probable but accurate words. Experiments\nconcerning math problem solving, extreme summarization, and the divergent\nassociation task show that our approach consistently performs at least as well\nas current alternatives in terms of quality and diversity.'}","['Giorgio Franceschelli', 'Mirco Musolesi']",{'name': 'Mirco Musolesi'},Mirco Musolesi,,"[{'href': 'http://arxiv.org/abs/2502.14037v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14037v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14037v1,None,http://arxiv.org/abs/2502.14037v1,,,261,0
http://arxiv.org/abs/2502.14047v1,True,2025-02-19T19:09:14Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=19, tm_min=9, tm_sec=14, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T19:09:14Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=19, tm_min=9, tm_sec=14, tm_wday=2, tm_yday=50, tm_isdst=0)",Towards a Learning Theory of Representation Alignment,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Towards a Learning Theory of Representation Alignment'}","It has recently been argued that AI models' representations are becoming
aligned as their scale and performance increase. Empirical analyses have been
designed to support this idea and conjecture the possible alignment of
different representations toward a shared statistical model of reality. In this
paper, we propose a learning-theoretic perspective to representation alignment.
First, we review and connect different notions of alignment based on metric,
probabilistic, and spectral ideas. Then, we focus on stitching, a particular
approach to understanding the interplay between different representations in
the context of a task. Our main contribution here is relating properties of
stitching to the kernel alignment of the underlying representation. Our results
can be seen as a first step toward casting representation alignment as a
learning-theoretic problem.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""It has recently been argued that AI models' representations are becoming\naligned as their scale and performance increase. Empirical analyses have been\ndesigned to support this idea and conjecture the possible alignment of\ndifferent representations toward a shared statistical model of reality. In this\npaper, we propose a learning-theoretic perspective to representation alignment.\nFirst, we review and connect different notions of alignment based on metric,\nprobabilistic, and spectral ideas. Then, we focus on stitching, a particular\napproach to understanding the interplay between different representations in\nthe context of a task. Our main contribution here is relating properties of\nstitching to the kernel alignment of the underlying representation. Our results\ncan be seen as a first step toward casting representation alignment as a\nlearning-theoretic problem.""}","['Francesco Insulla', 'Shuo Huang', 'Lorenzo Rosasco']",{'name': 'Lorenzo Rosasco'},Lorenzo Rosasco,,"[{'href': 'http://arxiv.org/abs/2502.14047v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14047v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14047v1,None,http://arxiv.org/abs/2502.14047v1,,,0,0
http://arxiv.org/abs/2502.14048v1,True,2025-02-19T19:09:40Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=19, tm_min=9, tm_sec=40, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T19:09:40Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=19, tm_min=9, tm_sec=40, tm_wday=2, tm_yday=50, tm_isdst=0)","Semantic Decomposition and Selective Context Filtering -- Text
  Processing Techniques for Context-Aware NLP-Based Systems","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Semantic Decomposition and Selective Context Filtering -- Text\n  Processing Techniques for Context-Aware NLP-Based Systems'}","In this paper, we present two techniques for use in context-aware systems:
Semantic Decomposition, which sequentially decomposes input prompts into a
structured and hierarchal information schema in which systems can parse and
process easily, and Selective Context Filtering, which enables systems to
systematically filter out specific irrelevant sections of contextual
information that is fed through a system's NLP-based pipeline. We will explore
how context-aware systems and applications can utilize these two techniques in
order to implement dynamic LLM-to-system interfaces, improve an LLM's ability
to generate more contextually cohesive user-facing responses, and optimize
complex automated workflows and pipelines.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""In this paper, we present two techniques for use in context-aware systems:\nSemantic Decomposition, which sequentially decomposes input prompts into a\nstructured and hierarchal information schema in which systems can parse and\nprocess easily, and Selective Context Filtering, which enables systems to\nsystematically filter out specific irrelevant sections of contextual\ninformation that is fed through a system's NLP-based pipeline. We will explore\nhow context-aware systems and applications can utilize these two techniques in\norder to implement dynamic LLM-to-system interfaces, improve an LLM's ability\nto generate more contextually cohesive user-facing responses, and optimize\ncomplex automated workflows and pipelines.""}",['Karl John Villardar'],{'name': 'Karl John Villardar'},Karl John Villardar,,"[{'href': 'http://arxiv.org/abs/2502.14048v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14048v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7; I.7.0', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14048v1,None,http://arxiv.org/abs/2502.14048v1,,,0,0
http://arxiv.org/abs/2502.14050v1,True,2025-02-19T19:12:34Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=19, tm_min=12, tm_sec=34, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T19:12:34Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=19, tm_min=12, tm_sec=34, tm_wday=2, tm_yday=50, tm_isdst=0)","Diversity-driven Data Selection for Language Model Tuning through Sparse
  Autoencoder","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Diversity-driven Data Selection for Language Model Tuning through Sparse\n  Autoencoder'}","Current pre-trained large language models typically need instruction tuning
to align with human preferences. However, instruction tuning data is often
quantity-saturated due to the large volume of data collection and fast model
iteration, leaving coreset data selection important but underexplored. On the
other hand, existing quality-driven data selection methods such as LIMA
(NeurIPS 2023 (Zhou et al., 2024)) and AlpaGasus (ICLR 2024 (Chen et al.))
generally ignore the equal importance of data diversity and complexity. In this
work, we aim to design a diversity-aware data selection strategy and creatively
propose using sparse autoencoders to tackle the challenge of data diversity
measure. In addition, sparse autoencoders can also provide more
interpretability of model behavior and explain, e.g., the surprising
effectiveness of selecting the longest response (ICML 2024 (Zhao et al.)).
Using effective data selection, we experimentally prove that models trained on
our selected data can outperform other methods in terms of model capabilities,
reduce training cost, and potentially gain more control over model behaviors.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Current pre-trained large language models typically need instruction tuning\nto align with human preferences. However, instruction tuning data is often\nquantity-saturated due to the large volume of data collection and fast model\niteration, leaving coreset data selection important but underexplored. On the\nother hand, existing quality-driven data selection methods such as LIMA\n(NeurIPS 2023 (Zhou et al., 2024)) and AlpaGasus (ICLR 2024 (Chen et al.))\ngenerally ignore the equal importance of data diversity and complexity. In this\nwork, we aim to design a diversity-aware data selection strategy and creatively\npropose using sparse autoencoders to tackle the challenge of data diversity\nmeasure. In addition, sparse autoencoders can also provide more\ninterpretability of model behavior and explain, e.g., the surprising\neffectiveness of selecting the longest response (ICML 2024 (Zhao et al.)).\nUsing effective data selection, we experimentally prove that models trained on\nour selected data can outperform other methods in terms of model capabilities,\nreduce training cost, and potentially gain more control over model behaviors.'}","['Xianjun Yang', 'Shaoliang Nie', 'Lijuan Liu', 'Suchin Gururangan', 'Ujjwal Karn', 'Rui Hou', 'Madian Khabsa', 'Yuning Mao']",{'name': 'Yuning Mao'},Yuning Mao,,"[{'href': 'http://arxiv.org/abs/2502.14050v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14050v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14050v1,None,http://arxiv.org/abs/2502.14050v1,,,28351,0
http://arxiv.org/abs/2502.14061v1,True,2025-02-19T19:21:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=19, tm_min=21, tm_sec=23, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T19:21:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=19, tm_min=21, tm_sec=23, tm_wday=2, tm_yday=50, tm_isdst=0)",EfficientPose 6D: Scalable and Efficient 6D Object Pose Estimation,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'EfficientPose 6D: Scalable and Efficient 6D Object Pose Estimation'}","In industrial applications requiring real-time feedback, such as quality
control and robotic manipulation, the demand for high-speed and accurate pose
estimation remains critical. Despite advances improving speed and accuracy in
pose estimation, finding a balance between computational efficiency and
accuracy poses significant challenges in dynamic environments. Most current
algorithms lack scalability in estimation time, especially for diverse
datasets, and the state-of-the-art (SOTA) methods are often too slow. This
study focuses on developing a fast and scalable set of pose estimators based on
GDRNPP to meet or exceed current benchmarks in accuracy and robustness,
particularly addressing the efficiency-accuracy trade-off essential in
real-time scenarios. We propose the AMIS algorithm to tailor the utilized model
according to an application-specific trade-off between inference time and
accuracy. We further show the effectiveness of the AMIS-based model choice on
four prominent benchmark datasets (LM-O, YCB-V, T-LESS, and ITODD).","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'In industrial applications requiring real-time feedback, such as quality\ncontrol and robotic manipulation, the demand for high-speed and accurate pose\nestimation remains critical. Despite advances improving speed and accuracy in\npose estimation, finding a balance between computational efficiency and\naccuracy poses significant challenges in dynamic environments. Most current\nalgorithms lack scalability in estimation time, especially for diverse\ndatasets, and the state-of-the-art (SOTA) methods are often too slow. This\nstudy focuses on developing a fast and scalable set of pose estimators based on\nGDRNPP to meet or exceed current benchmarks in accuracy and robustness,\nparticularly addressing the efficiency-accuracy trade-off essential in\nreal-time scenarios. We propose the AMIS algorithm to tailor the utilized model\naccording to an application-specific trade-off between inference time and\naccuracy. We further show the effectiveness of the AMIS-based model choice on\nfour prominent benchmark datasets (LM-O, YCB-V, T-LESS, and ITODD).'}","['Zixuan Fang', 'Thomas Pllabauer', 'Tristan Wirth', 'Sarah Berkei', 'Volker Knauthe', 'Arjan Kuijper']",{'name': 'Arjan Kuijper'},Arjan Kuijper,,"[{'href': 'http://arxiv.org/abs/2502.14061v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14061v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14061v1,None,http://arxiv.org/abs/2502.14061v1,,,318,0
http://arxiv.org/abs/2502.14068v1,True,2025-02-19T19:43:31Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=19, tm_min=43, tm_sec=31, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T19:43:31Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=19, tm_min=43, tm_sec=31, tm_wday=2, tm_yday=50, tm_isdst=0)","A Racing Dataset and Baseline Model for Track Detection in Autonomous
  Racing","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A Racing Dataset and Baseline Model for Track Detection in Autonomous\n  Racing'}","A significant challenge in racing-related research is the lack of publicly
available datasets containing raw images with corresponding annotations for the
downstream task. In this paper, we introduce RoRaTrack, a novel dataset that
contains annotated multi-camera image data from racing scenarios for track
detection. The data is collected on a Dallara AV-21 at a racing circuit in
Indiana, in collaboration with the Indy Autonomous Challenge (IAC). RoRaTrack
addresses common problems such as blurriness due to high speed, color inversion
from the camera, and absence of lane markings on the track. Consequently, we
propose RaceGAN, a baseline model based on a Generative Adversarial Network
(GAN) that effectively addresses these challenges. The proposed model
demonstrates superior performance compared to current state-of-the-art machine
learning models in track detection. The dataset and code for this work are
available at github.com/RaceGAN.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A significant challenge in racing-related research is the lack of publicly\navailable datasets containing raw images with corresponding annotations for the\ndownstream task. In this paper, we introduce RoRaTrack, a novel dataset that\ncontains annotated multi-camera image data from racing scenarios for track\ndetection. The data is collected on a Dallara AV-21 at a racing circuit in\nIndiana, in collaboration with the Indy Autonomous Challenge (IAC). RoRaTrack\naddresses common problems such as blurriness due to high speed, color inversion\nfrom the camera, and absence of lane markings on the track. Consequently, we\npropose RaceGAN, a baseline model based on a Generative Adversarial Network\n(GAN) that effectively addresses these challenges. The proposed model\ndemonstrates superior performance compared to current state-of-the-art machine\nlearning models in track detection. The dataset and code for this work are\navailable at github.com/RaceGAN.'}","['Shreya Ghosh', 'Yi-Huan Chen', 'Ching-Hsiang Huang', 'Abu Shafin Mohammad Mahdee Jameel', 'Chien Chou Ho', 'Aly El Gamal', 'Samuel Labi']",{'name': 'Samuel Labi'},Samuel Labi,Currently Under Review,"[{'href': 'http://arxiv.org/abs/2502.14068v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14068v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'eess.IV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14068v1,None,http://arxiv.org/abs/2502.14068v1,,,1065,0
http://arxiv.org/abs/2502.14074v1,True,2025-02-19T19:59:16Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=19, tm_min=59, tm_sec=16, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T19:59:16Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=19, tm_min=59, tm_sec=16, tm_wday=2, tm_yday=50, tm_isdst=0)",Investigating Non-Transitivity in LLM-as-a-Judge,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Investigating Non-Transitivity in LLM-as-a-Judge'}","Automatic evaluation methods based on large language models (LLMs) are
emerging as the standard tool for assessing the instruction-following abilities
of LLM-based agents. The most common method in this paradigm, pairwise
comparisons with a baseline model, critically depends on the assumption of
transitive preferences. However, the validity of this assumption remains
largely unexplored. In this study, we investigate the presence of
non-transitivity within the AlpacaEval framework and analyze its effects on
model rankings. We find that LLM judges exhibit non-transitive preferences,
leading to rankings that are sensitive to the choice of the baseline model. To
mitigate this issue, we show that round-robin tournaments combined with
Bradley-Terry models of preference can produce more reliable rankings. Notably,
our method increases both the Spearman correlation and the Kendall correlation
with Chatbot Arena (95.0% -> 96.4% and 82.1% -> 86.3% respectively). To address
the computational cost of round-robin tournaments, we propose Swiss-Wise
Iterative Matchmaking (Swim) tournaments, using a dynamic matching strategy to
capture the benefits of round-robin tournaments while maintaining computational
efficiency.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Automatic evaluation methods based on large language models (LLMs) are\nemerging as the standard tool for assessing the instruction-following abilities\nof LLM-based agents. The most common method in this paradigm, pairwise\ncomparisons with a baseline model, critically depends on the assumption of\ntransitive preferences. However, the validity of this assumption remains\nlargely unexplored. In this study, we investigate the presence of\nnon-transitivity within the AlpacaEval framework and analyze its effects on\nmodel rankings. We find that LLM judges exhibit non-transitive preferences,\nleading to rankings that are sensitive to the choice of the baseline model. To\nmitigate this issue, we show that round-robin tournaments combined with\nBradley-Terry models of preference can produce more reliable rankings. Notably,\nour method increases both the Spearman correlation and the Kendall correlation\nwith Chatbot Arena (95.0% -> 96.4% and 82.1% -> 86.3% respectively). To address\nthe computational cost of round-robin tournaments, we propose Swiss-Wise\nIterative Matchmaking (Swim) tournaments, using a dynamic matching strategy to\ncapture the benefits of round-robin tournaments while maintaining computational\nefficiency.'}","['Yi Xu', 'Laura Ruis', 'Tim Rocktschel', 'Robert Kirk']",{'name': 'Robert Kirk'},Robert Kirk,"8 pages, 6 figures, 2 tables (30 pages, 11 figures, 8 tables
  including references and appendices)","[{'href': 'http://arxiv.org/abs/2502.14074v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14074v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14074v1,None,http://arxiv.org/abs/2502.14074v1,,,2390,0
http://arxiv.org/abs/2502.14121v1,True,2025-02-19T21:49:05Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=21, tm_min=49, tm_sec=5, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T21:49:05Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=21, tm_min=49, tm_sec=5, tm_wday=2, tm_yday=50, tm_isdst=0)","Multi-Objective Bayesian Optimization for Networked Black-Box Systems: A
  Path to Greener Profits and Smarter Designs","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Multi-Objective Bayesian Optimization for Networked Black-Box Systems: A\n  Path to Greener Profits and Smarter Designs'}","Designing modern industrial systems requires balancing several competing
objectives, such as profitability, resilience, and sustainability, while
accounting for complex interactions between technological, economic, and
environmental factors. Multi-objective optimization (MOO) methods are commonly
used to navigate these tradeoffs, but selecting the appropriate algorithm to
tackle these problems is often unclear, particularly when system
representations vary from fully equation-based (white-box) to entirely
data-driven (black-box) models. While grey-box MOO methods attempt to bridge
this gap, they typically impose rigid assumptions on system structure,
requiring models to conform to the underlying structural assumptions of the
solver rather than the solver adapting to the natural representation of the
system of interest. In this chapter, we introduce a unifying approach to
grey-box MOO by leveraging network representations, which provide a general and
flexible framework for modeling interconnected systems as a series of function
nodes that share various inputs and outputs. Specifically, we propose MOBONS, a
novel Bayesian optimization-inspired algorithm that can efficiently optimize
general function networks, including those with cyclic dependencies, enabling
the modeling of feedback loops, recycle streams, and multi-scale simulations -
features that existing methods fail to capture. Furthermore, MOBONS
incorporates constraints, supports parallel evaluations, and preserves the
sample efficiency of Bayesian optimization while leveraging network structure
for improved scalability. We demonstrate the effectiveness of MOBONS through
two case studies, including one related to sustainable process design. By
enabling efficient MOO under general graph representations, MOBONS has the
potential to significantly enhance the design of more profitable, resilient,
and sustainable engineering systems.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Designing modern industrial systems requires balancing several competing\nobjectives, such as profitability, resilience, and sustainability, while\naccounting for complex interactions between technological, economic, and\nenvironmental factors. Multi-objective optimization (MOO) methods are commonly\nused to navigate these tradeoffs, but selecting the appropriate algorithm to\ntackle these problems is often unclear, particularly when system\nrepresentations vary from fully equation-based (white-box) to entirely\ndata-driven (black-box) models. While grey-box MOO methods attempt to bridge\nthis gap, they typically impose rigid assumptions on system structure,\nrequiring models to conform to the underlying structural assumptions of the\nsolver rather than the solver adapting to the natural representation of the\nsystem of interest. In this chapter, we introduce a unifying approach to\ngrey-box MOO by leveraging network representations, which provide a general and\nflexible framework for modeling interconnected systems as a series of function\nnodes that share various inputs and outputs. Specifically, we propose MOBONS, a\nnovel Bayesian optimization-inspired algorithm that can efficiently optimize\ngeneral function networks, including those with cyclic dependencies, enabling\nthe modeling of feedback loops, recycle streams, and multi-scale simulations -\nfeatures that existing methods fail to capture. Furthermore, MOBONS\nincorporates constraints, supports parallel evaluations, and preserves the\nsample efficiency of Bayesian optimization while leveraging network structure\nfor improved scalability. We demonstrate the effectiveness of MOBONS through\ntwo case studies, including one related to sustainable process design. By\nenabling efficient MOO under general graph representations, MOBONS has the\npotential to significantly enhance the design of more profitable, resilient,\nand sustainable engineering systems.'}","['Akshay Kudva', 'Wei-Ting Tang', 'Joel A. Paulson']",{'name': 'Joel A. Paulson'},Joel A. Paulson,,"[{'href': 'http://arxiv.org/abs/2502.14121v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14121v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14121v1,None,http://arxiv.org/abs/2502.14121v1,,,1906,0
http://arxiv.org/abs/2502.14131v1,True,2025-02-19T22:22:20Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=22, tm_min=22, tm_sec=20, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T22:22:20Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=22, tm_min=22, tm_sec=20, tm_wday=2, tm_yday=50, tm_isdst=0)","Gradients can train reward models: An Empirical Risk Minimization
  Approach for Offline Inverse RL and Dynamic Discrete Choice Model","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Gradients can train reward models: An Empirical Risk Minimization\n  Approach for Offline Inverse RL and Dynamic Discrete Choice Model'}","We study the problem of estimating Dynamic Discrete Choice (DDC) models, also
known as offline Maximum Entropy-Regularized Inverse Reinforcement Learning
(offline MaxEnt-IRL) in machine learning. The objective is to recover reward or
$Q^*$ functions that govern agent behavior from offline behavior data. In this
paper, we propose a globally convergent gradient-based method for solving these
problems without the restrictive assumption of linearly parameterized rewards.
The novelty of our approach lies in introducing the Empirical Risk Minimization
(ERM) based IRL/DDC framework, which circumvents the need for explicit state
transition probability estimation in the Bellman equation. Furthermore, our
method is compatible with non-parametric estimation techniques such as neural
networks. Therefore, the proposed method has the potential to be scaled to
high-dimensional, infinite state spaces. A key theoretical insight underlying
our approach is that the Bellman residual satisfies the Polyak-Lojasiewicz (PL)
condition -- a property that, while weaker than strong convexity, is sufficient
to ensure fast global convergence guarantees. Through a series of synthetic
experiments, we demonstrate that our approach consistently outperforms
benchmark methods and state-of-the-art alternatives.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'We study the problem of estimating Dynamic Discrete Choice (DDC) models, also\nknown as offline Maximum Entropy-Regularized Inverse Reinforcement Learning\n(offline MaxEnt-IRL) in machine learning. The objective is to recover reward or\n$Q^*$ functions that govern agent behavior from offline behavior data. In this\npaper, we propose a globally convergent gradient-based method for solving these\nproblems without the restrictive assumption of linearly parameterized rewards.\nThe novelty of our approach lies in introducing the Empirical Risk Minimization\n(ERM) based IRL/DDC framework, which circumvents the need for explicit state\ntransition probability estimation in the Bellman equation. Furthermore, our\nmethod is compatible with non-parametric estimation techniques such as neural\nnetworks. Therefore, the proposed method has the potential to be scaled to\nhigh-dimensional, infinite state spaces. A key theoretical insight underlying\nour approach is that the Bellman residual satisfies the Polyak-Lojasiewicz (PL)\ncondition -- a property that, while weaker than strong convexity, is sufficient\nto ensure fast global convergence guarantees. Through a series of synthetic\nexperiments, we demonstrate that our approach consistently outperforms\nbenchmark methods and state-of-the-art alternatives.'}","['Enoch H. Kang', 'Hema Yoganarasimhan', 'Lalit Jain']",{'name': 'Lalit Jain'},Lalit Jain,,"[{'href': 'http://arxiv.org/abs/2502.14131v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14131v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'econ.EM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14131v1,None,http://arxiv.org/abs/2502.14131v1,,,991,0
http://arxiv.org/abs/2502.14155v1,True,2025-02-19T23:51:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=23, tm_min=51, tm_sec=23, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T23:51:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=23, tm_min=51, tm_sec=23, tm_wday=2, tm_yday=50, tm_isdst=0)",Giving AI Personalities Leads to More Human-Like Reasoning,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Giving AI Personalities Leads to More Human-Like Reasoning'}","In computational cognitive modeling, capturing the full spectrum of human
judgment and decision-making processes, beyond just optimal behaviors, is a
significant challenge. This study explores whether Large Language Models (LLMs)
can emulate the breadth of human reasoning by predicting both intuitive, fast
System 1 and deliberate, slow System 2 processes. We investigate the potential
of AI to mimic diverse reasoning behaviors across a human population,
addressing what we call the {\em full reasoning spectrum problem}. We designed
reasoning tasks using a novel generalization of the Natural Language Inference
(NLI) format to evaluate LLMs' ability to replicate human reasoning. The
questions were crafted to elicit both System 1 and System 2 responses. Human
responses were collected through crowd-sourcing and the entire distribution was
modeled, rather than just the majority of the answers. We used
personality-based prompting inspired by the Big Five personality model to
elicit AI responses reflecting specific personality traits, capturing the
diversity of human reasoning, and exploring how personality traits influence
LLM outputs. Combined with genetic algorithms to optimize the weighting of
these prompts, this method was tested alongside traditional machine learning
models. The results show that LLMs can mimic human response distributions, with
open-source models like Llama and Mistral outperforming proprietary GPT models.
Personality-based prompting, especially when optimized with genetic algorithms,
significantly enhanced LLMs' ability to predict human response distributions,
suggesting that capturing suboptimal, naturalistic reasoning may require
modeling techniques incorporating diverse reasoning styles and psychological
profiles. The study concludes that personality-based prompting combined with
genetic algorithms is promising for enhancing AI's \textit{human-ness} in
reasoning.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""In computational cognitive modeling, capturing the full spectrum of human\njudgment and decision-making processes, beyond just optimal behaviors, is a\nsignificant challenge. This study explores whether Large Language Models (LLMs)\ncan emulate the breadth of human reasoning by predicting both intuitive, fast\nSystem 1 and deliberate, slow System 2 processes. We investigate the potential\nof AI to mimic diverse reasoning behaviors across a human population,\naddressing what we call the {\\em full reasoning spectrum problem}. We designed\nreasoning tasks using a novel generalization of the Natural Language Inference\n(NLI) format to evaluate LLMs' ability to replicate human reasoning. The\nquestions were crafted to elicit both System 1 and System 2 responses. Human\nresponses were collected through crowd-sourcing and the entire distribution was\nmodeled, rather than just the majority of the answers. We used\npersonality-based prompting inspired by the Big Five personality model to\nelicit AI responses reflecting specific personality traits, capturing the\ndiversity of human reasoning, and exploring how personality traits influence\nLLM outputs. Combined with genetic algorithms to optimize the weighting of\nthese prompts, this method was tested alongside traditional machine learning\nmodels. The results show that LLMs can mimic human response distributions, with\nopen-source models like Llama and Mistral outperforming proprietary GPT models.\nPersonality-based prompting, especially when optimized with genetic algorithms,\nsignificantly enhanced LLMs' ability to predict human response distributions,\nsuggesting that capturing suboptimal, naturalistic reasoning may require\nmodeling techniques incorporating diverse reasoning styles and psychological\nprofiles. The study concludes that personality-based prompting combined with\ngenetic algorithms is promising for enhancing AI's \\textit{human-ness} in\nreasoning.""}","['Animesh Nighojkar', 'Bekhzodbek Moydinboyev', 'My Duong', 'John Licato']",{'name': 'John Licato'},John Licato,,"[{'href': 'http://arxiv.org/abs/2502.14155v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14155v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14155v1,None,http://arxiv.org/abs/2502.14155v1,,,476,0
http://arxiv.org/abs/2502.14160v1,True,2025-02-20T00:07:06Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=0, tm_min=7, tm_sec=6, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T00:07:06Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=0, tm_min=7, tm_sec=6, tm_wday=3, tm_yday=51, tm_isdst=0)",Efficient Inverse Multiagent Learning,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Efficient Inverse Multiagent Learning'}","In this paper, we study inverse game theory (resp. inverse multiagent
learning) in which the goal is to find parameters of a game's payoff functions
for which the expected (resp. sampled) behavior is an equilibrium. We formulate
these problems as generative-adversarial (i.e., min-max) optimization problems,
for which we develop polynomial-time algorithms to solve, the former of which
relies on an exact first-order oracle, and the latter, a stochastic one. We
extend our approach to solve inverse multiagent simulacral learning in
polynomial time and number of samples. In these problems, we seek a simulacrum,
meaning parameters and an associated equilibrium that replicate the given
observations in expectation. We find that our approach outperforms the
widely-used ARIMA method in predicting prices in Spanish electricity markets
based on time-series data.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""In this paper, we study inverse game theory (resp. inverse multiagent\nlearning) in which the goal is to find parameters of a game's payoff functions\nfor which the expected (resp. sampled) behavior is an equilibrium. We formulate\nthese problems as generative-adversarial (i.e., min-max) optimization problems,\nfor which we develop polynomial-time algorithms to solve, the former of which\nrelies on an exact first-order oracle, and the latter, a stochastic one. We\nextend our approach to solve inverse multiagent simulacral learning in\npolynomial time and number of samples. In these problems, we seek a simulacrum,\nmeaning parameters and an associated equilibrium that replicate the given\nobservations in expectation. We find that our approach outperforms the\nwidely-used ARIMA method in predicting prices in Spanish electricity markets\nbased on time-series data.""}","['Denizalp Goktas', 'Amy Greenwald', 'Sadie Zhao', 'Alec Koppel', 'Sumitra Ganesh']",{'name': 'Sumitra Ganesh'},Sumitra Ganesh,"Paper was submitted to the International Conference on Learning
  Representations (2024) under the title of ""Generative Adversarial Inverse
  Multiagent Learning"", and renamed for the camera-ready submission as
  ""Efficient Inverse Multiagent Learning""","[{'href': 'http://arxiv.org/abs/2502.14160v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14160v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'econ.TH', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14160v1,None,http://arxiv.org/abs/2502.14160v1,,,102,0
http://arxiv.org/abs/2502.14174v1,True,2025-02-20T00:59:50Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=0, tm_min=59, tm_sec=50, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T00:59:50Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=0, tm_min=59, tm_sec=50, tm_wday=3, tm_yday=51, tm_isdst=0)","Weighted Low-rank Approximation via Stochastic Gradient Descent on
  Manifolds","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Weighted Low-rank Approximation via Stochastic Gradient Descent on\n  Manifolds'}","We solve a regularized weighted low-rank approximation problem by a
stochastic gradient descent on a manifold. To guarantee the convergence of our
stochastic gradient descent, we establish a convergence theorem on manifolds
for retraction-based stochastic gradient descents admitting confinements. On
sample data from the Netflix Prize training dataset, our algorithm outperforms
the existing stochastic gradient descent on Euclidean spaces. We also compare
the accelerated line search on this manifold to the existing accelerated line
search on Euclidean spaces.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'We solve a regularized weighted low-rank approximation problem by a\nstochastic gradient descent on a manifold. To guarantee the convergence of our\nstochastic gradient descent, we establish a convergence theorem on manifolds\nfor retraction-based stochastic gradient descents admitting confinements. On\nsample data from the Netflix Prize training dataset, our algorithm outperforms\nthe existing stochastic gradient descent on Euclidean spaces. We also compare\nthe accelerated line search on this manifold to the existing accelerated line\nsearch on Euclidean spaces.'}","['Conglong Xu', 'Peiqi Yang', 'Hao Wu']",{'name': 'Hao Wu'},Hao Wu,,"[{'href': 'http://arxiv.org/abs/2502.14174v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14174v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'math.OC', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'math.OC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14174v1,None,http://arxiv.org/abs/2502.14174v1,,,0,0
http://arxiv.org/abs/2502.14202v1,True,2025-02-20T02:20:06Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=2, tm_min=20, tm_sec=6, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T02:20:06Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=2, tm_min=20, tm_sec=6, tm_wday=3, tm_yday=51, tm_isdst=0)","Do LLMs Consider Security? An Empirical Study on Responses to
  Programming Questions","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Do LLMs Consider Security? An Empirical Study on Responses to\n  Programming Questions'}","The widespread adoption of conversational LLMs for software development has
raised new security concerns regarding the safety of LLM-generated content. Our
motivational study outlines ChatGPT's potential in volunteering
context-specific information to the developers, promoting safe coding
practices. Motivated by this finding, we conduct a study to evaluate the degree
of security awareness exhibited by three prominent LLMs: Claude 3, GPT-4, and
Llama 3. We prompt these LLMs with Stack Overflow questions that contain
vulnerable code to evaluate whether they merely provide answers to the
questions or if they also warn users about the insecure code, thereby
demonstrating a degree of security awareness. Further, we assess whether LLM
responses provide information about the causes, exploits, and the potential
fixes of the vulnerability, to help raise users' awareness. Our findings show
that all three models struggle to accurately detect and warn users about
vulnerabilities, achieving a detection rate of only 12.6% to 40% across our
datasets. We also observe that the LLMs tend to identify certain types of
vulnerabilities related to sensitive information exposure and improper input
neutralization much more frequently than other types, such as those involving
external control of file names or paths. Furthermore, when LLMs do issue
security warnings, they often provide more information on the causes, exploits,
and fixes of vulnerabilities compared to Stack Overflow responses. Finally, we
provide an in-depth discussion on the implications of our findings and present
a CLI-based prompting tool that can be used to generate significantly more
secure LLM responses.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""The widespread adoption of conversational LLMs for software development has\nraised new security concerns regarding the safety of LLM-generated content. Our\nmotivational study outlines ChatGPT's potential in volunteering\ncontext-specific information to the developers, promoting safe coding\npractices. Motivated by this finding, we conduct a study to evaluate the degree\nof security awareness exhibited by three prominent LLMs: Claude 3, GPT-4, and\nLlama 3. We prompt these LLMs with Stack Overflow questions that contain\nvulnerable code to evaluate whether they merely provide answers to the\nquestions or if they also warn users about the insecure code, thereby\ndemonstrating a degree of security awareness. Further, we assess whether LLM\nresponses provide information about the causes, exploits, and the potential\nfixes of the vulnerability, to help raise users' awareness. Our findings show\nthat all three models struggle to accurately detect and warn users about\nvulnerabilities, achieving a detection rate of only 12.6% to 40% across our\ndatasets. We also observe that the LLMs tend to identify certain types of\nvulnerabilities related to sensitive information exposure and improper input\nneutralization much more frequently than other types, such as those involving\nexternal control of file names or paths. Furthermore, when LLMs do issue\nsecurity warnings, they often provide more information on the causes, exploits,\nand fixes of vulnerabilities compared to Stack Overflow responses. Finally, we\nprovide an in-depth discussion on the implications of our findings and present\na CLI-based prompting tool that can be used to generate significantly more\nsecure LLM responses.""}","['Amirali Sajadi', 'Binh Le', 'Anh Nguyen', 'Kostadin Damevski', 'Preetha Chatterjee']",{'name': 'Preetha Chatterjee'},Preetha Chatterjee,,"[{'href': 'http://arxiv.org/abs/2502.14202v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14202v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.SE', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.SE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14202v1,None,http://arxiv.org/abs/2502.14202v1,,,1607,0
http://arxiv.org/abs/2502.14222v1,True,2025-02-20T03:37:46Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=3, tm_min=37, tm_sec=46, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T03:37:46Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=3, tm_min=37, tm_sec=46, tm_wday=3, tm_yday=51, tm_isdst=0)","Enhancing Pavement Sensor Data Acquisition for AI-Driven Transportation
  Research","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Enhancing Pavement Sensor Data Acquisition for AI-Driven Transportation\n  Research'}","Effective strategies for sensor data management are essential for advancing
transportation research, especially in the current data-driven era, due to the
advent of novel applications in artificial intelligence. This paper presents
comprehensive guidelines for managing transportation sensor data, encompassing
both archived static data and real-time data streams. The real-time system
architecture integrates various applications with data acquisition systems
(DAQ). By deploying the in-house designed, open-source Avena software platform
alongside the NATS messaging system as a secure communication broker, reliable
data exchange is ensured. While robust databases like TimescaleDB facilitate
organized storage, visualization platforms like Grafana provide real-time
monitoring capabilities.
  In contrast, static data standards address the challenges in handling
unstructured, voluminous datasets. The standards advocate for a combination of
cost-effective bulk cloud storage for unprocessed sensor data and relational
databases for recording summarized analyses. They highlight the role of cloud
data transfer tools like FME for efficient migration of sensor data from local
storages onto the cloud. Further, integration of robust visualization tools
into the framework helps in deriving patterns and trends from these complex
datasets.
  The proposals were applied to INDOT's real-world case studies involving the
I-65 and I-69 Greenfield districts. For real-time data collection, Campbell
Scientific DAQ systems were used, enabling continuous generation and monitoring
of sensor metrics. In the case of the archived I-69 database, summary data was
compiled in Oracle, while the unprocessed data was stored in SharePoint. The
results underline the effectiveness of the proposed guidelines and motivate
their adoption in research projects.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Effective strategies for sensor data management are essential for advancing\ntransportation research, especially in the current data-driven era, due to the\nadvent of novel applications in artificial intelligence. This paper presents\ncomprehensive guidelines for managing transportation sensor data, encompassing\nboth archived static data and real-time data streams. The real-time system\narchitecture integrates various applications with data acquisition systems\n(DAQ). By deploying the in-house designed, open-source Avena software platform\nalongside the NATS messaging system as a secure communication broker, reliable\ndata exchange is ensured. While robust databases like TimescaleDB facilitate\norganized storage, visualization platforms like Grafana provide real-time\nmonitoring capabilities.\n  In contrast, static data standards address the challenges in handling\nunstructured, voluminous datasets. The standards advocate for a combination of\ncost-effective bulk cloud storage for unprocessed sensor data and relational\ndatabases for recording summarized analyses. They highlight the role of cloud\ndata transfer tools like FME for efficient migration of sensor data from local\nstorages onto the cloud. Further, integration of robust visualization tools\ninto the framework helps in deriving patterns and trends from these complex\ndatasets.\n  The proposals were applied to INDOT's real-world case studies involving the\nI-65 and I-69 Greenfield districts. For real-time data collection, Campbell\nScientific DAQ systems were used, enabling continuous generation and monitoring\nof sensor metrics. In the case of the archived I-69 database, summary data was\ncompiled in Oracle, while the unprocessed data was stored in SharePoint. The\nresults underline the effectiveness of the proposed guidelines and motivate\ntheir adoption in research projects.""}","['Manish Kumar Krishne Gowda', 'Andrew Balmos', 'Shin Boonam', 'James V. Krogmeier']",{'name': 'James V. Krogmeier'},James V. Krogmeier,"This paper was accepted for presentation at the 104th TRB Annual
  Meeting, held on January 5-9, 2025, in Washington, D.C., and was presented
  during the poster session on January 8, 2025","[{'href': 'http://arxiv.org/abs/2502.14222v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14222v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.DB', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.DB', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'eess.SP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14222v1,None,http://arxiv.org/abs/2502.14222v1,,,2842,0
http://arxiv.org/abs/2502.14247v1,True,2025-02-20T04:22:30Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=4, tm_min=22, tm_sec=30, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T04:22:30Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=4, tm_min=22, tm_sec=30, tm_wday=3, tm_yday=51, tm_isdst=0)","Pandora3D: A Comprehensive Framework for High-Quality 3D Shape and
  Texture Generation","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Pandora3D: A Comprehensive Framework for High-Quality 3D Shape and\n  Texture Generation'}","This report presents a comprehensive framework for generating high-quality 3D
shapes and textures from diverse input prompts, including single images,
multi-view images, and text descriptions. The framework consists of 3D shape
generation and texture generation. (1). The 3D shape generation pipeline
employs a Variational Autoencoder (VAE) to encode implicit 3D geometries into a
latent space and a diffusion network to generate latents conditioned on input
prompts, with modifications to enhance model capacity. An alternative
Artist-Created Mesh (AM) generation approach is also explored, yielding
promising results for simpler geometries. (2). Texture generation involves a
multi-stage process starting with frontal images generation followed by
multi-view images generation, RGB-to-PBR texture conversion, and
high-resolution multi-view texture refinement. A consistency scheduler is
plugged into every stage, to enforce pixel-wise consistency among multi-view
textures during inference, ensuring seamless integration.
  The pipeline demonstrates effective handling of diverse input formats,
leveraging advanced neural architectures and novel methodologies to produce
high-quality 3D content. This report details the system architecture,
experimental results, and potential future directions to improve and expand the
framework. The source code and pretrained weights are released at:
\url{https://github.com/Tencent/Tencent-XR-3DGen}.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'This report presents a comprehensive framework for generating high-quality 3D\nshapes and textures from diverse input prompts, including single images,\nmulti-view images, and text descriptions. The framework consists of 3D shape\ngeneration and texture generation. (1). The 3D shape generation pipeline\nemploys a Variational Autoencoder (VAE) to encode implicit 3D geometries into a\nlatent space and a diffusion network to generate latents conditioned on input\nprompts, with modifications to enhance model capacity. An alternative\nArtist-Created Mesh (AM) generation approach is also explored, yielding\npromising results for simpler geometries. (2). Texture generation involves a\nmulti-stage process starting with frontal images generation followed by\nmulti-view images generation, RGB-to-PBR texture conversion, and\nhigh-resolution multi-view texture refinement. A consistency scheduler is\nplugged into every stage, to enforce pixel-wise consistency among multi-view\ntextures during inference, ensuring seamless integration.\n  The pipeline demonstrates effective handling of diverse input formats,\nleveraging advanced neural architectures and novel methodologies to produce\nhigh-quality 3D content. This report details the system architecture,\nexperimental results, and potential future directions to improve and expand the\nframework. The source code and pretrained weights are released at:\n\\url{https://github.com/Tencent/Tencent-XR-3DGen}.'}","['Jiayu Yang', 'Taizhang Shang', 'Weixuan Sun', 'Xibin Song', 'Ziang Chen', 'Senbo Wang', 'Shenzhou Chen', 'Weizhe Liu', 'Hongdong Li', 'Pan Ji']",{'name': 'Pan Ji'},Pan Ji,Tencent XR 3D Gen,"[{'href': 'http://arxiv.org/abs/2502.14247v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14247v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.GR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.GR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14247v1,None,http://arxiv.org/abs/2502.14247v1,,,257,0
http://arxiv.org/abs/2502.14255v1,True,2025-02-20T04:42:06Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=4, tm_min=42, tm_sec=6, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T04:42:06Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=4, tm_min=42, tm_sec=6, tm_wday=3, tm_yday=51, tm_isdst=0)","Effects of Prompt Length on Domain-specific Tasks for Large Language
  Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Effects of Prompt Length on Domain-specific Tasks for Large Language\n  Models'}","In recent years, Large Language Models have garnered significant attention
for their strong performance in various natural language tasks, such as machine
translation and question answering. These models demonstrate an impressive
ability to generalize across diverse tasks. However, their effectiveness in
tackling domain-specific tasks, such as financial sentiment analysis and
monetary policy understanding, remains a topic of debate, as these tasks often
require specialized knowledge and precise reasoning. To address such
challenges, researchers design various prompts to unlock the models' abilities.
By carefully crafting input prompts, researchers can guide these models to
produce more accurate responses. Consequently, prompt engineering has become a
key focus of study. Despite the advancements in both models and prompt
engineering, the relationship between the two-specifically, how prompt design
impacts models' ability to perform domain-specific tasks-remains underexplored.
This paper aims to bridge this research gap.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""In recent years, Large Language Models have garnered significant attention\nfor their strong performance in various natural language tasks, such as machine\ntranslation and question answering. These models demonstrate an impressive\nability to generalize across diverse tasks. However, their effectiveness in\ntackling domain-specific tasks, such as financial sentiment analysis and\nmonetary policy understanding, remains a topic of debate, as these tasks often\nrequire specialized knowledge and precise reasoning. To address such\nchallenges, researchers design various prompts to unlock the models' abilities.\nBy carefully crafting input prompts, researchers can guide these models to\nproduce more accurate responses. Consequently, prompt engineering has become a\nkey focus of study. Despite the advancements in both models and prompt\nengineering, the relationship between the two-specifically, how prompt design\nimpacts models' ability to perform domain-specific tasks-remains underexplored.\nThis paper aims to bridge this research gap.""}","['Qibang Liu', 'Wenzhe Wang', 'Jeffrey Willard']",{'name': 'Jeffrey Willard'},Jeffrey Willard,,"[{'href': 'http://arxiv.org/abs/2502.14255v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14255v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.ET', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14255v1,None,http://arxiv.org/abs/2502.14255v1,,,0,0
http://arxiv.org/abs/2502.14260v1,True,2025-02-20T04:56:03Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=4, tm_min=56, tm_sec=3, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T04:56:03Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=4, tm_min=56, tm_sec=3, tm_wday=3, tm_yday=51, tm_isdst=0)","EyeBench: A Call for More Rigorous Evaluation of Retinal Image
  Enhancement","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'EyeBench: A Call for More Rigorous Evaluation of Retinal Image\n  Enhancement'}","Over the past decade, generative models have achieved significant success in
enhancement fundus images.However, the evaluation of these models still
presents a considerable challenge. A comprehensive evaluation benchmark for
fundus image enhancement is indispensable for three main reasons: 1) The
existing denoising metrics (e.g., PSNR, SSIM) are hardly to extend to
downstream real-world clinical research (e.g., Vessel morphology consistency).
2) There is a lack of comprehensive evaluation for both paired and unpaired
enhancement methods, along with the need for expert protocols to accurately
assess clinical value. 3) An ideal evaluation system should provide insights to
inform future developments of fundus image enhancement. To this end, we propose
a novel comprehensive benchmark, EyeBench, to provide insights that align
enhancement models with clinical needs, offering a foundation for future work
to improve the clinical relevance and applicability of generative models for
fundus image enhancement. EyeBench has three appealing properties: 1)
multi-dimensional clinical alignment downstream evaluation: In addition to
evaluating the enhancement task, we provide several clinically significant
downstream tasks for fundus images, including vessel segmentation, DR grading,
denoising generalization, and lesion segmentation. 2) Medical expert-guided
evaluation design: We introduce a novel dataset that promote comprehensive and
fair comparisons between paired and unpaired methods and includes a manual
evaluation protocol by medical experts. 3) Valuable insights: Our benchmark
study provides a comprehensive and rigorous evaluation of existing methods
across different downstream tasks, assisting medical experts in making informed
choices. Additionally, we offer further analysis of the challenges faced by
existing methods. The code is available at
\url{https://github.com/Retinal-Research/EyeBench}","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Over the past decade, generative models have achieved significant success in\nenhancement fundus images.However, the evaluation of these models still\npresents a considerable challenge. A comprehensive evaluation benchmark for\nfundus image enhancement is indispensable for three main reasons: 1) The\nexisting denoising metrics (e.g., PSNR, SSIM) are hardly to extend to\ndownstream real-world clinical research (e.g., Vessel morphology consistency).\n2) There is a lack of comprehensive evaluation for both paired and unpaired\nenhancement methods, along with the need for expert protocols to accurately\nassess clinical value. 3) An ideal evaluation system should provide insights to\ninform future developments of fundus image enhancement. To this end, we propose\na novel comprehensive benchmark, EyeBench, to provide insights that align\nenhancement models with clinical needs, offering a foundation for future work\nto improve the clinical relevance and applicability of generative models for\nfundus image enhancement. EyeBench has three appealing properties: 1)\nmulti-dimensional clinical alignment downstream evaluation: In addition to\nevaluating the enhancement task, we provide several clinically significant\ndownstream tasks for fundus images, including vessel segmentation, DR grading,\ndenoising generalization, and lesion segmentation. 2) Medical expert-guided\nevaluation design: We introduce a novel dataset that promote comprehensive and\nfair comparisons between paired and unpaired methods and includes a manual\nevaluation protocol by medical experts. 3) Valuable insights: Our benchmark\nstudy provides a comprehensive and rigorous evaluation of existing methods\nacross different downstream tasks, assisting medical experts in making informed\nchoices. Additionally, we offer further analysis of the challenges faced by\nexisting methods. The code is available at\n\\url{https://github.com/Retinal-Research/EyeBench}'}","['Wenhui Zhu', 'Xuanzhao Dong', 'Xin Li', 'Yujian Xiong', 'Xiwen Chen', 'Peijie Qiu', 'Vamsi Krishna Vasa', 'Zhangsihao Yang', 'Yi Su', 'Oana Dumitrascu', 'Yalin Wang']",{'name': 'Yalin Wang'},Yalin Wang,,"[{'href': 'http://arxiv.org/abs/2502.14260v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14260v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'eess.IV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'eess.IV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14260v1,None,http://arxiv.org/abs/2502.14260v1,,,177,0
http://arxiv.org/abs/2502.14273v1,True,2025-02-20T05:18:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=5, tm_min=18, tm_sec=36, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T05:18:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=5, tm_min=18, tm_sec=36, tm_wday=3, tm_yday=51, tm_isdst=0)","LLM-EvRep: Learning an LLM-Compatible Event Representation Using a
  Self-Supervised Framework","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'LLM-EvRep: Learning an LLM-Compatible Event Representation Using a\n  Self-Supervised Framework'}","Recent advancements in event-based recognition have demonstrated significant
promise, yet most existing approaches rely on extensive training, limiting
their adaptability for efficient processing of event-driven visual content.
Meanwhile, large language models (LLMs) have exhibited remarkable zero-shot
capabilities across diverse domains, but their application to event-based
visual recognition remains largely unexplored. To bridge this gap, we propose
\textbf{LLM-EvGen}, an event representation generator that produces
LLM-compatible event representations \textbf{LLM-EvRep}, thereby enhancing the
performance of LLMs on event recognition tasks. The generator is trained using
a self-supervised framework, aligning the generated representations with
semantic consistency and structural fidelity. Comprehensive experiments were
conducted on three datasets: N-ImageNet, N-Caltech101, and N-MNIST. The results
demonstrate that our method, \textbf{LLM-EvRep}, outperforms the event-to-video
method, E2VID, by 15.93\%, 0.82\%, and 50.21\%, respectively, in recognition
tasks when evaluated using GPT-4o.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Recent advancements in event-based recognition have demonstrated significant\npromise, yet most existing approaches rely on extensive training, limiting\ntheir adaptability for efficient processing of event-driven visual content.\nMeanwhile, large language models (LLMs) have exhibited remarkable zero-shot\ncapabilities across diverse domains, but their application to event-based\nvisual recognition remains largely unexplored. To bridge this gap, we propose\n\\textbf{LLM-EvGen}, an event representation generator that produces\nLLM-compatible event representations \\textbf{LLM-EvRep}, thereby enhancing the\nperformance of LLMs on event recognition tasks. The generator is trained using\na self-supervised framework, aligning the generated representations with\nsemantic consistency and structural fidelity. Comprehensive experiments were\nconducted on three datasets: N-ImageNet, N-Caltech101, and N-MNIST. The results\ndemonstrate that our method, \\textbf{LLM-EvRep}, outperforms the event-to-video\nmethod, E2VID, by 15.93\\%, 0.82\\%, and 50.21\\%, respectively, in recognition\ntasks when evaluated using GPT-4o.'}","['Zongyou Yu', 'Qiang Qu', 'Qian Zhang', 'Nan Zhang', 'Xiaoming Chen']",{'name': 'Xiaoming Chen'},Xiaoming Chen,"6 pages, 2 figures,Companion Proceedings of the ACM Web Conference
  2025 (WWW Companion '25)","[{'href': 'http://arxiv.org/abs/2502.14273v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14273v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14273v1,None,http://arxiv.org/abs/2502.14273v1,,,144,0
http://arxiv.org/abs/2502.14276v1,True,2025-02-20T05:28:44Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=5, tm_min=28, tm_sec=44, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T05:28:44Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=5, tm_min=28, tm_sec=44, tm_wday=3, tm_yday=51, tm_isdst=0)",STeCa: Step-level Trajectory Calibration for LLM Agent Learning,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'STeCa: Step-level Trajectory Calibration for LLM Agent Learning'}","Large language model (LLM)-based agents have shown promise in tackling
complex tasks by interacting dynamically with the environment. Existing work
primarily focuses on behavior cloning from expert demonstrations and preference
learning through exploratory trajectory sampling. However, these methods often
struggle in long-horizon tasks, where suboptimal actions accumulate step by
step, causing agents to deviate from correct task trajectories. To address
this, we highlight the importance of timely calibration and the need to
automatically construct calibration trajectories for training agents. We
propose Step-Level Trajectory Calibration (STeCa), a novel framework for LLM
agent learning. Specifically, STeCa identifies suboptimal actions through a
step-level reward comparison during exploration. It constructs calibrated
trajectories using LLM-driven reflection, enabling agents to learn from
improved decision-making processes. These calibrated trajectories, together
with successful trajectory data, are utilized for reinforced training.
Extensive experiments demonstrate that STeCa significantly outperforms existing
methods. Further analysis highlights that step-level calibration enables agents
to complete tasks with greater robustness. Our code and data are available at
https://github.com/WangHanLinHenry/STeCa.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large language model (LLM)-based agents have shown promise in tackling\ncomplex tasks by interacting dynamically with the environment. Existing work\nprimarily focuses on behavior cloning from expert demonstrations and preference\nlearning through exploratory trajectory sampling. However, these methods often\nstruggle in long-horizon tasks, where suboptimal actions accumulate step by\nstep, causing agents to deviate from correct task trajectories. To address\nthis, we highlight the importance of timely calibration and the need to\nautomatically construct calibration trajectories for training agents. We\npropose Step-Level Trajectory Calibration (STeCa), a novel framework for LLM\nagent learning. Specifically, STeCa identifies suboptimal actions through a\nstep-level reward comparison during exploration. It constructs calibrated\ntrajectories using LLM-driven reflection, enabling agents to learn from\nimproved decision-making processes. These calibrated trajectories, together\nwith successful trajectory data, are utilized for reinforced training.\nExtensive experiments demonstrate that STeCa significantly outperforms existing\nmethods. Further analysis highlights that step-level calibration enables agents\nto complete tasks with greater robustness. Our code and data are available at\nhttps://github.com/WangHanLinHenry/STeCa.'}","['Hanlin Wang', 'Jian Wang', 'Chak Tou Leong', 'Wenjie Li']",{'name': 'Wenjie Li'},Wenjie Li,,"[{'href': 'http://arxiv.org/abs/2502.14276v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14276v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14276v1,None,http://arxiv.org/abs/2502.14276v1,,,61,0
http://arxiv.org/abs/2502.14293v1,True,2025-02-20T06:14:07Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=6, tm_min=14, tm_sec=7, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T06:14:07Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=6, tm_min=14, tm_sec=7, tm_wday=3, tm_yday=51, tm_isdst=0)","Graph Anomaly Detection via Adaptive Test-time Representation Learning
  across Out-of-Distribution Domains","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Graph Anomaly Detection via Adaptive Test-time Representation Learning\n  across Out-of-Distribution Domains'}","Graph Anomaly Detection (GAD) has demonstrated great effectiveness in
identifying unusual patterns within graph-structured data. However, while
labeled anomalies are often scarce in emerging applications, existing
supervised GAD approaches are either ineffective or not applicable when moved
across graph domains due to distribution shifts and heterogeneous feature
spaces. To address these challenges, we present AdaGraph-T3, a novel test-time
training framework for cross-domain GAD. AdaGraph-T3 combines supervised and
self-supervised learning during training while adapting to a new domain during
test time using only self-supervised learning by leveraging a homophily-based
affinity score that captures domain-invariant properties of anomalies. Our
framework introduces four key innovations to cross-domain GAD: an effective
self-supervision scheme, an attention-based mechanism that dynamically learns
edge importance weights during message passing, domain-specific encoders for
handling heterogeneous features, and class-aware regularization to address
imbalance. Experiments across multiple cross-domain settings demonstrate that
AdaGraph-T3 significantly outperforms existing approaches, achieving average
improvements of over 6.6% in AUROC and 7.9% in AUPRC compared to the best
competing model.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Graph Anomaly Detection (GAD) has demonstrated great effectiveness in\nidentifying unusual patterns within graph-structured data. However, while\nlabeled anomalies are often scarce in emerging applications, existing\nsupervised GAD approaches are either ineffective or not applicable when moved\nacross graph domains due to distribution shifts and heterogeneous feature\nspaces. To address these challenges, we present AdaGraph-T3, a novel test-time\ntraining framework for cross-domain GAD. AdaGraph-T3 combines supervised and\nself-supervised learning during training while adapting to a new domain during\ntest time using only self-supervised learning by leveraging a homophily-based\naffinity score that captures domain-invariant properties of anomalies. Our\nframework introduces four key innovations to cross-domain GAD: an effective\nself-supervision scheme, an attention-based mechanism that dynamically learns\nedge importance weights during message passing, domain-specific encoders for\nhandling heterogeneous features, and class-aware regularization to address\nimbalance. Experiments across multiple cross-domain settings demonstrate that\nAdaGraph-T3 significantly outperforms existing approaches, achieving average\nimprovements of over 6.6% in AUROC and 7.9% in AUPRC compared to the best\ncompeting model.'}","['Delaram Pirhayati', 'Arlei Silva']",{'name': 'Arlei Silva'},Arlei Silva,,"[{'href': 'http://arxiv.org/abs/2502.14293v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14293v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14293v1,None,http://arxiv.org/abs/2502.14293v1,,,0,0
http://arxiv.org/abs/2502.14297v1,True,2025-02-20T06:22:03Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=6, tm_min=22, tm_sec=3, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T06:22:03Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=6, tm_min=22, tm_sec=3, tm_wday=3, tm_yday=51, tm_isdst=0)","An Evaluation of Sakana's AI Scientist for Autonomous Research: Wishful
  Thinking or an Emerging Reality Towards 'Artificial General Research
  Intelligence' (AGRI)?","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""An Evaluation of Sakana's AI Scientist for Autonomous Research: Wishful\n  Thinking or an Emerging Reality Towards 'Artificial General Research\n  Intelligence' (AGRI)?""}","A major step toward Artificial General Intelligence (AGI) and Super
Intelligence is AI's ability to autonomously conduct research - what we term
Artificial General Research Intelligence (AGRI). If machines could generate
hypotheses, conduct experiments, and write research papers without human
intervention, it would transform science. Recently, Sakana.ai introduced the AI
Scientist, a system claiming to automate the research lifecycle, generating
both excitement and skepticism.
  We evaluated the AI Scientist and found it a milestone in AI-driven research.
While it streamlines some aspects, it falls short of expectations. Literature
reviews are weak, nearly half the experiments failed, and manuscripts sometimes
contain hallucinated results. Most notably, users must provide an experimental
pipeline, limiting the AI Scientist's autonomy in research design and
execution.
  Despite its limitations, the AI Scientist advances research automation. Many
reviewers or instructors who assess work superficially may not recognize its
output as AI-generated. The system produces research papers with minimal human
effort and low cost. Our analysis suggests a paper costs a few USD with a few
hours of human involvement, making it significantly faster than human
researchers. Compared to AI capabilities from a few years ago, this marks
progress toward AGRI.
  The rise of AI-driven research systems requires urgent discussion within
Information Retrieval (IR) and broader scientific communities. Enhancing
literature retrieval, citation validation, and evaluation benchmarks could
improve AI-generated research reliability. We propose concrete steps, including
AGRI-specific benchmarks, refined peer review, and standardized attribution
frameworks. Whether AGRI becomes a stepping stone to AGI depends on how the
academic and AI communities shape its development.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""A major step toward Artificial General Intelligence (AGI) and Super\nIntelligence is AI's ability to autonomously conduct research - what we term\nArtificial General Research Intelligence (AGRI). If machines could generate\nhypotheses, conduct experiments, and write research papers without human\nintervention, it would transform science. Recently, Sakana.ai introduced the AI\nScientist, a system claiming to automate the research lifecycle, generating\nboth excitement and skepticism.\n  We evaluated the AI Scientist and found it a milestone in AI-driven research.\nWhile it streamlines some aspects, it falls short of expectations. Literature\nreviews are weak, nearly half the experiments failed, and manuscripts sometimes\ncontain hallucinated results. Most notably, users must provide an experimental\npipeline, limiting the AI Scientist's autonomy in research design and\nexecution.\n  Despite its limitations, the AI Scientist advances research automation. Many\nreviewers or instructors who assess work superficially may not recognize its\noutput as AI-generated. The system produces research papers with minimal human\neffort and low cost. Our analysis suggests a paper costs a few USD with a few\nhours of human involvement, making it significantly faster than human\nresearchers. Compared to AI capabilities from a few years ago, this marks\nprogress toward AGRI.\n  The rise of AI-driven research systems requires urgent discussion within\nInformation Retrieval (IR) and broader scientific communities. Enhancing\nliterature retrieval, citation validation, and evaluation benchmarks could\nimprove AI-generated research reliability. We propose concrete steps, including\nAGRI-specific benchmarks, refined peer review, and standardized attribution\nframeworks. Whether AGRI becomes a stepping stone to AGI depends on how the\nacademic and AI communities shape its development.""}","['Joeran Beel', 'Min-Yen Kan', 'Moritz Baumgart']",{'name': 'Moritz Baumgart'},Moritz Baumgart,16 pages,"[{'href': 'http://arxiv.org/abs/2502.14297v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14297v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14297v1,None,http://arxiv.org/abs/2502.14297v1,,,65,0
http://arxiv.org/abs/2502.14302v1,True,2025-02-20T06:33:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=6, tm_min=33, tm_sec=23, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T06:33:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=6, tm_min=33, tm_sec=23, tm_wday=3, tm_yday=51, tm_isdst=0)","MedHallu: A Comprehensive Benchmark for Detecting Medical Hallucinations
  in Large Language Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'MedHallu: A Comprehensive Benchmark for Detecting Medical Hallucinations\n  in Large Language Models'}","Advancements in Large Language Models (LLMs) and their increasing use in
medical question-answering necessitate rigorous evaluation of their
reliability. A critical challenge lies in hallucination, where models generate
plausible yet factually incorrect outputs. In the medical domain, this poses
serious risks to patient safety and clinical decision-making. To address this,
we introduce MedHallu, the first benchmark specifically designed for medical
hallucination detection. MedHallu comprises 10,000 high-quality question-answer
pairs derived from PubMedQA, with hallucinated answers systematically generated
through a controlled pipeline. Our experiments show that state-of-the-art LLMs,
including GPT-4o, Llama-3.1, and the medically fine-tuned UltraMedical,
struggle with this binary hallucination detection task, with the best model
achieving an F1 score as low as 0.625 for detecting ""hard"" category
hallucinations. Using bidirectional entailment clustering, we show that
harder-to-detect hallucinations are semantically closer to ground truth.
Through experiments, we also show incorporating domain-specific knowledge and
introducing a ""not sure"" category as one of the answer categories improves the
precision and F1 scores by up to 38% relative to baselines.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Advancements in Large Language Models (LLMs) and their increasing use in\nmedical question-answering necessitate rigorous evaluation of their\nreliability. A critical challenge lies in hallucination, where models generate\nplausible yet factually incorrect outputs. In the medical domain, this poses\nserious risks to patient safety and clinical decision-making. To address this,\nwe introduce MedHallu, the first benchmark specifically designed for medical\nhallucination detection. MedHallu comprises 10,000 high-quality question-answer\npairs derived from PubMedQA, with hallucinated answers systematically generated\nthrough a controlled pipeline. Our experiments show that state-of-the-art LLMs,\nincluding GPT-4o, Llama-3.1, and the medically fine-tuned UltraMedical,\nstruggle with this binary hallucination detection task, with the best model\nachieving an F1 score as low as 0.625 for detecting ""hard"" category\nhallucinations. Using bidirectional entailment clustering, we show that\nharder-to-detect hallucinations are semantically closer to ground truth.\nThrough experiments, we also show incorporating domain-specific knowledge and\nintroducing a ""not sure"" category as one of the answer categories improves the\nprecision and F1 scores by up to 38% relative to baselines.'}","['Shrey Pandit', 'Jiawei Xu', 'Junyuan Hong', 'Zhangyang Wang', 'Tianlong Chen', 'Kaidi Xu', 'Ying Ding']",{'name': 'Ying Ding'},Ying Ding,Code and dataset are available at https://medhallu.github.io/,"[{'href': 'http://arxiv.org/abs/2502.14302v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14302v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14302v1,None,http://arxiv.org/abs/2502.14302v1,,,102,0
http://arxiv.org/abs/2502.14318v1,True,2025-02-20T07:13:29Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=7, tm_min=13, tm_sec=29, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T07:13:29Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=7, tm_min=13, tm_sec=29, tm_wday=3, tm_yday=51, tm_isdst=0)","Line Goes Up? Inherent Limitations of Benchmarks for Evaluating Large
  Language Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Line Goes Up? Inherent Limitations of Benchmarks for Evaluating Large\n  Language Models'}","Large language models (LLMs) regularly demonstrate new and impressive
performance on a wide range of language, knowledge, and reasoning benchmarks.
Such rapid progress has led many commentators to argue that LLM general
cognitive capabilities have likewise rapidly improved, with the implication
that such models are becoming progressively more capable on various real-world
tasks. Here I summarise theoretical and empirical considerations to challenge
this narrative. I argue that inherent limitations with the benchmarking
paradigm, along with specific limitations of existing benchmarks, render
benchmark performance highly unsuitable as a metric for generalisable
competence over cognitive tasks. I also contend that alternative methods for
assessing LLM capabilities, including adversarial stimuli and interpretability
techniques, have shown that LLMs do not have robust competence in many language
and reasoning tasks, and often fail to learn representations which facilitate
generalisable inferences. I conclude that benchmark performance should not be
used as a reliable indicator of general LLM cognitive capabilities.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large language models (LLMs) regularly demonstrate new and impressive\nperformance on a wide range of language, knowledge, and reasoning benchmarks.\nSuch rapid progress has led many commentators to argue that LLM general\ncognitive capabilities have likewise rapidly improved, with the implication\nthat such models are becoming progressively more capable on various real-world\ntasks. Here I summarise theoretical and empirical considerations to challenge\nthis narrative. I argue that inherent limitations with the benchmarking\nparadigm, along with specific limitations of existing benchmarks, render\nbenchmark performance highly unsuitable as a metric for generalisable\ncompetence over cognitive tasks. I also contend that alternative methods for\nassessing LLM capabilities, including adversarial stimuli and interpretability\ntechniques, have shown that LLMs do not have robust competence in many language\nand reasoning tasks, and often fail to learn representations which facilitate\ngeneralisable inferences. I conclude that benchmark performance should not be\nused as a reliable indicator of general LLM cognitive capabilities.'}",['James Fodor'],{'name': 'James Fodor'},James Fodor,10 pages,"[{'href': 'http://arxiv.org/abs/2502.14318v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14318v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14318v1,None,http://arxiv.org/abs/2502.14318v1,,,0,0
http://arxiv.org/abs/2502.14380v1,True,2025-02-20T09:12:51Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=9, tm_min=12, tm_sec=51, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T09:12:51Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=9, tm_min=12, tm_sec=51, tm_wday=3, tm_yday=51, tm_isdst=0)","Affinity and Diversity: A Unified Metric for Demonstration Selection via
  Internal Representations","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Affinity and Diversity: A Unified Metric for Demonstration Selection via\n  Internal Representations'}","The performance of In-Context Learning (ICL) is highly sensitive to the
selected demonstrations. Existing approaches to demonstration selection
optimize different objectives, yielding inconsistent results. To address this,
we propose a unified metric--affinity and diversity--that leverages ICL model's
internal representations. Our experiments show that both affinity and diversity
strongly correlate with test accuracies, indicating their effectiveness for
demonstration selection. Moreover, we show that our proposed metrics align well
with various previous works to unify the inconsistency.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""The performance of In-Context Learning (ICL) is highly sensitive to the\nselected demonstrations. Existing approaches to demonstration selection\noptimize different objectives, yielding inconsistent results. To address this,\nwe propose a unified metric--affinity and diversity--that leverages ICL model's\ninternal representations. Our experiments show that both affinity and diversity\nstrongly correlate with test accuracies, indicating their effectiveness for\ndemonstration selection. Moreover, we show that our proposed metrics align well\nwith various previous works to unify the inconsistency.""}","['Mariko Kato', 'Hakaze Cho', 'Yoshihiro Sakai', 'Naoya Inoue']",{'name': 'Naoya Inoue'},Naoya Inoue,"8 pages, 10 figures","[{'href': 'http://arxiv.org/abs/2502.14380v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14380v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14380v1,None,http://arxiv.org/abs/2502.14380v1,,,12,0
http://arxiv.org/abs/2502.14416v1,True,2025-02-20T10:11:27Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=10, tm_min=11, tm_sec=27, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T10:11:27Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=10, tm_min=11, tm_sec=27, tm_wday=3, tm_yday=51, tm_isdst=0)","Reliable Explainability of Deep Learning Spatial-Spectral Classifiers
  for Improved Semantic Segmentation in Autonomous Driving","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Reliable Explainability of Deep Learning Spatial-Spectral Classifiers\n  for Improved Semantic Segmentation in Autonomous Driving'}","Integrating hyperspectral imagery (HSI) with deep neural networks (DNNs) can
strengthen the accuracy of intelligent vision systems by combining spectral and
spatial information, which is useful for tasks like semantic segmentation in
autonomous driving. To advance research in such safety-critical systems,
determining the precise contribution of spectral information to complex DNNs'
output is needed. To address this, several saliency methods, such as class
activation maps (CAM), have been proposed primarily for image classification.
However, recent studies have raised concerns regarding their reliability. In
this paper, we address their limitations and propose an alternative approach by
leveraging the data provided by activations and weights from relevant DNN
layers to better capture the relationship between input features and
predictions. The study aims to assess the superior performance of HSI compared
to 3-channel and single-channel DNNs. We also address the influence of spectral
signature normalization for enhancing DNN robustness in real-world driving
conditions.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Integrating hyperspectral imagery (HSI) with deep neural networks (DNNs) can\nstrengthen the accuracy of intelligent vision systems by combining spectral and\nspatial information, which is useful for tasks like semantic segmentation in\nautonomous driving. To advance research in such safety-critical systems,\ndetermining the precise contribution of spectral information to complex DNNs'\noutput is needed. To address this, several saliency methods, such as class\nactivation maps (CAM), have been proposed primarily for image classification.\nHowever, recent studies have raised concerns regarding their reliability. In\nthis paper, we address their limitations and propose an alternative approach by\nleveraging the data provided by activations and weights from relevant DNN\nlayers to better capture the relationship between input features and\npredictions. The study aims to assess the superior performance of HSI compared\nto 3-channel and single-channel DNNs. We also address the influence of spectral\nsignature normalization for enhancing DNN robustness in real-world driving\nconditions.""}","['Jon Gutirrez-Zaballa', 'Koldo Basterretxea', 'Javier Echanobe']",{'name': 'Javier Echanobe'},Javier Echanobe,,"[{'title': 'doi', 'href': 'http://dx.doi.org/10.1109/WHISPERS65427.2024.10876465', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2502.14416v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14416v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'eess.IV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'eess.IV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14416v1,None,http://arxiv.org/abs/2502.14416v1,,10.1109/WHISPERS65427.2024.10876465,1402,0
http://arxiv.org/abs/2502.14424v1,True,2025-02-20T10:20:56Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=10, tm_min=20, tm_sec=56, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T10:20:56Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=10, tm_min=20, tm_sec=56, tm_wday=3, tm_yday=51, tm_isdst=0)",Distribution Matching for Self-Supervised Transfer Learning,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Distribution Matching for Self-Supervised Transfer Learning'}","In this paper, we propose a novel self-supervised transfer learning method
called Distribution Matching (DM), which drives the representation distribution
toward a predefined reference distribution while preserving augmentation
invariance. The design of DM results in a learned representation space that is
intuitively structured and offers easily interpretable hyperparameters.
Experimental results across multiple real-world datasets and evaluation metrics
demonstrate that DM performs competitively on target classification tasks
compared to existing self-supervised transfer learning methods. Additionally,
we provide robust theoretical guarantees for DM, including a population theorem
and an end-to-end sample theorem. The population theorem bridges the gap
between the self-supervised learning task and target classification accuracy,
while the sample theorem shows that, even with a limited number of samples from
the target domain, DM can deliver exceptional classification performance,
provided the unlabeled sample size is sufficiently large.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'In this paper, we propose a novel self-supervised transfer learning method\ncalled Distribution Matching (DM), which drives the representation distribution\ntoward a predefined reference distribution while preserving augmentation\ninvariance. The design of DM results in a learned representation space that is\nintuitively structured and offers easily interpretable hyperparameters.\nExperimental results across multiple real-world datasets and evaluation metrics\ndemonstrate that DM performs competitively on target classification tasks\ncompared to existing self-supervised transfer learning methods. Additionally,\nwe provide robust theoretical guarantees for DM, including a population theorem\nand an end-to-end sample theorem. The population theorem bridges the gap\nbetween the self-supervised learning task and target classification accuracy,\nwhile the sample theorem shows that, even with a limited number of samples from\nthe target domain, DM can deliver exceptional classification performance,\nprovided the unlabeled sample size is sufficiently large.'}","['Yuling Jiao', 'Wensen Ma', 'Defeng Sun', 'Hansheng Wang', 'Yang Wang']",{'name': 'Yang Wang'},Yang Wang,,"[{'href': 'http://arxiv.org/abs/2502.14424v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14424v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ME', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14424v1,None,http://arxiv.org/abs/2502.14424v1,,,0,0
http://arxiv.org/abs/2502.14445v1,True,2025-02-20T10:52:38Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=10, tm_min=52, tm_sec=38, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T10:52:38Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=10, tm_min=52, tm_sec=38, tm_wday=3, tm_yday=51, tm_isdst=0)",PredictaBoard: Benchmarking LLM Score Predictability,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'PredictaBoard: Benchmarking LLM Score Predictability'}","Despite possessing impressive skills, Large Language Models (LLMs) often fail
unpredictably, demonstrating inconsistent success in even basic common sense
reasoning tasks. This unpredictability poses a significant challenge to
ensuring their safe deployment, as identifying and operating within a reliable
""safe zone"" is essential for mitigating risks. To address this, we present
PredictaBoard, a novel collaborative benchmarking framework designed to
evaluate the ability of score predictors (referred to as assessors) to
anticipate LLM errors on specific task instances (i.e., prompts) from existing
datasets. PredictaBoard evaluates pairs of LLMs and assessors by considering
the rejection rate at different tolerance errors. As such, PredictaBoard
stimulates research into developing better assessors and making LLMs more
predictable, not only with a higher average performance. We conduct
illustrative experiments using baseline assessors and state-of-the-art LLMs.
PredictaBoard highlights the critical need to evaluate predictability alongside
performance, paving the way for safer AI systems where errors are not only
minimised but also anticipated and effectively mitigated. Code for our
benchmark can be found at
https://github.com/Kinds-of-Intelligence-CFI/PredictaBoard","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Despite possessing impressive skills, Large Language Models (LLMs) often fail\nunpredictably, demonstrating inconsistent success in even basic common sense\nreasoning tasks. This unpredictability poses a significant challenge to\nensuring their safe deployment, as identifying and operating within a reliable\n""safe zone"" is essential for mitigating risks. To address this, we present\nPredictaBoard, a novel collaborative benchmarking framework designed to\nevaluate the ability of score predictors (referred to as assessors) to\nanticipate LLM errors on specific task instances (i.e., prompts) from existing\ndatasets. PredictaBoard evaluates pairs of LLMs and assessors by considering\nthe rejection rate at different tolerance errors. As such, PredictaBoard\nstimulates research into developing better assessors and making LLMs more\npredictable, not only with a higher average performance. We conduct\nillustrative experiments using baseline assessors and state-of-the-art LLMs.\nPredictaBoard highlights the critical need to evaluate predictability alongside\nperformance, paving the way for safer AI systems where errors are not only\nminimised but also anticipated and effectively mitigated. Code for our\nbenchmark can be found at\nhttps://github.com/Kinds-of-Intelligence-CFI/PredictaBoard'}","['Lorenzo Pacchiardi', 'Konstantinos Voudouris', 'Ben Slater', 'Fernando Martnez-Plumed', 'Jos Hernndez-Orallo', 'Lexin Zhou', 'Wout Schellaert']",{'name': 'Wout Schellaert'},Wout Schellaert,,"[{'href': 'http://arxiv.org/abs/2502.14445v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14445v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14445v1,None,http://arxiv.org/abs/2502.14445v1,,,1863,0
http://arxiv.org/abs/2502.14457v1,True,2025-02-20T11:18:35Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=11, tm_min=18, tm_sec=35, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T11:18:35Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=11, tm_min=18, tm_sec=35, tm_wday=3, tm_yday=51, tm_isdst=0)","Watch Less, Feel More: Sim-to-Real RL for Generalizable Articulated
  Object Manipulation via Motion Adaptation and Impedance Control","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Watch Less, Feel More: Sim-to-Real RL for Generalizable Articulated\n  Object Manipulation via Motion Adaptation and Impedance Control'}","Articulated object manipulation poses a unique challenge compared to rigid
object manipulation as the object itself represents a dynamic environment. In
this work, we present a novel RL-based pipeline equipped with variable
impedance control and motion adaptation leveraging observation history for
generalizable articulated object manipulation, focusing on smooth and dexterous
motion during zero-shot sim-to-real transfer. To mitigate the sim-to-real gap,
our pipeline diminishes reliance on vision by not leveraging the vision data
feature (RGBD/pointcloud) directly as policy input but rather extracting useful
low-dimensional data first via off-the-shelf modules. Additionally, we
experience less sim-to-real gap by inferring object motion and its intrinsic
properties via observation history as well as utilizing impedance control both
in the simulation and in the real world. Furthermore, we develop a
well-designed training setting with great randomization and a specialized
reward system (task-aware and motion-aware) that enables multi-staged,
end-to-end manipulation without heuristic motion planning. To the best of our
knowledge, our policy is the first to report 84\% success rate in the real
world via extensive experiments with various unseen objects.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Articulated object manipulation poses a unique challenge compared to rigid\nobject manipulation as the object itself represents a dynamic environment. In\nthis work, we present a novel RL-based pipeline equipped with variable\nimpedance control and motion adaptation leveraging observation history for\ngeneralizable articulated object manipulation, focusing on smooth and dexterous\nmotion during zero-shot sim-to-real transfer. To mitigate the sim-to-real gap,\nour pipeline diminishes reliance on vision by not leveraging the vision data\nfeature (RGBD/pointcloud) directly as policy input but rather extracting useful\nlow-dimensional data first via off-the-shelf modules. Additionally, we\nexperience less sim-to-real gap by inferring object motion and its intrinsic\nproperties via observation history as well as utilizing impedance control both\nin the simulation and in the real world. Furthermore, we develop a\nwell-designed training setting with great randomization and a specialized\nreward system (task-aware and motion-aware) that enables multi-staged,\nend-to-end manipulation without heuristic motion planning. To the best of our\nknowledge, our policy is the first to report 84\\% success rate in the real\nworld via extensive experiments with various unseen objects.'}","['Tan-Dzung Do', 'Nandiraju Gireesh', 'Jilong Wang', 'He Wang']",{'name': 'He Wang'},He Wang,,"[{'href': 'http://arxiv.org/abs/2502.14457v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14457v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14457v1,None,http://arxiv.org/abs/2502.14457v1,,,53,0
http://arxiv.org/abs/2502.14462v1,True,2025-02-20T11:33:17Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=11, tm_min=33, tm_sec=17, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T11:33:17Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=11, tm_min=33, tm_sec=17, tm_wday=3, tm_yday=51, tm_isdst=0)","Single-image Reflectance and Transmittance Estimation from Any Flatbed
  Scanner","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Single-image Reflectance and Transmittance Estimation from Any Flatbed\n  Scanner'}","Flatbed scanners have emerged as promising devices for high-resolution,
single-image material capture. However, existing approaches assume very
specific conditions, such as uniform diffuse illumination, which are only
available in certain high-end devices, hindering their scalability and cost. In
contrast, in this work, we introduce a method inspired by intrinsic image
decomposition, which accurately removes both shading and specularity,
effectively allowing captures with any flatbed scanner. Further, we extend
previous work on single-image material reflectance capture with the estimation
of opacity and transmittance, critical components of full material appearance
(SVBSDF), improving the results for any material captured with a flatbed
scanner, at a very high resolution and accuracy","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Flatbed scanners have emerged as promising devices for high-resolution,\nsingle-image material capture. However, existing approaches assume very\nspecific conditions, such as uniform diffuse illumination, which are only\navailable in certain high-end devices, hindering their scalability and cost. In\ncontrast, in this work, we introduce a method inspired by intrinsic image\ndecomposition, which accurately removes both shading and specularity,\neffectively allowing captures with any flatbed scanner. Further, we extend\nprevious work on single-image material reflectance capture with the estimation\nof opacity and transmittance, critical components of full material appearance\n(SVBSDF), improving the results for any material captured with a flatbed\nscanner, at a very high resolution and accuracy'}","['Carlos Rodriguez-Pardo', 'David Pascual-Hernandez', 'Javier Rodriguez-Vazquez', 'Jorge Lopez-Moreno', 'Elena Garces']",{'name': 'Elena Garces'},Elena Garces,Accepted to Computers & Graphics,"[{'href': 'http://arxiv.org/abs/2502.14462v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14462v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.GR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.GR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T07 (Primary) 68T45, 68U10, 68U05 (Secondary)', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.4.0; I.2.6; I.3.0', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14462v1,None,http://arxiv.org/abs/2502.14462v1,,,1974,0
http://arxiv.org/abs/2502.14469v1,True,2025-02-20T11:46:51Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=11, tm_min=46, tm_sec=51, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T11:46:51Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=11, tm_min=46, tm_sec=51, tm_wday=3, tm_yday=51, tm_isdst=0)","Enhancing Smart Environments with Context-Aware Chatbots using Large
  Language Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Enhancing Smart Environments with Context-Aware Chatbots using Large\n  Language Models'}","This work presents a novel architecture for context-aware interactions within
smart environments, leveraging Large Language Models (LLMs) to enhance user
experiences. Our system integrates user location data obtained through UWB tags
and sensor-equipped smart homes with real-time human activity recognition (HAR)
to provide a comprehensive understanding of user context. This contextual
information is then fed to an LLM-powered chatbot, enabling it to generate
personalised interactions and recommendations based on the user's current
activity and environment. This approach moves beyond traditional static chatbot
interactions by dynamically adapting to the user's real-time situation. A case
study conducted from a real-world dataset demonstrates the feasibility and
effectiveness of our proposed architecture, showcasing its potential to create
more intuitive and helpful interactions within smart homes. The results
highlight the significant benefits of integrating LLM with real-time activity
and location data to deliver personalised and contextually relevant user
experiences.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""This work presents a novel architecture for context-aware interactions within\nsmart environments, leveraging Large Language Models (LLMs) to enhance user\nexperiences. Our system integrates user location data obtained through UWB tags\nand sensor-equipped smart homes with real-time human activity recognition (HAR)\nto provide a comprehensive understanding of user context. This contextual\ninformation is then fed to an LLM-powered chatbot, enabling it to generate\npersonalised interactions and recommendations based on the user's current\nactivity and environment. This approach moves beyond traditional static chatbot\ninteractions by dynamically adapting to the user's real-time situation. A case\nstudy conducted from a real-world dataset demonstrates the feasibility and\neffectiveness of our proposed architecture, showcasing its potential to create\nmore intuitive and helpful interactions within smart homes. The results\nhighlight the significant benefits of integrating LLM with real-time activity\nand location data to deliver personalised and contextually relevant user\nexperiences.""}","['Aurora Polo-Rodrguez', 'Laura Fiorini', 'Erika Rovini', 'Filippo Cavallo', 'Javier Medina-Quero']",{'name': 'Javier Medina-Quero'},Javier Medina-Quero,"11 pages, 3 figures","[{'href': 'http://arxiv.org/abs/2502.14469v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14469v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14469v1,None,http://arxiv.org/abs/2502.14469v1,,,2553,0
http://arxiv.org/abs/2502.14486v1,True,2025-02-20T12:07:40Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=12, tm_min=7, tm_sec=40, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T12:07:40Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=12, tm_min=7, tm_sec=40, tm_wday=3, tm_yday=51, tm_isdst=0)",How Jailbreak Defenses Work and Ensemble? A Mechanistic Investigation,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'How Jailbreak Defenses Work and Ensemble? A Mechanistic Investigation'}","Jailbreak attacks, where harmful prompts bypass generative models' built-in
safety, raise serious concerns about model vulnerability. While many defense
methods have been proposed, the trade-offs between safety and helpfulness, and
their application to Large Vision-Language Models (LVLMs), are not well
understood. This paper systematically examines jailbreak defenses by reframing
the standard generation task as a binary classification problem to assess model
refusal tendencies for both harmful and benign queries. We identify two key
defense mechanisms: safety shift, which increases refusal rates across all
queries, and harmfulness discrimination, which improves the model's ability to
distinguish between harmful and benign inputs. Using these mechanisms, we
develop two ensemble defense strategies-inter-mechanism ensembles and
intra-mechanism ensembles-to balance safety and helpfulness. Experiments on the
MM-SafetyBench and MOSSBench datasets with LLaVA-1.5 models show that these
strategies effectively improve model safety or optimize the trade-off between
safety and helpfulness.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Jailbreak attacks, where harmful prompts bypass generative models' built-in\nsafety, raise serious concerns about model vulnerability. While many defense\nmethods have been proposed, the trade-offs between safety and helpfulness, and\ntheir application to Large Vision-Language Models (LVLMs), are not well\nunderstood. This paper systematically examines jailbreak defenses by reframing\nthe standard generation task as a binary classification problem to assess model\nrefusal tendencies for both harmful and benign queries. We identify two key\ndefense mechanisms: safety shift, which increases refusal rates across all\nqueries, and harmfulness discrimination, which improves the model's ability to\ndistinguish between harmful and benign inputs. Using these mechanisms, we\ndevelop two ensemble defense strategies-inter-mechanism ensembles and\nintra-mechanism ensembles-to balance safety and helpfulness. Experiments on the\nMM-SafetyBench and MOSSBench datasets with LLaVA-1.5 models show that these\nstrategies effectively improve model safety or optimize the trade-off between\nsafety and helpfulness.""}","['Zhuohang Long', 'Siyuan Wang', 'Shujun Liu', 'Yuhang Lai', 'Xuanjing Huang', 'Zhongyu Wei']",{'name': 'Zhongyu Wei'},Zhongyu Wei,,"[{'href': 'http://arxiv.org/abs/2502.14486v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14486v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14486v1,None,http://arxiv.org/abs/2502.14486v1,,,119,0
http://arxiv.org/abs/2502.14487v1,True,2025-02-20T12:09:30Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=12, tm_min=9, tm_sec=30, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T12:09:30Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=12, tm_min=9, tm_sec=30, tm_wday=3, tm_yday=51, tm_isdst=0)",Temporal Misalignment and Probabilistic Neurons,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Temporal Misalignment and Probabilistic Neurons'}","Spiking Neural Networks (SNNs) offer a more energy-efficient alternative to
Artificial Neural Networks (ANNs) by mimicking biological neural principles,
establishing them as a promising approach to mitigate the increasing energy
demands of large-scale neural models. However, fully harnessing the
capabilities of SNNs remains challenging due to their discrete signal
processing and temporal dynamics. ANN-SNN conversion has emerged as a practical
approach, enabling SNNs to achieve competitive performance on complex machine
learning tasks. In this work, we identify a phenomenon in the ANN-SNN
conversion framework, termed temporal misalignment, in which random spike
rearrangement across SNN layers leads to performance improvements. Based on
this observation, we introduce biologically plausible two-phase probabilistic
(TPP) spiking neurons, further enhancing the conversion process. We demonstrate
the advantages of our proposed method both theoretically and empirically
through comprehensive experiments on CIFAR-10/100, CIFAR10-DVS, and ImageNet
across a variety of architectures, achieving state-of-the-art results.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Spiking Neural Networks (SNNs) offer a more energy-efficient alternative to\nArtificial Neural Networks (ANNs) by mimicking biological neural principles,\nestablishing them as a promising approach to mitigate the increasing energy\ndemands of large-scale neural models. However, fully harnessing the\ncapabilities of SNNs remains challenging due to their discrete signal\nprocessing and temporal dynamics. ANN-SNN conversion has emerged as a practical\napproach, enabling SNNs to achieve competitive performance on complex machine\nlearning tasks. In this work, we identify a phenomenon in the ANN-SNN\nconversion framework, termed temporal misalignment, in which random spike\nrearrangement across SNN layers leads to performance improvements. Based on\nthis observation, we introduce biologically plausible two-phase probabilistic\n(TPP) spiking neurons, further enhancing the conversion process. We demonstrate\nthe advantages of our proposed method both theoretically and empirically\nthrough comprehensive experiments on CIFAR-10/100, CIFAR10-DVS, and ImageNet\nacross a variety of architectures, achieving state-of-the-art results.'}","['Velibor Bojkovi', 'Xiaofeng Wu', 'Bin Gu']",{'name': 'Bin Gu'},Bin Gu,,"[{'href': 'http://arxiv.org/abs/2502.14487v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14487v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14487v1,None,http://arxiv.org/abs/2502.14487v1,,,14,0
http://arxiv.org/abs/2502.14499v1,True,2025-02-20T12:28:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=12, tm_min=28, tm_sec=23, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T12:28:23Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=12, tm_min=28, tm_sec=23, tm_wday=3, tm_yday=51, tm_isdst=0)",MLGym: A New Framework and Benchmark for Advancing AI Research Agents,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'MLGym: A New Framework and Benchmark for Advancing AI Research Agents'}","We introduce Meta MLGym and MLGym-Bench, a new framework and benchmark for
evaluating and developing LLM agents on AI research tasks. This is the first
Gym environment for machine learning (ML) tasks, enabling research on
reinforcement learning (RL) algorithms for training such agents. MLGym-bench
consists of 13 diverse and open-ended AI research tasks from diverse domains
such as computer vision, natural language processing, reinforcement learning,
and game theory. Solving these tasks requires real-world AI research skills
such as generating new ideas and hypotheses, creating and processing data,
implementing ML methods, training models, running experiments, analyzing the
results, and iterating through this process to improve on a given task. We
evaluate a number of frontier large language models (LLMs) on our benchmarks
such as Claude-3.5-Sonnet, Llama-3.1 405B, GPT-4o, o1-preview, and Gemini-1.5
Pro. Our MLGym framework makes it easy to add new tasks, integrate and evaluate
models or agents, generate synthetic data at scale, as well as develop new
learning algorithms for training agents on AI research tasks. We find that
current frontier models can improve on the given baselines, usually by finding
better hyperparameters, but do not generate novel hypotheses, algorithms,
architectures, or substantial improvements. We open-source our framework and
benchmark to facilitate future research in advancing the AI research
capabilities of LLM agents.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'We introduce Meta MLGym and MLGym-Bench, a new framework and benchmark for\nevaluating and developing LLM agents on AI research tasks. This is the first\nGym environment for machine learning (ML) tasks, enabling research on\nreinforcement learning (RL) algorithms for training such agents. MLGym-bench\nconsists of 13 diverse and open-ended AI research tasks from diverse domains\nsuch as computer vision, natural language processing, reinforcement learning,\nand game theory. Solving these tasks requires real-world AI research skills\nsuch as generating new ideas and hypotheses, creating and processing data,\nimplementing ML methods, training models, running experiments, analyzing the\nresults, and iterating through this process to improve on a given task. We\nevaluate a number of frontier large language models (LLMs) on our benchmarks\nsuch as Claude-3.5-Sonnet, Llama-3.1 405B, GPT-4o, o1-preview, and Gemini-1.5\nPro. Our MLGym framework makes it easy to add new tasks, integrate and evaluate\nmodels or agents, generate synthetic data at scale, as well as develop new\nlearning algorithms for training agents on AI research tasks. We find that\ncurrent frontier models can improve on the given baselines, usually by finding\nbetter hyperparameters, but do not generate novel hypotheses, algorithms,\narchitectures, or substantial improvements. We open-source our framework and\nbenchmark to facilitate future research in advancing the AI research\ncapabilities of LLM agents.'}","['Deepak Nathani', 'Lovish Madaan', 'Nicholas Roberts', 'Nikolay Bashlykov', 'Ajay Menon', 'Vincent Moens', 'Amar Budhiraja', 'Despoina Magka', 'Vladislav Vorotilov', 'Gaurav Chaurasia', 'Dieuwke Hupkes', 'Ricardo Silveira Cabral', 'Tatiana Shavrina', 'Jakob Foerster', 'Yoram Bachrach', 'William Yang Wang', 'Roberta Raileanu']",{'name': 'Roberta Raileanu'},Roberta Raileanu,"35 pages, 12 figures, 10 tables","[{'href': 'http://arxiv.org/abs/2502.14499v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14499v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14499v1,None,http://arxiv.org/abs/2502.14499v1,,,33471,0
http://arxiv.org/abs/2502.14546v1,True,2025-02-20T13:21:47Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=13, tm_min=21, tm_sec=47, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T13:21:47Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=13, tm_min=21, tm_sec=47, tm_wday=3, tm_yday=51, tm_isdst=0)",Position: Graph Learning Will Lose Relevance Due To Poor Benchmarks,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Position: Graph Learning Will Lose Relevance Due To Poor Benchmarks'}","While machine learning on graphs has demonstrated promise in drug design and
molecular property prediction, significant benchmarking challenges hinder its
further progress and relevance. Current benchmarking practices often lack focus
on transformative, real-world applications, favoring narrow domains like
two-dimensional molecular graphs over broader, impactful areas such as
combinatorial optimization, relational databases, or chip design. Additionally,
many benchmark datasets poorly represent the underlying data, leading to
inadequate abstractions and misaligned use cases. Fragmented evaluations and an
excessive focus on accuracy further exacerbate these issues, incentivizing
overfitting rather than fostering generalizable insights. These limitations
have prevented the development of truly useful graph foundation models. This
position paper calls for a paradigm shift toward more meaningful benchmarks,
rigorous evaluation protocols, and stronger collaboration with domain experts
to drive impactful and reliable advances in graph learning research, unlocking
the potential of graph learning.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'While machine learning on graphs has demonstrated promise in drug design and\nmolecular property prediction, significant benchmarking challenges hinder its\nfurther progress and relevance. Current benchmarking practices often lack focus\non transformative, real-world applications, favoring narrow domains like\ntwo-dimensional molecular graphs over broader, impactful areas such as\ncombinatorial optimization, relational databases, or chip design. Additionally,\nmany benchmark datasets poorly represent the underlying data, leading to\ninadequate abstractions and misaligned use cases. Fragmented evaluations and an\nexcessive focus on accuracy further exacerbate these issues, incentivizing\noverfitting rather than fostering generalizable insights. These limitations\nhave prevented the development of truly useful graph foundation models. This\nposition paper calls for a paradigm shift toward more meaningful benchmarks,\nrigorous evaluation protocols, and stronger collaboration with domain experts\nto drive impactful and reliable advances in graph learning research, unlocking\nthe potential of graph learning.'}","['Maya Bechler-Speicher', 'Ben Finkelshtein', 'Fabrizio Frasca', 'Luis Mller', 'Jan Tnshoff', 'Antoine Siraudin', 'Viktor Zaverkin', 'Michael M. Bronstein', 'Mathias Niepert', 'Bryan Perozzi', 'Mikhail Galkin', 'Christopher Morris']",{'name': 'Christopher Morris'},Christopher Morris,,"[{'href': 'http://arxiv.org/abs/2502.14546v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14546v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14546v1,None,http://arxiv.org/abs/2502.14546v1,,,3316,0
http://arxiv.org/abs/2502.14553v1,True,2025-02-20T13:31:50Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=13, tm_min=31, tm_sec=50, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T13:31:50Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=13, tm_min=31, tm_sec=50, tm_wday=3, tm_yday=51, tm_isdst=0)","Multiscale Byte Language Models -- A Hierarchical Architecture for
  Causal Million-Length Sequence Modeling","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Multiscale Byte Language Models -- A Hierarchical Architecture for\n  Causal Million-Length Sequence Modeling'}","Bytes form the basis of the digital world and thus are a promising building
block for multimodal foundation models. Recently, Byte Language Models (BLMs)
have emerged to overcome tokenization, yet the excessive length of bytestreams
requires new architectural paradigms. Therefore, we present the Multiscale Byte
Language Model (MBLM), a model-agnostic hierarchical decoder stack that allows
training with context windows of $5$M bytes on single GPU in full model
precision. We thoroughly examine MBLM's performance with Transformer and Mamba
blocks on both unimodal and multimodal tasks. Our experiments demonstrate that
hybrid architectures are efficient in handling extremely long byte sequences
during training while achieving near-linear generational efficiency. To the
best of our knowledge, we present the first evaluation of BLMs on visual Q\&A
tasks and find that, despite serializing images and the absence of an encoder,
a MBLM with pure next token prediction can match custom CNN-LSTM architectures
with designated classification heads. We show that MBLMs exhibit strong
adaptability in integrating diverse data representations, including pixel and
image filestream bytes, underlining their potential toward omnimodal foundation
models. Source code is publicly available at:
https://github.com/ai4sd/multiscale-byte-lm","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Bytes form the basis of the digital world and thus are a promising building\nblock for multimodal foundation models. Recently, Byte Language Models (BLMs)\nhave emerged to overcome tokenization, yet the excessive length of bytestreams\nrequires new architectural paradigms. Therefore, we present the Multiscale Byte\nLanguage Model (MBLM), a model-agnostic hierarchical decoder stack that allows\ntraining with context windows of $5$M bytes on single GPU in full model\nprecision. We thoroughly examine MBLM's performance with Transformer and Mamba\nblocks on both unimodal and multimodal tasks. Our experiments demonstrate that\nhybrid architectures are efficient in handling extremely long byte sequences\nduring training while achieving near-linear generational efficiency. To the\nbest of our knowledge, we present the first evaluation of BLMs on visual Q\\&A\ntasks and find that, despite serializing images and the absence of an encoder,\na MBLM with pure next token prediction can match custom CNN-LSTM architectures\nwith designated classification heads. We show that MBLMs exhibit strong\nadaptability in integrating diverse data representations, including pixel and\nimage filestream bytes, underlining their potential toward omnimodal foundation\nmodels. Source code is publicly available at:\nhttps://github.com/ai4sd/multiscale-byte-lm""}","['Eric Egli', 'Matteo Manica', 'Jannis Born']",{'name': 'Jannis Born'},Jannis Born,Under Review,"[{'href': 'http://arxiv.org/abs/2502.14553v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14553v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14553v1,None,http://arxiv.org/abs/2502.14553v1,,,1582,0
http://arxiv.org/abs/2502.14560v1,True,2025-02-20T13:45:17Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=13, tm_min=45, tm_sec=17, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T13:45:17Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=13, tm_min=45, tm_sec=17, tm_wday=3, tm_yday=51, tm_isdst=0)",Less is More: Improving LLM Alignment via Preference Data Selection,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Less is More: Improving LLM Alignment via Preference Data Selection'}","Direct Preference Optimization (DPO) has emerged as a promising approach for
aligning large language models with human preferences. While prior work mainly
extends DPO from the aspect of the objective function, we instead improve DPO
from the largely overlooked but critical aspect of data selection.
Specifically, we address the issue of parameter shrinkage caused by noisy data
by proposing a novel margin-maximization principle for dataset curation in DPO
training. To accurately estimate margins for data selection, we propose a
dual-margin guided approach that considers both external reward margins and
implicit DPO reward margins. Extensive experiments demonstrate that our method
reduces computational cost dramatically while improving performance.
Remarkably, by using just 10\% of the Ultrafeedback dataset, our approach
achieves 3\% to 8\% improvements across various Llama and Mistral series models
on the AlpacaEval 2.0 benchmark. Furthermore, our approach seamlessly extends
to iterative DPO, yielding a roughly 3\% improvement with 25\% online data,
while further reducing training time. These results highlight the potential of
data selection strategies for advancing preference optimization.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Direct Preference Optimization (DPO) has emerged as a promising approach for\naligning large language models with human preferences. While prior work mainly\nextends DPO from the aspect of the objective function, we instead improve DPO\nfrom the largely overlooked but critical aspect of data selection.\nSpecifically, we address the issue of parameter shrinkage caused by noisy data\nby proposing a novel margin-maximization principle for dataset curation in DPO\ntraining. To accurately estimate margins for data selection, we propose a\ndual-margin guided approach that considers both external reward margins and\nimplicit DPO reward margins. Extensive experiments demonstrate that our method\nreduces computational cost dramatically while improving performance.\nRemarkably, by using just 10\\% of the Ultrafeedback dataset, our approach\nachieves 3\\% to 8\\% improvements across various Llama and Mistral series models\non the AlpacaEval 2.0 benchmark. Furthermore, our approach seamlessly extends\nto iterative DPO, yielding a roughly 3\\% improvement with 25\\% online data,\nwhile further reducing training time. These results highlight the potential of\ndata selection strategies for advancing preference optimization.'}","['Xun Deng', 'Han Zhong', 'Rui Ai', 'Fuli Feng', 'Zheng Wang', 'Xiangnan He']",{'name': 'Xiangnan He'},Xiangnan He,,"[{'href': 'http://arxiv.org/abs/2502.14560v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14560v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14560v1,None,http://arxiv.org/abs/2502.14560v1,,,0,0
http://arxiv.org/abs/2502.14581v1,True,2025-02-20T14:12:18Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=14, tm_min=12, tm_sec=18, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T14:12:18Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=14, tm_min=12, tm_sec=18, tm_wday=3, tm_yday=51, tm_isdst=0)",A Statistical Case Against Empirical Human-AI Alignment,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'A Statistical Case Against Empirical Human-AI Alignment'}","Empirical human-AI alignment aims to make AI systems act in line with
observed human behavior. While noble in its goals, we argue that empirical
alignment can inadvertently introduce statistical biases that warrant caution.
This position paper thus advocates against naive empirical alignment, offering
prescriptive alignment and a posteriori empirical alignment as alternatives. We
substantiate our principled argument by tangible examples like human-centric
decoding of language models.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Empirical human-AI alignment aims to make AI systems act in line with\nobserved human behavior. While noble in its goals, we argue that empirical\nalignment can inadvertently introduce statistical biases that warrant caution.\nThis position paper thus advocates against naive empirical alignment, offering\nprescriptive alignment and a posteriori empirical alignment as alternatives. We\nsubstantiate our principled argument by tangible examples like human-centric\ndecoding of language models.'}","['Julian Rodemann', 'Esteban Garces Arias', 'Christoph Luther', 'Christoph Jansen', 'Thomas Augustin']",{'name': 'Thomas Augustin'},Thomas Augustin,"24 pages, 2 figures, 5 tables","[{'href': 'http://arxiv.org/abs/2502.14581v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14581v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.OT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14581v1,None,http://arxiv.org/abs/2502.14581v1,,,106,0
http://arxiv.org/abs/2502.14619v1,True,2025-02-20T14:57:14Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=14, tm_min=57, tm_sec=14, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T14:57:14Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=14, tm_min=57, tm_sec=14, tm_wday=3, tm_yday=51, tm_isdst=0)","Reward Models Identify Consistency, Not Causality","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Reward Models Identify Consistency, Not Causality'}","Reward models (RMs) play a crucial role in aligning large language models
(LLMs) with human preferences and enhancing reasoning quality. Traditionally,
RMs are trained to rank candidate outputs based on their correctness and
coherence. However, in this work, we present several surprising findings that
challenge common assumptions about RM behavior. Our analysis reveals that
state-of-the-art reward models prioritize structural consistency over causal
correctness. Specifically, removing the problem statement has minimal impact on
reward scores, whereas altering numerical values or disrupting the reasoning
flow significantly affects RM outputs. Furthermore, RMs exhibit a strong
dependence on complete reasoning trajectories truncated or incomplete steps
lead to significant variations in reward assignments, indicating that RMs
primarily rely on learned reasoning patterns rather than explicit problem
comprehension. These findings hold across multiple architectures, datasets, and
tasks, leading to three key insights: (1) RMs primarily assess coherence rather
than true reasoning quality; (2) The role of explicit problem comprehension in
reward assignment is overstated; (3) Current RMs may be more effective at
ranking responses than verifying logical validity. Our results suggest a
fundamental limitation in existing reward modeling approaches, emphasizing the
need for a shift toward causality-aware reward models that go beyond
consistency-driven evaluation.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Reward models (RMs) play a crucial role in aligning large language models\n(LLMs) with human preferences and enhancing reasoning quality. Traditionally,\nRMs are trained to rank candidate outputs based on their correctness and\ncoherence. However, in this work, we present several surprising findings that\nchallenge common assumptions about RM behavior. Our analysis reveals that\nstate-of-the-art reward models prioritize structural consistency over causal\ncorrectness. Specifically, removing the problem statement has minimal impact on\nreward scores, whereas altering numerical values or disrupting the reasoning\nflow significantly affects RM outputs. Furthermore, RMs exhibit a strong\ndependence on complete reasoning trajectories truncated or incomplete steps\nlead to significant variations in reward assignments, indicating that RMs\nprimarily rely on learned reasoning patterns rather than explicit problem\ncomprehension. These findings hold across multiple architectures, datasets, and\ntasks, leading to three key insights: (1) RMs primarily assess coherence rather\nthan true reasoning quality; (2) The role of explicit problem comprehension in\nreward assignment is overstated; (3) Current RMs may be more effective at\nranking responses than verifying logical validity. Our results suggest a\nfundamental limitation in existing reward modeling approaches, emphasizing the\nneed for a shift toward causality-aware reward models that go beyond\nconsistency-driven evaluation.'}","['Yuhui Xu', 'Hanze Dong', 'Lei Wang', 'Caiming Xiong', 'Junnan Li']",{'name': 'Junnan Li'},Junnan Li,16 pages,"[{'href': 'http://arxiv.org/abs/2502.14619v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14619v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14619v1,None,http://arxiv.org/abs/2502.14619v1,,,116,0
http://arxiv.org/abs/2502.14627v1,True,2025-02-20T15:06:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=15, tm_min=6, tm_sec=15, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T15:06:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=15, tm_min=6, tm_sec=15, tm_wday=3, tm_yday=51, tm_isdst=0)","ATRI: Mitigating Multilingual Audio Text Retrieval Inconsistencies by
  Reducing Data Distribution Errors","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'ATRI: Mitigating Multilingual Audio Text Retrieval Inconsistencies by\n  Reducing Data Distribution Errors'}","Multilingual audio-text retrieval (ML-ATR) is a challenging task that aims to
retrieve audio clips or multilingual texts from databases. However, existing
ML-ATR schemes suffer from inconsistencies for instance similarity matching
across languages. We theoretically analyze the inconsistency in terms of both
multilingual modal alignment direction error and weight error, and propose the
theoretical weight error upper bound for quantifying the inconsistency. Based
on the analysis of the weight error upper bound, we find that the inconsistency
problem stems from the data distribution error caused by random sampling of
languages. We propose a consistent ML-ATR scheme using 1-to-k contrastive
learning and audio-English co-anchor contrastive learning, aiming to mitigate
the negative impact of data distribution error on recall and consistency in
ML-ATR. Experimental results on the translated AudioCaps and Clotho datasets
show that our scheme achieves state-of-the-art performance on recall and
consistency metrics for eight mainstream languages, including English. Our code
will be available at https://github.com/ATRI-ACL/ATRI-ACL.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Multilingual audio-text retrieval (ML-ATR) is a challenging task that aims to\nretrieve audio clips or multilingual texts from databases. However, existing\nML-ATR schemes suffer from inconsistencies for instance similarity matching\nacross languages. We theoretically analyze the inconsistency in terms of both\nmultilingual modal alignment direction error and weight error, and propose the\ntheoretical weight error upper bound for quantifying the inconsistency. Based\non the analysis of the weight error upper bound, we find that the inconsistency\nproblem stems from the data distribution error caused by random sampling of\nlanguages. We propose a consistent ML-ATR scheme using 1-to-k contrastive\nlearning and audio-English co-anchor contrastive learning, aiming to mitigate\nthe negative impact of data distribution error on recall and consistency in\nML-ATR. Experimental results on the translated AudioCaps and Clotho datasets\nshow that our scheme achieves state-of-the-art performance on recall and\nconsistency metrics for eight mainstream languages, including English. Our code\nwill be available at https://github.com/ATRI-ACL/ATRI-ACL.'}","['Yuguo Yin', 'Yuxin Xie', 'Wenyuan Yang', 'Dongchao Yang', 'Jinghan Ru', 'Xianwei Zhuang', 'Liming Liang', 'Yuexian Zou']",{'name': 'Yuexian Zou'},Yuexian Zou,,"[{'href': 'http://arxiv.org/abs/2502.14627v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14627v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.SD', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.SD', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'eess.AS', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14627v1,None,http://arxiv.org/abs/2502.14627v1,,,49,0
http://arxiv.org/abs/2502.14671v1,True,2025-02-20T16:05:45Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=16, tm_min=5, tm_sec=45, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T16:05:45Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=16, tm_min=5, tm_sec=45, tm_wday=3, tm_yday=51, tm_isdst=0)","Explanations of Deep Language Models Explain Language Representations in
  the Brain","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Explanations of Deep Language Models Explain Language Representations in\n  the Brain'}","Recent advances in artificial intelligence have given rise to large language
models (LLMs) that not only achieve human-like performance but also share
computational principles with the brain's language processing mechanisms. While
previous research has primarily focused on aligning LLMs' internal
representations with neural activity, we introduce a novel approach that
leverages explainable AI (XAI) methods to forge deeper connections between the
two domains. Using attribution methods, we quantified how preceding words
contribute to an LLM's next-word predictions and employed these explanations to
predict fMRI recordings from participants listening to the same narratives. Our
findings demonstrate that attribution methods robustly predict brain activity
across the language network, surpassing traditional internal representations in
early language areas. This alignment is hierarchical: early-layer explanations
correspond to the initial stages of language processing in the brain, while
later layers align with more advanced stages. Moreover, the layers more
influential on LLM next-word prediction$\unicode{x2014}$those with higher
attribution scores$\unicode{x2014}$exhibited stronger alignment with neural
activity. This work establishes a bidirectional bridge between AI and
neuroscience. First, we demonstrate that attribution methods offer a powerful
lens for investigating the neural mechanisms of language comprehension,
revealing how meaning emerges from preceding context. Second, we propose using
brain alignment as a metric to evaluate the validity of attribution methods,
providing a framework for assessing their biological plausibility.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Recent advances in artificial intelligence have given rise to large language\nmodels (LLMs) that not only achieve human-like performance but also share\ncomputational principles with the brain's language processing mechanisms. While\nprevious research has primarily focused on aligning LLMs' internal\nrepresentations with neural activity, we introduce a novel approach that\nleverages explainable AI (XAI) methods to forge deeper connections between the\ntwo domains. Using attribution methods, we quantified how preceding words\ncontribute to an LLM's next-word predictions and employed these explanations to\npredict fMRI recordings from participants listening to the same narratives. Our\nfindings demonstrate that attribution methods robustly predict brain activity\nacross the language network, surpassing traditional internal representations in\nearly language areas. This alignment is hierarchical: early-layer explanations\ncorrespond to the initial stages of language processing in the brain, while\nlater layers align with more advanced stages. Moreover, the layers more\ninfluential on LLM next-word prediction$\\unicode{x2014}$those with higher\nattribution scores$\\unicode{x2014}$exhibited stronger alignment with neural\nactivity. This work establishes a bidirectional bridge between AI and\nneuroscience. First, we demonstrate that attribution methods offer a powerful\nlens for investigating the neural mechanisms of language comprehension,\nrevealing how meaning emerges from preceding context. Second, we propose using\nbrain alignment as a metric to evaluate the validity of attribution methods,\nproviding a framework for assessing their biological plausibility.""}","['Maryam Rahimi', 'Yadollah Yaghoobzadeh', 'Mohammad Reza Daliri']",{'name': 'Mohammad Reza Daliri'},Mohammad Reza Daliri,,"[{'href': 'http://arxiv.org/abs/2502.14671v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14671v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-bio.NC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14671v1,"School of Cognitive Sciences, Institute for Research in Fundamental Sciences, Tehran, Iran",http://arxiv.org/abs/2502.14671v1,,,3589,0
http://arxiv.org/abs/2502.14698v1,True,2025-02-20T16:22:40Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=16, tm_min=22, tm_sec=40, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T16:22:40Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=16, tm_min=22, tm_sec=40, tm_wday=3, tm_yday=51, tm_isdst=0)",General Uncertainty Estimation with Delta Variances,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'General Uncertainty Estimation with Delta Variances'}","Decision makers may suffer from uncertainty induced by limited data. This may
be mitigated by accounting for epistemic uncertainty, which is however
challenging to estimate efficiently for large neural networks. To this extent
we investigate Delta Variances, a family of algorithms for epistemic
uncertainty quantification, that is computationally efficient and convenient to
implement. It can be applied to neural networks and more general functions
composed of neural networks. As an example we consider a weather simulator with
a neural-network-based step function inside -- here Delta Variances empirically
obtain competitive results at the cost of a single gradient computation. The
approach is convenient as it requires no changes to the neural network
architecture or training procedure. We discuss multiple ways to derive Delta
Variances theoretically noting that special cases recover popular techniques
and present a unified perspective on multiple related methods. Finally we
observe that this general perspective gives rise to a natural extension and
empirically show its benefit.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Decision makers may suffer from uncertainty induced by limited data. This may\nbe mitigated by accounting for epistemic uncertainty, which is however\nchallenging to estimate efficiently for large neural networks. To this extent\nwe investigate Delta Variances, a family of algorithms for epistemic\nuncertainty quantification, that is computationally efficient and convenient to\nimplement. It can be applied to neural networks and more general functions\ncomposed of neural networks. As an example we consider a weather simulator with\na neural-network-based step function inside -- here Delta Variances empirically\nobtain competitive results at the cost of a single gradient computation. The\napproach is convenient as it requires no changes to the neural network\narchitecture or training procedure. We discuss multiple ways to derive Delta\nVariances theoretically noting that special cases recover popular techniques\nand present a unified perspective on multiple related methods. Finally we\nobserve that this general perspective gives rise to a natural extension and\nempirically show its benefit.'}","['Simon Schmitt', 'John Shawe-Taylor', 'Hado van Hasselt']",{'name': 'Hado van Hasselt'},Hado van Hasselt,,"[{'href': 'http://arxiv.org/abs/2502.14698v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14698v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.AP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14698v1,None,http://arxiv.org/abs/2502.14698v1,,,588,0
http://arxiv.org/abs/2502.14708v1,True,2025-02-20T16:32:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=16, tm_min=32, tm_sec=42, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T16:32:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=16, tm_min=32, tm_sec=42, tm_wday=3, tm_yday=51, tm_isdst=0)",Human Misperception of Generative-AI Alignment: A Laboratory Experiment,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Human Misperception of Generative-AI Alignment: A Laboratory Experiment'}","We conduct an incentivized laboratory experiment to study people's perception
of generative artificial intelligence (GenAI) alignment in the context of
economic decision-making. Using a panel of economic problems spanning the
domains of risk, time preference, social preference, and strategic
interactions, we ask human subjects to make choices for themselves and to
predict the choices made by GenAI on behalf of a human user. We find that
people overestimate the degree of alignment between GenAI's choices and human
choices. In every problem, human subjects' average prediction about GenAI's
choice is substantially closer to the average human-subject choice than it is
to the GenAI choice. At the individual level, different subjects' predictions
about GenAI's choice in a given problem are highly correlated with their own
choices in the same problem. We explore the implications of people
overestimating GenAI alignment in a simple theoretical model.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""We conduct an incentivized laboratory experiment to study people's perception\nof generative artificial intelligence (GenAI) alignment in the context of\neconomic decision-making. Using a panel of economic problems spanning the\ndomains of risk, time preference, social preference, and strategic\ninteractions, we ask human subjects to make choices for themselves and to\npredict the choices made by GenAI on behalf of a human user. We find that\npeople overestimate the degree of alignment between GenAI's choices and human\nchoices. In every problem, human subjects' average prediction about GenAI's\nchoice is substantially closer to the average human-subject choice than it is\nto the GenAI choice. At the individual level, different subjects' predictions\nabout GenAI's choice in a given problem are highly correlated with their own\nchoices in the same problem. We explore the implications of people\noverestimating GenAI alignment in a simple theoretical model.""}","['Kevin He', 'Ran Shorrer', 'Mengjia Xia']",{'name': 'Mengjia Xia'},Mengjia Xia,,"[{'href': 'http://arxiv.org/abs/2502.14708v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14708v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'econ.TH', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'econ.TH', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.GT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14708v1,None,http://arxiv.org/abs/2502.14708v1,,,0,0
http://arxiv.org/abs/2502.14714v1,True,2025-02-20T16:39:57Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=16, tm_min=39, tm_sec=57, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T16:39:57Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=16, tm_min=39, tm_sec=57, tm_wday=3, tm_yday=51, tm_isdst=0)","From Knowledge Generation to Knowledge Verification: Examining the
  BioMedical Generative Capabilities of ChatGPT","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'From Knowledge Generation to Knowledge Verification: Examining the\n  BioMedical Generative Capabilities of ChatGPT'}","The generative capabilities of LLM models present opportunities in
accelerating tasks and concerns with the authenticity of the knowledge it
produces. To address the concerns, we present a computational approach that
systematically evaluates the factual accuracy of biomedical knowledge that an
LLM model has been prompted to generate. Our approach encompasses two
processes: the generation of disease-centric associations and the verification
of them using the semantic knowledge of the biomedical ontologies. Using
ChatGPT as the select LLM model, we designed a set of prompt-engineering
processes to generate linkages between diseases, drugs, symptoms, and genes to
establish grounds for assessments. Experimental results demonstrate high
accuracy in identifying disease terms (88%-97%), drug names (90%-91%), and
genetic information (88%-98%). The symptom term identification accuracy was
notably lower (49%-61%), as verified against the DOID, ChEBI, SYMPTOM, and GO
ontologies accordingly. The verification of associations reveals literature
coverage rates of (89%-91%) among disease-drug and disease-gene associations.
The low identification accuracy for symptom terms also contributed to the
verification of symptom-related associations (49%-62%).","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The generative capabilities of LLM models present opportunities in\naccelerating tasks and concerns with the authenticity of the knowledge it\nproduces. To address the concerns, we present a computational approach that\nsystematically evaluates the factual accuracy of biomedical knowledge that an\nLLM model has been prompted to generate. Our approach encompasses two\nprocesses: the generation of disease-centric associations and the verification\nof them using the semantic knowledge of the biomedical ontologies. Using\nChatGPT as the select LLM model, we designed a set of prompt-engineering\nprocesses to generate linkages between diseases, drugs, symptoms, and genes to\nestablish grounds for assessments. Experimental results demonstrate high\naccuracy in identifying disease terms (88%-97%), drug names (90%-91%), and\ngenetic information (88%-98%). The symptom term identification accuracy was\nnotably lower (49%-61%), as verified against the DOID, ChEBI, SYMPTOM, and GO\nontologies accordingly. The verification of associations reveals literature\ncoverage rates of (89%-91%) among disease-drug and disease-gene associations.\nThe low identification accuracy for symptom terms also contributed to the\nverification of symptom-related associations (49%-62%).'}","['Ahmed Abdeen Hamed', 'Byung Suk Lee']",{'name': 'Byung Suk Lee'},Byung Suk Lee,"26 pages, 6 figures, In Review with a Cell Press Journal","[{'href': 'http://arxiv.org/abs/2502.14714v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14714v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2; I.2.4; I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14714v1,None,http://arxiv.org/abs/2502.14714v1,,,2,0
http://arxiv.org/abs/2502.14724v1,True,2025-02-20T16:50:38Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=16, tm_min=50, tm_sec=38, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T16:50:38Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=16, tm_min=50, tm_sec=38, tm_wday=3, tm_yday=51, tm_isdst=0)",Ranking Joint Policies in Dynamic Games using Evolutionary Dynamics,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Ranking Joint Policies in Dynamic Games using Evolutionary Dynamics'}","Game-theoretic solution concepts, such as the Nash equilibrium, have been key
to finding stable joint actions in multi-player games. However, it has been
shown that the dynamics of agents' interactions, even in simple two-player
games with few strategies, are incapable of reaching Nash equilibria,
exhibiting complex and unpredictable behavior. Instead, evolutionary approaches
can describe the long-term persistence of strategies and filter out transient
ones, accounting for the long-term dynamics of agents' interactions. Our goal
is to identify agents' joint strategies that result in stable behavior, being
resistant to changes, while also accounting for agents' payoffs, in dynamic
games. Towards this goal, and building on previous results, this paper proposes
transforming dynamic games into their empirical forms by considering agents'
strategies instead of agents' actions, and applying the evolutionary
methodology $\alpha$-Rank to evaluate and rank strategy profiles according to
their long-term dynamics. This methodology not only allows us to identify joint
strategies that are strong through agents' long-term interactions, but also
provides a descriptive, transparent framework regarding the high ranking of
these strategies. Experiments report on agents that aim to collaboratively
solve a stochastic version of the graph coloring problem. We consider different
styles of play as strategies to define the empirical game, and train policies
realizing these strategies, using the DQN algorithm. Then we run simulations to
generate the payoff matrix required by $\alpha$-Rank to rank joint strategies.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Game-theoretic solution concepts, such as the Nash equilibrium, have been key\nto finding stable joint actions in multi-player games. However, it has been\nshown that the dynamics of agents' interactions, even in simple two-player\ngames with few strategies, are incapable of reaching Nash equilibria,\nexhibiting complex and unpredictable behavior. Instead, evolutionary approaches\ncan describe the long-term persistence of strategies and filter out transient\nones, accounting for the long-term dynamics of agents' interactions. Our goal\nis to identify agents' joint strategies that result in stable behavior, being\nresistant to changes, while also accounting for agents' payoffs, in dynamic\ngames. Towards this goal, and building on previous results, this paper proposes\ntransforming dynamic games into their empirical forms by considering agents'\nstrategies instead of agents' actions, and applying the evolutionary\nmethodology $\\alpha$-Rank to evaluate and rank strategy profiles according to\ntheir long-term dynamics. This methodology not only allows us to identify joint\nstrategies that are strong through agents' long-term interactions, but also\nprovides a descriptive, transparent framework regarding the high ranking of\nthese strategies. Experiments report on agents that aim to collaboratively\nsolve a stochastic version of the graph coloring problem. We consider different\nstyles of play as strategies to define the empirical game, and train policies\nrealizing these strategies, using the DQN algorithm. Then we run simulations to\ngenerate the payoff matrix required by $\\alpha$-Rank to rank joint strategies.""}","['Natalia Koliou', 'George Vouros']",{'name': 'George Vouros'},George Vouros,,"[{'href': 'http://arxiv.org/abs/2502.14724v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14724v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14724v1,None,http://arxiv.org/abs/2502.14724v1,,,0,0
http://arxiv.org/abs/2502.14727v1,True,2025-02-20T16:54:07Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=16, tm_min=54, tm_sec=7, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T16:54:07Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=16, tm_min=54, tm_sec=7, tm_wday=3, tm_yday=51, tm_isdst=0)","WavRAG: Audio-Integrated Retrieval Augmented Generation for Spoken
  Dialogue Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'WavRAG: Audio-Integrated Retrieval Augmented Generation for Spoken\n  Dialogue Models'}","Retrieval Augmented Generation (RAG) has gained widespread adoption owing to
its capacity to empower large language models (LLMs) to integrate external
knowledge. However, existing RAG frameworks are primarily designed for
text-based LLMs and rely on Automatic Speech Recognition to process speech
input, which discards crucial audio information, risks transcription errors,
and increases computational overhead. Therefore, we introduce WavRAG, the first
retrieval augmented generation framework with native, end-to-end audio support.
WavRAG offers two key features: 1) Bypassing ASR, WavRAG directly processes raw
audio for both embedding and retrieval. 2) WavRAG integrates audio and text
into a unified knowledge representation. Specifically, we propose the
WavRetriever to facilitate the retrieval from a text-audio hybrid knowledge
base, and further enhance the in-context capabilities of spoken dialogue models
through the integration of chain-of-thought reasoning. In comparison to
state-of-the-art ASR-Text RAG pipelines, WavRAG achieves comparable retrieval
performance while delivering a 10x acceleration. Furthermore, WavRAG's unique
text-audio hybrid retrieval capability extends the boundaries of RAG to the
audio modality.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Retrieval Augmented Generation (RAG) has gained widespread adoption owing to\nits capacity to empower large language models (LLMs) to integrate external\nknowledge. However, existing RAG frameworks are primarily designed for\ntext-based LLMs and rely on Automatic Speech Recognition to process speech\ninput, which discards crucial audio information, risks transcription errors,\nand increases computational overhead. Therefore, we introduce WavRAG, the first\nretrieval augmented generation framework with native, end-to-end audio support.\nWavRAG offers two key features: 1) Bypassing ASR, WavRAG directly processes raw\naudio for both embedding and retrieval. 2) WavRAG integrates audio and text\ninto a unified knowledge representation. Specifically, we propose the\nWavRetriever to facilitate the retrieval from a text-audio hybrid knowledge\nbase, and further enhance the in-context capabilities of spoken dialogue models\nthrough the integration of chain-of-thought reasoning. In comparison to\nstate-of-the-art ASR-Text RAG pipelines, WavRAG achieves comparable retrieval\nperformance while delivering a 10x acceleration. Furthermore, WavRAG's unique\ntext-audio hybrid retrieval capability extends the boundaries of RAG to the\naudio modality.""}","['Yifu Chen', 'Shengpeng Ji', 'Haoxiao Wang', 'Ziqing Wang', 'Siyu Chen', 'Jinzheng He', 'Jin Xu', 'Zhou Zhao']",{'name': 'Zhou Zhao'},Zhou Zhao,,"[{'href': 'http://arxiv.org/abs/2502.14727v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14727v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.SD', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.SD', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'eess.AS', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14727v1,None,http://arxiv.org/abs/2502.14727v1,,,20,0
http://arxiv.org/abs/2502.14753v1,True,2025-02-20T17:24:06Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=17, tm_min=24, tm_sec=6, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T17:24:06Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=17, tm_min=24, tm_sec=6, tm_wday=3, tm_yday=51, tm_isdst=0)","MedVAE: Efficient Automated Interpretation of Medical Images with
  Large-Scale Generalizable Autoencoders","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'MedVAE: Efficient Automated Interpretation of Medical Images with\n  Large-Scale Generalizable Autoencoders'}","Medical images are acquired at high resolutions with large fields of view in
order to capture fine-grained features necessary for clinical decision-making.
Consequently, training deep learning models on medical images can incur large
computational costs. In this work, we address the challenge of downsizing
medical images in order to improve downstream computational efficiency while
preserving clinically-relevant features. We introduce MedVAE, a family of six
large-scale 2D and 3D autoencoders capable of encoding medical images as
downsized latent representations and decoding latent representations back to
high-resolution images. We train MedVAE autoencoders using a novel two-stage
training approach with 1,052,730 medical images. Across diverse tasks obtained
from 20 medical image datasets, we demonstrate that (1) utilizing MedVAE latent
representations in place of high-resolution images when training downstream
models can lead to efficiency benefits (up to 70x improvement in throughput)
while simultaneously preserving clinically-relevant features and (2) MedVAE can
decode latent representations back to high-resolution images with high
fidelity. Our work demonstrates that large-scale, generalizable autoencoders
can help address critical efficiency challenges in the medical domain. Our code
is available at https://github.com/StanfordMIMI/MedVAE.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Medical images are acquired at high resolutions with large fields of view in\norder to capture fine-grained features necessary for clinical decision-making.\nConsequently, training deep learning models on medical images can incur large\ncomputational costs. In this work, we address the challenge of downsizing\nmedical images in order to improve downstream computational efficiency while\npreserving clinically-relevant features. We introduce MedVAE, a family of six\nlarge-scale 2D and 3D autoencoders capable of encoding medical images as\ndownsized latent representations and decoding latent representations back to\nhigh-resolution images. We train MedVAE autoencoders using a novel two-stage\ntraining approach with 1,052,730 medical images. Across diverse tasks obtained\nfrom 20 medical image datasets, we demonstrate that (1) utilizing MedVAE latent\nrepresentations in place of high-resolution images when training downstream\nmodels can lead to efficiency benefits (up to 70x improvement in throughput)\nwhile simultaneously preserving clinically-relevant features and (2) MedVAE can\ndecode latent representations back to high-resolution images with high\nfidelity. Our work demonstrates that large-scale, generalizable autoencoders\ncan help address critical efficiency challenges in the medical domain. Our code\nis available at https://github.com/StanfordMIMI/MedVAE.'}","['Maya Varma', 'Ashwin Kumar', 'Rogier van der Sluijs', 'Sophie Ostmeier', 'Louis Blankemeier', 'Pierre Chambon', 'Christian Bluethgen', 'Jip Prince', 'Curtis Langlotz', 'Akshay Chaudhari']",{'name': 'Akshay Chaudhari'},Akshay Chaudhari,,"[{'href': 'http://arxiv.org/abs/2502.14753v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14753v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'eess.IV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'eess.IV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14753v1,None,http://arxiv.org/abs/2502.14753v1,,,991,0
http://arxiv.org/abs/2502.14760v1,True,2025-02-20T17:35:32Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=17, tm_min=35, tm_sec=32, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T17:35:32Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=17, tm_min=35, tm_sec=32, tm_wday=3, tm_yday=51, tm_isdst=0)","EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of
  Optimization Formulations","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of\n  Optimization Formulations'}","A fundamental problem in combinatorial optimization is identifying equivalent
formulations, which can lead to more efficient solution strategies and deeper
insights into a problem's computational complexity. The need to automatically
identify equivalence between problem formulations has grown as optimization
copilots--systems that generate problem formulations from natural language
descriptions--have proliferated. However, existing approaches to checking
formulation equivalence lack grounding, relying on simple heuristics which are
insufficient for rigorous validation. Inspired by Karp reductions, in this work
we introduce quasi-Karp equivalence, a formal criterion for determining when
two optimization formulations are equivalent based on the existence of a
mapping between their decision variables. We propose EquivaMap, a framework
that leverages large language models to automatically discover such mappings,
enabling scalable and reliable equivalence verification. To evaluate our
approach, we construct the first open-source dataset of equivalent optimization
formulations, generated by applying transformations such as adding slack
variables or valid inequalities to existing formulations. Empirically,
EquivaMap significantly outperforms existing methods, achieving substantial
improvements in correctly identifying formulation equivalence.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""A fundamental problem in combinatorial optimization is identifying equivalent\nformulations, which can lead to more efficient solution strategies and deeper\ninsights into a problem's computational complexity. The need to automatically\nidentify equivalence between problem formulations has grown as optimization\ncopilots--systems that generate problem formulations from natural language\ndescriptions--have proliferated. However, existing approaches to checking\nformulation equivalence lack grounding, relying on simple heuristics which are\ninsufficient for rigorous validation. Inspired by Karp reductions, in this work\nwe introduce quasi-Karp equivalence, a formal criterion for determining when\ntwo optimization formulations are equivalent based on the existence of a\nmapping between their decision variables. We propose EquivaMap, a framework\nthat leverages large language models to automatically discover such mappings,\nenabling scalable and reliable equivalence verification. To evaluate our\napproach, we construct the first open-source dataset of equivalent optimization\nformulations, generated by applying transformations such as adding slack\nvariables or valid inequalities to existing formulations. Empirically,\nEquivaMap significantly outperforms existing methods, achieving substantial\nimprovements in correctly identifying formulation equivalence.""}","['Haotian Zhai', 'Connor Lawless', 'Ellen Vitercik', 'Liu Leqi']",{'name': 'Liu Leqi'},Liu Leqi,,"[{'href': 'http://arxiv.org/abs/2502.14760v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14760v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.OC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14760v1,None,http://arxiv.org/abs/2502.14760v1,,,271,0
http://arxiv.org/abs/2502.14778v1,True,2025-02-20T17:59:59Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=17, tm_min=59, tm_sec=59, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T17:59:59Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=17, tm_min=59, tm_sec=59, tm_wday=3, tm_yday=51, tm_isdst=0)",Harnessing PDF Data for Improving Japanese Large Multimodal Models,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Harnessing PDF Data for Improving Japanese Large Multimodal Models'}","Large Multimodal Models (LMMs) have demonstrated strong performance in
English, but their effectiveness in Japanese remains limited due to the lack of
high-quality training data. Current Japanese LMMs often rely on translated
English datasets, restricting their ability to capture Japan-specific cultural
knowledge. To address this, we explore the potential of Japanese PDF data as a
training resource, an area that remains largely underutilized. We introduce a
fully automated pipeline that leverages pretrained models to extract image-text
pairs from PDFs through layout analysis, OCR, and vision-language pairing,
removing the need for manual annotation. Additionally, we construct instruction
data from extracted image-text pairs to enrich the training data. To evaluate
the effectiveness of PDF-derived data, we train Japanese LMMs and assess their
performance on the Japanese LMM Benchmark. Our results demonstrate substantial
improvements, with performance gains ranging from 3.9% to 13.8% on Heron-Bench.
Further analysis highlights the impact of PDF-derived data on various factors,
such as model size and language models, reinforcing its value as a multimodal
resource for Japanese LMMs. We plan to make the source code and data publicly
available upon acceptance.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Multimodal Models (LMMs) have demonstrated strong performance in\nEnglish, but their effectiveness in Japanese remains limited due to the lack of\nhigh-quality training data. Current Japanese LMMs often rely on translated\nEnglish datasets, restricting their ability to capture Japan-specific cultural\nknowledge. To address this, we explore the potential of Japanese PDF data as a\ntraining resource, an area that remains largely underutilized. We introduce a\nfully automated pipeline that leverages pretrained models to extract image-text\npairs from PDFs through layout analysis, OCR, and vision-language pairing,\nremoving the need for manual annotation. Additionally, we construct instruction\ndata from extracted image-text pairs to enrich the training data. To evaluate\nthe effectiveness of PDF-derived data, we train Japanese LMMs and assess their\nperformance on the Japanese LMM Benchmark. Our results demonstrate substantial\nimprovements, with performance gains ranging from 3.9% to 13.8% on Heron-Bench.\nFurther analysis highlights the impact of PDF-derived data on various factors,\nsuch as model size and language models, reinforcing its value as a multimodal\nresource for Japanese LMMs. We plan to make the source code and data publicly\navailable upon acceptance.'}","['Jeonghun Baek', 'Akiko Aizawa', 'Kiyoharu Aizawa']",{'name': 'Kiyoharu Aizawa'},Kiyoharu Aizawa,"15 pages, 8 figures","[{'href': 'http://arxiv.org/abs/2502.14778v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14778v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14778v1,None,http://arxiv.org/abs/2502.14778v1,,,769,0
http://arxiv.org/abs/2502.14780v1,True,2025-02-20T18:01:41Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=1, tm_sec=41, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T18:01:41Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=1, tm_sec=41, tm_wday=3, tm_yday=51, tm_isdst=0)","ReVision: A Dataset and Baseline VLM for Privacy-Preserving
  Task-Oriented Visual Instruction Rewriting","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'ReVision: A Dataset and Baseline VLM for Privacy-Preserving\n  Task-Oriented Visual Instruction Rewriting'}","Efficient and privacy-preserving multimodal interaction is essential as AR,
VR, and modern smartphones with powerful cameras become primary interfaces for
human-computer communication. Existing powerful large vision-language models
(VLMs) enabling multimodal interaction often rely on cloud-based processing,
raising significant concerns about (1) visual privacy by transmitting sensitive
vision data to servers, and (2) their limited real-time, on-device usability.
This paper explores Visual Instruction Rewriting, a novel approach that
transforms multimodal instructions into text-only commands, allowing seamless
integration of lightweight on-device instruction rewriter VLMs (250M
parameters) with existing conversational AI systems, enhancing vision data
privacy. To achieve this, we present a dataset of over 39,000 examples across
14 domains and develop a compact VLM, pretrained on image captioning datasets
and fine-tuned for instruction rewriting. Experimental results, evaluated
through NLG metrics such as BLEU, METEOR, and ROUGE, along with semantic
parsing analysis, demonstrate that even a quantized version of the model
(<500MB storage footprint) can achieve effective instruction rewriting, thus
enabling privacy-focused, multimodal AI applications.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Efficient and privacy-preserving multimodal interaction is essential as AR,\nVR, and modern smartphones with powerful cameras become primary interfaces for\nhuman-computer communication. Existing powerful large vision-language models\n(VLMs) enabling multimodal interaction often rely on cloud-based processing,\nraising significant concerns about (1) visual privacy by transmitting sensitive\nvision data to servers, and (2) their limited real-time, on-device usability.\nThis paper explores Visual Instruction Rewriting, a novel approach that\ntransforms multimodal instructions into text-only commands, allowing seamless\nintegration of lightweight on-device instruction rewriter VLMs (250M\nparameters) with existing conversational AI systems, enhancing vision data\nprivacy. To achieve this, we present a dataset of over 39,000 examples across\n14 domains and develop a compact VLM, pretrained on image captioning datasets\nand fine-tuned for instruction rewriting. Experimental results, evaluated\nthrough NLG metrics such as BLEU, METEOR, and ROUGE, along with semantic\nparsing analysis, demonstrate that even a quantized version of the model\n(<500MB storage footprint) can achieve effective instruction rewriting, thus\nenabling privacy-focused, multimodal AI applications.'}","['Abhijit Mishra', 'Richard Noh', 'Hsiang Fu', 'Mingda Li', 'Minji Kim']",{'name': 'Minji Kim'},Minji Kim,"12 pages, 7 figures, 3 tables","[{'href': 'http://arxiv.org/abs/2502.14780v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14780v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14780v1,None,http://arxiv.org/abs/2502.14780v1,,,2,0
http://arxiv.org/abs/2502.14785v1,True,2025-02-20T18:05:34Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=5, tm_sec=34, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T18:05:34Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=5, tm_sec=34, tm_wday=3, tm_yday=51, tm_isdst=0)",Real-Time Device Reach Forecasting Using HLL and MinHash Data Sketches,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Real-Time Device Reach Forecasting Using HLL and MinHash Data Sketches'}","Predicting the right number of TVs (Device Reach) in real-time based on a
user-specified targeting attributes is imperative for running multi-million
dollar ADs business. The traditional approach of SQL queries to join billions
of records across multiple targeting dimensions is extremely slow. As a
workaround, many applications will have an offline process to crunch these
numbers and present the results after many hours. In our case, the solution was
an offline process taking 24 hours to onboard a customer resulting in a
potential loss of business. To solve this problem, we have built a new
real-time prediction system using MinHash and HyperLogLog (HLL) data sketches
to compute the device reach at runtime when a user makes a request. However,
existing MinHash implementations do not solve the complex problem of multilevel
aggregation and intersection. This work will show how we have solved this
problem, in addition, we have improved MinHash algorithm to run 4 times faster
using Single Instruction Multiple Data (SIMD) vectorized operations for high
speed and accuracy with constant space to process billions of records. Finally,
by experiments, we prove that the results are as accurate as traditional
offline prediction system with an acceptable error rate of 5%.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Predicting the right number of TVs (Device Reach) in real-time based on a\nuser-specified targeting attributes is imperative for running multi-million\ndollar ADs business. The traditional approach of SQL queries to join billions\nof records across multiple targeting dimensions is extremely slow. As a\nworkaround, many applications will have an offline process to crunch these\nnumbers and present the results after many hours. In our case, the solution was\nan offline process taking 24 hours to onboard a customer resulting in a\npotential loss of business. To solve this problem, we have built a new\nreal-time prediction system using MinHash and HyperLogLog (HLL) data sketches\nto compute the device reach at runtime when a user makes a request. However,\nexisting MinHash implementations do not solve the complex problem of multilevel\naggregation and intersection. This work will show how we have solved this\nproblem, in addition, we have improved MinHash algorithm to run 4 times faster\nusing Single Instruction Multiple Data (SIMD) vectorized operations for high\nspeed and accuracy with constant space to process billions of records. Finally,\nby experiments, we prove that the results are as accurate as traditional\noffline prediction system with an acceptable error rate of 5%.'}","['Chandrashekar Muniyappa', 'Kendall Willets', 'Sriraman Krishnamoorthy']",{'name': 'Sriraman Krishnamoorthy'},Sriraman Krishnamoorthy,,"[{'title': 'doi', 'href': 'http://dx.doi.org/10.1109/ISCMI51676.2020.9311573', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2502.14785v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14785v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.DB', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.DB', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '60G25', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.5.3', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14785v1,None,http://arxiv.org/abs/2502.14785v1,2020 7th Intl. Conference on Soft Computing & Machine Intelligence,10.1109/ISCMI51676.2020.9311573,31,0
http://arxiv.org/abs/2502.14791v1,True,2025-02-20T18:11:38Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=11, tm_sec=38, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T18:11:38Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=11, tm_sec=38, tm_wday=3, tm_yday=51, tm_isdst=0)",Rapid Word Learning Through Meta In-Context Learning,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Rapid Word Learning Through Meta In-Context Learning'}","Humans can quickly learn a new word from a few illustrative examples, and
then systematically and flexibly use it in novel contexts. Yet the abilities of
current language models for few-shot word learning, and methods for improving
these abilities, are underexplored. In this study, we introduce a novel method,
Meta-training for IN-context learNing Of Words (Minnow). This method trains
language models to generate new examples of a word's usage given a few
in-context examples, using a special placeholder token to represent the new
word. This training is repeated on many new words to develop a general
word-learning ability. We find that training models from scratch with Minnow on
human-scale child-directed language enables strong few-shot word learning,
comparable to a large language model (LLM) pre-trained on orders of magnitude
more data. Furthermore, through discriminative and generative evaluations, we
demonstrate that finetuning pre-trained LLMs with Minnow improves their ability
to discriminate between new words, identify syntactic categories of new words,
and generate reasonable new usages and definitions for new words, based on one
or a few in-context examples. These findings highlight the data efficiency of
Minnow and its potential to improve language model performance in word learning
tasks.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Humans can quickly learn a new word from a few illustrative examples, and\nthen systematically and flexibly use it in novel contexts. Yet the abilities of\ncurrent language models for few-shot word learning, and methods for improving\nthese abilities, are underexplored. In this study, we introduce a novel method,\nMeta-training for IN-context learNing Of Words (Minnow). This method trains\nlanguage models to generate new examples of a word's usage given a few\nin-context examples, using a special placeholder token to represent the new\nword. This training is repeated on many new words to develop a general\nword-learning ability. We find that training models from scratch with Minnow on\nhuman-scale child-directed language enables strong few-shot word learning,\ncomparable to a large language model (LLM) pre-trained on orders of magnitude\nmore data. Furthermore, through discriminative and generative evaluations, we\ndemonstrate that finetuning pre-trained LLMs with Minnow improves their ability\nto discriminate between new words, identify syntactic categories of new words,\nand generate reasonable new usages and definitions for new words, based on one\nor a few in-context examples. These findings highlight the data efficiency of\nMinnow and its potential to improve language model performance in word learning\ntasks.""}","['Wentao Wang', 'Guangyuan Jiang', 'Tal Linzen', 'Brenden M. Lake']",{'name': 'Brenden M. Lake'},Brenden M. Lake,,"[{'href': 'http://arxiv.org/abs/2502.14791v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14791v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14791v1,None,http://arxiv.org/abs/2502.14791v1,,,2119,0
http://arxiv.org/abs/2502.14807v1,True,2025-02-20T18:30:34Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=30, tm_sec=34, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T18:30:34Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=30, tm_sec=34, tm_wday=3, tm_yday=51, tm_isdst=0)","FetalCLIP: A Visual-Language Foundation Model for Fetal Ultrasound Image
  Analysis","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'FetalCLIP: A Visual-Language Foundation Model for Fetal Ultrasound Image\n  Analysis'}","Foundation models are becoming increasingly effective in the medical domain,
offering pre-trained models on large datasets that can be readily adapted for
downstream tasks. Despite progress, fetal ultrasound images remain a
challenging domain for foundation models due to their inherent complexity,
often requiring substantial additional training and facing limitations due to
the scarcity of paired multimodal data. To overcome these challenges, here we
introduce FetalCLIP, a vision-language foundation model capable of generating
universal representation of fetal ultrasound images. FetalCLIP was pre-trained
using a multimodal learning approach on a diverse dataset of 210,035 fetal
ultrasound images paired with text. This represents the largest paired dataset
of its kind used for foundation model development to date. This unique training
approach allows FetalCLIP to effectively learn the intricate anatomical
features present in fetal ultrasound images, resulting in robust
representations that can be used for a variety of downstream applications. In
extensive benchmarking across a range of key fetal ultrasound applications,
including classification, gestational age estimation, congenital heart defect
(CHD) detection, and fetal structure segmentation, FetalCLIP outperformed all
baselines while demonstrating remarkable generalizability and strong
performance even with limited labeled data. We plan to release the FetalCLIP
model publicly for the benefit of the broader scientific community.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Foundation models are becoming increasingly effective in the medical domain,\noffering pre-trained models on large datasets that can be readily adapted for\ndownstream tasks. Despite progress, fetal ultrasound images remain a\nchallenging domain for foundation models due to their inherent complexity,\noften requiring substantial additional training and facing limitations due to\nthe scarcity of paired multimodal data. To overcome these challenges, here we\nintroduce FetalCLIP, a vision-language foundation model capable of generating\nuniversal representation of fetal ultrasound images. FetalCLIP was pre-trained\nusing a multimodal learning approach on a diverse dataset of 210,035 fetal\nultrasound images paired with text. This represents the largest paired dataset\nof its kind used for foundation model development to date. This unique training\napproach allows FetalCLIP to effectively learn the intricate anatomical\nfeatures present in fetal ultrasound images, resulting in robust\nrepresentations that can be used for a variety of downstream applications. In\nextensive benchmarking across a range of key fetal ultrasound applications,\nincluding classification, gestational age estimation, congenital heart defect\n(CHD) detection, and fetal structure segmentation, FetalCLIP outperformed all\nbaselines while demonstrating remarkable generalizability and strong\nperformance even with limited labeled data. We plan to release the FetalCLIP\nmodel publicly for the benefit of the broader scientific community.'}","['Fadillah Maani', 'Numan Saeed', 'Tausifa Saleem', 'Zaid Farooq', 'Hussain Alasmawi', 'Werner Diehl', 'Ameera Mohammad', 'Gareth Waring', 'Saudabi Valappi', 'Leanne Bricker', 'Mohammad Yaqub']",{'name': 'Mohammad Yaqub'},Mohammad Yaqub,,"[{'href': 'http://arxiv.org/abs/2502.14807v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14807v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'eess.IV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'eess.IV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14807v1,None,http://arxiv.org/abs/2502.14807v1,,,462,0
http://arxiv.org/abs/2502.14815v1,True,2025-02-20T18:36:25Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=36, tm_sec=25, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T18:36:25Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=36, tm_sec=25, tm_wday=3, tm_yday=51, tm_isdst=0)",Optimizing Model Selection for Compound AI Systems,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Optimizing Model Selection for Compound AI Systems'}","Compound AI systems that combine multiple LLM calls, such as self-refine and
multi-agent-debate, achieve strong performance on many AI tasks. We address a
core question in optimizing compound systems: for each LLM call or module in
the system, how should one decide which LLM to use? We show that these LLM
choices have a large effect on quality, but the search space is exponential. We
propose LLMSelector, an efficient framework for model selection in compound
systems, which leverages two key empirical insights: (i) end-to-end performance
is often monotonic in how well each module performs, with all other modules
held fixed, and (ii) per-module performance can be estimated accurately by an
LLM. Building upon these insights, LLMSelector iteratively selects one module
and allocates to it the model with the highest module-wise performance, as
estimated by an LLM, until no further gain is possible. LLMSelector is
applicable to any compound system with a bounded number of modules, and its
number of API calls scales linearly with the number of modules, achieving
high-quality model allocation both empirically and theoretically. Experiments
with popular compound systems such as multi-agent debate and self-refine using
LLMs such as GPT-4o, Claude 3.5 Sonnet and Gemini 1.5 show that LLMSelector
confers 5%-70% accuracy gains compared to using the same LLM for all modules.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Compound AI systems that combine multiple LLM calls, such as self-refine and\nmulti-agent-debate, achieve strong performance on many AI tasks. We address a\ncore question in optimizing compound systems: for each LLM call or module in\nthe system, how should one decide which LLM to use? We show that these LLM\nchoices have a large effect on quality, but the search space is exponential. We\npropose LLMSelector, an efficient framework for model selection in compound\nsystems, which leverages two key empirical insights: (i) end-to-end performance\nis often monotonic in how well each module performs, with all other modules\nheld fixed, and (ii) per-module performance can be estimated accurately by an\nLLM. Building upon these insights, LLMSelector iteratively selects one module\nand allocates to it the model with the highest module-wise performance, as\nestimated by an LLM, until no further gain is possible. LLMSelector is\napplicable to any compound system with a bounded number of modules, and its\nnumber of API calls scales linearly with the number of modules, achieving\nhigh-quality model allocation both empirically and theoretically. Experiments\nwith popular compound systems such as multi-agent debate and self-refine using\nLLMs such as GPT-4o, Claude 3.5 Sonnet and Gemini 1.5 show that LLMSelector\nconfers 5%-70% accuracy gains compared to using the same LLM for all modules.'}","['Lingjiao Chen', 'Jared Quincy Davis', 'Boris Hanin', 'Peter Bailis', 'Matei Zaharia', 'James Zou', 'Ion Stoica']",{'name': 'Ion Stoica'},Ion Stoica,,"[{'href': 'http://arxiv.org/abs/2502.14815v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14815v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14815v1,None,http://arxiv.org/abs/2502.14815v1,,,4097,0
http://arxiv.org/abs/2502.14820v1,True,2025-02-20T18:41:48Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=41, tm_sec=48, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T18:41:48Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=41, tm_sec=48, tm_wday=3, tm_yday=51, tm_isdst=0)",eC-Tab2Text: Aspect-Based Text Generation from e-Commerce Product Tables,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'eC-Tab2Text: Aspect-Based Text Generation from e-Commerce Product Tables'}","Large Language Models (LLMs) have demonstrated exceptional versatility across
diverse domains, yet their application in e-commerce remains underexplored due
to a lack of domain-specific datasets. To address this gap, we introduce
eC-Tab2Text, a novel dataset designed to capture the intricacies of e-commerce,
including detailed product attributes and user-specific queries. Leveraging
eC-Tab2Text, we focus on text generation from product tables, enabling LLMs to
produce high-quality, attribute-specific product reviews from structured
tabular data. Fine-tuned models were rigorously evaluated using standard
Table2Text metrics, alongside correctness, faithfulness, and fluency
assessments. Our results demonstrate substantial improvements in generating
contextually accurate reviews, highlighting the transformative potential of
tailored datasets and fine-tuning methodologies in optimizing e-commerce
workflows. This work highlights the potential of LLMs in e-commerce workflows
and the essential role of domain-specific datasets in tailoring them to
industry-specific challenges.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large Language Models (LLMs) have demonstrated exceptional versatility across\ndiverse domains, yet their application in e-commerce remains underexplored due\nto a lack of domain-specific datasets. To address this gap, we introduce\neC-Tab2Text, a novel dataset designed to capture the intricacies of e-commerce,\nincluding detailed product attributes and user-specific queries. Leveraging\neC-Tab2Text, we focus on text generation from product tables, enabling LLMs to\nproduce high-quality, attribute-specific product reviews from structured\ntabular data. Fine-tuned models were rigorously evaluated using standard\nTable2Text metrics, alongside correctness, faithfulness, and fluency\nassessments. Our results demonstrate substantial improvements in generating\ncontextually accurate reviews, highlighting the transformative potential of\ntailored datasets and fine-tuning methodologies in optimizing e-commerce\nworkflows. This work highlights the potential of LLMs in e-commerce workflows\nand the essential role of domain-specific datasets in tailoring them to\nindustry-specific challenges.'}","['Luis Antonio Gutirrez Guanilo', 'Mir Tafseer Nayeem', 'Cristian Lpez', 'Davood Rafiei']",{'name': 'Davood Rafiei'},Davood Rafiei,NAACL 2025 (Industry Track),"[{'href': 'http://arxiv.org/abs/2502.14820v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14820v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.DB', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14820v1,None,http://arxiv.org/abs/2502.14820v1,,,284,0
http://arxiv.org/abs/2502.14827v1,True,2025-02-20T18:45:00Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=45, tm_sec=0, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T18:45:00Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=45, tm_sec=0, tm_wday=3, tm_yday=51, tm_isdst=0)","Exploring Advanced Techniques for Visual Question Answering: A
  Comprehensive Comparison","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Exploring Advanced Techniques for Visual Question Answering: A\n  Comprehensive Comparison'}","Visual Question Answering (VQA) has emerged as a pivotal task in the
intersection of computer vision and natural language processing, requiring
models to understand and reason about visual content in response to natural
language questions. Analyzing VQA datasets is essential for developing robust
models that can handle the complexities of multimodal reasoning. Several
approaches have been developed to examine these datasets, each offering
distinct perspectives on question diversity, answer distribution, and
visual-textual correlations. Despite significant progress, existing VQA models
face challenges related to dataset bias, limited model complexity, commonsense
reasoning gaps, rigid evaluation methods, and generalization to real world
scenarios. This paper presents a comprehensive comparative study of five
advanced VQA models: ABC-CNN, KICNLE, Masked Vision and Language Modeling,
BLIP-2, and OFA, each employing distinct methodologies to address these
challenges.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Visual Question Answering (VQA) has emerged as a pivotal task in the\nintersection of computer vision and natural language processing, requiring\nmodels to understand and reason about visual content in response to natural\nlanguage questions. Analyzing VQA datasets is essential for developing robust\nmodels that can handle the complexities of multimodal reasoning. Several\napproaches have been developed to examine these datasets, each offering\ndistinct perspectives on question diversity, answer distribution, and\nvisual-textual correlations. Despite significant progress, existing VQA models\nface challenges related to dataset bias, limited model complexity, commonsense\nreasoning gaps, rigid evaluation methods, and generalization to real world\nscenarios. This paper presents a comprehensive comparative study of five\nadvanced VQA models: ABC-CNN, KICNLE, Masked Vision and Language Modeling,\nBLIP-2, and OFA, each employing distinct methodologies to address these\nchallenges.'}","['Aiswarya Baby', 'Tintu Thankom Koshy']",{'name': 'Tintu Thankom Koshy'},Tintu Thankom Koshy,"8 pages, No figures","[{'href': 'http://arxiv.org/abs/2502.14827v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14827v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.ET', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14827v1,None,http://arxiv.org/abs/2502.14827v1,,,24,0
http://arxiv.org/abs/2502.14831v1,True,2025-02-20T18:45:44Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=45, tm_sec=44, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T18:45:44Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=45, tm_sec=44, tm_wday=3, tm_yday=51, tm_isdst=0)",Improving the Diffusability of Autoencoders,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Improving the Diffusability of Autoencoders'}","Latent diffusion models have emerged as the leading approach for generating
high-quality images and videos, utilizing compressed latent representations to
reduce the computational burden of the diffusion process. While recent
advancements have primarily focused on scaling diffusion backbones and
improving autoencoder reconstruction quality, the interaction between these
components has received comparatively less attention. In this work, we perform
a spectral analysis of modern autoencoders and identify inordinate
high-frequency components in their latent spaces, which are especially
pronounced in the autoencoders with a large bottleneck channel size. We
hypothesize that this high-frequency component interferes with the
coarse-to-fine nature of the diffusion synthesis process and hinders the
generation quality. To mitigate the issue, we propose scale equivariance: a
simple regularization strategy that aligns latent and RGB spaces across
frequencies by enforcing scale equivariance in the decoder. It requires minimal
code changes and only up to 20K autoencoder fine-tuning steps, yet
significantly improves generation quality, reducing FID by 19% for image
generation on ImageNet-1K 256x256 and FVD by at least 44% for video generation
on Kinetics-700 17x256x256.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Latent diffusion models have emerged as the leading approach for generating\nhigh-quality images and videos, utilizing compressed latent representations to\nreduce the computational burden of the diffusion process. While recent\nadvancements have primarily focused on scaling diffusion backbones and\nimproving autoencoder reconstruction quality, the interaction between these\ncomponents has received comparatively less attention. In this work, we perform\na spectral analysis of modern autoencoders and identify inordinate\nhigh-frequency components in their latent spaces, which are especially\npronounced in the autoencoders with a large bottleneck channel size. We\nhypothesize that this high-frequency component interferes with the\ncoarse-to-fine nature of the diffusion synthesis process and hinders the\ngeneration quality. To mitigate the issue, we propose scale equivariance: a\nsimple regularization strategy that aligns latent and RGB spaces across\nfrequencies by enforcing scale equivariance in the decoder. It requires minimal\ncode changes and only up to 20K autoencoder fine-tuning steps, yet\nsignificantly improves generation quality, reducing FID by 19% for image\ngeneration on ImageNet-1K 256x256 and FVD by at least 44% for video generation\non Kinetics-700 17x256x256.'}","['Ivan Skorokhodov', 'Sharath Girish', 'Benran Hu', 'Willi Menapace', 'Yanyu Li', 'Rameen Abdal', 'Sergey Tulyakov', 'Aliaksandr Siarohin']",{'name': 'Aliaksandr Siarohin'},Aliaksandr Siarohin,"26 pages, 22 figures, 9 tables","[{'href': 'http://arxiv.org/abs/2502.14831v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14831v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14831v1,None,http://arxiv.org/abs/2502.14831v1,,,9308,0
http://arxiv.org/abs/2502.14834v1,True,2025-02-20T18:47:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=47, tm_sec=36, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T18:47:36Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=47, tm_sec=36, tm_wday=3, tm_yday=51, tm_isdst=0)","LongWriter-V: Enabling Ultra-Long and High-Fidelity Generation in
  Vision-Language Models","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'LongWriter-V: Enabling Ultra-Long and High-Fidelity Generation in\n  Vision-Language Models'}","Existing Large Vision-Language Models (LVLMs) can process inputs with context
lengths up to 128k visual and text tokens, yet they struggle to generate
coherent outputs beyond 1,000 words. We find that the primary limitation is the
absence of long output examples during supervised fine-tuning (SFT). To tackle
this issue, we introduce LongWriter-V-22k, a SFT dataset comprising 22,158
examples, each with multiple input images, an instruction, and corresponding
outputs ranging from 0 to 10,000 words. Moreover, to achieve long outputs that
maintain high-fidelity to the input images, we employ Direct Preference
Optimization (DPO) to the SFT model. Given the high cost of collecting human
feedback for lengthy outputs (e.g., 3,000 words), we propose IterDPO, which
breaks long outputs into segments and uses iterative corrections to form
preference pairs with the original outputs. Additionally, we develop
MMLongBench-Write, a benchmark featuring six tasks to evaluate the
long-generation capabilities of VLMs. Our 7B parameter model, trained with
LongWriter-V-22k and IterDPO, achieves impressive performance on this
benchmark, outperforming larger proprietary models like GPT-4o. Code and data:
https://github.com/THU-KEG/LongWriter-V","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Existing Large Vision-Language Models (LVLMs) can process inputs with context\nlengths up to 128k visual and text tokens, yet they struggle to generate\ncoherent outputs beyond 1,000 words. We find that the primary limitation is the\nabsence of long output examples during supervised fine-tuning (SFT). To tackle\nthis issue, we introduce LongWriter-V-22k, a SFT dataset comprising 22,158\nexamples, each with multiple input images, an instruction, and corresponding\noutputs ranging from 0 to 10,000 words. Moreover, to achieve long outputs that\nmaintain high-fidelity to the input images, we employ Direct Preference\nOptimization (DPO) to the SFT model. Given the high cost of collecting human\nfeedback for lengthy outputs (e.g., 3,000 words), we propose IterDPO, which\nbreaks long outputs into segments and uses iterative corrections to form\npreference pairs with the original outputs. Additionally, we develop\nMMLongBench-Write, a benchmark featuring six tasks to evaluate the\nlong-generation capabilities of VLMs. Our 7B parameter model, trained with\nLongWriter-V-22k and IterDPO, achieves impressive performance on this\nbenchmark, outperforming larger proprietary models like GPT-4o. Code and data:\nhttps://github.com/THU-KEG/LongWriter-V'}","['Shangqing Tu', 'Yucheng Wang', 'Daniel Zhang-Li', 'Yushi Bai', 'Jifan Yu', 'Yuhao Wu', 'Lei Hou', 'Huiqin Liu', 'Zhiyuan Liu', 'Bin Xu', 'Juanzi Li']",{'name': 'Juanzi Li'},Juanzi Li,,"[{'href': 'http://arxiv.org/abs/2502.14834v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14834v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14834v1,None,http://arxiv.org/abs/2502.14834v1,,,723,0
http://arxiv.org/abs/2502.14856v1,True,2025-02-20T18:58:10Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=58, tm_sec=10, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T18:58:10Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=58, tm_sec=10, tm_wday=3, tm_yday=51, tm_isdst=0)","FR-Spec: Accelerating Large-Vocabulary Language Models via
  Frequency-Ranked Speculative Sampling","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'FR-Spec: Accelerating Large-Vocabulary Language Models via\n  Frequency-Ranked Speculative Sampling'}","Speculative sampling has emerged as an important technique for accelerating
the auto-regressive generation process of large language models (LLMs) by
utilizing a draft-then-verify mechanism to produce multiple tokens per forward
pass. While state-of-the-art speculative sampling methods use only a single
layer and a language modeling (LM) head as the draft model to achieve
impressive layer compression, their efficiency gains are substantially reduced
for large-vocabulary LLMs, such as Llama-3-8B with a vocabulary of 128k tokens.
To address this, we present FR-Spec, a frequency-ranked speculative sampling
framework that optimizes draft candidate selection through vocabulary space
compression. By constraining the draft search to a frequency-prioritized token
subset, our method reduces LM Head computation overhead by 75% while ensuring
the equivalence of the final output distribution. Experiments across multiple
datasets demonstrate an average of 1.12$\times$ speedup over the
state-of-the-art speculative sampling method EAGLE-2.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Speculative sampling has emerged as an important technique for accelerating\nthe auto-regressive generation process of large language models (LLMs) by\nutilizing a draft-then-verify mechanism to produce multiple tokens per forward\npass. While state-of-the-art speculative sampling methods use only a single\nlayer and a language modeling (LM) head as the draft model to achieve\nimpressive layer compression, their efficiency gains are substantially reduced\nfor large-vocabulary LLMs, such as Llama-3-8B with a vocabulary of 128k tokens.\nTo address this, we present FR-Spec, a frequency-ranked speculative sampling\nframework that optimizes draft candidate selection through vocabulary space\ncompression. By constraining the draft search to a frequency-prioritized token\nsubset, our method reduces LM Head computation overhead by 75% while ensuring\nthe equivalence of the final output distribution. Experiments across multiple\ndatasets demonstrate an average of 1.12$\\times$ speedup over the\nstate-of-the-art speculative sampling method EAGLE-2.'}","['Weilin Zhao', 'Tengyu Pan', 'Xu Han', 'Yudi Zhang', 'Ao Sun', 'Yuxiang Huang', 'Kaihuo Zhang', 'Weilun Zhao', 'Yuxuan Li', 'Jianyong Wang', 'Zhiyuan Liu', 'Maosong Sun']",{'name': 'Maosong Sun'},Maosong Sun,,"[{'href': 'http://arxiv.org/abs/2502.14856v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14856v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14856v1,None,http://arxiv.org/abs/2502.14856v1,,,1531,0
http://arxiv.org/abs/2502.14862v1,True,2025-02-20T18:59:34Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=59, tm_sec=34, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T18:59:34Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=59, tm_sec=34, tm_wday=3, tm_yday=51, tm_isdst=0)",Interpretable Text Embeddings and Text Similarity Explanation: A Primer,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Interpretable Text Embeddings and Text Similarity Explanation: A Primer'}","Text embeddings and text embedding models are a backbone of many AI and NLP
systems, particularly those involving search. However, interpretability
challenges persist, especially in explaining obtained similarity scores, which
is crucial for applications requiring transparency. In this paper, we give a
structured overview of interpretability methods specializing in explaining
those similarity scores, an emerging research area. We study the methods'
individual ideas and techniques, evaluating their potential for improving
interpretability of text embeddings and explaining predicted similarities.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Text embeddings and text embedding models are a backbone of many AI and NLP\nsystems, particularly those involving search. However, interpretability\nchallenges persist, especially in explaining obtained similarity scores, which\nis crucial for applications requiring transparency. In this paper, we give a\nstructured overview of interpretability methods specializing in explaining\nthose similarity scores, an emerging research area. We study the methods'\nindividual ideas and techniques, evaluating their potential for improving\ninterpretability of text embeddings and explaining predicted similarities.""}","['Juri Opitz', 'Lucas Mller', 'Andrianos Michail', 'Simon Clematide']",{'name': 'Simon Clematide'},Simon Clematide,,"[{'href': 'http://arxiv.org/abs/2502.14862v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14862v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14862v1,None,http://arxiv.org/abs/2502.14862v1,,,15,0
http://arxiv.org/abs/2502.11190v1,True,2025-02-16T16:31:00Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=16, tm_min=31, tm_sec=0, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T16:31:00Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=16, tm_min=31, tm_sec=0, tm_wday=6, tm_yday=47, tm_isdst=0)",ReLearn: Unlearning via Learning for Large Language Models,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'ReLearn: Unlearning via Learning for Large Language Models'}","Current unlearning methods for large language models usually rely on reverse
optimization to reduce target token probabilities. However, this paradigm
disrupts the subsequent tokens prediction, degrading model performance and
linguistic coherence. Moreover, existing evaluation metrics overemphasize
contextual forgetting while inadequately assessing response fluency and
relevance. To address these challenges, we propose ReLearn, a data augmentation
and fine-tuning pipeline for effective unlearning, along with a comprehensive
evaluation framework. This framework introduces Knowledge Forgetting Rate (KFR)
and Knowledge Retention Rate (KRR) to measure knowledge-level preservation, and
Linguistic Score (LS) to evaluate generation quality. Our experiments show that
ReLearn successfully achieves targeted forgetting while preserving high-quality
output. Through mechanistic analysis, we further demonstrate how reverse
optimization disrupts coherent text generation, while ReLearn preserves this
essential capability. Code is available at https://github.com/zjunlp/unlearn.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Current unlearning methods for large language models usually rely on reverse\noptimization to reduce target token probabilities. However, this paradigm\ndisrupts the subsequent tokens prediction, degrading model performance and\nlinguistic coherence. Moreover, existing evaluation metrics overemphasize\ncontextual forgetting while inadequately assessing response fluency and\nrelevance. To address these challenges, we propose ReLearn, a data augmentation\nand fine-tuning pipeline for effective unlearning, along with a comprehensive\nevaluation framework. This framework introduces Knowledge Forgetting Rate (KFR)\nand Knowledge Retention Rate (KRR) to measure knowledge-level preservation, and\nLinguistic Score (LS) to evaluate generation quality. Our experiments show that\nReLearn successfully achieves targeted forgetting while preserving high-quality\noutput. Through mechanistic analysis, we further demonstrate how reverse\noptimization disrupts coherent text generation, while ReLearn preserves this\nessential capability. Code is available at https://github.com/zjunlp/unlearn.'}","['Haoming Xu', 'Ningyuan Zhao', 'Liming Yang', 'Sendong Zhao', 'Shumin Deng', 'Mengru Wang', 'Bryan Hooi', 'Nay Oo', 'Huajun Chen', 'Ningyu Zhang']",{'name': 'Ningyu Zhang'},Ningyu Zhang,Work in progress,"[{'href': 'http://arxiv.org/abs/2502.11190v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11190v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11190v1,None,http://arxiv.org/abs/2502.11190v1,,,7298,0
http://arxiv.org/abs/2502.11196v1,True,2025-02-16T16:55:43Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=16, tm_min=55, tm_sec=43, tm_wday=6, tm_yday=47, tm_isdst=0)",2025-02-16T16:55:43Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=16, tm_hour=16, tm_min=55, tm_sec=43, tm_wday=6, tm_yday=47, tm_isdst=0)","How Do LLMs Acquire New Knowledge? A Knowledge Circuits Perspective on
  Continual Pre-Training","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'How Do LLMs Acquire New Knowledge? A Knowledge Circuits Perspective on\n  Continual Pre-Training'}","Despite exceptional capabilities in knowledge-intensive tasks, Large Language
Models (LLMs) face a critical gap in understanding how they internalize new
knowledge, particularly how to structurally embed acquired knowledge in their
neural computations. We address this issue through the lens of knowledge
circuit evolution, identifying computational subgraphs that facilitate
knowledge storage and processing. Our systematic analysis of circuit evolution
throughout continual pre-training reveals several key findings: (1) the
acquisition of new knowledge is influenced by its relevance to pre-existing
knowledge; (2) the evolution of knowledge circuits exhibits a distinct phase
shift from formation to optimization; (3) the evolution of knowledge circuits
follows a deep-to-shallow pattern. These insights not only advance our
theoretical understanding of the mechanisms of new knowledge acquisition in
LLMs, but also provide potential implications for improving continual
pre-training strategies to enhance model performance. Code and data will be
available at https://github.com/zjunlp/DynamicKnowledgeCircuits.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Despite exceptional capabilities in knowledge-intensive tasks, Large Language\nModels (LLMs) face a critical gap in understanding how they internalize new\nknowledge, particularly how to structurally embed acquired knowledge in their\nneural computations. We address this issue through the lens of knowledge\ncircuit evolution, identifying computational subgraphs that facilitate\nknowledge storage and processing. Our systematic analysis of circuit evolution\nthroughout continual pre-training reveals several key findings: (1) the\nacquisition of new knowledge is influenced by its relevance to pre-existing\nknowledge; (2) the evolution of knowledge circuits exhibits a distinct phase\nshift from formation to optimization; (3) the evolution of knowledge circuits\nfollows a deep-to-shallow pattern. These insights not only advance our\ntheoretical understanding of the mechanisms of new knowledge acquisition in\nLLMs, but also provide potential implications for improving continual\npre-training strategies to enhance model performance. Code and data will be\navailable at https://github.com/zjunlp/DynamicKnowledgeCircuits.'}","['Yixin Ou', 'Yunzhi Yao', 'Ningyu Zhang', 'Hui Jin', 'Jiacheng Sun', 'Shumin Deng', 'Zhenguo Li', 'Huajun Chen']",{'name': 'Huajun Chen'},Huajun Chen,Work in progress,"[{'href': 'http://arxiv.org/abs/2502.11196v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11196v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11196v1,None,http://arxiv.org/abs/2502.11196v1,,,9614,0
http://arxiv.org/abs/2502.11554v1,True,2025-02-17T08:36:12Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=8, tm_min=36, tm_sec=12, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T08:36:12Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=8, tm_min=36, tm_sec=12, tm_wday=0, tm_yday=48, tm_isdst=0)",Toward Metaphor-Fluid Conversation Design for Voice User Interfaces,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Toward Metaphor-Fluid Conversation Design for Voice User Interfaces'}","Metaphors play a critical role in shaping user experiences with Voice User
Interfaces (VUIs), yet existing designs often rely on static, human-centric
metaphors that fail to adapt to diverse contexts and user needs. This paper
introduces Metaphor-Fluid Design, a novel approach that dynamically adjusts
metaphorical representations based on conversational use-contexts. We compare
this approach to a Default VUI, which characterizes the present implementation
of commercial VUIs commonly designed around the persona of an assistant,
offering a uniform interaction style across contexts. In Study 1 (N=130),
metaphors were mapped to four key use-contexts-commands, information seeking,
sociality, and error recovery-along the dimensions of formality and hierarchy,
revealing distinct preferences for task-specific metaphorical designs. Study 2
(N=91) evaluates a Metaphor-Fluid VUI against a Default VUI, showing that the
Metaphor-Fluid VUI enhances perceived intention to adopt, enjoyment, and
likability by aligning better with user expectations for different contexts.
However, individual differences in metaphor preferences highlight the need for
personalization. These findings challenge the one-size-fits-all paradigm of VUI
design and demonstrate the potential of Metaphor-Fluid Design to create more
adaptive and engaging human-AI interactions.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Metaphors play a critical role in shaping user experiences with Voice User\nInterfaces (VUIs), yet existing designs often rely on static, human-centric\nmetaphors that fail to adapt to diverse contexts and user needs. This paper\nintroduces Metaphor-Fluid Design, a novel approach that dynamically adjusts\nmetaphorical representations based on conversational use-contexts. We compare\nthis approach to a Default VUI, which characterizes the present implementation\nof commercial VUIs commonly designed around the persona of an assistant,\noffering a uniform interaction style across contexts. In Study 1 (N=130),\nmetaphors were mapped to four key use-contexts-commands, information seeking,\nsociality, and error recovery-along the dimensions of formality and hierarchy,\nrevealing distinct preferences for task-specific metaphorical designs. Study 2\n(N=91) evaluates a Metaphor-Fluid VUI against a Default VUI, showing that the\nMetaphor-Fluid VUI enhances perceived intention to adopt, enjoyment, and\nlikability by aligning better with user expectations for different contexts.\nHowever, individual differences in metaphor preferences highlight the need for\npersonalization. These findings challenge the one-size-fits-all paradigm of VUI\ndesign and demonstrate the potential of Metaphor-Fluid Design to create more\nadaptive and engaging human-AI interactions.'}","['Smit Desai', 'Jessie Chin', 'Dakuo Wang', 'Benjamin Cowan', 'Michael Twidale']",{'name': 'Michael Twidale'},Michael Twidale,,"[{'href': 'http://arxiv.org/abs/2502.11554v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11554v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.ET', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11554v1,None,http://arxiv.org/abs/2502.11554v1,,,102,0
http://arxiv.org/abs/2502.11840v1,True,2025-02-17T14:35:16Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=14, tm_min=35, tm_sec=16, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T14:35:16Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=14, tm_min=35, tm_sec=16, tm_wday=0, tm_yday=48, tm_isdst=0)","ChordFormer: A Conformer-Based Architecture for Large-Vocabulary Audio
  Chord Recognition","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'ChordFormer: A Conformer-Based Architecture for Large-Vocabulary Audio\n  Chord Recognition'}","Chord recognition serves as a critical task in music information retrieval
due to the abstract and descriptive nature of chords in music analysis. While
audio chord recognition systems have achieved significant accuracy for small
vocabularies (e.g., major/minor chords), large-vocabulary chord recognition
remains a challenging problem. This complexity also arises from the inherent
long-tail distribution of chords, where rare chord types are underrepresented
in most datasets, leading to insufficient training samples. Effective chord
recognition requires leveraging contextual information from audio sequences,
yet existing models, such as combinations of convolutional neural networks,
bidirectional long short-term memory networks, and bidirectional transformers,
face limitations in capturing long-term dependencies and exhibit suboptimal
performance on large-vocabulary chord recognition tasks. This work proposes
ChordFormer, a novel conformer-based architecture designed to tackle structural
chord recognition (e.g., triads, bass, sevenths) for large vocabularies.
ChordFormer leverages conformer blocks that integrate convolutional neural
networks with transformers, thus enabling the model to capture both local
patterns and global dependencies effectively. By addressing challenges such as
class imbalance through a reweighted loss function and structured chord
representations, ChordFormer outperforms state-of-the-art models, achieving a
2% improvement in frame-wise accuracy and a 6% increase in class-wise accuracy
on large-vocabulary chord datasets. Furthermore, ChordFormer excels in handling
class imbalance, providing robust and balanced recognition across chord types.
This approach bridges the gap between theoretical music knowledge and practical
applications, advancing the field of large-vocabulary chord recognition.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Chord recognition serves as a critical task in music information retrieval\ndue to the abstract and descriptive nature of chords in music analysis. While\naudio chord recognition systems have achieved significant accuracy for small\nvocabularies (e.g., major/minor chords), large-vocabulary chord recognition\nremains a challenging problem. This complexity also arises from the inherent\nlong-tail distribution of chords, where rare chord types are underrepresented\nin most datasets, leading to insufficient training samples. Effective chord\nrecognition requires leveraging contextual information from audio sequences,\nyet existing models, such as combinations of convolutional neural networks,\nbidirectional long short-term memory networks, and bidirectional transformers,\nface limitations in capturing long-term dependencies and exhibit suboptimal\nperformance on large-vocabulary chord recognition tasks. This work proposes\nChordFormer, a novel conformer-based architecture designed to tackle structural\nchord recognition (e.g., triads, bass, sevenths) for large vocabularies.\nChordFormer leverages conformer blocks that integrate convolutional neural\nnetworks with transformers, thus enabling the model to capture both local\npatterns and global dependencies effectively. By addressing challenges such as\nclass imbalance through a reweighted loss function and structured chord\nrepresentations, ChordFormer outperforms state-of-the-art models, achieving a\n2% improvement in frame-wise accuracy and a 6% increase in class-wise accuracy\non large-vocabulary chord datasets. Furthermore, ChordFormer excels in handling\nclass imbalance, providing robust and balanced recognition across chord types.\nThis approach bridges the gap between theoretical music knowledge and practical\napplications, advancing the field of large-vocabulary chord recognition.'}","['Muhammad Waseem Akram', 'Stefano Dettori', 'Valentina Colla', 'Giorgio Carlo Buttazzo']",{'name': 'Giorgio Carlo Buttazzo'},Giorgio Carlo Buttazzo,"13 pages, 4 figures","[{'href': 'http://arxiv.org/abs/2502.11840v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11840v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.SD', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.SD', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11840v1,None,http://arxiv.org/abs/2502.11840v1,,,455,0
http://arxiv.org/abs/2502.11882v1,True,2025-02-17T15:09:45Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=15, tm_min=9, tm_sec=45, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T15:09:45Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=15, tm_min=9, tm_sec=45, tm_wday=0, tm_yday=48, tm_isdst=0)","Leveraging Dual Process Theory in Language Agent Framework for Real-time
  Simultaneous Human-AI Collaboration","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Leveraging Dual Process Theory in Language Agent Framework for Real-time\n  Simultaneous Human-AI Collaboration'}","Agents built on large language models (LLMs) have excelled in turn-by-turn
human-AI collaboration but struggle with simultaneous tasks requiring real-time
interaction. Latency issues and the challenge of inferring variable human
strategies hinder their ability to make autonomous decisions without explicit
instructions. Through experiments with current independent System 1 and System
2 methods, we validate the necessity of using Dual Process Theory (DPT) in
real-time tasks. We propose DPT-Agent, a novel language agent framework that
integrates System 1 and System 2 for efficient real-time simultaneous human-AI
collaboration. DPT-Agent's System 1 uses a Finite-state Machine (FSM) and
code-as-policy for fast, intuitive, and controllable decision-making.
DPT-Agent's System 2 integrates Theory of Mind (ToM) and asynchronous
reflection to infer human intentions and perform reasoning-based autonomous
decisions. We demonstrate the effectiveness of DPT-Agent through further
experiments with rule-based agents and human collaborators, showing significant
improvements over mainstream LLM-based frameworks. To the best of our
knowledge, DPT-Agent is the first language agent framework that achieves
successful real-time simultaneous human-AI collaboration autonomously. Code of
DPT-Agent can be found in https://github.com/sjtu-marl/DPT-Agent.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Agents built on large language models (LLMs) have excelled in turn-by-turn\nhuman-AI collaboration but struggle with simultaneous tasks requiring real-time\ninteraction. Latency issues and the challenge of inferring variable human\nstrategies hinder their ability to make autonomous decisions without explicit\ninstructions. Through experiments with current independent System 1 and System\n2 methods, we validate the necessity of using Dual Process Theory (DPT) in\nreal-time tasks. We propose DPT-Agent, a novel language agent framework that\nintegrates System 1 and System 2 for efficient real-time simultaneous human-AI\ncollaboration. DPT-Agent's System 1 uses a Finite-state Machine (FSM) and\ncode-as-policy for fast, intuitive, and controllable decision-making.\nDPT-Agent's System 2 integrates Theory of Mind (ToM) and asynchronous\nreflection to infer human intentions and perform reasoning-based autonomous\ndecisions. We demonstrate the effectiveness of DPT-Agent through further\nexperiments with rule-based agents and human collaborators, showing significant\nimprovements over mainstream LLM-based frameworks. To the best of our\nknowledge, DPT-Agent is the first language agent framework that achieves\nsuccessful real-time simultaneous human-AI collaboration autonomously. Code of\nDPT-Agent can be found in https://github.com/sjtu-marl/DPT-Agent.""}","['Shao Zhang', 'Xihuai Wang', 'Wenhao Zhang', 'Chaoran Li', 'Junru Song', 'Tingyu Li', 'Lin Qiu', 'Xuezhi Cao', 'Xunliang Cai', 'Wen Yao', 'Weinan Zhang', 'Xinbing Wang', 'Ying Wen']",{'name': 'Ying Wen'},Ying Wen,Preprint under review,"[{'href': 'http://arxiv.org/abs/2502.11882v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11882v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11882v1,None,http://arxiv.org/abs/2502.11882v1,,,103,0
http://arxiv.org/abs/2502.11946v2,True,2025-02-18T07:29:10Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=7, tm_min=29, tm_sec=10, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-17T15:58:56Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=15, tm_min=58, tm_sec=56, tm_wday=0, tm_yday=48, tm_isdst=0)","Step-Audio: Unified Understanding and Generation in Intelligent Speech
  Interaction","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Step-Audio: Unified Understanding and Generation in Intelligent Speech\n  Interaction'}","Real-time speech interaction, serving as a fundamental interface for
human-machine collaboration, holds immense potential. However, current
open-source models face limitations such as high costs in voice data
collection, weakness in dynamic control, and limited intelligence. To address
these challenges, this paper introduces Step-Audio, the first production-ready
open-source solution. Key contributions include: 1) a 130B-parameter unified
speech-text multi-modal model that achieves unified understanding and
generation, with the Step-Audio-Chat version open-sourced; 2) a generative
speech data engine that establishes an affordable voice cloning framework and
produces the open-sourced lightweight Step-Audio-TTS-3B model through
distillation; 3) an instruction-driven fine control system enabling dynamic
adjustments across dialects, emotions, singing, and RAP; 4) an enhanced
cognitive architecture augmented with tool calling and role-playing abilities
to manage complex tasks effectively. Based on our new StepEval-Audio-360
evaluation benchmark, Step-Audio achieves state-of-the-art performance in human
evaluations, especially in terms of instruction following. On open-source
benchmarks like LLaMA Question, shows 9.3% average performance improvement,
demonstrating our commitment to advancing the development of open-source
multi-modal language technologies. Our code and models are available at
https://github.com/stepfun-ai/Step-Audio.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Real-time speech interaction, serving as a fundamental interface for\nhuman-machine collaboration, holds immense potential. However, current\nopen-source models face limitations such as high costs in voice data\ncollection, weakness in dynamic control, and limited intelligence. To address\nthese challenges, this paper introduces Step-Audio, the first production-ready\nopen-source solution. Key contributions include: 1) a 130B-parameter unified\nspeech-text multi-modal model that achieves unified understanding and\ngeneration, with the Step-Audio-Chat version open-sourced; 2) a generative\nspeech data engine that establishes an affordable voice cloning framework and\nproduces the open-sourced lightweight Step-Audio-TTS-3B model through\ndistillation; 3) an instruction-driven fine control system enabling dynamic\nadjustments across dialects, emotions, singing, and RAP; 4) an enhanced\ncognitive architecture augmented with tool calling and role-playing abilities\nto manage complex tasks effectively. Based on our new StepEval-Audio-360\nevaluation benchmark, Step-Audio achieves state-of-the-art performance in human\nevaluations, especially in terms of instruction following. On open-source\nbenchmarks like LLaMA Question, shows 9.3% average performance improvement,\ndemonstrating our commitment to advancing the development of open-source\nmulti-modal language technologies. Our code and models are available at\nhttps://github.com/stepfun-ai/Step-Audio.'}","['Ailin Huang', 'Boyong Wu', 'Bruce Wang', 'Chao Yan', 'Chen Hu', 'Chengli Feng', 'Fei Tian', 'Feiyu Shen', 'Jingbei Li', 'Mingrui Chen', 'Peng Liu', 'Ruihang Miao', 'Wang You', 'Xi Chen', 'Xuerui Yang', 'Yechang Huang', 'Yuxiang Zhang', 'Zheng Gong', 'Zixin Zhang', 'Hongyu Zhou', 'Jianjian Sun', 'Brian Li', 'Chengting Feng', 'Changyi Wan', 'Hanpeng Hu', 'Jianchang Wu', 'Jiangjie Zhen', 'Ranchen Ming', 'Song Yuan', 'Xuelin Zhang', 'Yu Zhou', 'Bingxin Li', 'Buyun Ma', 'Hongyuan Wang', 'Kang An', 'Wei Ji', 'Wen Li', 'Xuan Wen', 'Xiangwen Kong', 'Yuankai Ma', 'Yuanwei Liang', 'Yun Mou', 'Bahtiyar Ahmidi', 'Bin Wang', 'Bo Li', 'Changxin Miao', 'Chen Xu', 'Chenrun Wang', 'Dapeng Shi', 'Deshan Sun', 'Dingyuan Hu', 'Dula Sai', 'Enle Liu', 'Guanzhe Huang', 'Gulin Yan', 'Heng Wang', 'Haonan Jia', 'Haoyang Zhang', 'Jiahao Gong', 'Junjing Guo', 'Jiashuai Liu', 'Jiahong Liu', 'Jie Feng', 'Jie Wu', 'Jiaoren Wu', 'Jie Yang', 'Jinguo Wang', 'Jingyang Zhang', 'Junzhe Lin', 'Kaixiang Li', 'Lei Xia', 'Li Zhou', 'Liang Zhao', 'Longlong Gu', 'Mei Chen', 'Menglin Wu', 'Ming Li', 'Mingxiao Li', 'Mingliang Li', 'Mingyao Liang', 'Na Wang', 'Nie Hao', 'Qiling Wu', 'Qinyuan Tan', 'Ran Sun', 'Shuai Shuai', 'Shaoliang Pang', 'Shiliang Yang', 'Shuli Gao', 'Shanshan Yuan', 'Siqi Liu', 'Shihong Deng', 'Shilei Jiang', 'Sitong Liu', 'Tiancheng Cao', 'Tianyu Wang', 'Wenjin Deng', 'Wuxun Xie', 'Weipeng Ming', 'Wenqing He', 'Wen Sun', 'Xin Han', 'Xin Huang', 'Xiaomin Deng', 'Xiaojia Liu', 'Xin Wu', 'Xu Zhao', 'Yanan Wei', 'Yanbo Yu', 'Yang Cao', 'Yangguang Li', 'Yangzhen Ma', 'Yanming Xu', 'Yaoyu Wang', 'Yaqiang Shi', 'Yilei Wang', 'Yizhuang Zhou', 'Yinmin Zhong', 'Yang Zhang', 'Yaoben Wei', 'Yu Luo', 'Yuanwei Lu', 'Yuhe Yin', 'Yuchu Luo', 'Yuanhao Ding', 'Yuting Yan', 'Yaqi Dai', 'Yuxiang Yang', 'Zhe Xie', 'Zheng Ge', 'Zheng Sun', 'Zhewei Huang', 'Zhichao Chang', 'Zhisheng Guan', 'Zidong Yang', 'Zili Zhang', 'Binxing Jiao', 'Daxin Jiang', 'Heung-Yeung Shum', 'Jiansheng Chen', 'Jing Li', 'Shuchang Zhou', 'Xiangyu Zhang', 'Xinhao Zhang', 'Yibo Zhu']",{'name': 'Yibo Zhu'},Yibo Zhu,,"[{'href': 'http://arxiv.org/abs/2502.11946v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.11946v2', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SD', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'eess.AS', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.11946v2,None,http://arxiv.org/abs/2502.11946v2,,,8984,0
http://arxiv.org/abs/2502.12327v1,True,2025-02-17T21:19:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=21, tm_min=19, tm_sec=15, tm_wday=0, tm_yday=48, tm_isdst=0)",2025-02-17T21:19:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=17, tm_hour=21, tm_min=19, tm_sec=15, tm_wday=0, tm_yday=48, tm_isdst=0)","Learning Plasma Dynamics and Robust Rampdown Trajectories with
  Predict-First Experiments at TCV","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Learning Plasma Dynamics and Robust Rampdown Trajectories with\n  Predict-First Experiments at TCV'}","The rampdown in tokamak operations is a difficult to simulate phase during
which the plasma is often pushed towards multiple instability limits. To
address this challenge, and reduce the risk of disrupting operations, we
leverage recent advances in Scientific Machine Learning (SciML) to develop a
neural state-space model (NSSM) that predicts plasma dynamics during Tokamak
\`a Configuration Variable (TCV) rampdowns. By integrating simple physics
structure and data-driven models, the NSSM efficiently learns plasma dynamics
during the rampdown from a modest dataset of 311 pulses with only five pulses
in the reactor relevant high performance regime. The NSSM is parallelized
across uncertainties, and reinforcement learning (RL) is applied to design
trajectories that avoid multiple instability limits with high probability.
Experiments at TCV ramping down high performance plasmas show statistically
significant improvements in current and energy at plasma termination, with
improvements in speed through continuous re-training. A predict-first
experiment, increasing plasma current by 20\% from baseline, demonstrates the
NSSM's ability to make small extrapolations with sufficient accuracy to design
trajectories that successfully terminate the pulse. The developed approach
paves the way for designing tokamak controls with robustness to considerable
uncertainty, and demonstrates the relevance of the SciML approach to learning
plasma dynamics for rapidly developing robust trajectories and controls during
the incremental campaigns of upcoming burning plasma tokamaks.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""The rampdown in tokamak operations is a difficult to simulate phase during\nwhich the plasma is often pushed towards multiple instability limits. To\naddress this challenge, and reduce the risk of disrupting operations, we\nleverage recent advances in Scientific Machine Learning (SciML) to develop a\nneural state-space model (NSSM) that predicts plasma dynamics during Tokamak\n\\`a Configuration Variable (TCV) rampdowns. By integrating simple physics\nstructure and data-driven models, the NSSM efficiently learns plasma dynamics\nduring the rampdown from a modest dataset of 311 pulses with only five pulses\nin the reactor relevant high performance regime. The NSSM is parallelized\nacross uncertainties, and reinforcement learning (RL) is applied to design\ntrajectories that avoid multiple instability limits with high probability.\nExperiments at TCV ramping down high performance plasmas show statistically\nsignificant improvements in current and energy at plasma termination, with\nimprovements in speed through continuous re-training. A predict-first\nexperiment, increasing plasma current by 20\\% from baseline, demonstrates the\nNSSM's ability to make small extrapolations with sufficient accuracy to design\ntrajectories that successfully terminate the pulse. The developed approach\npaves the way for designing tokamak controls with robustness to considerable\nuncertainty, and demonstrates the relevance of the SciML approach to learning\nplasma dynamics for rapidly developing robust trajectories and controls during\nthe incremental campaigns of upcoming burning plasma tokamaks.""}","['Allen M. Wang', 'Alessandro Pau', 'Cristina Rea', 'Oswin So', 'Charles Dawson', 'Olivier Sauter', 'Mark D. Boyer', 'Anna Vu', 'Cristian Galperti', 'Chuchu Fan', 'Antoine Merle', 'Yoeri Poels', 'Cristina Venturini', 'Stefano Marchioni', 'the TCV Team']",{'name': 'the TCV Team'},the TCV Team,,"[{'href': 'http://arxiv.org/abs/2502.12327v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12327v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'physics.plasm-ph', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'physics.plasm-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'eess.SY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12327v1,None,http://arxiv.org/abs/2502.12327v1,,,3296,0
http://arxiv.org/abs/2502.12397v1,True,2025-02-18T00:11:08Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=0, tm_min=11, tm_sec=8, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T00:11:08Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=0, tm_min=11, tm_sec=8, tm_wday=1, tm_yday=49, tm_isdst=0)",Could AI Leapfrog the Web? Evidence from Teachers in Sierra Leone,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Could AI Leapfrog the Web? Evidence from Teachers in Sierra Leone'}","Access to digital information is a driver of economic development. But
although 85% of sub-Saharan Africa's population is covered by mobile broadband
signal, only 37% use the internet, and those who do seldom use the web. We
investigate whether AI can bridge this gap by analyzing how 469 teachers use an
AI chatbot in Sierra Leone. The chatbot, accessible via a common messaging app,
is compared against traditional web search. Teachers use AI more frequently
than web search for teaching assistance. Data cost is the most frequently cited
reason for low internet usage across Africa. The average web search result
consumes 3,107 times more data than an AI response, making AI 87% less
expensive than web search. Additionally, only 2% of results for corresponding
web searches contain content from Sierra Leone. In blinded evaluations, an
independent sample of teachers rate AI responses as more relevant, helpful, and
correct than web search results. These findings suggest that AI-driven
solutions can cost-effectively bridge information gaps in low-connectivity
regions.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Access to digital information is a driver of economic development. But\nalthough 85% of sub-Saharan Africa's population is covered by mobile broadband\nsignal, only 37% use the internet, and those who do seldom use the web. We\ninvestigate whether AI can bridge this gap by analyzing how 469 teachers use an\nAI chatbot in Sierra Leone. The chatbot, accessible via a common messaging app,\nis compared against traditional web search. Teachers use AI more frequently\nthan web search for teaching assistance. Data cost is the most frequently cited\nreason for low internet usage across Africa. The average web search result\nconsumes 3,107 times more data than an AI response, making AI 87% less\nexpensive than web search. Additionally, only 2% of results for corresponding\nweb searches contain content from Sierra Leone. In blinded evaluations, an\nindependent sample of teachers rate AI responses as more relevant, helpful, and\ncorrect than web search results. These findings suggest that AI-driven\nsolutions can cost-effectively bridge information gaps in low-connectivity\nregions.""}","['Daniel Bjrkegren', 'Jun Ho Choi', 'Divya Budihal', 'Dominic Sobhani', 'Oliver Garrod', 'Paul Atherton']",{'name': 'Paul Atherton'},Paul Atherton,,"[{'href': 'http://arxiv.org/abs/2502.12397v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12397v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'econ.GN', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-fin.EC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12397v1,None,http://arxiv.org/abs/2502.12397v1,,,10,0
http://arxiv.org/abs/2502.12466v1,True,2025-02-18T02:54:25Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=2, tm_min=54, tm_sec=25, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T02:54:25Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=2, tm_min=54, tm_sec=25, tm_wday=1, tm_yday=49, tm_isdst=0)","EquiBench: Benchmarking Code Reasoning Capabilities of Large Language
  Models via Equivalence Checking","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'EquiBench: Benchmarking Code Reasoning Capabilities of Large Language\n  Models via Equivalence Checking'}","Equivalence checking, i.e., determining whether two programs produce
identical outputs for all possible inputs, underpins a broad range of
applications, including software refactoring, testing, and optimization. We
present the task of equivalence checking as a new way to evaluate the code
reasoning abilities of large language models (LLMs). We introduce EquiBench, a
dataset of 2400 program pairs spanning four programming languages and six
equivalence categories. These pairs are systematically generated through
program analysis, compiler scheduling, and superoptimization, covering
nontrivial structural transformations that demand deep semantic reasoning
beyond simple syntactic variations. Our evaluation of 17 state-of-the-art LLMs
shows that OpenAI o3-mini achieves the highest overall accuracy of 78.0%. In
the most challenging categories, the best accuracies are 62.3% and 68.8%, only
modestly above the 50% random baseline for binary classification, indicating
significant room for improvement in current models' code reasoning
capabilities.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Equivalence checking, i.e., determining whether two programs produce\nidentical outputs for all possible inputs, underpins a broad range of\napplications, including software refactoring, testing, and optimization. We\npresent the task of equivalence checking as a new way to evaluate the code\nreasoning abilities of large language models (LLMs). We introduce EquiBench, a\ndataset of 2400 program pairs spanning four programming languages and six\nequivalence categories. These pairs are systematically generated through\nprogram analysis, compiler scheduling, and superoptimization, covering\nnontrivial structural transformations that demand deep semantic reasoning\nbeyond simple syntactic variations. Our evaluation of 17 state-of-the-art LLMs\nshows that OpenAI o3-mini achieves the highest overall accuracy of 78.0%. In\nthe most challenging categories, the best accuracies are 62.3% and 68.8%, only\nmodestly above the 50% random baseline for binary classification, indicating\nsignificant room for improvement in current models' code reasoning\ncapabilities.""}","['Anjiang Wei', 'Jiannan Cao', 'Ran Li', 'Hongyu Chen', 'Yuhui Zhang', 'Ziheng Wang', 'Yaofeng Sun', 'Yuan Liu', 'Thiago S. F. X. Teixeira', 'Diyi Yang', 'Ke Wang', 'Alex Aiken']",{'name': 'Alex Aiken'},Alex Aiken,,"[{'href': 'http://arxiv.org/abs/2502.12466v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12466v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.PL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12466v1,None,http://arxiv.org/abs/2502.12466v1,,,3,0
http://arxiv.org/abs/2502.12623v1,True,2025-02-18T08:09:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=8, tm_min=9, tm_sec=42, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T08:09:42Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=8, tm_min=9, tm_sec=42, tm_wday=1, tm_yday=49, tm_isdst=0)","DeepResonance: Enhancing Multimodal Music Understanding via
  Music-centric Multi-way Instruction Tuning","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'DeepResonance: Enhancing Multimodal Music Understanding via\n  Music-centric Multi-way Instruction Tuning'}","Recent advancements in music large language models (LLMs) have significantly
improved music understanding tasks, which involve the model's ability to
analyze and interpret various musical elements. These improvements primarily
focused on integrating both music and text inputs. However, the potential of
incorporating additional modalities such as images, videos and textual music
features to enhance music understanding remains unexplored. To bridge this gap,
we propose DeepResonance, a multimodal music understanding LLM fine-tuned via
multi-way instruction tuning with multi-way aligned music, text, image, and
video data. To this end, we construct Music4way-MI2T, Music4way-MV2T, and
Music4way-Any2T, three 4-way training and evaluation datasets designed to
enable DeepResonance to integrate both visual and textual music feature
content. We also introduce multi-sampled ImageBind embeddings and a
pre-alignment Transformer to enhance modality fusion prior to input into text
LLMs, tailoring DeepResonance for multi-way instruction tuning. Our model
achieves state-of-the-art performances across six music understanding tasks,
highlighting the benefits of the auxiliary modalities and the structural
superiority of DeepResonance. We plan to open-source the models and the newly
constructed datasets.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Recent advancements in music large language models (LLMs) have significantly\nimproved music understanding tasks, which involve the model's ability to\nanalyze and interpret various musical elements. These improvements primarily\nfocused on integrating both music and text inputs. However, the potential of\nincorporating additional modalities such as images, videos and textual music\nfeatures to enhance music understanding remains unexplored. To bridge this gap,\nwe propose DeepResonance, a multimodal music understanding LLM fine-tuned via\nmulti-way instruction tuning with multi-way aligned music, text, image, and\nvideo data. To this end, we construct Music4way-MI2T, Music4way-MV2T, and\nMusic4way-Any2T, three 4-way training and evaluation datasets designed to\nenable DeepResonance to integrate both visual and textual music feature\ncontent. We also introduce multi-sampled ImageBind embeddings and a\npre-alignment Transformer to enhance modality fusion prior to input into text\nLLMs, tailoring DeepResonance for multi-way instruction tuning. Our model\nachieves state-of-the-art performances across six music understanding tasks,\nhighlighting the benefits of the auxiliary modalities and the structural\nsuperiority of DeepResonance. We plan to open-source the models and the newly\nconstructed datasets.""}","['Zhuoyuan Mao', 'Mengjie Zhao', 'Qiyu Wu', 'Hiromi Wakaki', 'Yuki Mitsufuji']",{'name': 'Yuki Mitsufuji'},Yuki Mitsufuji,,"[{'href': 'http://arxiv.org/abs/2502.12623v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.12623v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.SD', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.SD', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.MM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'eess.AS', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.12623v1,None,http://arxiv.org/abs/2502.12623v1,,,259,0
http://arxiv.org/abs/2502.13130v1,True,2025-02-18T18:55:21Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=55, tm_sec=21, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T18:55:21Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=55, tm_sec=21, tm_wday=1, tm_yday=49, tm_isdst=0)",Magma: A Foundation Model for Multimodal AI Agents,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Magma: A Foundation Model for Multimodal AI Agents'}","We present Magma, a foundation model that serves multimodal AI agentic tasks
in both the digital and physical worlds. Magma is a significant extension of
vision-language (VL) models in that it not only retains the VL understanding
ability (verbal intelligence) of the latter, but is also equipped with the
ability to plan and act in the visual-spatial world (spatial-temporal
intelligence) and complete agentic tasks ranging from UI navigation to robot
manipulation. To endow the agentic capabilities, Magma is pretrained on large
amounts of heterogeneous datasets spanning from images, videos to robotics
data, where the actionable visual objects (e.g., clickable buttons in GUI) in
images are labeled by Set-of-Mark (SoM) for action grounding, and the object
movements (e.g., the trace of human hands or robotic arms) in videos are
labeled by Trace-of-Mark (ToM) for action planning. Extensive experiments show
that SoM and ToM reach great synergy and facilitate the acquisition of
spatial-temporal intelligence for our Magma model, which is fundamental to a
wide range of tasks as shown in Fig.1. In particular, Magma creates new
state-of-the-art results on UI navigation and robotic manipulation tasks,
outperforming previous models that are specifically tailored to these tasks. On
image and video-related multimodal tasks, Magma also compares favorably to
popular large multimodal models that are trained on much larger datasets. We
make our model and code public for reproducibility at
https://microsoft.github.io/Magma.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'We present Magma, a foundation model that serves multimodal AI agentic tasks\nin both the digital and physical worlds. Magma is a significant extension of\nvision-language (VL) models in that it not only retains the VL understanding\nability (verbal intelligence) of the latter, but is also equipped with the\nability to plan and act in the visual-spatial world (spatial-temporal\nintelligence) and complete agentic tasks ranging from UI navigation to robot\nmanipulation. To endow the agentic capabilities, Magma is pretrained on large\namounts of heterogeneous datasets spanning from images, videos to robotics\ndata, where the actionable visual objects (e.g., clickable buttons in GUI) in\nimages are labeled by Set-of-Mark (SoM) for action grounding, and the object\nmovements (e.g., the trace of human hands or robotic arms) in videos are\nlabeled by Trace-of-Mark (ToM) for action planning. Extensive experiments show\nthat SoM and ToM reach great synergy and facilitate the acquisition of\nspatial-temporal intelligence for our Magma model, which is fundamental to a\nwide range of tasks as shown in Fig.1. In particular, Magma creates new\nstate-of-the-art results on UI navigation and robotic manipulation tasks,\noutperforming previous models that are specifically tailored to these tasks. On\nimage and video-related multimodal tasks, Magma also compares favorably to\npopular large multimodal models that are trained on much larger datasets. We\nmake our model and code public for reproducibility at\nhttps://microsoft.github.io/Magma.'}","['Jianwei Yang', 'Reuben Tan', 'Qianhui Wu', 'Ruijie Zheng', 'Baolin Peng', 'Yongyuan Liang', 'Yu Gu', 'Mu Cai', 'Seonghyeon Ye', 'Joel Jang', 'Yuquan Deng', 'Lars Liden', 'Jianfeng Gao']",{'name': 'Jianfeng Gao'},Jianfeng Gao,"29 pages, 16 figures, technical report from MSR","[{'href': 'http://arxiv.org/abs/2502.13130v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13130v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.HC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13130v1,None,http://arxiv.org/abs/2502.13130v1,,,6470,0
http://arxiv.org/abs/2502.13233v1,True,2025-02-18T19:12:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=19, tm_min=12, tm_sec=15, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T19:12:15Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=19, tm_min=12, tm_sec=15, tm_wday=1, tm_yday=49, tm_isdst=0)","SearchRAG: Can Search Engines Be Helpful for LLM-based Medical Question
  Answering?","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'SearchRAG: Can Search Engines Be Helpful for LLM-based Medical Question\n  Answering?'}","Large Language Models (LLMs) have shown remarkable capabilities in general
domains but often struggle with tasks requiring specialized knowledge.
Conventional Retrieval-Augmented Generation (RAG) techniques typically retrieve
external information from static knowledge bases, which can be outdated or
incomplete, missing fine-grained clinical details essential for accurate
medical question answering. In this work, we propose SearchRAG, a novel
framework that overcomes these limitations by leveraging real-time search
engines. Our method employs synthetic query generation to convert complex
medical questions into search-engine-friendly queries and utilizes
uncertainty-based knowledge selection to filter and incorporate the most
relevant and informative medical knowledge into the LLM's input. Experimental
results demonstrate that our method significantly improves response accuracy in
medical question answering tasks, particularly for complex questions requiring
detailed and up-to-date knowledge.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Large Language Models (LLMs) have shown remarkable capabilities in general\ndomains but often struggle with tasks requiring specialized knowledge.\nConventional Retrieval-Augmented Generation (RAG) techniques typically retrieve\nexternal information from static knowledge bases, which can be outdated or\nincomplete, missing fine-grained clinical details essential for accurate\nmedical question answering. In this work, we propose SearchRAG, a novel\nframework that overcomes these limitations by leveraging real-time search\nengines. Our method employs synthetic query generation to convert complex\nmedical questions into search-engine-friendly queries and utilizes\nuncertainty-based knowledge selection to filter and incorporate the most\nrelevant and informative medical knowledge into the LLM's input. Experimental\nresults demonstrate that our method significantly improves response accuracy in\nmedical question answering tasks, particularly for complex questions requiring\ndetailed and up-to-date knowledge.""}","['Yucheng Shi', 'Tianze Yang', 'Canyu Chen', 'Quanzheng Li', 'Tianming Liu', 'Xiang Li', 'Ninghao Liu']",{'name': 'Ninghao Liu'},Ninghao Liu,"8 pages, three figures","[{'href': 'http://arxiv.org/abs/2502.13233v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13233v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.IT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13233v1,None,http://arxiv.org/abs/2502.13233v1,,,1159,0
http://arxiv.org/abs/2502.13398v1,True,2025-02-19T03:14:11Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=3, tm_min=14, tm_sec=11, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T03:14:11Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=3, tm_min=14, tm_sec=11, tm_wday=2, tm_yday=50, tm_isdst=0)","$\mathtt{GeLLM^3O}$: Generalizing Large Language Models for
  Multi-property Molecule Optimization","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': '$\\mathtt{GeLLM^3O}$: Generalizing Large Language Models for\n  Multi-property Molecule Optimization'}","Despite recent advancements, most computational methods for molecule
optimization are constrained to single- or double-property optimization tasks
and suffer from poor scalability and generalizability to novel optimization
tasks. Meanwhile, Large Language Models (LLMs) demonstrate remarkable
out-of-domain generalizability to novel tasks. To demonstrate LLMs' potential
for molecule optimization, we introduce $\mathtt{MoMUInstruct}$, the first
high-quality instruction-tuning dataset specifically focused on complex
multi-property molecule optimization tasks. Leveraging $\mathtt{MoMUInstruct}$,
we develop $\mathtt{GeLLM^3O}$s, a series of instruction-tuned LLMs for
molecule optimization. Extensive evaluations across 5 in-domain and 5
out-of-domain tasks demonstrate that $\mathtt{GeLLM^3O}$s consistently
outperform state-of-the-art baselines. $\mathtt{GeLLM^3O}$s also exhibit
outstanding zero-shot generalization to unseen tasks, significantly
outperforming powerful closed-source LLMs. Such strong generalizability
demonstrates the tremendous potential of $\mathtt{GeLLM^3O}$s as foundational
models for molecule optimization, thereby tackling novel optimization tasks
without resource-intensive retraining. $\mathtt{MoMUInstruct}$, models, and
code are accessible through https://github.com/ninglab/GeLLMO.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""Despite recent advancements, most computational methods for molecule\noptimization are constrained to single- or double-property optimization tasks\nand suffer from poor scalability and generalizability to novel optimization\ntasks. Meanwhile, Large Language Models (LLMs) demonstrate remarkable\nout-of-domain generalizability to novel tasks. To demonstrate LLMs' potential\nfor molecule optimization, we introduce $\\mathtt{MoMUInstruct}$, the first\nhigh-quality instruction-tuning dataset specifically focused on complex\nmulti-property molecule optimization tasks. Leveraging $\\mathtt{MoMUInstruct}$,\nwe develop $\\mathtt{GeLLM^3O}$s, a series of instruction-tuned LLMs for\nmolecule optimization. Extensive evaluations across 5 in-domain and 5\nout-of-domain tasks demonstrate that $\\mathtt{GeLLM^3O}$s consistently\noutperform state-of-the-art baselines. $\\mathtt{GeLLM^3O}$s also exhibit\noutstanding zero-shot generalization to unseen tasks, significantly\noutperforming powerful closed-source LLMs. Such strong generalizability\ndemonstrates the tremendous potential of $\\mathtt{GeLLM^3O}$s as foundational\nmodels for molecule optimization, thereby tackling novel optimization tasks\nwithout resource-intensive retraining. $\\mathtt{MoMUInstruct}$, models, and\ncode are accessible through https://github.com/ninglab/GeLLMO.""}","['Vishal Dey', 'Xiao Hu', 'Xia Ning']",{'name': 'Xia Ning'},Xia Ning,Vishal Dey and Xiao Hu contributed equally to this paper,"[{'href': 'http://arxiv.org/abs/2502.13398v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13398v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.chem-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-bio.QM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13398v1,None,http://arxiv.org/abs/2502.13398v1,,,8,0
http://arxiv.org/abs/2502.13440v1,True,2025-02-19T05:31:13Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=5, tm_min=31, tm_sec=13, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T05:31:13Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=5, tm_min=31, tm_sec=13, tm_wday=2, tm_yday=50, tm_isdst=0)",Semi-supervised classification of bird vocalizations,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Semi-supervised classification of bird vocalizations'}","Changes in bird populations can indicate broader changes in ecosystems,
making birds one of the most important animal groups to monitor. Combining
machine learning and passive acoustics enables continuous monitoring over
extended periods without direct human involvement. However, most existing
techniques require extensive expert-labeled datasets for training and cannot
easily detect time-overlapping calls in busy soundscapes. We propose a
semi-supervised acoustic bird detector designed to allow both the detection of
time-overlapping calls (when separated in frequency) and the use of few labeled
training samples. The classifier is trained and evaluated on a combination of
community-recorded open-source data and long-duration soundscape recordings
from Singapore. It achieves a mean F0.5 score of 0.701 across 315 classes from
110 bird species on a hold-out test set, with an average of 11 labeled training
samples per class. It outperforms the state-of-the-art BirdNET classifier on a
test set of 103 bird species despite significantly fewer labeled training
samples. The detector is further tested on 144 microphone-hours of continuous
soundscape data. The rich soundscape in Singapore makes suppression of false
positives a challenge on raw, continuous data streams. Nevertheless, we
demonstrate that achieving high precision in such environments with minimal
labeled training data is possible.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Changes in bird populations can indicate broader changes in ecosystems,\nmaking birds one of the most important animal groups to monitor. Combining\nmachine learning and passive acoustics enables continuous monitoring over\nextended periods without direct human involvement. However, most existing\ntechniques require extensive expert-labeled datasets for training and cannot\neasily detect time-overlapping calls in busy soundscapes. We propose a\nsemi-supervised acoustic bird detector designed to allow both the detection of\ntime-overlapping calls (when separated in frequency) and the use of few labeled\ntraining samples. The classifier is trained and evaluated on a combination of\ncommunity-recorded open-source data and long-duration soundscape recordings\nfrom Singapore. It achieves a mean F0.5 score of 0.701 across 315 classes from\n110 bird species on a hold-out test set, with an average of 11 labeled training\nsamples per class. It outperforms the state-of-the-art BirdNET classifier on a\ntest set of 103 bird species despite significantly fewer labeled training\nsamples. The detector is further tested on 144 microphone-hours of continuous\nsoundscape data. The rich soundscape in Singapore makes suppression of false\npositives a challenge on raw, continuous data streams. Nevertheless, we\ndemonstrate that achieving high precision in such environments with minimal\nlabeled training data is possible.'}","['Simen Hexeberg', 'Mandar Chitre', 'Matthias Hoffmann-Kuhnt', 'Bing Wen Low']",{'name': 'Bing Wen Low'},Bing Wen Low,,"[{'href': 'http://arxiv.org/abs/2502.13440v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13440v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.SD', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.SD', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'eess.AS', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-bio.QM', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13440v1,None,http://arxiv.org/abs/2502.13440v1,,,4969,0
http://arxiv.org/abs/2502.13606v1,True,2025-02-19T10:37:04Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=10, tm_min=37, tm_sec=4, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T10:37:04Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=10, tm_min=37, tm_sec=4, tm_wday=2, tm_yday=50, tm_isdst=0)",LaVCa: LLM-assisted Visual Cortex Captioning,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'LaVCa: LLM-assisted Visual Cortex Captioning'}","Understanding the property of neural populations (or voxels) in the human
brain can advance our comprehension of human perceptual and cognitive
processing capabilities and contribute to developing brain-inspired computer
models. Recent encoding models using deep neural networks (DNNs) have
successfully predicted voxel-wise activity. However, interpreting the
properties that explain voxel responses remains challenging because of the
black-box nature of DNNs. As a solution, we propose LLM-assisted Visual Cortex
Captioning (LaVCa), a data-driven approach that uses large language models
(LLMs) to generate natural-language captions for images to which voxels are
selective. By applying LaVCa for image-evoked brain activity, we demonstrate
that LaVCa generates captions that describe voxel selectivity more accurately
than the previously proposed method. Furthermore, the captions generated by
LaVCa quantitatively capture more detailed properties than the existing method
at both the inter-voxel and intra-voxel levels. Furthermore, a more detailed
analysis of the voxel-specific properties generated by LaVCa reveals
fine-grained functional differentiation within regions of interest (ROIs) in
the visual cortex and voxels that simultaneously represent multiple distinct
concepts. These findings offer profound insights into human visual
representations by assigning detailed captions throughout the visual cortex
while highlighting the potential of LLM-based methods in understanding brain
representations. Please check out our webpage at
https://sites.google.com/view/lavca-llm/","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Understanding the property of neural populations (or voxels) in the human\nbrain can advance our comprehension of human perceptual and cognitive\nprocessing capabilities and contribute to developing brain-inspired computer\nmodels. Recent encoding models using deep neural networks (DNNs) have\nsuccessfully predicted voxel-wise activity. However, interpreting the\nproperties that explain voxel responses remains challenging because of the\nblack-box nature of DNNs. As a solution, we propose LLM-assisted Visual Cortex\nCaptioning (LaVCa), a data-driven approach that uses large language models\n(LLMs) to generate natural-language captions for images to which voxels are\nselective. By applying LaVCa for image-evoked brain activity, we demonstrate\nthat LaVCa generates captions that describe voxel selectivity more accurately\nthan the previously proposed method. Furthermore, the captions generated by\nLaVCa quantitatively capture more detailed properties than the existing method\nat both the inter-voxel and intra-voxel levels. Furthermore, a more detailed\nanalysis of the voxel-specific properties generated by LaVCa reveals\nfine-grained functional differentiation within regions of interest (ROIs) in\nthe visual cortex and voxels that simultaneously represent multiple distinct\nconcepts. These findings offer profound insights into human visual\nrepresentations by assigning detailed captions throughout the visual cortex\nwhile highlighting the potential of LLM-based methods in understanding brain\nrepresentations. Please check out our webpage at\nhttps://sites.google.com/view/lavca-llm/'}","['Takuya Matsuyama', 'Shinji Nishimoto', 'Yu Takagi']",{'name': 'Yu Takagi'},Yu Takagi,33 pages,"[{'href': 'http://arxiv.org/abs/2502.13606v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13606v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'q-bio.NC', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'q-bio.NC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13606v1,None,http://arxiv.org/abs/2502.13606v1,,,16,0
http://arxiv.org/abs/2502.13870v1,True,2025-02-19T16:49:55Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=16, tm_min=49, tm_sec=55, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T16:49:55Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=16, tm_min=49, tm_sec=55, tm_wday=2, tm_yday=50, tm_isdst=0)",SPEX: Scaling Feature Interaction Explanations for LLMs,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'SPEX: Scaling Feature Interaction Explanations for LLMs'}","Large language models (LLMs) have revolutionized machine learning due to
their ability to capture complex interactions between input features. Popular
post-hoc explanation methods like SHAP provide marginal feature attributions,
while their extensions to interaction importances only scale to small input
lengths ($\approx 20$). We propose Spectral Explainer (SPEX), a model-agnostic
interaction attribution algorithm that efficiently scales to large input
lengths ($\approx 1000)$. SPEX exploits underlying natural sparsity among
interactions -- common in real-world data -- and applies a sparse Fourier
transform using a channel decoding algorithm to efficiently identify important
interactions. We perform experiments across three difficult long-context
datasets that require LLMs to utilize interactions between inputs to complete
the task. For large inputs, SPEX outperforms marginal attribution methods by up
to 20% in terms of faithfully reconstructing LLM outputs. Further, SPEX
successfully identifies key features and interactions that strongly influence
model output. For one of our datasets, HotpotQA, SPEX provides interactions
that align with human annotations. Finally, we use our model-agnostic approach
to generate explanations to demonstrate abstract reasoning in closed-source
LLMs (GPT-4o mini) and compositional reasoning in vision-language models.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large language models (LLMs) have revolutionized machine learning due to\ntheir ability to capture complex interactions between input features. Popular\npost-hoc explanation methods like SHAP provide marginal feature attributions,\nwhile their extensions to interaction importances only scale to small input\nlengths ($\\approx 20$). We propose Spectral Explainer (SPEX), a model-agnostic\ninteraction attribution algorithm that efficiently scales to large input\nlengths ($\\approx 1000)$. SPEX exploits underlying natural sparsity among\ninteractions -- common in real-world data -- and applies a sparse Fourier\ntransform using a channel decoding algorithm to efficiently identify important\ninteractions. We perform experiments across three difficult long-context\ndatasets that require LLMs to utilize interactions between inputs to complete\nthe task. For large inputs, SPEX outperforms marginal attribution methods by up\nto 20% in terms of faithfully reconstructing LLM outputs. Further, SPEX\nsuccessfully identifies key features and interactions that strongly influence\nmodel output. For one of our datasets, HotpotQA, SPEX provides interactions\nthat align with human annotations. Finally, we use our model-agnostic approach\nto generate explanations to demonstrate abstract reasoning in closed-source\nLLMs (GPT-4o mini) and compositional reasoning in vision-language models.'}","['Justin Singh Kang', 'Landon Butler', 'Abhineet Agarwal', 'Yigit Efe Erginbas', 'Ramtin Pedarsani', 'Kannan Ramchandran', 'Bin Yu']",{'name': 'Bin Yu'},Bin Yu,,"[{'href': 'http://arxiv.org/abs/2502.13870v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13870v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.IT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13870v1,None,http://arxiv.org/abs/2502.13870v1,,,5570,0
http://arxiv.org/abs/2502.14114v1,True,2025-02-19T21:31:05Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=21, tm_min=31, tm_sec=5, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T21:31:05Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=21, tm_min=31, tm_sec=5, tm_wday=2, tm_yday=50, tm_isdst=0)","Zero loss guarantees and explicit minimizers for generic
  overparametrized Deep Learning networks","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Zero loss guarantees and explicit minimizers for generic\n  overparametrized Deep Learning networks'}","We determine sufficient conditions for overparametrized deep learning (DL)
networks to guarantee the attainability of zero loss in the context of
supervised learning, for the $\mathcal{L}^2$ cost and {\em generic} training
data. We present an explicit construction of the zero loss minimizers without
invoking gradient descent. On the other hand, we point out that increase of
depth can deteriorate the efficiency of cost minimization using a gradient
descent algorithm by analyzing the conditions for rank loss of the training
Jacobian. Our results clarify key aspects on the dichotomy between zero loss
reachability in underparametrized versus overparametrized DL.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'We determine sufficient conditions for overparametrized deep learning (DL)\nnetworks to guarantee the attainability of zero loss in the context of\nsupervised learning, for the $\\mathcal{L}^2$ cost and {\\em generic} training\ndata. We present an explicit construction of the zero loss minimizers without\ninvoking gradient descent. On the other hand, we point out that increase of\ndepth can deteriorate the efficiency of cost minimization using a gradient\ndescent algorithm by analyzing the conditions for rank loss of the training\nJacobian. Our results clarify key aspects on the dichotomy between zero loss\nreachability in underparametrized versus overparametrized DL.'}","['Thomas Chen', 'Andrew G. Moore']",{'name': 'Andrew G. Moore'},Andrew G. Moore,"AMS Latex, 9 pages","[{'href': 'http://arxiv.org/abs/2502.14114v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14114v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.AP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.OC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '57R70, 62M45', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14114v1,None,http://arxiv.org/abs/2502.14114v1,,,0,0
http://arxiv.org/abs/2502.14143v1,True,2025-02-19T23:03:21Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=23, tm_min=3, tm_sec=21, tm_wday=2, tm_yday=50, tm_isdst=0)",2025-02-19T23:03:21Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=19, tm_hour=23, tm_min=3, tm_sec=21, tm_wday=2, tm_yday=50, tm_isdst=0)",Multi-Agent Risks from Advanced AI,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Multi-Agent Risks from Advanced AI'}","The rapid development of advanced AI agents and the imminent deployment of
many instances of these agents will give rise to multi-agent systems of
unprecedented complexity. These systems pose novel and under-explored risks. In
this report, we provide a structured taxonomy of these risks by identifying
three key failure modes (miscoordination, conflict, and collusion) based on
agents' incentives, as well as seven key risk factors (information asymmetries,
network effects, selection pressures, destabilising dynamics, commitment
problems, emergent agency, and multi-agent security) that can underpin them. We
highlight several important instances of each risk, as well as promising
directions to help mitigate them. By anchoring our analysis in a range of
real-world examples and experimental evidence, we illustrate the distinct
challenges posed by multi-agent systems and their implications for the safety,
governance, and ethics of advanced AI.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': ""The rapid development of advanced AI agents and the imminent deployment of\nmany instances of these agents will give rise to multi-agent systems of\nunprecedented complexity. These systems pose novel and under-explored risks. In\nthis report, we provide a structured taxonomy of these risks by identifying\nthree key failure modes (miscoordination, conflict, and collusion) based on\nagents' incentives, as well as seven key risk factors (information asymmetries,\nnetwork effects, selection pressures, destabilising dynamics, commitment\nproblems, emergent agency, and multi-agent security) that can underpin them. We\nhighlight several important instances of each risk, as well as promising\ndirections to help mitigate them. By anchoring our analysis in a range of\nreal-world examples and experimental evidence, we illustrate the distinct\nchallenges posed by multi-agent systems and their implications for the safety,\ngovernance, and ethics of advanced AI.""}","['Lewis Hammond', 'Alan Chan', 'Jesse Clifton', 'Jason Hoelscher-Obermaier', 'Akbir Khan', 'Euan McLean', 'Chandler Smith', 'Wolfram Barfuss', 'Jakob Foerster', 'Tom Gaveniak', 'The Anh Han', 'Edward Hughes', 'Vojtch Kovak', 'Jan Kulveit', 'Joel Z. Leibo', 'Caspar Oesterheld', 'Christian Schroeder de Witt', 'Nisarg Shah', 'Michael Wellman', 'Paolo Bova', 'Theodor Cimpeanu', 'Carson Ezell', 'Quentin Feuillade-Montixi', 'Matija Franklin', 'Esben Kran', 'Igor Krawczuk', 'Max Lamparth', 'Niklas Lauffer', 'Alexander Meinke', 'Sumeet Motwani', 'Anka Reuel', 'Vincent Conitzer', 'Michael Dennis', 'Iason Gabriel', 'Adam Gleave', 'Gillian Hadfield', 'Nika Haghtalab', 'Atoosa Kasirzadeh', 'Sbastien Krier', 'Kate Larson', 'Joel Lehman', 'David C. Parkes', 'Georgios Piliouras', 'Iyad Rahwan']",{'name': 'Iyad Rahwan'},Iyad Rahwan,"Cooperative AI Foundation, Technical Report #1","[{'href': 'http://arxiv.org/abs/2502.14143v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14143v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CY', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.ET', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14143v1,None,http://arxiv.org/abs/2502.14143v1,,,36875,0
http://arxiv.org/abs/2502.14372v1,True,2025-02-20T09:05:34Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=9, tm_min=5, tm_sec=34, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T09:05:34Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=9, tm_min=5, tm_sec=34, tm_wday=3, tm_yday=51, tm_isdst=0)","Discovering highly efficient low-weight quantum error-correcting codes
  with reinforcement learning","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Discovering highly efficient low-weight quantum error-correcting codes\n  with reinforcement learning'}","The realization of scalable fault-tolerant quantum computing is expected to
hinge on quantum error-correcting codes. In the quest for more efficient
quantum fault tolerance, a critical code parameter is the weight of
measurements that extract information about errors to enable error correction:
as higher measurement weights require higher implementation costs and introduce
more errors, it is important in code design to optimize measurement weight.
This underlies the surging interest in quantum low-density parity-check (qLDPC)
codes, the study of which has primarily focused on the asymptotic
(large-code-limit) properties. In this work, we introduce a versatile and
computationally efficient approach to stabilizer code weight reduction based on
reinforcement learning (RL), which produces new low-weight codes that
substantially outperform the state of the art in practically relevant parameter
regimes, extending significantly beyond previously accessible small distances.
For example, our approach demonstrates savings in physical qubit overhead
compared to existing results by 1 to 2 orders of magnitude for weight 6 codes
and brings the overhead into a feasible range for near-future experiments. We
also investigate the interplay between code parameters using our RL framework,
offering new insights into the potential efficiency and power of practically
viable coding strategies. Overall, our results demonstrate how RL can
effectively advance the crucial yet challenging problem of quantum code
discovery and thereby facilitate a faster path to the practical implementation
of fault-tolerant quantum technologies.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'The realization of scalable fault-tolerant quantum computing is expected to\nhinge on quantum error-correcting codes. In the quest for more efficient\nquantum fault tolerance, a critical code parameter is the weight of\nmeasurements that extract information about errors to enable error correction:\nas higher measurement weights require higher implementation costs and introduce\nmore errors, it is important in code design to optimize measurement weight.\nThis underlies the surging interest in quantum low-density parity-check (qLDPC)\ncodes, the study of which has primarily focused on the asymptotic\n(large-code-limit) properties. In this work, we introduce a versatile and\ncomputationally efficient approach to stabilizer code weight reduction based on\nreinforcement learning (RL), which produces new low-weight codes that\nsubstantially outperform the state of the art in practically relevant parameter\nregimes, extending significantly beyond previously accessible small distances.\nFor example, our approach demonstrates savings in physical qubit overhead\ncompared to existing results by 1 to 2 orders of magnitude for weight 6 codes\nand brings the overhead into a feasible range for near-future experiments. We\nalso investigate the interplay between code parameters using our RL framework,\noffering new insights into the potential efficiency and power of practically\nviable coding strategies. Overall, our results demonstrate how RL can\neffectively advance the crucial yet challenging problem of quantum code\ndiscovery and thereby facilitate a faster path to the practical implementation\nof fault-tolerant quantum technologies.'}","['Austin Yubo He', 'Zi-Wen Liu']",{'name': 'Zi-Wen Liu'},Zi-Wen Liu,"18 pages, 14 figures, 4 tables","[{'href': 'http://arxiv.org/abs/2502.14372v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14372v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'quant-ph', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'quant-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.IT', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14372v1,None,http://arxiv.org/abs/2502.14372v1,,,0,0
http://arxiv.org/abs/2502.14866v1,True,2025-02-20T18:59:52Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=59, tm_sec=52, tm_wday=3, tm_yday=51, tm_isdst=0)",2025-02-20T18:59:52Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=20, tm_hour=18, tm_min=59, tm_sec=52, tm_wday=3, tm_yday=51, tm_isdst=0)","LServe: Efficient Long-sequence LLM Serving with Unified Sparse
  Attention","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'LServe: Efficient Long-sequence LLM Serving with Unified Sparse\n  Attention'}","Large language models (LLMs) have shown remarkable potential in processing
long sequences, yet efficiently serving these long-context models remains
challenging due to the quadratic computational complexity of attention in the
prefilling stage and the large memory footprint of the KV cache in the decoding
stage. To address these issues, we introduce LServe, an efficient system that
accelerates long-sequence LLM serving via hybrid sparse attention. This method
unifies different hardware-friendly, structured sparsity patterns for both
prefilling and decoding attention into a single framework, where computations
on less important tokens are skipped block-wise. LServe demonstrates the
compatibility of static and dynamic sparsity in long-context LLM attention.
This design enables multiplicative speedups by combining these optimizations.
Specifically, we convert half of the attention heads to nearly free streaming
heads in both the prefilling and decoding stages. Additionally, we find that
only a constant number of KV pages is required to preserve long-context
capabilities, irrespective of context length. We then design a hierarchical KV
page selection policy that dynamically prunes KV pages based on query-centric
similarity. On average, LServe accelerates LLM prefilling by up to 2.9x and
decoding by 1.3-2.1x over vLLM, maintaining long-context accuracy. Code is
released at https://github.com/mit-han-lab/omniserve.","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Large language models (LLMs) have shown remarkable potential in processing\nlong sequences, yet efficiently serving these long-context models remains\nchallenging due to the quadratic computational complexity of attention in the\nprefilling stage and the large memory footprint of the KV cache in the decoding\nstage. To address these issues, we introduce LServe, an efficient system that\naccelerates long-sequence LLM serving via hybrid sparse attention. This method\nunifies different hardware-friendly, structured sparsity patterns for both\nprefilling and decoding attention into a single framework, where computations\non less important tokens are skipped block-wise. LServe demonstrates the\ncompatibility of static and dynamic sparsity in long-context LLM attention.\nThis design enables multiplicative speedups by combining these optimizations.\nSpecifically, we convert half of the attention heads to nearly free streaming\nheads in both the prefilling and decoding stages. Additionally, we find that\nonly a constant number of KV pages is required to preserve long-context\ncapabilities, irrespective of context length. We then design a hierarchical KV\npage selection policy that dynamically prunes KV pages based on query-centric\nsimilarity. On average, LServe accelerates LLM prefilling by up to 2.9x and\ndecoding by 1.3-2.1x over vLLM, maintaining long-context accuracy. Code is\nreleased at https://github.com/mit-han-lab/omniserve.'}","['Shang Yang', 'Junxian Guo', 'Haotian Tang', 'Qinghao Hu', 'Guangxuan Xiao', 'Jiaming Tang', 'Yujun Lin', 'Zhijian Liu', 'Yao Lu', 'Song Han']",{'name': 'Song Han'},Song Han,"Accepted by MLSys 2025. Code available at:
  https://github.com/mit-han-lab/omniserve","[{'href': 'http://arxiv.org/abs/2502.14866v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.14866v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.DC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.PF', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.14866v1,None,http://arxiv.org/abs/2502.14866v1,,,10608,0
http://arxiv.org/abs/2502.13115v1,True,2025-02-18T18:35:24Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=35, tm_sec=24, tm_wday=1, tm_yday=49, tm_isdst=0)",2025-02-18T18:35:24Z,"time.struct_time(tm_year=2025, tm_mon=2, tm_mday=18, tm_hour=18, tm_min=35, tm_sec=24, tm_wday=1, tm_yday=49, tm_isdst=0)",Near-Optimal Private Learning in Linear Contextual Bandits,"{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'Near-Optimal Private Learning in Linear Contextual Bandits'}","We analyze the problem of private learning in generalized linear contextual
bandits. Our approach is based on a novel method of re-weighted regression,
yielding an efficient algorithm with regret of order
$\sqrt{T}+\frac{1}{\alpha}$ and $\sqrt{T}/\alpha$ in the joint and local model
of $\alpha$-privacy, respectively. Further, we provide near-optimal private
procedures that achieve dimension-independent rates in private linear models
and linear contextual bandits. In particular, our results imply that joint
privacy is almost ""for free"" in all the settings we consider, partially
addressing the open problem posed by Azize and Basu (2024).","{'type': 'text/plain', 'language': None, 'base': 'http://export.arxiv.org/api/query?search_query=cat%3Acs.AI+AND+submittedDate%3A%5B20250215000000+TO+20250222000000%5D&id_list=&start=0&max_results=1000&sortBy=relevance&sortOrder=descending', 'value': 'We analyze the problem of private learning in generalized linear contextual\nbandits. Our approach is based on a novel method of re-weighted regression,\nyielding an efficient algorithm with regret of order\n$\\sqrt{T}+\\frac{1}{\\alpha}$ and $\\sqrt{T}/\\alpha$ in the joint and local model\nof $\\alpha$-privacy, respectively. Further, we provide near-optimal private\nprocedures that achieve dimension-independent rates in private linear models\nand linear contextual bandits. In particular, our results imply that joint\nprivacy is almost ""for free"" in all the settings we consider, partially\naddressing the open problem posed by Azize and Basu (2024).'}","['Fan Chen', 'Jiachun Li', 'Alexander Rakhlin', 'David Simchi-Levi']",{'name': 'David Simchi-Levi'},David Simchi-Levi,,"[{'href': 'http://arxiv.org/abs/2502.13115v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2502.13115v1', 'rel': 'related', 'type': 'application/pdf'}]","{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom'}","[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.ST', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.TH', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",http://arxiv.org/pdf/2502.13115v1,None,http://arxiv.org/abs/2502.13115v1,,,11,0
